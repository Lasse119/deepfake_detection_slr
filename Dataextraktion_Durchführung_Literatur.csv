ID;Title;Authors;Year;Abstract;Keywords;Database
2;Deepfake Creation and Detection using Ensemble Deep Learning Models;Rao, Sanjeev and Shelke, Nitin Arvind and Goel, Aditya and Bansal, Harshita;2022;The use of Artificial Intelligence to create falsified videos using Deep Neural Networks is posing a serious problem in distinguishing the real from the counterfeit. These counterfeit videos are known as �Deepfakes�. Due to their realistic appearance and their subsequent ability to influence perceptions and mass sentiment, deepfakes must be monitored. Malicious deepfakes must be detected, and their circulation is immediately controlled. Many deepfake detection technologies have been developed that use particular features to classify fabricated media. This paper proposes the framework of deepfake detection using deep neural network models. The hybrid combination of deep learning models predicts deepfakes with better accuracy. The proposed model is tested and evaluated on the DFDC and CelebDF dataset that classifies more deepfake videos.;LSTM, GANs, Deepfakes, Deep Learning, Artificial Intelligence;ACM
3;Realistic Facial Deep Fakes Detection Through Self-Supervised Features Generated by a Self-Distilled Vision Transformer;Gomes, Bruno Rocha and Busson, Antonio J. G. and Boaro, Jos\'{e} and Colcher, S\'{e}rgio;2023;Several large-scale datasets and models to detect deep fake content and aid in combatting its harms have emerged. The best models usually combine Vision Transformers with CNN-based architectures. However, the recent emergence of the so-called Foundation Models (FMs), in which deep learning models are fed with massive amounts of unlabeled data (usually by applying self-supervised techniques), has established a whole new perspective for many tasks previously addressed with specific-tailored models. This work investigates how good FMs can be in DeepFake detection, especially in the case of realistic facial production or adulteration. With this realm, we investigate a model using DINO, a foundation model based on Vision Transformers (ViT) that produces universal self-supervised features suitable for image-level visual tasks. Our experiments show that this model can improve deep fake facial detection in many scenarios with different baselines. In particular, the results showed that models trained with self-attention activation maps had higher AUC and F1-score than the baseline ones in all CNN architectures we used.;vision transfomers, self-supervised, deep learning, deep fake detection;ACM
4;Head Pose Estimation Patterns as Deepfake Detectors;Becattini, Federico and Bisogni, Carmen and Loia, Vincenzo and Pero, Chiara and Hao, Fei;2024;The capacity to create �fake� videos has recently raised concerns about the reliability of multimedia content. Identifying between true and false information is a critical step toward resolving this problem. On this issue, several algorithms utilizing deep learning and facial landmarks have yielded intriguing results. Facial landmarks are traits that are solely tied to the subject�s head posture. Based on this observation, we study how Head Pose Estimation (HPE) patterns may be utilized to detect deepfakes in this work. The HPE patterns studied are based on FSA-Net, SynergyNet, and WSM, which are among the most performant approaches on the state-of-the-art. Finally, using a machine learning technique based on K-Nearest Neighbor and Dynamic Time Warping, their temporal patterns are categorized as authentic or false. We also offer a set of experiments for examining the feasibility of using deep learning techniques on such patterns. The findings reveal that the ability to recognize a deepfake video utilizing an HPE pattern is dependent on the HPE methodology. On the contrary, performance is less dependent on the performance of the utilized HPE technique. Experiments are carried out on the FaceForensics++ dataset that presents both identity swap and expression swap examples. The findings show that FSA-Net is an effective feature extraction method for determining whether a pattern belongs to a deepfake or not. The approach is also robust in comparison to deepfake videos created using various methods or for different goals. In the mean the method obtain 86% of accuracy on the identity swap task and 86.5% of accuracy on the expression swap. These findings offer up various possibilities and future directions for solving the deepfake detection problem using specialized HPE approaches, which are also known to be fast and reliable.;DeepFake, face recognition, Head Pose Estimation, machine learning, deep learning;ACM
5;Cross-Forgery Analysis of Vision Transformers and CNNs for Deepfake Image Detection;Coccomini, Davide Alessandro and Caldelli, Roberto and Falchi, Fabrizio and Gennaro, Claudio and Amato, Giuseppe;2022;Deepfake Generation Techniques are evolving at a rapid pace, making it possible to create realistic manipulated images and videos and endangering the serenity of modern society. The continual emergence of new and varied techniques brings with it a further problem to be faced, namely the ability of deepfake detection models to update themselves promptly in order to be able to identify manipulations carried out using even the most recent methods. This is an extremely complex problem to solve, as training a model requires large amounts of data, which are difficult to obtain if the deepfake generation method is too recent. Moreover, continuously retraining a network would be unfeasible. In this paper, we ask ourselves if, among the various deep learning techniques, there is one that is able to generalise the concept of deepfake to such an extent that it does not remain tied to one or more specific deepfake generation methods used in the training set. We compared a Vision Transformer with an EfficientNetV2 on a cross-forgery context based on the ForgeryNet dataset. From our experiments, It emerges that EfficientNetV2 has a greater tendency to specialize often obtaining better results on training methods while Vision Transformers exhibit a superior generalization ability that makes them more competent even on images generated with new methodologies.;transformer networks, deep learning, deep fake detection;ACM
7;Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection;Tsigos, Konstantinos and Apostolidis, Evlampios and Baxevanakis, Spyridon and Papadopoulos, Symeon and Mezaris, Vasileios;2024;"In this paper we propose a new framework for evaluating the performance of explanation methods on the decisions of a deepfake detector. This framework assesses the ability of an explanation method to spot the regions of a fake image with the biggest influence on the decision of the deepfake detector, by examining the extent to which these regions can be modified through a set of adversarial attacks, in order to flip the detector�s prediction or reduce its initial prediction; we anticipate a larger drop in deepfake detection accuracy and prediction, for methods that spot these regions more accurately. Based on this framework, we conduct a comparative study using a state-of-the-art model for deepfake detection that has been trained on the FaceForensics++ dataset, and five explanation methods from the literature. The findings of our quantitative and qualitative evaluations document the advanced performance of the LIME explanation method against the other compared ones, and indicate this method as the most appropriate for explaining the decisions of the utilized deepfake detector.";Adversarial image generation, Deepfake detection, Evaluation framework, Explainable AI, Visual explanations;ACM
8;Deepfake Detection Analyzing Hybrid Dataset Utilizing CNN and SVM;Mallet, Jacob and Pryor, Laura and Dave, Rushit and Vanamala, Mounika;2023;"Social media is currently being used by many individuals online as a major source of information. However, not all information shared online is true, even photos and videos can be doctored. Deepfakes have recently risen with the rise of technological advancement and have allowed nefarious online users to replace one's face with a computer-generated face of anyone they would like, including important political and cultural figures. Deepfakes are now a tool to be able to spread mass misinformation. There is now an immense need to create models that are able to detect deepfakes and keep them from being spread as seemingly real images or videos. In this paper, we propose a new deepfake detection schema using two popular machine learning algorithms; support vector machine and convolutional neural network, along with a publicly available dataset?named the 140k Real and Fake Faces to accurately detect deepfakes in images with accuracy rates reaching as high as 88.33%.?&nbsp;";convolutional neural network, Support vector machine, Machine Learning, Fake Image Detection, Deepfake;ACM
9;IoT based application designing of Deep Fake Test for Face animation;Sridevi, Kotari and Kanaprthi. Suresh Kumar and D. Sameera and Garapati, Yugandhar and D. Krishnamadhuri and Bethu, Srikanth;2022;"Development of Deep Learning models of Internet of Things (IoT) enclosures with limited resources are difficult because Both Quality of Results are difficult to achieve&nbsp;- QoR as follows two models, DNN Model, and Inference Accuracy and Quality of Services such as power consumption, throughput, and latency. Currently, the development of DNN models is often separated from deploying them to IoT devices, which leads to the most effective solution. If there are many records that represent objects of substantially the same class (face, human body, etc.), you can apply frames to each object of this class. To achieve this, use an independent representation to distinguish between appearance and progress data. Deep fake detection is achieved by using a novel, lightweight Deep Learning method on the IoT platform that is memory-efficient and lightweight.&nbsp;It is carried out in two different stages. The first phase of the deep fake test aims to implement a method of extracting images from a video and using them in conjunction with a Deep Neural Network to implement a test for face animation.&nbsp;It has been reported that the impact of the background elimination has been reported before the background subtraction. Here the Trans GAN model is used for the image classification. In the second phase, the work can be recorded and executed by the IOT device that can record live video streams and then detect activity involved in live video. An activity detection prototype based on IoT devices with small processing power is presented. This prototype provides improvements to the system, extending its application in various ways to improve portability, networking, and other equipment capabilities. The proposed architecture will be evaluated against four highly competitive object detection benchmarking tasks CIFAR10, CIFAR100, SVHN, and ImageNet.";Object detection, GAN, Face animation, Deep Fake;ACM
10;Where Do Deep Fakes Look? Synthetic Face Detection via Gaze Tracking;Demir, Ilke and Ciftci, Umur Aybars;2021;Following the recent initiatives for the democratization of AI, deep fake generators have become increasingly popular and accessible, causing dystopian scenarios towards social erosion of trust. A particular domain, such as biological signals, attracted attention towards detection methods that are capable of exploiting authenticity signatures in real videos that are not yet faked by generative approaches. In this paper, we first propose several prominent eye and gaze features that deep fakes exhibit differently. Second, we compile those features into signatures and analyze and compare those of real and fake videos, formulating geometric, visual, metric, temporal, and spectral variations. Third, we generalize this formulation to the deep fake detection problem by a deep neural network, to classify any video in the wild as fake or real. We evaluate our approach on several deep fake datasets, achieving 92.48% accuracy on FaceForensics++, 80.0% on Deep Fakes (in the wild), 88.35% on CelebDF, and 99.27% on DeeperForensics datasets. Our approach outperforms most deep and biological fake detectors with complex network architectures without the proposed gaze signatures. We conduct ablation studies involving different features, architectures, sequence durations, and post-processing artifacts.;neural networks, generative models, gaze, fake detection, deep fakes;ACM
11;Enhancing Deepfake Detection: Spatial-Temporal Preprocessing and Self-Attention ResI3D Model;Son, Sangho and Lee, Jaekyu and Min, Kyungha and Kim, Wooju;2024;Deepfake technology is the outcome of employing deep learning techniques to overlay the face of one individual onto the video of another. As deep learning technology advances rapidly, the proliferation of high-quality deepfakes for malicious digital activities is notably on the rise. With growing concerns about the misuse of deepfake technology, there is an increasing demand for research into deep learning-based methodologies to detect and counteract it. While Deepfake detection using deep learning has been a subject of prior research, these approaches primarily rely on images hence not utilizing temporal information. Additionally, research combining CNN and RNN has inherent limitations. It operates with compressed data, resulting in the loss of spatial information and the utilization of the inherent temporal characteristics in pixel-to-pixel temporal data. In this study, we propose a detection model that harnesses the inherent attributes of video data through self-attention on both the spatial and temporal axes, using the ResI3D model along with the Non-Local Block. Additionally, we conducted experiments during the preprocessing phase to validate and implement methods that facilitate the model's effective learning of both temporal and spatial information. As a result, our model demonstrated enhanced performance when compared to existing deepfake video detection models.;Anomaly Detection, Computer Vision, Deepfakes, Neural Networks;ACM
13;Data Augmentation-based Novel Deep Learning Method for Deepfaked Images Detection;Iqbal, Farkhund and Abbasi, Ahmed and Javed, Abdul Rehman and Almadhor, Ahmad and Jalil, Zunera and Anwar, Sajid and Rida, Imad;2024;Recent advances in artificial intelligence have led to deepfake images, enabling users to replace a real face with a genuine one. deepfake images have recently been used to malign public figures, politicians, and even average citizens. deepfake but realistic images have been used to stir political dissatisfaction, blackmail, propagate false news, and even carry out bogus terrorist attacks. Thus, identifying real images from fakes has got more challenging. To avoid these issues, this study employs transfer learning and data augmentation technique to classify deepfake images. For experimentation, 190,335 RGB-resolution deepfake and real images and image augmentation methods are used to prepare the dataset. The experiments use the deep learning models: convolutional neural network (CNN), Inception V3, visual geometry group (VGG19), and VGG16 with a transfer learning approach. Essential evaluation metrics (accuracy, precision, recall, F1-score, confusion matrix, and AUC-ROC curve score) are used to test the efficacy of the proposed approach. Results revealed that the proposed approach achieves an accuracy, recall, F1-score and AUC-ROC score of 90% and 91% precision, with our fine-tuned VGG16 model outperforming other DL models in recognizing real and deepfakes.;Deepfake detection, data augmentation, image processing, deep learning, artificial intelligence, transfer learning;ACM
15;Recapture Detection to Fight Deep Identity Theft;Trabelsi, Anis and Pic, Marc and Dugelay, Jean-Luc;2023;The progress made in deep learning has allowed the deployment of more powerful biometric authentication systems instead of traditional ones based on passwords or PIN codes. Facial recognition is widely used on smartphones to grant user access. However, advances in deep learning also improve methods for doctoring images and videos. A fraudulent user can use these methods to steal the identity of another person. It is very easy for impostors to present to the smartphone an image or video of the victim's face displayed on another screen. In this paper, we describe the security risks when a facial recognition system is attacked by presenting an image, a video or an interactive deepfake displayed on a screen. We also present a deep learning-based method to detect this kind of attack.;recaptured image detection, identity theft, face anti-spoofing, e-KYC, digital image forensics;ACM
17;Autoencoder-based Data Augmentation for Deepfake Detection;Stanciu, Dan-Cristian and Ionescu, Bogdan;2023;Image generation has seen huge leaps in the last few years. Less than 10 years ago we could not generate accurate images using deep learning at all, and now it is almost impossible for the average person to distinguish a real image from a generated one. In spite of the fact that image generation has some amazing use cases, it can also be used with ill intent. As an example, deepfakes have become more and more indistinguishable from real pictures and that poses a real threat to society. It is important for us to be vigilant and active against deepfakes, to ensure that the false information spread is kept under control. In this context, the need for good deepfake detectors feels more and more urgent. There is a constant battle between deepfake generators and deepfake detection algorithms, each one evolving at a rapid pace. But, there is a big problem with deepfake detectors: they can only be trained on so many data points and images generated by specific architectures. Therefore, while we can detect deepfakes on certain datasets with near 100% accuracy, it is sometimes very hard to generalize and catch all real-world instances. Our proposed solution is a way to augment deepfake detection datasets using deep learning architectures, such as Autoencoders or U-Net. We show that augmenting deepfake detection datasets using deep learning improves generalization to other datasets. We test our algorithm using multiple architectures, with experimental validation being carried out on state-of-the-art datasets like CelebDF and DFDC Preview. The framework we propose can give flexibility to any model, helping to generalize to unseen datasets and manipulations.;autoencoder, data augmentation, deep learning, deepfake, digital video forensics, face manipulation, generalization;ACM
18;DEEPFAKER: A Unified Evaluation Platform for Facial Deepfake and Detection Models;Wang, Li and Meng, Xiangtao and Li, Dan and Zhang, Xuhong and Ji, Shouling and Guo, Shanqing;2024;"Deepfake data contains realistically manipulated faces�its abuses pose a huge threat to the security and privacy-critical applications. Intensive research from academia and industry has produced many deepfake/detection models, leading to a constant race of attack and defense. However, due to the lack of a unified evaluation platform, many critical questions on this subject remain largely unexplored. How is the anti-detection ability of the existing deepfake models? How generalizable are existing detection models against different deepfake samples? How effective are the detection APIs provided by the cloud-based vendors? How evasive and transferable are adversarial deepfakes in the lab and real-world environment? How do various factors impact the performance of deepfake and detection models?To bridge the gap, we design and implement DEEPFAKER1 a unified and comprehensive deepfake detection evaluation platform. Specifically, DEEPFAKER has integrated 10 state-of-the-art deepfake methods and 9 representative detection methods, while providing a user-friendly interface and modular design that allows for easy integration of new methods. Leveraging DEEPFAKER, we conduct a large-scale empirical study of facial deepfake/detection models and draw a set of key findings: (i)&nbsp;the detection methods have poor generalization on samples generated by different deepfake methods; (ii)&nbsp;there is no significant correlation between anti-detection ability and visual quality of deepfake samples; (iii)&nbsp;the current detection APIs have poor detection performance and adversarial deepfakes can achieve about 70% attack success rate on all cloud-based vendors, calling for an urgent need to deploy effective and robust detection APIs; (iv)&nbsp;the detection methods in the lab are more robust against transfer attacks than the detection APIs in the real-world environment; and (v)&nbsp;deepfake videos may not always be more difficult to detect after video compression. We envision that DEEPFAKER will benefit future research on facial deepfake and detection.";Facial deepfake, deepfake detection, adversarial machine learning, experimental evaluation;ACM
20;Deepfake Video Detection via Predictive Representation Learning;Ge, Shiming and Lin, Fanzhao and Li, Chenyu and Zhang, Daichi and Wang, Weiping and Zeng, Dan;2022;Increasingly advanced deepfake approaches have made the detection of deepfake videos very challenging. We observe that the general deepfake videos often exhibit appearance-level temporal inconsistencies in some facial components between frames, resulting in discriminative spatiotemporal latent patterns among semantic-level feature maps. Inspired by this finding, we propose a predictive representative learning approach termed Latent Pattern Sensing to capture these semantic change characteristics for deepfake video detection. The approach cascades a Convolution Neural Network-based encoder, a ConvGRU-based aggregator, and a single-layer binary classifier. The encoder and aggregator are pretrained in a self-supervised manner to form the representative spatiotemporal context features. Then, the classifier is trained to classify the context features, distinguishing fake videos from real ones. Finally, we propose a selective self-distillation fine-tuning method to further improve the robustness and performance of the detector. In this manner, the extracted features can simultaneously describe the latent patterns of videos across frames spatially and temporally in a unified way, leading to an effective and robust deepfake video detector. Extensive experiments and comprehensive analysis prove the effectiveness of our approach, e.g., achieving a very highest Area Under Curve (AUC) score of 99.94% on FaceForensics++ benchmark and surpassing 12 states of the art at least 7.90%@AUC and 8.69%@AUC on challenging DFDC and Celeb-DF(v2) benchmarks, respectively.;video understanding, deep learning, representation learning, Deepfake video detection;ACM
22;The MeVer DeepFake Detection Service: Lessons Learnt from Developing and Deploying in the Wild;Baxevanakis, Spiros and Kordopatis-Zilos, Giorgos and Galopoulos, Panagiotis and Apostolidis, Lazaros and Levacher, Killian and Baris Schlicht, Ipek and Teyssou, Denis and Kompatsiaris, Ioannis and Papadopoulos, Symeon;2022;Enabled by recent improvements in generation methodologies, DeepFakes have become mainstream due to their increasingly better visual quality, the increase in easy-to-use generation tools and the rapid dissemination through social media. This fact poses a severe threat to our societies with the potential to erode social cohesion and influence our democracies. To mitigate the threat, numerous DeepFake detection schemes have been introduced in the literature but very few provide a web service that can be used in the wild. In this paper, we introduce the MeVer DeepFake detection service, a web service detecting deep learning manipulations in images and video. We present the design and implementation of the proposed processing pipeline that involves a model ensemble scheme, and we endow the service with a model card for transparency. Experimental results show that our service performs robustly on the three benchmark datasets while being vulnerable to Adversarial Attacks. Finally, we outline our experience and lessons learned when deploying a research system into production in the hopes that it will be useful to other academic and industry teams.;web service, trustworthy AI, DeepFake detection;ACM
24;EfficientNet-based multi-dimensional network optimization for Deepfake video detection;Zhang, Yong and Zhang, Xinqi and Li, Bingjie;2024;"The rapid development of deep learning techniques, especially generative adversarial networks, has led to the generation of very realistic forged faces. Deepfake technology has brought convenience to society and also produced a large number of undesirable effects. Many detectors have been developed to defend videos generated by Deepfake manipulation techniques. In this paper, we take low overhead and high performance as the task of Deepfake detection and propose a new EfficientNet-B0 combined with ViT Deepfake detection network, which consists of two key components: (1) ConvFFN block, which brings a larger receptive field to the network; (2) Transformer Encoder with Hilo, which separates the high and low frequencies of the attention layer to focus on the global structure. We conducted extensive experiments on the DFDC dataset and the FF++ dataset to demonstrate the stability and practical applicability of the proposed method.";ConvFFN, Deepfake, HiLo, Transformer Encoder;ACM
26;WildDeepfake: A Challenging Real-World Dataset for Deepfake Detection;Zi, Bojia and Chang, Minghao and Chen, Jingjing and Ma, Xingjun and Jiang, Yu-Gang;2020;"In recent years, the abuse of a face swap technique called deepfake has raised enormous public concerns. So far, a large number of deepfake videos (known as ""deepfakes"") have been crafted and uploaded to the internet, calling for effective countermeasures. One promising countermeasure against deepfakes is deepfake detection. Several deepfake datasets have been released to support the training and testing of deepfake detectors, such as DeepfakeDetection [1] and FaceForensics++ [23]. While this has greatly advanced deepfake detection, most of the real videos in these datasets are filmed with a few volunteer actors in limited scenes, and the fake videos are crafted by researchers using a few popular deepfake softwares. Detectors developed on these datasets may become less effective against real-world deepfakes on the internet. To better support detection against real-world deepfakes, in this paper, we introduce a new dataset WildDeepfake, which consists of 7,314 face sequences extracted from 707 deepfake videos collected completely from the internet. WildDeepfake is a small dataset that can be used, in addition to existing datasets, to develop and test the effectiveness of deepfake detectors against real-world deepfakes. We conduct a systematic evaluation of a set of baseline detection networks on both existing and our WildDeepfake datasets, and show that WildDeepfake is indeed a more challenging dataset, where the detection performance can decrease drastically. We also propose two (eg. 2D and 3D) Attention-based Deepfake Detection Networks (ADDNets) to leverage the attention masks on real/fake faces for improved detection. We empirically verify the effectiveness of ADDNets on both existing datasets and WildDeepfake. The dataset is available at: https://github.com/deepfakeinthewild/deepfake-in-the-wild.";deepfake detection, deep learning, datasets;ACM
27;Uncovering the Strength of Capsule Networks in Deepfake Detection;Stanciu, Dan-Cristian and Ionescu, Bogdan;2022;Information is everywhere, and sometimes we have no idea if what we read, watch or listen is accurate, real or authentic. This paper focuses on detecting deep learning generated videos, or deepfakes - a phenomenon which is more and more present in today's society. While there are some very good methods of detecting deepfakes, there are two key elements that should always be considered, i.e., no method is perfect and deepfake generation techniques continue to evolve, sometimes even faster than detection methods. In our proposed architectures, we focus on a family of deep learning methods that is new, has several advantages over traditional Convolutional Neural Networks and has been underutilized in the fight against fake information, namely the Capsule Networks. We show that: (i) state-of-the-art Capsule Network architectures can be improved in the context of deepfake detection, (ii) they can be used to obtain accurate results using a very small number of parameters, and (iii) Capsule Networks are a viable option over deep convolutional models. Experimental validation is carried out on two publicly available datasets, namely FaceForensics++ and CelebDF, showing very promising results.;face manipulation, digital video forensics, deepfake, deep learning, capsule networks;ACM
28;Boosting Deepfake Detection Features with Attention Units;Waseem, Saima and ABU-BAKAR, SYED A.R. and Omar, Zaid and Ashfaq Ahmed, Bilal and Baloch, Saba;2023;"One of the emerging problems of deep learning technology is deepfake videos with easy access to powerful and inexpensive computing power; The internet is littered with fake material like fake photos, videos, and audios. People�s identities, privacy and reputations are at risk due to the widespread proliferation of fake media content. Since videos can have a potentially destructive effect on society, establishing their legitimacy is crucial. Thus, we investigate different attention mechanisms in this paper for deepfake detection. In videos, attention mechanisms are responsible for directing the convolutional Neural Network�s (CNNs) emphasis to the most critical parts of the frame in terms of both content and context. Therefore, we answer the question: How do you apply attention to deepfake detection? And what form of attention is effective for deepfake detection tasks? To address these concerns, we conduct research and experimental testing on videos that have been manipulated using four different methods drawn from the FaceForensics++ dataset. We conduct a cross-data evaluat ion for the network with and without attention to assess the network�s capacity to detect previously unseen manipulated images. The proposed approach outperformed conventional Convolutional Neural Networks for deepfake detection by 8% AUC performance.";Attention, Deepfake, Excitation., Facial manipulation, Squeeze;ACM
29;One Detector to Rule Them All: Towards a General Deepfake Attack Detection Framework;Tariq, Shahroz and Lee, Sangyup and Woo, Simon;2021;Deep learning-based video manipulation methods have become widely accessible to the masses. With little to no effort, people can quickly learn how to generate deepfake (DF) videos. While deep learning-based detection methods have been proposed to identify specific types of DFs, their performance suffers for other types of deepfake methods, including real-world deepfakes, on which they are not sufficiently trained. In other words, most of the proposed deep learning-based detection methods lack transferability and generalizability. Beyond detecting a single type of DF from benchmark deepfake datasets, we focus on developing a generalized approach to detect multiple types of DFs, including deepfakes from unknown generation methods such as DeepFake-in-the-Wild (DFW) videos. To better cope with unknown and unseen deepfakes, we introduce a Convolutional LSTM-based Residual Network (CLRNet), which adopts a unique model training strategy and explores spatial as well as the temporal information in a deepfakes. Through extensive experiments, we show that existing defense methods are not ready for real-world deployment. Whereas our defense method (CLRNet) achieves far better generalization when detecting various benchmark deepfake methods (97.57% on average). Furthermore, we evaluate our approach with a high-quality DeepFake-in-the-Wild dataset, collected from the Internet containing numerous videos and having more than 150,000 frames. Our CLRNet model demonstrated that it generalizes well against high-quality DFW videos by achieving 93.86% detection accuracy, outperforming existing state-of-the-art defense methods by a considerable margin.;Video Forensics, Domain Generalization and Adaptation, Deepfake;ACM
30;Deep Convolutional Pooling Transformer for Deepfake Detection;Wang, Tianyi and Cheng, Harry and Chow, Kam Pui and Nie, Liqiang;2023;Recently, Deepfake has drawn considerable public attention due to security and privacy concerns in social media digital forensics. As the wildly spreading Deepfake videos on the Internet become more realistic, traditional detection techniques have failed in distinguishing between real and fake. Most existing deep learning methods mainly focus on local features and relations within the face image using convolutional neural networks as a backbone. However, local features and relations are insufficient for model training to learn enough general information for Deepfake detection. Therefore, the existing Deepfake detection methods have reached a bottleneck to further improve the detection performance. To address this issue, we propose a deep convolutional Transformer to incorporate the decisive image features both locally and globally. Specifically, we apply convolutional pooling and re-attention to enrich the extracted features and enhance efficacy. Moreover, we employ the barely discussed image keyframes in model training for performance improvement and visualize the feature quantity gap between the key and normal image frames caused by video compression. We finally illustrate the transferability with extensive experiments on several Deepfake benchmark datasets. The proposed solution consistently outperforms several state-of-the-art baselines on both within- and cross-dataset experiments.;transformer, image keyframes, Deepfake detection;ACM
31;BZNet: Unsupervised Multi-scale Branch Zooming Network for Detecting Low-quality Deepfake Videos;Lee, Sangyup and An, Jaeju and Woo, Simon S.;2022;Generating a deep learning-based fake video has become no longer rocket science. The advancement of automated Deepfake (DF) generation tools that mimic certain targets has rendered society vulnerable to fake news or misinformation propagation. In real-world scenarios, DF videos are compressed to low-quality (LQ) videos, taking up less storage space and facilitating dissemination through the web and social media. Such LQ DF videos are much more challenging to detect than high-quality (HQ) DF videos. To address this challenge, we rethink the design of standard deep learning-based DF detectors, specifically exploiting feature extraction to enhance the features of LQ images. We propose a novel LQ DF detection architecture, multi-scale Branch Zooming Network (BZNet), which adopts an unsupervised super-resolution (SR) technique and utilizes multi-scale images for training. We train our BZNet only using highly compressed LQ images and experiment under a realistic setting, where HQ training data are not readily accessible. Extensive experiments on the FaceForensics++ LQ and GAN-generated datasets demonstrate that our BZNet architecture improves the detection accuracy of existing CNN-based classifiers by 4.21% on average. Furthermore, we evaluate our method against a real-world Deepfake-in-the-Wild dataset collected from the internet, which contains 200 videos featuring 50 celebrities worldwide, outperforming the state-of-the-art methods by 4.13%.;Deepfake Detection, Forensics, Low-quality Deepfakes, Multi-scale Learning, Unsupervised Super-Resolution;ACM
34;TCSD: Triple Complementary Streams Detector for Comprehensive Deepfake Detection;Liu, Xiaolong and Yu, Yang and Li, Xiaolong and Zhao, Yao and Guo, Guodong;2023;Advancements in computer vision and deep learning have made it difficult to distinguish deepfake visual media. While existing detection frameworks have achieved significant performance on challenging deepfake datasets, these approaches consider only a single perspective. More importantly, in urban scenes, neither complex scenarios can be covered by a single view nor can the correlation between multiple datasets of information be well utilized. In this article, to mine the new view for deepfake detection and utilize the correlation of multi-view information contained in images, we propose a novel triple complementary streams detector (TCSD). First, a novel depth estimator is designed to extract depth information (DI), which has not been used in previous methods. Then, to supplement depth information for obtaining comprehensive forgery clues, we consider the incoherence between image foreground and background information (FBI) and the inconsistency between local and global information (LGI). In addition, we designed an attention-based multi-scale feature extraction (MsFE) module to extract more complementary features from DI, FBI, and LGI. Finally, two attention-based feature fusion modules are proposed to adaptively fuse information. Extensive experiment results show that the proposed approach achieves state-of-the-art performance on detecting deepfakes.;generalization ability, complementary information mining, depth information, Deepfake;ACM
36;Fairness evaluation in deepfake detection models using metamorphic testing;Pu, Muxin and Kuan, Meng Yi and Lim, Nyee Thoang and Chong, Chun Yong and Lim, Mei Kuan;2023;Fairness of deepfake detectors in the presence of anomalies are not well investigated, especially if those anomalies are more prominent in either male or female subjects. The primary motivation for this work is to evaluate how deepfake detection model behaves under such anomalies. However, due to the black-box nature of deep learning (DL) and artificial intelligence (AI) systems, it is hard to predict the performance of a model when the input data is modified. Crucially, if this defect is not addressed properly, it will adversely affect the fairness of the model and result in discrimination of certain sub-population unintentionally. Therefore, the objective of this work is to adopt metamorphic testing to examine the reliability of the selected deepfake detection model, and how the transformation of input variation places influence on the output. We have chosen MesoInception-4, a state-of-the-art deepfake detection model, as the target model and makeup as the anomalies. Makeups are applied through utilizing the Dlib library to obtain the 68 facial landmarks prior to filling in the RGB values. Metamorphic relations are derived based on the notion that realistic perturbations of the input images, such as makeup, involving eyeliners, eyeshadows, blushes, and lipsticks (which are common cosmetic appearance) applied to male and female images, should not alter the output of the model by a huge margin. Furthermore, we narrow down the scope to focus on revealing potential gender biases in DL and AI systems. Specifically, we are interested to examine whether MesoInception-4 model produces unfair decisions, which should be considered as a consequence of robustness issues. The findings from our work have the potential to pave the way for new research directions in the quality assurance and fairness in DL and AI systems.;robustness testing, oracle problem, metamorphic testing, fairness testing;ACM
38;A Detection Method for DeepFake Hard Compressed Videos based on Super-resolution Reconstruction Using CNN;Hongmeng, Zhang and Zhiqiang, Zhu and Lei, Sun and Xiuqing, Mao and Yuehan, Wang;2020;The DeepFake video detection method based on convolutional neural networks has a poor performance in the dataset of hard compressed DeepFake video. And a large number of false tests will occur to the real data. To solve this problem, a networks model detection method for super-resolution reconstruction of DeepFake video is proposed. First of all, the face area of real data is processed by Gaussian blur, which is converted into negative data, and the real data and processing data are input into neural network for training. Then the residual network is used for super-resolution reconstruction of test data. Finally, the trained model is used to test the video after super-resolution reconstruction. Experiments show that the proposed method can reduce the false detection rate and improve the accuracy in detection of single frames.;Super-resolution reconstruction, Hard compressed video, DeepFake detection, Deep Learning;ACM
39;Face Forgery Detection via Symmetric Transformer;Song, Luchuan and Li, Xiaodan and Fang, Zheng and Jin, Zhenchao and Chen, YueFeng and Xu, Chenliang;2022;The deep learning-based face forgery detection is a novel yet challenging task. Despite impressive results have been achieved, there are still some limitations in the existing methods. For example, the previous methods are hard to maintain consistent predictions for consecutive frames, even if all of those frames are actually forged. We propose a symmetric transformer for channel and spatial feature extraction, which is because the channel and spatial features of a robust forgery detector should be consistent in the temporal domain. The symmetric transformer adopt the newly-designed attention-based strategies for channel variance and spatial gradients as the vital features, which greatly improves the robustness of deepfake video detection. Moreover, this symmetric structure acts on temporal and spatial features respectively, which ensures the robustness of detection from two different aspects. Our symmetric transformer is an end-to-end optimized network. Experiments are conducted on various settings, the proposed methods achieve significantly improvement on prediction robustness and perform better than state-of-the-art methods on different datasets.;symmetric transformer, deepfake video detection;ACM
41;A Forensic Method for DeepFake Image based on Face Recognition;Wu, Jian and Feng, Kai and Chang, Xu and Yang, Tongfeng;2020;DeepFake digital images have serious negative impacts on news integrity, legal forensics, and social security. In order to detect the DeepFake digital images more accurately, a method based on face recognition is proposed. Face image feature vectors are extracted by Facenet, and the Euclidean distances among the vectors of different face images are calculated as classification principle. Then, the machine learning algorithms is trained to perform binary classification of real and fake face images. The experimental results on the Celeb-DF data set show that the proposed method has better detection effect than the existing detection methods.;Image Forensic, Face Recognition, DeepFake;ACM
44;Emotions Don't Lie: An Audio-Visual Deepfake Detection Method using Affective Cues;Mittal, Trisha and Bhattacharya, Uttaran and Chandra, Rohan and Bera, Aniket and Manocha, Dinesh;2020;"We present a learning-based method for detecting real and fake deepfake multimedia content. To maximize information for learning, we extract and analyze the similarity between the two audio and visual modalities from within the same video. Additionally, we extract and compare affective cues corresponding to perceived emotion from the two modalities within a video to infer whether the input video is ""real"" or ""fake"". We propose a deep learning network, inspired by the Siamese network architecture and the triplet loss. To validate our model, we report the AUC metric on two large-scale deepfake detection datasets, DeepFake-TIMIT Dataset and DFDC. We compare our approach with several SOTA deepfake detection methods and report per-video AUC of 84.4% on the DFDC and 96.6% on the DF-TIMIT datasets, respectively. To the best of our knowledge, ours is the first approach that simultaneously exploits audio and video modalities and also perceived emotions from the two modalities for deepfake detection.";multimedia forensics, emotions, deepfakes, audio-visual, affective computing;ACM
45;Evaluation of an Audio-Video Multimodal Deepfake Dataset using Unimodal and Multimodal Detectors;Khalid, Hasam and Kim, Minha and Tariq, Shahroz and Woo, Simon S.;2021;Significant advancements made in the generation of deepfakes have caused security and privacy issues. Attackers can easily impersonate a person's identity in an image by replacing his face with the target person's face. Moreover, a new domain of cloning human voices using deep-learning technologies is also emerging. Now, an attacker can generate realistic cloned voices of humans using only a few seconds of audio of the target person. With the emerging threat of potential harm deepfakes can cause, researchers have proposed deepfake detection methods. However, they only focus on detecting a single modality, i.e., either video or audio. On the other hand, to develop a good deepfake detector that can cope with the recent advancements in deepfake generation, we need to have a detector that can detect deepfakes of multiple modalities, i.e., videos and audios. To build such a detector, we need a dataset that contains video and respective audio deepfakes. We were able to find a most recent deepfake dataset, Audio-Video Multimodal Deepfake Detection Dataset (FakeAVCeleb), that contains not only deepfake videos but synthesized fake audios as well. We used this multimodal deepfake dataset and performed detailed baseline experiments using state-of-the-art unimodal, ensemble-based, and multimodal detection methods to evaluate it. We conclude through detailed experimentation that unimodals, addressing only a single modality, video or audio, do not perform well compared to ensemble-based methods. Whereas purely multimodal-based baselines provide the worst performance.;multimodal, media forensics, measurement, deepfakaes, datasets;ACM
47;Spatiotemporal Inconsistency Learning for DeepFake Video Detection;Gu, Zhihao and Chen, Yang and Yao, Taiping and Ding, Shouhong and Li, Jilin and Huang, Feiyue and Ma, Lizhuang;2021;The rapid development of facial manipulation techniques has aroused public concerns in recent years. Following the success of deep learning, existing methods always formulate DeepFake video detection as a binary classification problem and develop frame-based and video-based solutions. However, little attention has been paid to capturing the spatial-temporal inconsistency in forged videos. To address this issue, we term this task as a Spatial-Temporal Inconsistency Learning (STIL) process and instantiate it into a novel STIL block, which consists of a Spatial Inconsistency Module (SIM), a Temporal Inconsistency Module (TIM), and an Information Supplement Module (ISM). Specifically, we present a novel temporal modeling paradigm in TIM by exploiting the temporal difference over adjacent frames along with both horizontal and vertical directions. And the ISM simultaneously utilizes the spatial information from SIM and temporal information from TIM to establish a more comprehensive spatial-temporal representation. Moreover, our STIL block is flexible and could be plugged into existing 2D CNNs. Extensive experiments and visualizations are presented to demonstrate the effectiveness of our method against the state-of-the-art competitors.;video analysis, spatiotemporal inconsistency modeling, deepfake video detection;ACM
48;Towards Generalizable Deepfake Detection with Locality-aware AutoEncoder;Du, Mengnan and Pentyala, Shiva and Li, Yuening and Hu, Xia;2020;With advancements of deep learning techniques, it is now possible to generate super-realistic images and videos, i.e., deepfakes. These deepfakes could reach mass audience and result in adverse impacts on our society. Although lots of efforts have been devoted to detect deepfakes, their performance drops significantly on previously unseen but related manipulations and the detection generalization capability remains a problem. Motivated by the fine-grained nature and spatial locality characteristics of deepfakes, we propose Locality-Aware AutoEncoder (LAE) to bridge the generalization gap. In the training process, we use a pixel-wise mask to regularize local interpretation of LAE to enforce the model to learn intrinsic representation from the forgery region, instead of capturing artifacts in the training set and learning superficial correlations to perform detection. We further propose an active learning framework to select the challenging candidates for labeling, which requires human masks for less than 3% of the training data, dramatically reducing the annotation efforts to regularize interpretations. Experimental results on three deepfake detection tasks indicate that LAE could focus on the forgery regions to make decisions. The analysis further shows that LAE outperforms the state-of-the-arts by 6.52%, 12.03%, and 3.08% respectively on three deepfake detection tasks in terms of generalization accuracy on previously unseen manipulations.;interpretation, generalization, deepfake detection, GAN;ACM
50;Mastering Deepfake Detection: A Cutting-edge Approach to Distinguish GAN and Diffusion-model Images;Guarnera, Luca and Giudice, Oliver and Battiato, Sebastiano;2024;Detecting and recognizing deepfakes is a pressing issue in the digital age. In this study, we first collected a dataset of pristine images and fake ones properly generated by nine different Generative Adversarial Network (GAN) architectures and four Diffusion Models (DM). The dataset contained a total of 83,000 images, with equal distribution between the real and deepfake data. Then, to address different deepfake detection and recognition tasks, we proposed a hierarchical multi-level approach. At the first level, we classified real images from AI-generated ones. At the second level, we distinguished between images generated by GANs and DMs. At the third level (composed of two additional sub-levels), we recognized the specific GAN and DM architectures used to generate the synthetic data. Experimental results demonstrated that our approach achieved more than 97% classification accuracy, outperforming existing state-of-the-art methods. The models obtained in the different levels turn out to be robust to various attacks such as JPEG compression (with different quality factor values) and resize (and others), demonstrating that the framework can be used and applied in real-world contexts (such as the analysis of multimedia data shared in the various social platforms) for support even in forensic investigations to counter the illicit use of these powerful and modern generative models. We are able to identify the specific GAN and DM architecture used to generate the image, which is critical in tracking down the source of the deepfake. Our hierarchical multi-level approach to deepfake detection and recognition shows promising results in identifying deepfakes allowing focus on underlying task by improving (about 2% on the average) standard multiclass flat detection systems. The proposed method has the potential to enhance the performance of deepfake detection systems, aid in the fight against the spread of fake images, and safeguard the authenticity of digital media.;Deepfake detection, generative adversarial nets, diffusion models, multimedia forensics;ACM
51;Multimodal Neurosymbolic Approach for Explainable Deepfake Detection;Haq, Ijaz Ul and Malik, Khalid Mahmood and Muhammad, Khan;2024;"Deepfake detection has become increasingly important in recent years owing to the widespread availability of deepfake generation technologies. Existing deepfake detection methods present two primary limitations; i.e., they are trained on a specific type of deepfake dataset, which renders them vulnerable to unseen deepfakes, and they regard deepfakes as a �black box� with limited explainability, making it difficult for non-AI experts to understand and trust the decisions. Hence, this article proposes a novel neurosymbolic deepfake detection framework that exploits the fact that human emotions cannot be imitated easily owing to their complex nature. We argue that deep fakes typically exhibit inter- or intra-modality inconsistencies in the emotional expressions of the person being manipulated. Thus, the proposed framework performs inter- and intra-modality reasoning on emotions extracted from audio and visual modalities using a psychological and arousal-valence model for deepfake detection. In addition to fake detection, the proposed framework provides textual explanations for its decisions. The results obtained using the Presidential Deepfakes Dataset and World Leaders Dataset of real and manipulated videos demonstrate the effectiveness of our approach in detecting deepfakes and highlight the potential of a neurosymbolic approach for expandability.";Deepfake detection, Emotion recognition, Knowledge base, Manipulation detection, Neurosymbolic;ACM
57;Deepfake Videos in the Wild: Analysis and Detection;Pu, Jiameng and Mangaokar, Neal and Kelly, Lauren and Bhattacharya, Parantapa and Sundaram, Kavya and Javed, Mobin and Wang, Bolun and Viswanath, Bimal;2021;AI-manipulated videos, commonly known as deepfakes, are an emerging problem. Recently, researchers in academia and industry have contributed several (self-created) benchmark deepfake datasets, and deepfake detection algorithms. However, little effort has gone towards understanding deepfake videos in the wild, leading to a limited understanding of the real-world applicability of research contributions in this space. Even if detection schemes are shown to perform well on existing datasets, it is unclear how well the methods generalize to real-world deepfakes. To bridge this gap in knowledge, we make the following contributions: First, we collect and present the largest dataset of deepfake videos in the wild, containing 1,869 videos from YouTube and Bilibili, and extract over 4.8M frames of content. Second, we present a comprehensive analysis of the growth patterns, popularity, creators, manipulation strategies, and production methods of deepfake content in the real-world. Third, we systematically evaluate existing defenses using our new dataset, and observe that they are not ready for deployment in the real-world. Fourth, we explore the potential for transfer learning schemes and competition-winning techniques to improve defenses.;Deepfake Videos, Deepfake Detection, Deepfake Datasets.;ACM
58;DeepFake detection method based on multi-scale interactive dual-stream network;Ziyuan Cheng and Yiyang Wang and Yongjing Wan and Cuiling Jiang;2024;"DeepFake face forgery has a serious negative impact on both society and individuals. Therefore, research on DeepFake detection technologies is necessary. At present, DeepFake detection technology based on deep learning has achieved acceptable results on high-quality datasets; however, its detection performance on low-quality datasets and cross-datasets remains poor. To address this problem, this paper presents a multi-scale interactive dual-stream network (MSIDSnet). The network is divided into spatial- and frequency-domain streams and uses a multi-scale fusion module to capture both the facial features of images that have been manipulated in the spatial domain under different circumstances and the fine-grained high-frequency noise information of forged images. The network fully integrates the features of the spatial- and frequency-domain streams through an interactive dual-stream module and uses vision transformer (ViT) to further learn the global information of the forged facial features for classification. Experimental results confirm that the accuracy of this method reached 99.30?% on the high-quality dataset Celeb-DF-v2, and 95.51?% on the low-quality dataset FaceForensics++. Moreover, the results of the cross-dataset experiments were superior to those of the other comparison methods.";DeepFake detection, Multi-scale fusion, Interactive dual-stream, High-frequency noise;ScienceDirect
59;Less is more: A minimalist approach to robust GAN-generated face detection;Tanusree Ghosh and Ruchira Naskar;2024;Hyper-realistic images that are not differentiable from authentic images to regular viewers have become extremely easy to generate and highly accessible. Furthermore, the increasing pervasiveness of social media networks in our daily lives has facilitated the easy dissemination of fake news accompanied by such synthetic images. Hyper-realistic artificial face images are often illicitly used as profile pictures on social media sites, further using such profiles to spread fabricated information, resulting in social perils. Most available synthetic image detectors are challenging to implement in practical scenarios due to their high complexity and performance degradation for images from Online Social Networks (OSNs). In this work, we develop a deep learning-based lightweight synthetic image detector called Relative Chrominance Distance Network (RCD-Net). In this paper, we introduce the RCD image feature set for the first time, which gives a pair-wise chrominance component-based distance measure. To show its effectiveness, we explore multiple luminance-chrominance spaces. Compared to the state-of-the-art (SOTA), our model hugely reduces the network parameter requirements, making it incredibly lightweight. We also study the robustness of the proposed solution against common post-processing operations in the context of online social media networks. Experimental results prove that the proposed solution achieves SOTA performance at a much lower complexity than available solutions.;Fake image detection, Deepfake detection, GAN forensics, Digital image forensics, Synthetic image detection, GAN-face detection;ScienceDirect
60;Fake news or real? Detecting deepfake videos using geometric facial structure and graph neural network;Shahela Saif and Samabia Tehseen and Syed Sohaib Ali;2024;Deepfake videos are increasingly used in spreading fake news or propaganda having a serious impact on people and society. Traditional deepfake detectors exploit spatial and/or temporal inconsistencies to differentiate between real and fake videos. Owing to the rapidly advancing deepfake creation algorithms, the latest detectors have made use of physiological and biological facial features to create more generic solutions. Our proposed solution uses facial landmarks as the physiological identifiers of a person�s face and through them develops a relationship between facial areas in normal speech and tampered speech. By creating a graph structure from the resulting sparse data, we were able to use a spatio-temporal graph convolutional network for classification, which has significantly fewer parameters and a shorter training time than traditional CNNs. We conducted a multitude of experiments on 3 datasets, utilizing spatio-temporal features. The results demonstrate that this technique has better generalization, and high performance compared to latest research in deepfake detection without the reliance on large deep learning models which are tuned to learning image discrepancies more than data patterns. Moreover, our use of facial landmark-based features with a graph structure paves the way for the development of an explainable AI model that can be relied on.;Video forgery, Forgery detection, Deepfakes, Deepfake videos, Deepfake detection, Graph convolution network;ScienceDirect
62;A new deepfake detection model for responding to perception attacks in embodied artificial intelligence;JunShuai Zheng and XiYuan Hu and Chen Chen and YiChao Zhou and DongYang Gao and ZhenMin Tang;2024;Embodied artificial intelligence (AI) represents a new generation of robotics technology combined with artificial intelligence, and it is at the forefront of current research. To reduce the impact of deepfake technology on embodied perception and enhance the security and reliability of embodied AI, this paper proposes a novel deepfake detection model with a new Balanced Contrastive Learning strategy, named BCL. By integrating unsupervised contrastive learning and supervised contrastive learning with deepfake detection, the model effectively extracts the underlying features of fake images from both individual level and category level, thereby leading to more discriminative features. In addition, a Multi-scale Attention Interaction module (MAI) is proposed to enrich the representative ability of features. By cross-fusing the semantic features of different receptive fields of the encoder, more effective deepfake traces can be mined. Finally, extensive experiments demonstrate that our method has good performance and generalization capabilities across intra-dataset, cross-dataset and cross-manipulation scenarios.;Deepfake detection, Unsupervised contrastive learning, Supervised contrastive learning, Balanced contrastive learning;ScienceDirect
63;Towards DeepFake video forensics based on facial textural disparities in multi-color channels;Zhiming Xia and Tong Qiao and Ming Xu and Ning Zheng and Shichuang Xie;2022;With the development of deep learning, AI-synthesized techniques, such as DeepFake, are widely spread on the Internet. Although many state-of-the-art detection methods have been able to obtain a good detection performance, most neural network models based on data-driven training lack interpretability during feature extraction and analysis. In this study, we propose an interpretable DeepFake video detection method based on facial textural disparities in multi-color channels. We observe that the face region from the DeepFake video appears to be smoother than that of the real one. First, we analyze the statistical disparities between the real and fake frame in each color channel. Next, it is proposed to use the co-occurrence matrix to construct a low-dimensional set of features to distinguish the real video from the DeepFake video. Meanwhile, we evaluate the video-level and frame-level detection performance on the benchmark, where the method can achieve AUC value of 0.996 on FaceForensics++, and 0.718 on Celeb-DF. Our proposed method performs remarkably better than the traditional machine learning based detectors, and comparably to some current deep learning based detectors. More importantly, our proposed method is robust in the face of compression attacks, and more time-efficient compared to existing methods based on deep learning.;Multimedia forensics, DeepFake detection, Color channels, Facial texture;ScienceDirect
67;The Analysis of Neural Network Models to Distinguish AI generated faces from Real faces;Joshita Malla and Harshini Vemuri and SreeDivya Nagalli and S Abhishek and T Anjali;2024;The rise of Artificial Intelligence (AI)-generated faces that are identical to actual ones is both a technological innovation and a major concern. While considering the implications, some of the existing security systems are unable to differentiate between a high-quality deep-fake and an actual intruder's face. For instance, the risks are quite high at an airport security checkpoint, where facial recognition is the first line of security against unauthorized entry. The primary concern here is how trustworthy the computer programs and algorithms will be in recognizing counterfeits among a plethora of actual and artificially generated faces. This necessitates the need to introduce machine learning approaches to differentiate between actual and fraudulent faces, particularly when AI-generated faces are involved. Effective artificial intelligence systems must be adaptive and change quickly in the face of more complex threats rather than simply recognizing them. AI-generated faces are becoming more convincing by the day, increasing the risk of their exploitation. This poses the need to ensure that the technology on which people rely should be robust and trustworthy in critical situations, whether it is a security checkpoint or an e-commerce site. In this perspective, this study has attempted to develop and implement Artificial Intelligence-powered solutions to detect the artificial faces while ensuring reliability for critical functions in an age where reality constantly blends with fiction.;Artificial Intelligence, Deep Fake, Deep Learning, Facial Recognition, Privacy, Security;ScienceDirect
68;Digital forensics for the socio-cyber world (DF-SCW): A novel framework for deepfake multimedia investigation on social media platforms;Abdullah {Ayub Khan} and Yen-Lin Chen and Fahima Hajjej and Aftab {Ahmed Shaikh} and Jing Yang and Chin {Soon Ku} and Lip {Yee Por};2024;Owing to the major development of social media platforms, the usage of technological adaptation increases by means of editing software tools. Posting media in social communication environments has become one of our common daily routines. Before posting, various editing generators are used to manipulate pixel values, such as for enhancing brightness and contrast. Undoubtedly, this software helps bring posting media from ordinary to outstanding. But such a type of editing crosses the line in terms of creating fakes�anything that comes from anywhere and does not retain its originality anyway. It poses a series of issues in the process of multimedia forensics investigation and chain of custody. In order to restrict the attempts at deep faking and make the investigation hierarchy more effective, efficient, and reliable in the socio-cyber space (SCS), this paper presents a novel framework called DF-SCW. A digital forensics-enabled socio-cyber world with artificial intelligence (AI), especially deep neural networks (DNNs), for detecting and analyzing deep fake media investigations on social media platforms. It compares pixels with their neighboring values in the same media (such as images and videos) to identify information about the original one. There is a media flag designed to filter out malicious and dangerous attempts, like a powerful leader declaring war. Putting flags on such fakes helps digital investigators resist sharing the posts. In addition, the other prospect of this research is to make the digital forensics ecosystem more appropriate to take qualitative judgments in real-time while media is uploaded on social media platforms. The simulation of the proposed DF-SCW is tested on three different platforms, such as Instagram, Facebook, and Twitter. Through the experiment, the DF-SCW outperformed in terms of detection, identification, and analysis of deepfake media by an increased rate of 3.77%.;Multimedia forensics, Artificial intelligence, Deepfake investigation, Socio-cyber environment, Social media platforms;ScienceDirect
70;AVFakeNet: A unified end-to-end Dense Swin Transformer deep learning model for audio�visual? deepfakes detection;Hafsa Ilyas and Ali Javed and Khalid Mahmood Malik;2023;Recent advances in the field of machine learning and social media platforms facilitate the creation and rapid dissemination of realistic fake content (i.e., images, videos, audios). Initially, the fake content generation involved the manipulation of either audio or video streams but currently, more realistic deepfakes content is being produced via modifying both audio�visual streams. Researchers in the field of deepfakes detection mostly focus on identifying fake videos exploiting solely visual or audio modality. However, there exist a few approaches for audio�visual deepfakes detection but mostly are not evaluated on a multimodal dataset with deepfakes videos having the manipulations in both streams. The unified approaches evaluated on the audio�visual deepfakes dataset have reported low detection accuracies and failed when the faces are side-posed. Therefore, in this paper, we introduced a novel AVFakeNet framework that focuses on both the audio and visual modalities of a video for deepfakes detection. More specifically, our unified AVFakeNet model is a novel Dense Swin Transformer Net (DST-Net) which consists of an input block, feature extraction block, and output block. The input and output block comprises dense layers while the feature extraction block employs a customized swin transformer module. We have performed extensive experimentation on five different datasets (FakeAVCeleb, Celeb-DF, ASVSpoof-2019 LA, World Leaders dataset, Presidential Deepfakes dataset) comprising audio, visual, and audio�visual deepfakes along with a cross-corpora evaluation to signify the effectiveness and generalizability of our unified framework. Experimental results highlight the effectiveness of the proposed framework in terms of accurately detecting deepfakes videos via scrutinizing both the audio and visual streams.;AVFakeNet, Audio�visual deepfake detection, Dense swin transformer, FakeAVCeleb, ASVSpoof-2019;ScienceDirect
72;Deep Fakes in Healthcare: How Deep Learning Can Help to Detect Forgeries;Alaa Alsaheel and Reem Alhassoun and Reema Alrashed and Noura Almatrafi and Noura Almallouhi and Saleh Albahli;2023;With the increasing use of deep learning technology, there is a growing concern over creating deep fake images and videos that can potentially be used for fraud. In healthcare, manipulating medical images could lead to misdiagnosis and potentially life-threatening consequences. Therefore, the primary purpose of this study is to explore the use of deep learning algorithms to detect deep fake images by solving the problem of recognizing the handling of samples of cancer and other diseases. Therefore, this research proposes a framework that leverages state-of-the-art deep convolutional neural networks (CNN) and a large dataset of authentic and deep fake medical images to train a model capable of distinguishing between authentic and fake medical images. Specifically, the paper trained six CNN models, namely, ResNet101, ResNet50, DensNet121, DenseNet201, MobileNetV2, and MobileNet. These models had trained using 2000 samples over three classes: Untampered, False-Benign, and False-Malicious, and compared against several state-of-the-art deep fake detection models. The proposed model enhanced ResNet101 by adding more layers, achieving a training accuracy of 99%. The findings of this study show near-perfect accuracy in detecting instances of tumor injections and removals.;Deep learning, image processing, medical imaging, artificial intelligence;ScienceDirect
75;ViXNet: Vision Transformer with Xception Network for deepfakes based video and image forgery detection;Shreyan Ganguly and Aditya Ganguly and Sk Mohiuddin and Samir Malakar and Ram Sarkar;2022;With the advent of image generative technologies, there is a huge growth in the development of facial manipulation techniques that allow people to easily modify media data like videos and images by changing the identity or facial expression of the target person with another person�s face. Colloquially, these manipulated videos and images are termed �deepfakes�. As a result, every piece of content in digital media comes with a question � is this authentic? Hence, there is an unprecedented need for a competent deepfakes detection method. The rapid changes in forging methods make this a very challenging task and thus generalization of the detection methods is also of utmost required. However, the generalization strengths of the prevailing deepfakes detection methods are not satisfactory. In other words, these models perform well when trained and tested on the same dataset but fail to perform satisfactorily when models are trained on one dataset and tested on another. The most modern deep learning aided deepfakes detection techniques looked for a consistent pattern among the leftover artifacts in specific facial regions of the target face rather than the entire face. To this end, we propose a Vision Transformer with Xception Network (ViXNet) to learn the consistency of these almost imperceptible artifacts left by deepfaking methods on the entire facial region. The ViXNet comprises two branches � one tries to learn inconsistencies among local face region specifics by combining patch-wise self-attention module and vision transformer, and the other generates global spatial features using a deep convolutional neural network. To assess the performance of ViXNet, we evaluate it using two different experimental setups � intra-dataset and inter-dataset when using three standard deepfakes video datasets, namely FaceForensics++, and Celeb-DF (V2) and one deepfakes image dataset called Deepfakes. We have attained 98.57% (83.60%), 99.26% (74.78%), and 98.93% (75.13%) AUC scores using intra(inter)-dataset experimental setups on FaceForensics++, Celeb-DF (V2), and Deepfakes datasets respectively. Additionally, we have evaluated ViXNet on the Deepfake Detection Challenge (DFDC) dataset and we have obtained 86.32% AUC score and 79.06% F1-score on the said dataset. Performances of the proposed model are comparable to state-of-the-art methods. Besides, the obtained results ensure the robustness and the generalization ability of the proposed model.;Deepfakes, FaceSwap, Soft attention, Vision transformer, Forgery detection, Xception model;ScienceDirect
76;MeST-Former: Motion-enhanced Spatiotemporal Transformer for generalizable Deepfake detection;Baoping Liu and Bo Liu and Ming Ding and Tianqing Zhu;2024;The rise of Deepfake technology has sparked significant concerns due to its potential for misuse and malicious manipulation of multimedia content. Various detection approaches aimed at detecting Deepfake videos have been proposed, mostly relying on the identification of spatial and temporal artifacts. However, due to the different contexts of source images and the variety of generation techniques, current Deepfake detection methods usually perform well on training datasets, and yet generalize poorly to those unseen identities in new datasets. This issue is widely known as the generalization challenge of Deepfake detection. To address this challenge, this paper proposes an advanced spatiotemporal Deepfake video detector, named Motion-enhanced Spatiotemporal Transformer (MeST-Former). MeST-Former is based on the spatiotemporal modeling capacity of the video Swin Transformer. The spatial and temporal features are obtained from the RGB and motion images, respectively. To enhance the generalization ability of MeST-Former to unseen identities in unseen datasets, the ID-related components in the spatial and temporal features are detached. Specifically, MeST-Former adopts the newly proposed Identity-Decoupling Attention (IDC-Att) module to disentangle the ID-related and ID-unrelated components. Only the ID-unrelated components are used to construct more generalizable spatiotemporal representations. This process makes the constructed spatiotemporal features identity-agnostic and more generalizable to unseen identities. We conducted extensive experiments to evaluate the performance of the MeST-Former. Our results indicate that MeST-Former achieves accurate and generalizable Deepfake detection performance. Notably, MeST-Former also demonstrates high efficacy in detecting AI-animated talking-head videos.;Deepfake detection, Spatiotemporal, Motion, Identity-agnostic, Transformer;ScienceDirect
77;Image forgery detection by transforming local descriptors into deep-derived features;Muhammad Aqib Anwar and Syed Fahad Tahir and Labiba Gillani Fahad and Kashif Kifayat;2023;Image forgery is the intentional alteration of digital images, either manually using image editors or through deep fake techniques, for the purpose of disseminating fake information. We propose a forgery detection approach that efficiently detects copy-move and splicing attacks of varying scales in digital images. Our goal is to identify the homogeneous region(s) inconsistent with the rest of the image. This region property has been typically employed in object detection and classification, while we exploit this property to detect forgery in images. Thus, we generate the deep-derived features from the existing hand-crafted features in forgery detection as input to the VGG16, a deep learning method, trained for object classification. We use a binary class SVM trained on the obtained deep-derived features to determine whether an image is real or fake. We perform extensive experiments on three publicly available image manipulation datasets, DVMM, Casia and Korus to validate the effectiveness of the proposed methodology. The results show a better accuracy compared to the state-of-the-art methods.;Forgery detection, Local descriptors, Deep derived features, Support vector machine;ScienceDirect
79;Deepfake detection in digital media forensics;Vurimi Veera Venkata Naga Sai Vamsi and Sukanya S. Shet and Sodum Sai Mohan Reddy and Sharon S. Rose and Sona R. Shetty and S. Sathvika and Supriya M.�S. and Sahana P. Shankar;2022;With the development of technology and ease of creation of fake content, the manipulation of media is carried out on a large scale in recent times. The rise of AI altered videos or Deepfake media has posed a great threat to media integrity and is being produced and spread widely across social media platforms, the detection of which is seen to be a major challenge. In this paper, an approach for Deepfake detection has been provided. ResNext, a Convolutional Neural Network (CNN) algorithm and Long Short-Term Memory (LSTM) is used as an approach to detect the Deepfake videos. The approach and its steps are discussed in this paper. The accuracy obtained for the developed Deep-Learning (DL) model over the Celeb-Df dataset is 91%.;Celeb-Df, CNN, LSTM, Deepfake, Prediction, ResNext, Deep Learning;ScienceDirect
80;DFGNN: An interpretable and generalized graph neural network for deepfakes detection;Fatima Khalid and Ali Javed and Qurat-ul ain and Hafsa Ilyas and Aun Irtaza;2023;Deepfakes are generated using sophisticated deep-learning models to create fake images or videos. As the techniques for creating deepfakes improve, issues like defamation, impersonation, fraud, and misinformation on social media are becoming more prevalent. Existing deep learning-based deepfakes detection models are not interpretable and don�t generalize well when tested across diverse deepfakes generating techniques and datasets. Therefore, the creation of reliable and effective deepfakes detection algorithms is required which are not only generalizable but also interpretable. This paper introduces a novel graph neural network-based architecture to identify hyper-realist deepfake content. Currently, very limited efforts have been done to address the problem of deepfakes detection using graph neural networks. The proposed model is based on the pyramid structure that takes advantage of multi-scale images property by extracting features with progressively smaller spatial sizes as layer depth increases. The method first sliced the image into patches, which are referred to as nodes, and then constructed a graph by connecting the nearest neighbors. To transform and exchange information between all nodes, the proposed model has two basic modules: GraphNet, which uses graph convolution layers to aggregate and update graph information, and FFN, which has linear layers for the transformation of node features. The effectiveness of the method is assessed using the diverse Deepfake Detection Challenge dataset (DFDC), FaceForensics++ (FF++), World Leaders dataset (WLRD), and the Celeb-DF. To demonstrate the generalizability of the proposed method for accurate deepfakes detection, open/close set, cross-set, and cross-corpora evaluations were also performed. The AUC values of 0.98 on FF++, 0.95 on Celeb-DF, 0.92 on DFDC, and 1.00 on most of the sets of WLRD datasets demonstrate the efficacy of the method for identifying manipulated facial images produced using various deepfakes techniques.;Celeb-DF, Deepfakes, DFDC, FaceForensics++, Graph Neural Network, World Leaders Dataset;ScienceDirect
81;SFormer: An end-to-end spatio-temporal transformer architecture for deepfake detection;Staffy Kingra and Naveen Aggarwal and Nirmal Kaur;2024;Growing AI advancements are continuously pacing GAN enhancement that eventually facilitates the generation of deepfake media. Manipulated media poses serious risks pertaining court proceedings, journalism, politics, and many more where digital media have a substantial impact on society. State-of-the-art techniques for deepfake detection rely on convolutional networks for spatial analysis, and recurrent networks for temporal analysis. Since transformers are capable of recognizing wide-range dependencies with a global spatial view and along temporal sequence too, a novel approach called �SFormer� is proposed in this paper, utilizing a transformer architecture for both spatial and temporal analysis to detect deepfakes. Further, state-of-the-art techniques suffer from high computational complexity and overfitting which causes loss in generalizability. The proposed model utilized a Swin Transformer for spatial analysis that resulted in low complexity, thereby enhancing its generalization ability and robustness against the different manipulation types. Proposed end-to-end transformer based model, SFormer, is proven to be effective for numerous deepfake datasets, including FF++, DFD, Celeb-DF, DFDC and Deeper-Forensics, and achieved an accuracy of 100%, 97.81%, 99.1%, 93.67% and 100% respectively. Moreover, SFormer has demonstrated superior performance compared to existing spatio-temporal and transformer-based approaches for deepfake detection.;Deepfake detection, Digital forensics, Facial manipulation detection, Spatio-temporal, Transformer;ScienceDirect
82;A 3D-CAE-CNN model for Deep Representation Learning of 3D images;Emmanuel Pintelas and Panagiotis Pintelas;2022;Deep Representation Learning technologies based on supervised Convolutional Neural Networks (CNNs) have attained significant interest mainly due to their superior performance for learning abstract and robust features used in object detection and image classification tasks. However, to efficiently train such models requires a large number of labeled instances especially when these instances are high dimensional such as for 3-Dimensional (3D) Image inputs. Due to this extra dimension the dimensionality of such instances increases drastically. Therefore, the utilization of Unsupervised CNNs topologies such 3D Convolutional AutoEncoders (3D-CAE) have also been proposed. CAEs can learn features (and later used for classification tasks using common machine learning classifiers), without relying on instance labels and thus they are not prone to label limitation. Nevertheless, it is not clear if the features that CAEs learn, are relevant regarding the classification or object detection task since these features are learned via no target output class. For these reasons, in this work we combine 3D-CAE and 3D-CNN to work synergistically together in order to build a hybrid deep representation learning framework model which exploits the advantages of both unsupervised and supervised representation/feature learning approaches, applied on 3D Image inputs. In order to evaluate our strategy, we performed extensive experimental simulations for the DeepFake and Pneumonia detection problems utilizing Video and 3D Scans datasets respectively. Our proposed framework outperformed all the other utilized frameworks, revealing the efficiency of our applied methodology.;Deep Representation Learning, Convolutional AutoEncoders, Deep convolutional neural networks, 3D image classification, DeepFake video detection, 3D Pneumonia detection;ScienceDirect
83;Rethinking gradient operator for exposing AI-enabled face forgeries;Zhiqing Guo and Gaobo Yang and Dengyong Zhang and Ming Xia;2023;For image forensics, convolutional neural networks (CNNs) tend to learn image content features rather than subtle manipulation traces, which constrains detection performance. Existing works usually address this issue by following a common pipeline, namely subtracting the original pixel value from the predicted pixel value to enforce CNNs to learn more features from the manipulation traces. However, due to the complicated learning mechanism, they might still have some unnecessary performance losses. In this work, we rethink the advantages of image gradient operator in exposing AI-enabled face forgeries, and design two plug-and-play modules, namely tensor pre-processing (TP) and manipulation trace attention (MTA), by combining the gradient operator with CNNs. Specifically, the TP module refines the feature tensor of each channel in the network by the gradient operator to highlight manipulation traces and improve feature representation. Moreover, the MTA module considers two dimensions, namely channel and manipulation traces, to enforce the network to learn the distribution of the manipulation traces. Both modules can be seamlessly integrated into existing CNNs for end-to-end training. Experiments show that the proposed expert system achieves better results than prior works on five public image datasets. The code is available at: https://github.com/EricGzq/GocNet-pytorch.;Face forgery detection, Deepfake detection, Gradient operator, Tensor pre-processing, Attention mechanism;ScienceDirect
84;An efficient deepfake video detection using robust deep learning;Abdul Qadir and Rabbia Mahum and Mohammed A. El-Meligy and Adham E. Ragab and Abdulmalik AlSalman and Muhammad Awais;2024;The creation and manipulation of synthetic images have evolved rapidly, causing serious concerns about their effects on society. Although there have been various attempts to identify deep fake videos, these approaches are not universal. Identifying these misleading deepfakes is the first step in preventing them from spreading on social media sites. We introduce a unique deep-learning technique to identify fraudulent clips. Most deepfake identifiers currently focus on identifying face exchange, lip synchronous, expression modification, puppeteers, and other factors. However, exploring a consistent basis for all forms of fake videos and images in real-time forensics is challenging. We propose a hybrid technique that takes input from videos of successive targeted frames, then feeds these frames to the ResNet-Swish-BiLSTM, an optimized convolutional BiLSTM-based residual network for training and classification. This proposed method helps identify artifacts in deepfake images that do not seem real. To assess the robustness of our proposed model, we used the open deepfake detection challenge dataset (DFDC) and Face Forensics deepfake collections (FF++). We achieved 96.23% accuracy when using the FF++ digital record. In contrast, we attained 78.33% accuracy using the aggregated records from FF++ and DFDC. We performed extensive experiments and believe that our proposed method provides more significant results than existing techniques.;Video deepfakes, Multimedia forensics, Swish, Visual manipulation;ScienceDirect
86;TAENet: Two-branch Autoencoder Network for Interpretable Deepfake Detection;Fuqiang Du and Min Yu and Boquan Li and Kam Pui Chow and Jianguo Jiang and Yixin Zhang and Yachao Liang and Min Li and Weiqing Huang;2024;Deepfake detection attracts increasingly attention due to serious security issues caused by facial manipulation techniques. Recently, deep learning-based detectors have achieved promising performance. However, these detectors suffer severe untrustworthy due to the lack of interpretability. Thus, it is essential to work on the interpretibility of deepfake detectors to improve the reliability and traceability of digital evidence. In this work, we propose a two-branch autoencoder network named TAENet for interpretable deepfake detection. TAENet is composed of Content Feature Disentanglement (CFD), Content Map Generation (CMG), and Classification. CFD extracts latent features of real and forged content with dual encoder and feature discriminator. CMG employs a Pixel-level Content Map Generation Loss (PCMGL) to guide the dual decoder in visualizing the latent representations of real and forged contents as real-map and fake-map. In classification module, the Auxiliary Classifier (AC) serves as map amplifier to improve the accuracy of real-map image extraction. Finally, the learned model decouples the input image into two maps that have the same size as the input, providing visualized evidence for deepfake detection. Extensive experiments demonstrate that TAENet can offer interpretability in deepfake detection without compromising accuracy.;Deepfake detection, Interpretibility representation, Image forensic, Disentanglement learning;ScienceDirect
88;Deep learning model to detect deceptive generative adversarial network generated images using multimedia forensic;Haewon Byeon and Mohammad Shabaz and Kapil Shrivastava and Anjali Joshi and Ismail Keshta and Rajvardhan Oak and Pavitar Parkash Singh and Mukesh Soni;2024;Computer-generated imagery has been made more lifelike and misleading by new Generative Adversarial Network (GAN) models, such as StyleGAN, posing severe risks to people's safety, social order, and privacy. Deceptive content creation, including Deepfakes, image tampering, and information hiding, can be facilitated through the misuse of GANs. To tackle these challenges, a detection model is proposed in this research, employing a spatial-frequency joint dual-stream convolutional neural network. Learnable frequency-domain filtering kernels and frequency-domain networks are leveraged to thoroughly learn and extract frequency-domain features, considering the discernible artifacts left by GAN images in the frequency spectrum due to the upsampling process during production. Lastly, the two sets of traits are combined to identify GAN-created faces. The proposed model outperforms state-of-the-art methods, as evidenced by experimental findings on various datasets, both in terms of detection accuracy on high-quality created datasets and generalization across datasets.;Deep learning, GANs, Deepfake, Image tampering, Information hiding, Multimedia forensic, Image detection;ScienceDirect
89;Exposing low-quality deepfake videos of Social Network Service using Spatial Restored Detection Framework;Ying Li and Shan Bian and Chuntao Wang and Kemal Polat and Adi Alhudhaif and Fayadh Alenezi;2023;The increasing abuse of facial manipulation methods, such as FaceSwap, Deepfakes etc., seriously threatens the authenticity of digital images/videos on the Internet. Therefore, it is of great importance to identify the facial videos to confirm the contents and avoid fake news or rumors. Many researchers have paid great attention to the detection of deepfakes and put forward a number of deep-learning-based detection models. The existing approaches mostly face the performance degradation in detecting low-quality(LQ) videos, i.e. heavily compressed or low-resolution videos through some SNS (Social Network Service), resulting in the limitation in real applications. To address this issue, in this paper, a novel Spatial Restore Detection Framework(SRDF) is proposed for improving the detection performance for LQ videos by restoring spatial features. We designed a feature extraction-enhancement block and a mapping block inspired by super-resolution methods, to restore and enhance texture features. An attention module was introduced to guide the texture features restoration and enhancement stage attending to different local areas and restoring the texture features. Besides, an improved isolated loss was put forward to prevent the expansion of a single area concerned. Moreover, we adopted a regional data augmentation strategy to prompt feature restore and enhancement in the region attended. Extensive experiments conducted on two deepfake datasets have validated the superiority of the proposed method compared to the state-of-the-art, especially in the scenarios of detecting low-quality deepfake videos.;Deepfake detection, Video forensics, Super resolution, Attention mechanism;ScienceDirect
90;Detection of real-time deep fakes and face forgery in video conferencing employing generative adversarial networks;Sunil Kumar Sharma and Abdullah AlEnizi and Manoj Kumar and Osama Alfarraj and Majed Alowaidi;2024;As facial modification technology advances rapidly, it poses a challenge to methods used to detect fake faces. The advent of deep learning and AI-based technologies has led to the creation of counterfeit photographs that are more difficult to discern apart from real ones. Existing Deep fake detection systems excel at spotting fake content with low visual quality and are easily recognized by visual artifacts. The study employed a unique active forensic strategy Compact Ensemble-based discriminators architecture using Deep Conditional Generative Adversarial Networks (CED-DCGAN), for identifying real-time deep fakes in video conferencing. DCGAN focuses on video-deep fake detection on features since technologies for creating convincing fakes are improving rapidly. As a first step towards recognizing DCGAN-generated images, split real-time video images into frames containing essential elements and then use that bandwidth to train an ensemble-based discriminator as a classifier. Spectra anomalies are produced by up-sampling processes, standard procedures in GAN systems for making large amounts of fake data films. The Compact Ensemble discriminator (CED) concentrates on the most distinguishing feature between the natural and synthetic images, giving the generators a robust training signal. As empirical results on publicly available datasets show, the suggested algorithms outperform state-of-the-art methods and the proposed CED-DCGAN technique successfully detects high-fidelity deep fakes in video conferencing and generalizes well when comparing with other techniques. Python tool is used for implementing this proposed study and the accuracy obtained for proposed work is 98.23�%.;Deep fake detection, Deep conditional generative adversarial networks, Ensemble discriminators;ScienceDirect
91;Revealing and Classification of Deepfakes Video's Images using a Customize Convolution Neural Network Model;Usha Kosarkar and Gopal Sarkarkar and Shilpa Gedam;2023;"Deepfake has been exploited in recent years despite its widespread usage in a variety of areas to create dangerous material such as fake movies, rumors, and false news by changing or substituting the face information of the sources and so poses enormous security concerns to society. Research on active detection & prevention technologies is critical as deepfake continues to evolve. Deepfake has been a blessing, but we've taken advantage of it by utilizing it to swap faces. Deepfake is a new subdomain of Artificial Intelligence (AI) technology in which one person's face is layered over another person's face, which is becoming more and more popular on social networking sites. Deepfake pictures and videos can now be created much more quickly and cheaply due to ML (Machine Learning), which is a primary component of deepfakes. Despite negative connotations attached to the term ""deepfakes,"" technology is increasingly being used in commercial & individual contexts. New technical advancements have made it more difficult to distinguish between deepfakes and images that have been digitally manipulated. The rise of deepfake technologies has sparked a growing sense of unease. The primary goal of this project is to properly distinguish deepfake pictures from real images using deep learning techniques. In this study, we implemented a customized CNN algorithm to identify deepfake pictures from a video dataset and conducted a comparative analysis with two other methods to determine which way was superior. The Kaggle dataset was used to train & test our model. Convolutional neural networks (CNNs) have been used in this research to distinguish authentic & deepfake images by training three distinct CNN models. A customized CNN model, which includes several additional layers such as a dense layer, MaxPooling, as well as a dropout layer, has also been developed and implemented. This method follows the frames extraction, face feature extraction, data preprocessing, and classification phases in determining whether Real or Fake images in the video reflect the objectives. Accuracy, loss, and the area under the receiver operating characteristic (ROC) curve were used to characterize the data. Customized CNN outperformed all other models, achieving 91.4% accuracy, a reduced loss value of 0.342, as well as an AUC of 0.92. Besides, we obtained 85.2% testing accuracy from the CNN and 95.5% testing accuracy from the MLP-CNN model.";Deepfake detection, Deep learning, Customize CNN, Deepfake Detection Challenge Dataset, Classification;ScienceDirect
93;A facial geometry based detection model for face manipulation using CNN-LSTM architecture;Peifeng Liang and Gang Liu and Zenggang Xiong and Honghui Fan and Hongjin Zhu and Xuemin Zhang;2023;This issue of DeepFake technique that may cause great threat to privacy, democracy, and national security has attracted the attention of deep learning researchers. DeepFake detection, therefore, has been a very hot issue in deep learning research. The face landmark feature maps are often used by many DeepFake approaches in generating fake faces. It also provides key information to help to detect manipulated face images. In this paper, we propose a detection approach for manipulated face images. To make full use of face landmark information, we propose a facial geometry prior module (FGPM) to extract facial geometry feature maps. Then the facial geometry feature maps are embedded into upsampling feature maps generated by the CNN-LSTM network. The proposed FGPM exploits facial maps and frequency domain correlation to analyze the discriminative characteristics between manipulated and non-manipulated regions by incorporating the CNN-LSTM network. Finally, a decoder is used to learn the mapping from low-resolution feature maps to pixel-wise to predict manipulation localization. Or a softmax classifier is used to predict real or fake face images. By experimenting on several popular datasets, the proposed detection model has demonstrated the capability of localizing manipulation at the pixel level and with a high prediction on real or fake face images.;DeepFake detection, CNN-LSTM, Facial geometry prior module, Resampling, Facial analysis;ScienceDirect
94;Golden ratio based deep fake video detection system with fusion of capsule networks;Samet Dincer and Guzin Ulutas and Beste Ustubioglu and Gul Tahaoglu and Nicolas Sklavos;2024;In recent years, with the massive development of new deep learning tools, the production of fake video content has become widespread. This fake content has the potential to cause serious social problems. Therefore, detecting fake content is of great importance. For this purpose, we present a new method for deepfake video detection. In most of the studies, which image frames of the videos are selected to be used in the detection models is determined randomly. This randomness can cause important image frames to be missed which can improve detection performance. The proposed method differs from other studies in the literature by determining which image frames to select from the videos with the help of the golden ratio information on the face. The method was developed using three different feature extraction methods, VGG19, EfficientNet B0, EfficientNet B4, and two different capsule network models, CapsuleNet and ArCapsNet. Performance evaluations were performed on Celeb-DF and DFDC-P, two of the currently challenging deepfake video datasets. The results were improved by fusing the best performing models. For Celeb-DF dataset, 93.63% ACC, 99.14% AUC and for DFDC-P dataset, 82.84% ACC, 89.08% AUC were obtained.;Data security, Multimedia security, Cryptography, Deepfake, Cyber security;ScienceDirect
95;An adversarial attack approach for eXplainable AI evaluation on deepfake detection models;Balachandar Gowrisankar and Vrizlynn L.L. Thing;2024;With the rising concern on model interpretability, the application of eXplainable AI (XAI) tools on deepfake detection models has been a topic of interest recently. In image classification tasks, XAI tools highlight pixels influencing the decision given by a model. This helps in troubleshooting the model and determining areas that may require further tuning of parameters. With a wide range of tools available in the market, choosing the right tool for a model becomes necessary as each one may highlight different sets of pixels for a given image. There is a need to evaluate different tools and decide the best performing ones among them. Generic XAI evaluation methods like insertion or removal of salient pixels/segments are applicable for general image classification tasks but may produce less meaningful results when applied on deepfake detection models due to their functionality. In this paper, we perform experiments to show that generic removal/insertion XAI evaluation methods are not suitable for deepfake detection models. We also propose and implement an XAI evaluation approach specifically suited for deepfake detection models.;Deepfake, Explainable AI, Evaluation, Adversarial attack, Image forensics;ScienceDirect
97;DeepFake Videos Detection Based on Texture Features;Bozhi Xu and Jiarui Liu and Jifan Liang and Wei Lu and Yue Zhang;2021;In recent years, with the rapid development of deep learning technologies, some neural network models have been applied to generate fake media. DeepFakes, a deep learning based forgery technology, can tamper with the face easily and generate fake videos that are difficult to be distinguished by human eyes. The spread of face manipulation videos is very easy to bring fake information. Therefore, it is important to develop effective detection methods to verify the authenticity of the videos. Due to that it is still challenging for current forgery technologies to generate all facial details and the blending operations are used in the forgery process, the texture details of the fake face are insufficient. Therefore, in this paper, a new method is proposed to detect DeepFake videos. Firstly, the texture features are constructed, which are based on the gradient domain, standard deviation, gray level co-occurrence matrix and wavelet transform of the face region. Then, the features are processed by the feature selection method to form a discriminant feature vector, which is finally employed to SVM for classification at the frame level. The experimental results on the mainstream DeepFake datasets demonstrate that the proposed method can achieve ideal performance, proving the effectiveness of the proposed method for DeepFake videos detection.;DeepFake, video tampering, tampering detection, texture feature;ScienceDirect
98;Triple-modality interaction for deepfake detection on zero-shot identity;JunHo Yoon and Angel Panizo-LLedot and David Camacho and Chang Choi;2024;Recent advancements in generative AI technology have created more realistic fake data that are utilized in various fields, such as data augmentation. However, the misuse of deepfake technology has led to increased damage. Consequently, ongoing research aims to analyze modality characteristics and detect deepfakes through AI-based methods. Existing AI-based deepfake-detection techniques have limitations in detecting deepfakes in modalities and identities that are not included in the training data. This study proposes a baseline approach based on zero-shot identity and one-shot deepfake detection for detecting deepfakes in environments with limited data. Additionally, we propose a triple-modality interaction based on a multimodal transformer (TMI-Former) to consider the triple-modality aspects of deepfakes. TMI-Former comprises four stages: vision feature extraction, representation, residual connection, and late-level fusion. It operates in a two-stage manner, extracting visual features and reconstructing them using auditory and linguistic features, thereby allowing for triple-modality interactions. In environments with limited data, such as zero-shot identity and one-shot deepfake scenarios, TMI-Former demonstrated effectiveness, with an accuracy ranging from 18.75% to 19.5% and an f1-score ranging from 0.2238 to 0.3561, compared to unimodal AI. Furthermore, TMI-Former shows superior performance compared to the existing multi-modal AI, with an accuracy ranging from 1.44% to 19.75% and an f1-score ranging from 0.0146 to 0.4169.;Multi-modal, One-shot, Deepfake, Disinformation detection;ScienceDirect
99;Detecting fake images by identifying potential texture difference;Jiachen Yang and Shuai Xiao and Aiyun Li and Guipeng Lan and Huihui Wang;2021;Fake detection has become an urgent task. Generative adversarial networks (GANs) extended to deep learning has shown its extraordinary ability in the fields of image, audio, and speech. But advanced technology benefits us, it also poses a threat to us when used in Cyber Crime. The Deepfake (common name for face manipulation methods) based on GANs can realize the replacement of different faces. Due to the development of GANs, faces generated by Deepfake can already be visually real. Deepfake can purposely replace any face to a different person, so that a fabricated event may be widely spread because of the convenience of the Internet, causing serious impacts such as personal attacks and cyber crime. Based on cutting-edge research , this paper proposes a intelligence forensic method of Deepfake detection. We first discover the subtle texture differences between real and fake image in image saliency, which shows difference in the texture of faces. To amplify this difference, we exploit guided filter with saliency map as guide map to enhance the texture artifacts caused by the post-processing and display the potential features of forgery. Resnet18 classification network efficiently learns the exposed difference and finally realizes the real and fake detection of face images. We evaluate the performance of the method and experiments verify that the proposed method can achieve the state-of-the-art detection accuracy .;Fake detection, Security and privacy, Digital forensic, Image saliency, Texture difference;ScienceDirect
100;DEFAEK: Domain Effective Fast Adaptive Network for Face Anti-Spoofing;Jiun-Da Lin and Yue-Hua Han and Po-Han Huang and Julianne Tan and Jun-Cheng Chen and M. Tanveer and Kai-Lung Hua;2023;Existing deep learning based face anti-spoofing (FAS) or deepfake detection approaches usually rely on large-scale datasets and powerful networks with significant amount of parameters to achieve satisfactory performance. However, these make them resource-heavy and unsuitable for handheld devices. Moreover, they are limited by the types of spoof in the dataset they train on and require considerable training time. To produce a robust FAS model, they need large datasets covering the widest variety of predefined presentation attacks possible. Testing on new or unseen attacks or environments generally results in poor performance. Ideally, the FAS model should learn discriminative features that can generalize well even on unseen spoof types. In this paper, we propose a fast learning approach called Domain Effective Fast Adaptive nEt-worK (DEFAEK), a face anti-spoofing approach based on the optimization-based meta-learning paradigm that effectively and quickly adapts to new tasks. DEFAEK treats differences in an environment as domains and simulates multiple domain shifts during training. To further improve the effectiveness and efficiency of meta-learning, we adopt the metric learning in the inner loop update with careful sample selection. With extensive experiments on the challenging CelebA-Spoof and FaceForensics++ datasets, the evaluation results show that DEFAEK can learn cues independent of the environment with good generalization capability. In addition, the resulting model is lightweight following the design principle of modern lightweight network architecture and still generalizes well on unseen classes. In addition, we also demonstrate our model�s capabilities by comparing the numbers of parameters, FLOPS, and model performance with other state-of-the-art methods.;Meta-learning, Metric loss, Fast learning, Face anti-spoofing, DeepFake;ScienceDirect
102;Video Deepfake classification using particle swarm optimization-based evolving ensemble models;Li Zhang and Dezong Zhao and Chee Peng Lim and Houshyar Asadi and Haoqian Huang and Yonghong Yu and Rong Gao;2024;The recent breakthrough of deep learning based generative models has led to the escalated generation of photo-realistic synthetic videos with significant visual quality. Automated reliable detection of such forged videos requires the extraction of fine-grained discriminative spatial-temporal cues. To tackle such challenges, we propose weighted and evolving ensemble models comprising 3D Convolutional Neural Networks (CNNs) and CNN-Recurrent Neural Networks (RNNs) with Particle Swarm Optimization (PSO) based network topology and hyper-parameter optimization for video authenticity classification. A new PSO algorithm is proposed, which embeds Muller's method and fixed-point iteration based leader enhancement, reinforcement learning-based optimal search action selection, a petal spiral simulated search mechanism, and cross-breed elite signal generation based on adaptive geometric surfaces. The PSO variant optimizes the RNN topologies in CNN-RNN, as well as key learning configurations of 3D CNNs, with the attempt to extract effective discriminative spatial-temporal cues. Both weighted and evolving ensemble strategies are used for ensemble formulation with aforementioned optimized networks as base classifiers. In particular, the proposed PSO algorithm is used to identify optimal subsets of optimized base networks for dynamic ensemble generation to balance between ensemble complexity and performance. Evaluated using several well-known synthetic video datasets, our approach outperforms existing studies and various ensemble models devised by other search methods with statistical significance for video authenticity classification. The proposed PSO model also illustrates statistical superiority over a number of search methods for solving optimization problems pertaining to a variety of artificial landscapes with diverse geometrical layouts.;Video deepfake classification, Hybrid deep neural network, 3d convolutional neural network, Evolutionary algorithm, Evolving ensemble classifier;ScienceDirect
103;Deepfake noise investigation and detection;Tianyi Wang and Ming Liu and Wei Cao and Kam Pui Chow;2022;The fast development of Deepfake has brought huge current and potential future negative impacts to our daily lives. As the circulating popular Deepfake videos have become difficult to be distinguished by human eyes, various Deepfake detection approaches have been attempted using deep learning models. However, even though some existing detection methods have achieved reasonable detection performance with respect to the statistical evaluation metrics, the actual underlying Deepfake forensic traces have been barely discussed. In this study, we investigate the special forensic noise traces within Deepfake image frames and propose a noise-based Deepfake detection model approach using a deep neural network. We train a Siamese noise extractor using a novel face-background strategy to investigate different forensic noise traces of a synthesized face area and an unmodified background area. A similarity matrix module is proposed to analyze the forensic noise trace difference between a cropped face square and a cropped background square from a candidate image frame for the Deepfake detection task. As a result, our proposed model trained on the high-quality Celeb-DF dataset has achieved state-of-the-art performance with 99.15% accuracy and 99.92% AUC score on the in-dataset testing set and 88.95% AUC score on the highly difficult unknown-attack Deepfake video dataset. Furthermore, the visualization of the Deepfake forensic noise traces has shown the explicit distinction between synthesized faces and any unmodified area. We believe that the visualized evidence could provide better proof of Deepfake detection results rather than simply the statistical evaluation numbers.;Deepfake detection, Digital image forensics, Noise trace extraction and investigation, Siamese network;ScienceDirect
104;Feature fusion Vision Transformers using MLP-Mixer for enhanced deepfake detection;Ehab Essa;2024;Deepfake technology, utilizing deep learning and computer vision, presents significant security threats by generating highly realistic synthetic media, such as images and videos. In this paper, we propose a feature fusion-based method for deepfake detection, harnessing the capabilities of three Vision Transformer (ViT) architectures: Dual Attention Vision Transformers (DaViT), Inception Transformer (iFormer), and Group Propagation Vision Transformer (GPViT). The proposed feature fusion method integrates the local�global contextual understanding of DaViT, the frequency spectrum broadening of iFormer, and the high-resolution feature retention of GPViT to provide a comprehensive analysis of visual data, crucial for detecting subtle manipulations typical in deepfakes. An MLP-Mixer (Multi-Layer Perceptron-Mixer) model is proposed for the feature fusion process for effective feature integration, enhancing the detection capabilities while preserving the individual strengths of each ViT model. The performance of the proposed method is evaluated using standard datasets, namely FaceForensics++ and Celeb-DF, demonstrating its robustness and generalizability across various scenarios. For the four manipulation techniques in the FaceForensics++ dataset, namely DeepFakes (DF), Face2Face (F2F), FaceSwap (FS), and NeuralTextures (NT), the proposed method achieves area under the curve (AUC) of 99.75%, 97.04%, 98.78%, and 87.49% respectively, Moreover, it demonstrates an AUC of 99.84% on the Celeb-DF dataset. The performance of the proposed model has been evaluated against many state-of-the-art methods to ensure its robustness and generalization capabilities.;Deepfake detection, Vision Transformer, Feature fusion, MLP-Mixer;ScienceDirect
105;Machine learning based medical image deepfake detection: A comparative study;Siddharth Solaiyappan and Yuxin Wen;2022;Deep generative networks in recent years have reinforced the need for caution while consuming various modalities of digital information. One avenue of deepfake creation is aligned with injection and removal of tumors from medical scans. Failure to detect medical deepfakes can lead to large setbacks on hospital resources or even loss of life. This paper attempts to address the detection of such attacks with a structured case study. Specifically, we evaluate eight different machine learning algorithms, which include three conventional machine learning methods (Support Vector Machine, Random Forest, Decision Tree) and five deep learning models (DenseNet121, DenseNet201, ResNet50, ResNet101, VGG19) in distinguishing between tampered and untampered images. For deep learning models, the five models are used for feature extraction, then each pre-trained model is fine-tuned. The findings of this work show near perfect accuracy in detecting instances of tumor injections and removals.;Computed tomography, Generative adversarial networks, Deepfake detection, DICOM, Tampered images, Machine learning;ScienceDirect
106;LBPNet: Exploiting texture descriptor for deepfake detection;Staffy Kingra and Naveen Aggarwal and Nirmal Kaur;2022;Recent AI advancements made it significantly easier to generate high-quality synthesized faces, referred as deepfakes. It can make people saying and doing things that never happened actually. Owing to the vast usage of social media, manipulated content is susceptible to spread unrest in the society. With the continuous evolvement of AI-enabled deepfake generators, the research on deepake detection has started progressing in the last few years. From analyzing eye-blinking in the previous generation deepfakes to deep learning based models for advanced deepfakes, the existing deepfake detectors have analyzed numerous artefacts. This paper proposes a novel detection approach, LBPNet, to distinguish deepfaked faces from genuine ones by means of exploiting inconsistencies in texture information. In particular, Local Binary Pattern (LBP) of deepfaked and pristine faces have been investigated through a CNN based model. Moreover, the proposed LBPNet technique is evaluated on more advanced and diverse deepfaked datasets such as Celeb-DF, DFDC, and DeeperForensics, which provided a detection accuracy of 92.38%, 80% and 86% respectively. Comprehensive analysis on different benchmark datasets and comparison with state-of-art endorse the superior performance of the proposed method. Thorough experimentations also reveal the robustness of LBPNet against different compression levels and tampering types.;Local Binary Pattern, Deepfake, LBP, Face swap, Texture, Deep network;ScienceDirect
107;Deepfake forensics analysis: An explainable hierarchical ensemble of weakly supervised models;Samuel Henrique Silva and Mazal Bethany and Alexis Megan Votto and Ian Henry Scarff and Nicole Beebe and Peyman Najafirad;2022;Deepfakes have become exponentially more common and sophisticated in recent years, so much so that forensic specialists, policy makers, and the public alike are anxious about their role in spreading disinformation. Recently, the detection and creation of such forgery became a popular research topic, leading to significant growth in publications related to the creation of deepfakes, detection methods, and datasets containing the latest deepfake creation methods. The most successful approaches in identifying and preventing deepfakes are deep learning methods that rely on convolutional neural networks as the backbone for a binary classification task. A convolutional neural network extracts the underlying patterns from the input frames. It feeds these to a binary classification fully connected network, which classifies these patterns as trustworthy or untrustworthy. We claim that this method is not ideal in a scenario in which the generation algorithms constantly evolve since the detection algorithm is not robust enough to detect comparably minor artifacts introduced by the generation algorithms. This work proposes a hierarchical explainable forensics algorithm that incorporates humans in the detection loop. We curate the data through a deep learning detection algorithm and share an explainable decision to humans alongside a set of forensic analyses on the decision region. On the detection side, we propose an attention-based explainable deepfake detection algorithm. We address this generalization issue by implementing an ensemble of standard and attention-based data-augmented detection networks. We use the attention blocks to evaluate the face regions where the model focuses its decision. We simultaneously drop and enlarge the region to push the model to base its decision on more regions of the face, while maintaining a specific focal point for its decision. In this case, we use an ensemble of models to improve the generalization. We also evaluate the models� decision using Grad-CAM explanation to focus on the attention maps. The region uncovered by the explanation layer is cropped and undergoes a series of frequency and statistical analyses that help humans decide if the frame is real or fake. We evaluate our model in one of the most challenging datasets, the DFDC, and achieve an accuracy of 92.4%. We successfully maintain this accuracy in datasets not used in the training process.;Deepfake, Forensics, Deep learning, Facial recognition;ScienceDirect
109;Artificial rabbits optimization with transfer learning based deepfake detection model for biometric applications;Sana Alazwari and Marwa Obayya {Jamal Alsamri} and Mohammad Alamgeer and Rana Alabdan and Ibrahim Alzahrani and Mohammed Rizwanullah and Azza {Elneil Osman};2024;Deepfake detection is a significant area of research in biometric applications, as it is essential to ensure the integrity and authenticity of biometric information. Biometric data, including fingerprint recognition, facial recognition, and voice recognition, are used extensively for identification and authentication, which makes it crucial to prevent and detect deepfake attacks. Deepfake is a manipulated digital media, for example, a video or image of a person can be replaced with a similarity of another person. A crucial way to deepfake detection in biometric applications is to use a machine learning (ML) algorithm, particularly deep learning (DL), that could learn to distinguish between fake and real biometric information. Hence, the study proposes an Artificial Rabbits Optimization with Transfer Learning Deepfake Detection for Biometric Applications (AROTL-DFDBA) technique. The AROTL-DFDBA technique intends to detect fake and original biometric data using the DL model. In the presented AROTL-DFDBA technique, modified DarkNet-53 model for the feature extraction process. Besides, the ARO method was applied for the optimum hyperparameter selection of the modified DarkNet-53 model. For deepfake detection, the Weighted Regularized Extreme Learning Machine (WR-ELM) technique is applied. The simulation outcomes of the AROTL-DFDBA method can be validated on the DeepFake dataset. The extensive simulation results signify better detection outcomes of the AROTL-DFDBA technique over other existing techniques with a maximum accuracy of 96.48%.;Biometric applications, Computer vision, Deep fake detection, Deep learning, Artificial rabbits optimizer;ScienceDirect
110;Magnifying multimodal forgery clues for Deepfake detection;Xiaolong Liu and Yang Yu and Xiaolong Li and Yao Zhao;2023;Advancements in computer vision and deep learning have led to difficulty in distinguishing the generated Deepfake media. In addition, recent forgery techniques also modify the audio information based on the forged video, which brings new challenges. However, due to the cross-modal bias, recent multimodal detection methods do not well explore the intra-modal and cross-modal forgery clues, which leads to limited detection performance. In this paper, we propose a novel audio-visual aware multimodal Deepfake detection framework to magnify intra-modal and cross-modal forgery clues. Firstly, to capture temporal intra-modal defects, Forgery Clues Magnification Transformer (FCMT) module is proposed to magnify forgery clues based on sequence-level relationships. Then, the Distribution Difference based Inconsistency Computing (DDIC) module based on Jensen�Shannon divergence is designed to adaptively align multimodal information for further magnifying the cross-modal inconsistency. Next, we further explore spatial artifacts by connecting multi-scale feature representation to provide comprehensive information. Finally, a feature fusion module is designed to adaptively fuse features to generate a more discriminative feature. Experiments demonstrate that the proposed framework outperforms independently trained models, and at the same time, yields superior generalization capability on unseen types of Deepfake.;Deepfake forgery detection, Multimodal clues magnification, Cross-modal inconsistency, Multi-scale representation;ScienceDirect
112;Preserving manipulated and synthetic Deepfake detection through face texture naturalness;Chit-Jie Chew and Yu-Cheng Lin and Ying-Chin Chen and Yun-Yi Fan and Jung-San Lee;2024;With the rapid development of deep learning and face recognition technology, AI(Artificial Intelligence) experts have rated Deepfake cheating as the top AI threat. It is difficult for the human eye to distinguish the fake face images generated by Deepfake. Therefore, it has become a popular tool for criminals to seek benefits. Deepfake can be mainly divided into two types, a manipulated Deepfake that falsifies images of others by targeting real faces, and a synthetic Deepfake using GAN to generate a new fake image. So far, seldom cybersecurity system is able to detect these two types simultaneously. In this article, we aim to propose a hybrid Deepfake detection mechanism (HDDM) based on face texture and naturalness degree. HDDM constructs a unique texture from a facial image based on CNN(Convolutional Neural Network) and builds a naturalness degree recognition model via DNN(Deep Neural Network) to help cheating detection. Experimental results have proved that HDDM possesses a sound effect and stability for synthetic and manipulated Deepfake attacks. In particular, the WildDeepfake simulation has demonstrated the possibility of applying HDDM to the real world.;Facial texture, Naturalness, Deepfake, DNN;ScienceDirect
114;A deep learning model for FaceSwap and face-reenactment deepfakes detection;Marriam Nawaz and Ali Javed and Aun Irtaza;2024;Recently, the higher availability of multimedia content on social websites, together with lightweight deep learning (DL) empowered tools like Generative Adversarial Networks (GANs) has caused the generation of realistic deepfakes. Such fabricated data has the potential to spread disinformation, revenge porn, initiate monetary scams, and can result in adverse immoral and illegal societal issues, etc. Hence, the accurate identification of deepfakes is mandatory to discriminate between real and manipulated content. In this work, we have presented a DL-based approach namely a unified network for FaceSwap (FS) and Face-Reenactment (FR) Deepfakes Detection (AUFF-Net). More clearly, both the spatial and temporal information from the video samples are used to detect two types of visual manipulations i.e., FS and FR. For this reason, a novel DL framework namely the Inception-Swish-ResNet-v2 model is introduced as a feature extractor for computing the information at the spatial level. While the Bi-LSTM model is utilized to measure the temporal information. Additionally, 3 dense layers are included at the last of the model structure to suggest a discriminative group of the feature vector We performed extensive experimentation on a challenging dataset namely the FaceForensic++, and attainede average accuracy values of 99.21?%, and 98.32?% for FS, or FR, respectively. Furthermore, we introduced an explainability module to show the reliable keypoints selection capability of our technique. Moreover, we have performed a cross-dataset evaluation to show the generalization power of our approach. Both the qualitative and quantitative results have confirmed the effectiveness of the suggested approach for visual manipulation categorization under the occurrence of various adversarial attacks.;Deep learning, Deepfakes, FaceSwap, Face-reenactment, Inception-swish-Resnet-v2, Bi-LSTM;ScienceDirect
115;A multi-label classification method based on transformer for deepfake detection;Liwei Deng and Yunlong Zhu and Dexu Zhao and Fei Chen;2024;With the continuous development of hardware and deep learning technologies, existing forgery techniques are capable of more refined facial manipulations, making detection tasks increasingly challenging. Therefore, forgery detection cannot be viewed merely as a traditional binary classification task. To achieve finer forgery detection, we propose a method based on multi-label detection classification capable of identifying the presence of forgery in multiple facial components. Initially, the dataset undergoes preprocessing to meet the requirements of this task. Subsequently, we introduce a Detail-Enhancing Attention Module into the network to amplify subtle forgery traces in shallow feature maps and enhance the network's feature extraction capabilities. Additionally, we employ a Global�Local Transformer Decoder to improve the network's ability to focus on local information. Finally, extensive experiments demonstrate that our approach achieves 92.45% mAP and 90.23% mAUC, enabling precise detection of facial components in images, thus validating the effectiveness of our proposed method.;Deepfake detection, Multi-label classification, Transformer;ScienceDirect
116;Compressed Deepfake Detection using Spatio-Temporal Approach with Model Pruning;Vidya K and Praveen Ramesh and Hrithik Viknesh and Sanjay Devanand;2023;Deepfake is a deep learning�technology that replaces source person face photos with the�target person face photos in a movie to create a video of the target by�executing the�actions performed by source person. Due to the�limited storage capacity and network bandwidth constraints, compressed media is now commonly employed in social networks. The goal of this research study�is to determine whether or not a given compressed video is a deepfake. To do this, both the spatial and temporal components of the video should be considered, and the findings will be integrated by�using an appropriate fusion approach. Hence, the deep learning model used in the spatial approach is pruned using the Network Pruning technique to achieve a better performance. The combined prediction of the spatial and temporal approaches indicates whether the given video is deepfake or not.;Compressed, Fusion, Pruning, Spatio-Temporal features;ScienceDirect
117;Texture and artifact decomposition for improving generalization in deep-learning-based deepfake detection;Jie Gao and Marco Micheletto and Giulia Orr� and Sara Concas and Xiaoyi Feng and Gian Luca Marcialis and Fabio Roli;2024;The harmful utilization of DeepFake technology poses a significant threat to public welfare, precipitating a crisis in public opinion. Existing detection methodologies, predominantly relying on convolutional neural networks and deep learning paradigms, focus on achieving high in-domain recognition accuracy amidst many forgery techniques. However, overseeing the intricate interplay between textures and artifacts results in compromised performance across diverse forgery scenarios. This paper introduces a groundbreaking framework, denoted as Texture and Artifact Detector (TAD), to mitigate the challenge posed by the limited generalization ability stemming from the mutual neglect of textures and artifacts. Specifically, our approach delves into the similarities among disparate forged datasets, discerning synthetic content based on the consistency of textures and the presence of artifacts. Furthermore, we use a model ensemble learning strategy to judiciously aggregate texture disparities and artifact patterns inherent in various forgery types, thereby enabling the model�s generalization ability. Our comprehensive experimental analysis, encompassing extensive intra-dataset and cross-dataset validations along with evaluations on both video sequences and individual frames, confirms the effectiveness of TAD. The results from four benchmark datasets highlight the significant impact of the synergistic consideration of texture and artifact information, leading to a marked improvement in detection capabilities.;DeepFake detection, Generalization, Texture, Artifact, Ensemble learning strategy;ScienceDirect
118;Customized Convolutional Neural Network for Accurate Detection of Deep Fake Images in Video Collections;Dmitry Gura and Bo Dong and Duaa Mehiar and Nidal Al Said;2024;The motivation for this study is that the quality of deep fakes is constantly improving, which leads to the need to develop new methods for their detection. The proposed Customized Convolutional Neural Network method involves extracting structured data from video frames using facial landmark detection, which is then used as input to the CNN. The customized Convolutional Neural Network method is the date augmented-based CNN model to generate �fake data� or �fake images�. This study was carried out using Python and its libraries. We used 242 films from the dataset gathered by the Deep Fake Detection Challenge, of which 199 were made up and the remaining 53 were real. Ten seconds were allotted for each video. There were 318 videos used in all, 199 of which were fake and 119 of which were real. Our proposed method achieved a testing accuracy of 91.47%, loss of 0.342, and AUC score of 0.92, outperforming two alternative approaches, CNN and MLP-CNN. Furthermore, our method succeeded in greater accuracy than contemporary models such as XceptionNet, Meso-4, EfficientNet-BO, MesoInception-4, VGG-16, and DST-Net. The novelty of this investigation is the development of a new Convolutional Neural Network (CNN) learning model that can accurately detect deep fake face photos.;Deep fake detection video analysis, convolutional neural network, machine learning, video dataset collection, facial landmark prediction, accuracy, models;ScienceDirect
119;A dual descriptor combined with frequency domain reconstruction learning for face forgery detection in deepfake videos;Xin Jin and Nan Wu and Qian Jiang and Yuru Kou and Hanxian Duan and Puming Wang and Shaowen Yao;2024;Conventional face forgery detectors have primarily relied on image artifacts produced by deepfake video generation models. These methods have performed well when the training and test sets were derived from the same deepfake algorithm, but accuracy and generalizability remain a challenge for diverse datasets. In this study, both supervised and unsupervised approaches are proposed for more accurate detection in in-domain and cross-domain experiments. Specifically, two descriptors are introduced to extract rich information in the spatial domain to achieve higher accuracy. A frequency domain reconstruction module is then included to expand the representation space for facial features. A reconstruction method based on an auto-encoder was also applied to obtain a frequency domain coding vector. In this process, reconstruction learning was sufficient for extracting unknown information, while a combination with classification learning provided essential high-frequency pixel differences between real and fake samples, thus facilitating forgery identification. A series of validation experiments with large-scale benchmark datasets demonstrated that the proposed technique was superior to existing methods.;Deepfake detection, Digital forensics, Frequency domain analysis, Deep learning, Auto encoder, Video forgery;ScienceDirect
120;JRC: Deepfake detection via joint reconstruction and classification;Bosheng Yan and Chang-Tsun Li and Xuequan Lu;2024;Deep learning has enabled realistic face manipulation for malicious purposes (e.g., deepfakes), which poses significant concerns over the integrity of the media in circulation. Most existing deep learning techniques for deepfake detection can achieve promising performance in the intra-dataset evaluation setting, but are unable to perform satisfactorily in the inter-dataset evaluation setting. Most previous methods use a backbone network to extract global features for making predictions and only employ binary supervision to train the network. Classification merely based on the learning of global features often leads to weak generalizability to deepfakes of unseen manipulation methods. In this paper, we design a two-branch Convolutional AutoEncoder (CAE), which considers the reconstruction and classification tasks simultaneously for deepfake detection. This Joint Reconstruction and Classification (JRC) method shares the information learned by one task with the other, each focusing on different aspects, and hence boosts the overall performance. JRC is end-to-end, and experiments demonstrate that it achieves state-of-the-art performance on three commonly-used datasets, particularly in the cross-dataset evaluation setting.;Deepfake detection, Unsupervised reconstruction, Joint supervision;ScienceDirect
122;Deepfake detection using deep feature stacking and meta-learning;Gourab Naskar and Sk Mohiuddin and Samir Malakar and Erik Cuevas and Ram Sarkar;2024;Deepfake is a type of face manipulation technique using deep learning that allows for the replacement of faces in videos in a very realistic way. While this technology has many practical uses, if used maliciously, it can have a significant number of bad impacts on society, such as spreading fake news or cyberbullying. Therefore, the ability to detect deepfake has become a pressing need. This paper aims to address the problem of deepfake detection by identifying deepfake forgeries in video sequences. In this paper, a solution to the said problem is presented, which at first uses a stacking based ensemble approach, where features obtained from two popular deep learning models, namely Xception and EfficientNet-B7, are combined. Then by selecting a near-optimal subset of features using a ranking based approach, the final classification is performed to classify real and fake videos using a meta-learner, called multi-layer perceptron. In our experimentation, we have achieved an accuracy of 96.33% on Celeb-DF (V2) dataset and 98.00% on the FaceForensics++ dataset using the meta-learning model both of which are higher than the individual base models. Various types of experiments have been conducted to validate the robustness of the current method.;Deepfake, Stacking based ensemble, Deep learning, Feature selection, Meta-learning;ScienceDirect
123;Counter-act against GAN-based attacks: A collaborative learning approach for anti-forensic detection;Kutub Uddin and Tae Hyun Jeong and Byung Tae Oh;2024;The massive success of deep learning allows us to forge images in more perfect manners for ethical and even unethical purposes. Several forensic methods have been proposed to expose artifacts in fake images. However, the practice of anti-forensics (AF), particularly deep learning-based AF on digital images, has made such forgeries difficult to detect. Therefore, a counter-AF (CAF) algorithm is necessary to reveal AF traces and ensure the authenticity of image content. In this study, we propose a novel data-driven approach to counteract generative adversarial network (GAN)-based AF attacks. We consider different forgery techniques, such as noise addition, filtering, and deepfake generation to generate fake images. Subsequently, GAN-based AF attacks were applied to conceal the forgery fingerprints such that they can deceive forensic methods. We built a new CAF method that allows collaborative learning to detect GAN-based AF attacks. We designed a novel CAF-GAN model by considering the commonly used GAN architectures. The proposed CAF-GAN model generates a new image from the input image, which helps collaborative learning to detect AF images. GAN-based AF attacks can effectively hide forgery fingerprints and significantly reduce the performance of forensic methods. However, the proposed CAF method can effectively detect AF images in match and mismatch scenarios of AF and CAF-GAN models.;Image forensic, Anti-forensic, GAN-based attacks, Counter-anti-forensic, Deep learning, And metric learning;ScienceDirect
124;DF-UDetector: An effective method towards robust deepfake detection via feature restoration;Jianpeng Ke and Lina Wang;2023;The abuse of deepfakes, a rising face swap technique, causes severe concerns about the authenticity of visual content and the dissemination of misinformation. To alleviate the threats imposed by deepfakes, a vast body of data-centric detectors has been deployed. However, the performance of these methods can be easily defected by degradations on deepfakes. To improve the performance of degradation deepfake detection, we creatively explore the recovery method in the feature space to preserve the artifacts for detection instead of directly in the image domain. In this paper, we propose a method, namely DF-UDetector, against degradation deepfakes by modeling the degraded images and transforming the extracted features to a high-quality level. To be specific, the whole model consists of three key components: an image feature extractor to capture image features, a feature transforming module to map the degradation features into a higher quality, and a discriminator to determine whether the feature map is of high quality enough. Extensive experiments on multiple video datasets show that our proposed model performs comparably or even better than state-of-the-art counterparts. Moreover, DF-UDetector outperforms by a small margin when detecting deepfakes in the wild.;Degradation deepfake detection, Feature space manipulation, Deep neural networks, Face manipulation, Deep learning, Deepfakes;ScienceDirect
126;Deepfake forensics: Cross-manipulation robustness of feedforward- and recurrent convolutional forgery detection methods;Frederic Chamot and Zeno Geradts and Evert Haasdijk;2022;Recently, deep-learning based video-manipulation techniques, so-called deepfakes, have gained a lot of traction in popular media. Deepfakes are predominantly used to photo-realistically alter the identity of actors recorded on video, and misuse of this new technology has the potential to harm individuals, companies, or to inflict damage in a societal context. The accelerated pace, at which deepfake technology is improved, challenges contemporary research to provide the urgently required detection methods. A major obstacle to reliable deepfake detection in the field is the impaired generalizability across specific instances of deepfake models, i.e. detection performance of previously not encountered manipulation models. The present work aims to establish a better understanding of the critical factors that guide cross-manipulation detection performance. Recent studies have indicated that the properties of video-based modeling may be leveraged to enhance the detection of unknown deepfake manipulations. Therefore, we compare multiple image- and video-based detection models and evaluate their performance on instances both generated by known, and unknown manipulation models. Furthermore we attempt to replicate research that successfully improved cross-manipulation detection by using image-perturbation methods to degrade training data. Using multiple data-sources to emulate in- and out-sample detection performance, we demonstrate that none of the two model types show universally superior performance. Also, our results confirm that cross-manipulation evaluation results in problematic detection accuracy for all models, regardless of whether we apply image-perturbation techniques during training. Additionally, the detection performance on a set of manually selected, high-quality deepfake videos indicates that the current state-of-the-art detection models are not yet fully equipped for real-world applications.;Deepfake detection, Computer vision, Image perturbations, Recurrent convolutional networks;ScienceDirect
127;Learning Spatio-temporal features to detect manipulated facial videos created by the Deepfake techniques;Xuan Hau Nguyen and Thai Son Tran and Van Thinh Le and Kim Duy Nguyen and Dinh-Tu Truong;2021;In the last years, the face synthetic video generation has been rapid, and hyper-realistic forged videos are based on Deepfake techniques. It leads to a loss of trust in videos' content and makes it malicious by spreading forged videos on the internet. Until now, there are a few algorithms that have been suggested for detecting forged videos created by Deepfake techniques, but most of them based on analyzing or learning features on frames separately in a video. Those algorithms often pay less attention to Spatio-temporal features, so these algorithms' accuracy is usually not good. This paper proposes a 3-dimensional (3-D) convolutional neural network model that can learn Spatio-temporal features from an adjacent frame sequence in a video. Our proposed network's binary detection accuracy reached over 99% on the two largest benchmark datasets as Deepfake of FaceForensics++ and VidTIMIT datasets. The experimental results of the proposed method outperform state-of-the-art methods.;Video forensic, Deepfake video detection, Autoencoder-decoder, Generative adversarial networks, Deep learning, 3-D convolutional neural network;ScienceDirect
128;GAN-CNN Ensemble: A Robust Deepfake Detection Model of Social Media Images Using Minimized Catastrophic Forgetting and Generative Replay Technique;Preeti Sharma and Manoj Kumar and Hitesh Kumar Sharma;2024;Deep-fake photographs are difficult to discern from real ones, especially when utilized in social media platforms. Anyone can willfully create disinformation about public personalities, politicians, and celebrities using these deep fake photographs. So, it is an important need of society to work for an effective model for its detection. The models for deep fake detection commonly use CNN-based detectors. These detectors experience a drop in performance when used for transfer learning or continual learning techniques. A significant limitation in this process is CNN's catastrophe forgetting defect. For the solution of this problem, a Generative replay technique in the form of a GAN-CNN model is implemented that works to minimize this catastrophe forgetting issue that further helps for better detection. It involves generating and storing samples from previous tasks and then replaying them during the training of new tasks which makes CNN more robust to identify deep fakes. The GAN model used in this work is traditional DCGAN improved with necessary adjustments to achieve training stability. It is observed that the model attained a good accuracy of 98.67%(training),70.08% (testing) and minimum loss with a value of 0. 0337 for 100 epochs. Also, it acquired good precision values of 68% and 72%, Recall values are 74% and 66%, and F1 scores of 71% and 69% for classes 0 and 1 respectively. The model outcome is found stable and reliable in deep fake detection under dynamic training conditions. Optimum values of evaluation parameters ensure the model's capacity to learn new tasks preserving the existing task-learning knowledge.;"Deep Learning, CNN;GAN;Catastrophe forgetting;CNN continual learning;Lifelong learning, GAN-CNN deep fake detector";ScienceDirect
130;Watching the BiG artifacts: Exposing DeepFake videos via Bi-granularity artifacts;Han Chen and Yuezun Li and Dongdong Lin and Bin Li and Junqiang Wu;2023;Recent years have witnessed significant advances in AI-based face manipulation techniques, known as DeepFakes, which has brought severe threats to society. Hence, an emerging and increasingly important research topic is how to detect DeepFake videos. In this paper, we propose a new DeepFake detection method based on Bi-granularity artifacts (BiG-Arts). We observe that the most of DeepFake video generation can commonly introduce bi-granularity artifacts: the intrinsic-granularity artifacts and extrinsic-granularity artifacts. Specifically, the intrinsic-granularity artifacts are caused by a common series of operations in model generation such as up-convolution or up-sampling, while the extrinsic-granularity artifacts are introduced by a common step in post-processing that blends the synthesized face to original video. To this end, we formulate DeepFake detection as multi-task learning problem, to simultaneously predict the intrinsic and extrinsic artifacts. Benefiting from the guidance of detecting Bi-granularity artifacts, our method is notably boosted in both within-datasets and cross-datasets scenarios. Extensive experiments are conducted on several DeepFake datasets, which corroborates the superiority of our method. Our method has been contributed as a part of the solution to achieve the Top-1 rank in DFGC competition (https://competitions.codalab.org/competitions/29583).;Multimedia forensics, Deepfake detection, Granularity artifacts, Multi-task learning;ScienceDirect
134;Deepfake detection: Enhancing performance with spatiotemporal texture and deep learning feature fusion;Abdelwahab Almestekawy and Hala H. Zayed and Ahmed Taha;2024;Deepfakes bring critical ethical issues about consent, authenticity, and the manipulation of digital content. Identifying Deepfake videos is one step towards fighting their malicious uses. While the previous works introduced accurate methods for Deepfake detection, the stability of the proposed methods is rarely discussed. The problem statement of this paper is to build a stable model for Deepfake detection. The results of the model should be reproducible. In other words, if other researchers repeat the same experiments, the results should not differ. The proposed technique combines multiple spatiotemporal textures and deep learning-based features. An enhanced 3D Convolutional Neural Network, which contains a spatiotemporal attention layer, is utilized in a Siamese architecture. Various analyses are carried out on the control parameters, feature importance, and reproducibility of results. Our technique is tested on four datasets: Celeb-DF, FaceForensics++, DeepfakeTIMIT, and FaceShifter. The results demonstrate that a Siamese architecture can improve the accuracy of 3D Convolutional Neural Networks by 7.9�% and reduce the standard deviation of accuracy to 0.016, which indicates reproducible results. Furthermore, adding texture features enhances accuracy by up to 91.96�%. The final model can achieve an Area Under Curve (AUC) up to 97.51�% and 95.44�% in same-dataset and cross-dataset scenarios, respectively. The main contributions of this work are the enhancement of model stability and the assurance of result repeatability, ensuring consistent results with high accuracy.;Deepfake detection, Deep learning, 3D CNN, Siamese architecture;ScienceDirect
135;Reducing Dataset Specificity for Deepfakes Using Ensemble Learning;Qaiser Abbas and Turki Alghamdi and Yazed Alsaawy and Tahir Alyas and Ali Alzahrani and Khawar Iqbal Malik and Saira Bibi;2022;The emergence of deep fake videos in recent years has made image falsification a real danger. A person�s face and emotions are deep-faked in a video or speech and are substituted with a different face or voice employing deep learning to analyze speech or emotional content. Because of how clever these videos are frequently, Manipulation is challenging to spot. Social media are the most frequent and dangerous targets since they are weak outlets that are open to extortion or slander a human. In earlier times, it was not so easy to alter the videos, which required expertise in the domain and time. Nowadays, the generation of fake videos has become easier and with a high level of realism in the video. Deepfakes are forgeries and altered visual data that appear in still photos or video footage. Numerous automatic identification systems have been developed to solve this issue, however they are constrained to certain datasets and perform poorly when applied to different datasets. This study aims to develop an ensemble learning model utilizing a convolutional neural network (CNN) to handle deepfakes or Face2Face. We employed ensemble learning, a technique combining many classifiers to achieve higher prediction performance than a single classifier, boosting the model�s accuracy. The performance of the generated model is evaluated on Face Forensics. This work is about building a new powerful model for automatically identifying deep fake videos with the DeepFake-Detection-Challenges (DFDC) dataset. We test our model using the DFDC, one of the most difficult datasets and get an accuracy of 96%.;Deep machine learning, deep fake, CNN, DFDC, ensemble learning;ScienceDirect
137;Deepfake Detection Using Machine Learning Algorithms;"M. S. Rana; B. Murali; A. H. Sung";2021;Deepfake, a new video manipulation technique, has drawn much attention recently. Among the unlawful or nefarious applications, Deepfake has been used for spreading misinformation, fomenting political discord, smearing opponents, or even blackmailing. As the technology becomes more sophisticated and the apps for creating them ever more available, detecting Deepfake has become a challenging task, and accordingly researchers have proposed various deep learning (DL) methods for detection. Though the DL-based approach can achieve good solutions, this paper presents the results of our study indicating that traditional machine learning (ML) techniques alone can obtain superior performance in detecting Deepfake. The ML-based approach is based on the standard methods of feature development and feature selection, followed by training, tuning, and testing an ML classifier. The advantage of the ML approach is that it allows better understandability and interpretability of the model with reduced computational cost. We present results on several Deepfake datasets that are obtained relatively fast with comparable or superior performance to the state-of-the-art DL-based methods: 99.84% accuracy on FaceForecics++, 99.38% accuracy on DFDC, 99.66% accuracy on VDFD, and 99.43% on Celeb-DF datasets. Our results suggest that an effective system for detecting Deepfakes can be built using traditional ML methods.;"Deepfake;Deep Learning;Machine Learning;Face Manipulation";IEEE
138;A Novel Approach for Detecting Deepfake Face Using Machine Learning Algorithms;"M. Kumar; P. K. Rai; P. Kumar";2024;In today's digital age, the ability to identify, differentiate, and authenticate manipulated online content is essential. Being ability to discriminate between the real and the fake is crucial. Recent advances in technologies such as artificial intelligence, machine learning, and deep learning are playing a major role in the generation of deepfake media (images and videos). Very realistic deep fake images and videos can be produced by utilizing sophisticated deep learning models such as generative adversarial neural networks (GAN s) and autoencoders, in conjunction with a sizable image collection pertaining to the subject matter. Deepfakes (DF) refer to artificially synthesized images or videos created using features such as face swapping and facial expression recombination. These face manipulation techniques have become extremely sophisticated. Deepfakes can be used to create child pornography, pornographic images of celebrities, revenge porn, fake news and harassment, spreading disinformation on social media platforms, financial fraud, election manipulation, and more. Therefore, there is a need to design and develop a robust framework to identify these deepfake images and videos. The purpose of this paper is to identify deepfakes from visual deepfake datasets and perform a comparative analysis of deep fake detection through machine learning algorithms.;"Deepfake;Artificial Intelligence (AI);Machine Learning (ML);Deep Learning;Generative Adversarial Neural Networks (GANs);Face Swapping";IEEE
141;A Comparative Study: Deepfake Detection Using Deep-learning;"N. Khatri; V. Borar; R. Garg";2023;"In recent decades, we have seen significant advancement in fields like Artificial Intelligence, Machine Learning, and Deep Learning, resulting in the developing of new technologies such as deepfake. Deepfakes are a form of digital media that replaces one identity�s likeness with another or creates a synthetic personality: in the form of high-quality realistic fake video, image, or audio. Deepfakes can be helpful in education, art, activism, and self-expression; however, some subjects can use deepfakes to harm the portrayal of people, create pornographic content, and spread misleading information. High-quality deepfakes are easy to build but incredibly difficult to detect, creating a need to explore technologies which can be helpful in deepfake detection. Therefore, we present a comparative study of deep-learning models that can benefit deepfake detection. We have explored four deep-learning models, namely, VGG16, MobileNetV2, XceptionNet, and InceptionV3 and trained these models on the FaceForensics++ dataset. Finally, we evaluate the performance of these models for deepfake detection and conclude the study with our observations and future scope for improvement in this field.";"deepfake detection;computer vision;deep learning;image classification;convolutional neural networks";IEEE
142;DeepFake Detection Using Error Level Analysis and Deep Learning;"R. Rafique; M. Nawaz; H. Kibriya; M. Masood";2021;The image recognition software is used in numerous distinctive industries that include entertainment and media. The deep learning (DL) algorithms have been of great help in the development of several techniques used for creating, altering, and locating any data. The deepfake method is a photo-faking technique that includes replacing two people's faces to an extent that it becomes very difficult to identify it with a naked eye. The convolution neural network (CNN) models including Alex Net and Shuffle Net are used to recognize genuine and counterfeit face images in this article. The technique analyzes the performance and working of all distinctive algorithms using the real/fake face recognition collection from Yonsei University's Computational Intelligence Photography Lab. The first step in the process starts by the normalizing of pictures then the Error Level Analysis is carried out before it is put into several difference CNN models. Then the in-depth features are extracted from the CNN models utilizing the Support Vector Machine and the K-nearest neighbor methods. The most perfect accuracy of 88.2% of Shuffle Net via KNN was analyzed while Alex Net's vector had the accuracy of 86.8%.;"Deep Learning;Machine Learning;CNN;Deepfake Detection;SVM;KNN";IEEE
145;Advanced Deepfake Detection using Machine Learning Algorithms: A Statistical Analysis and Performance Comparison;"M. S. Rana; A. H. Sung";2024;As techniques and tools for synthetic media and Deepfakes continue to advance, it is increasingly clear that video, audio and images can no longer be relied upon as truthful recordings of reality. Every digital communication channel is now vulnerable to manipulation, and there is widespread use of Deepfakes to propagate misinformation and disinformation, inflame political discord, defame opposition, commit cyber frauds or blackmail individuals. While deep learning (DL) methods have been widely used to identify Deepfakes, this paper demonstrates that classical machine learning (ML) methods can achieve superior performance--comparable with or exceeding state-of-the-art DL methods in detecting Deepfakes. Using the traditional procedures of feature development and selection, training, and testing of ML classifiers for the task actually provides better understandability and interpretability while consuming much less computing resource. In addition, an omnibus test, the Analysis of Variance (ANOVA), is conducted to compare the performance of multiple ML models. We present experiments that achieve 99.84% accuracy on the FaceForecics++ dataset, 99.38% accuracy on the DFDC dataset, 99.66% accuracy on the VDFD dataset, and 99.43% accuracy on the Celeb-DF dataset. Our study thus challenges the notion that DL approaches are the only effective way to detect Deepfakes and demonstrates that judicious use of ML approaches can be highly efficacious and cost-effective.;"Deepfakes;Deepfake Detection;Face Manipulation;Machine Learning;Analysis of Variance;Omnibus Test";IEEE
146;Facial Action Unit-Based Deepfake Video Detection Using Deep Learning;"Q. Jaleel; I. Hadi";2022;Deepfake videos are becoming more realistic, making them a menace. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Widespread use of falsified videos and images on social media requires accurate detection. An identity switch (DeepFake) and an expression swap create facial modifications. This paper can detect deepfakes that are perfectly created. Traditional detection approaches that observe artifacts and pixel irregularities cannot keep up with modern technology. The paper is divided into two stages. In the first stage, the paper extracts facial action units from a person and creates a profile for him. This profile represents the behavior of his facial expressions, which differ from one person to another. This was done by building a deep learning network and training it based on a dataset. The second stage is testing, which involves taking videos, extracting facial action units, and testing them on the network to classify them as fake or real. The network has proven its ability to classify with high accuracy of %95.75 compared to traditional methods.;"GAN;facial action unit;Facial expression recognition;Media Forensics;DeepFake Detection;face detection";IEEE
147;Synthetic Content Detection in Deepfake Video using Deep Learning;"K. Jalui; A. Jagtap; S. Sharma; G. Mary; R. Fernandes; M. Kolhekar";2022;In recent years, significant improvements in the field of deep learning have promoted the development of highly realistic AI-based video manipulation and forgery technologies commonly known as �DeepFake� using Autoencoders and Generative Adversarial Networks (GANs). Although this technology has its own set of beneficial applications, it decreases the integrity of digital visual media and can have serious sociopolitical implications. With new improving video manipulation tools, the detection of deepfake is a major challenge. According to the recent surveys that are reported, the deepfake systems are able to give a decision about whether a given video contains fake content or not. The objective of our project is to identify the presence of deepfake content in the digital video and report the same. Our system uses ResNext Convolution Neural Network for extracting the features of the video at frame level and Long Short-Term Memory (LSTM) for training a model to classify if a video is deepfake or pristine. We have trained the network using Deepfake Detection Challenge dataset. The result along with the confidence score of the model is shown to the user using a simple graphical user interface.;"Deep Fake Detection;Deep Learning;Auto Encoders;Generative Adversarial Networks;Convolution Neural Network (CNN);Long Short-Term Memory (LSTM)";IEEE
148;AI Based Deepfake Detection;"A. Garde; S. Suratkar; F. Kazi";2022;Advances in machine learning, especially following the 2014 release of Generative Adversarial Networks, have allowed techniques and methods to be used for nefarious ends. Generative Adversarial Networks can even create fake images and videos which appears to be real to human eyes. Generative Adversarial Networks can swap the faces of two different people. For film producers or graphic designers, this tool is quite useful. Face swapping has been done in movies to replace the real person's face with that of the actor. A computer-generated versions of actors Carrie Fisher and Peter Cushing have been featured in a movie named �Star Wars: The Rise of Skywalker� from the �Star wars� film series just like they appeared in the 1977 original, while other Marvel films have �de-aged� actors such as Michael Douglas and Robert Downey Jr. However, this has the potential to be misused. By producing ultra-realistic Deep Fake videos using various trailblazing machine learning techniques, felon are trying to harass, blackmail the innocents. It can also be used to induce political instability by disseminating erroneous information, which can cause communal, diplomatic, and violent outbreak with disastrous consequences. This gives rise to a significant menaces to security of the person as well as national defence, necessitating the development of automated methods for detecting deep fake videos. The eye blinking pattern in deepfaked videos is not formed as naturally as it should be due to the incapability of Generative Adversarial Networks. This will come in handy when constructing a deepfake detecting algorithm. The project uses an object's eye blinking pattern to determine whether or not a video is deepfaked.;"Deep-Fake;GANs;Deep Learning;Eye blinking;Convolutional Neural Networks;SVM";IEEE
149;Security Strengthen and Detection of Deepfake Videos and Images Using Deep Learning Techniques;"S. Talreja; A. Bindle; V. Kumar; I. Budhiraja; P. Bhattacharya";2024;The identification of fraudulent movies or images created using deep learning algorithms is the subject of this research and attempts an in-depth investigation of Deepfake Detection. Deepfakes are created by manipulating or replacing certain parts of an original video or image using machine learning algorithms, usually concentrating on face features. Deepfake detection's main goal is to precisely recognize and distinguish these altered media from real movies and photos. This study looks at a number of deepfake detection techniques, including forensic methods, machine learning algorithms, and picture analysis. These approaches' efficiency and performance are assessed based on their capacity to accurately identify and categories deep-fakes. The paper also examines the difficulties and restrictions of deepfake detection, such as the development of more complex and convincing deepfakes. Further, prospective uses and future possibilities for deepfake detection research are examined, with an emphasis on improving detection skills and creating effective countermeasures. Overall, this research offers insightful information about cutting-edge methods and developments in Deepfake Detection, giving a greater comprehension of its importance in resolving the issues brought on by manipulated media in the current digital era.;"DeepFake Detection;Deep Learning;Machine Learning";IEEE
152;Detection of Deep-Morphed Deepfake Images to Make Robust Automatic Facial Recognition Systems;"A. Mitra; S. P. Mohanty; P. Corcoran; E. Kougianos";2021;Face Morphing has emerged as a pervasive attack of Facial Recognition Systems. The rapid growth of Generative Adversarial Networks takes it to a complete new level. Deepfake or deep neural network based face morphing, a.k.a deep-morph attack, presents a significant threat to Facial Recognition System. In this paper, we propose a novel Convolutional Neural Network based detection method of deep morphed deepfake images which is suitable for IoT environments in smart cities. A high accuracy of 94.83% has been achieved for the DeepfakeTIMIT HQ dataset. This lightweight and fast network is a natural choice for IoT environments.;"Smart City;Facial recognition System;Deep-fake;Deep-Morph;Deep Learning;Convolutional Neural Network";IEEE
153;Unmasking Deepfake Faces from Videos Using An Explainable Cost-Sensitive Deep Learning Approach;"F. Mahmud; Y. Abdullah; M. Islam; T. Aziz";2023;Deepfake technology is widely used, which has led to serious worries about the authenticity of digital media, making the need for trustworthy deepfake face recognition techniques more urgent than ever. This study employs a resource-effective and transparent cost-sensitive deep learning method to effectively detect deepfake faces in videos. To create a reliable deepfake detection system, four pre-trained Convolutional Neural Network (CNN) models: XceptionNet, InceptionResNetV2, EfficientNetV2S, and EfficientNetV2M were used. FaceForensics++ and CelebDf-V2 as benchmark datasets were used to assess the performance of our method. To efficiently process video data, key frame extraction was used as a feature extraction technique. Our main contribution is to show the model�s adaptability and effectiveness in correctly identifying deepfake faces in videos. Furthermore, a cost-sensitive neural network method was applied to solve the dataset imbalance issue that arises frequently in deepfake detection. The XceptionNet model on the CelebDf-V2 dataset gave the proposed methodology a 98% accuracy, which was the highest possible whereas, the InceptionResNetV2 model, achieves an accuracy of 94% on the FaceForensics++ dataset. Source Code: https://github.com/Faysal-MD/Unmasking-Deepfake-Faces-from-Videos-An-Explainable-Cost-Sensitive-Deep-Learning-Approach-IEEE2023;"Deepfake video;Keyframe;Explainable AI (XAI);Cost-sensitive;Face Detection;CelebDf;FaceForensics++;CNN";IEEE
155;Enhanced Preprocessing Stage For Feature Extraction of Deepfake Detection Based on Deep Learning Methods;"M. A. Abdulhamid; A. N. Hashim";2023;Biometric identities are at risk of deepfake facial manipulation. Over the past few years, deepfake detection has been the subject of extensive research, most which centered on the application of machine learning strategies. However, the recognition of deepfake is still one of the most challenging problems in computer vision today. Deep learning has recently gained popularity due to its potential to solve a wide range of real-world problems, including detecting deepfakes. Our research focused on improving feature extraction methods by using deep learning and comparing preprocessing methods to show how they affect detection performance. A preprocessing approach was proposed to improve the regions of interest (ROIs) used to feed Moodle feature extraction. The proposed algorithmic approach involves finding one key frame extracted from a video by using the oriented fast and rotated brief algorithm, detecting the face oval region using the DLIB library as an ROI and performing quality improvement via contrast-limited adaptive histogram equalization (CLAHE)/adaptive histogram equalization (AHE) and comparing them. On the FaceForensics ++ dataset, CLAHE demonstrated superior performance compared with AHE with InceptionV3 as a feature extractor. The final classification result had an accuracy ratio of 89%, and the area under the curve was measured to be 77%.;"Preprocessing;Deepfake;Histogram equalization;Machine learning";IEEE
156;DFFMD: A Deepfake Face Mask Dataset for Infectious Disease Era With Deepfake Detection Algorithms;"N. M. Alnaim; Z. M. Almutairi; M. S. Alsuwat; H. H. Alalawi; A. Alshobaili; F. S. Alenezi";2023;Deepfake is a technology that creates fake images and videos with replaced or synthesized faces. Deepfakes are becoming a concerning social phenomenon, as they can be maliciously used to generate false political news, disseminate dangerous information, falsify electronic evidence, and commit digital harassment and fraud. The ease and accuracy of creating Deepfakes have been bolstered by the popularity of wearing face masks since the beginning of the infectious disease outbreak (2020). Because these masks obstruct defining facial features, fake videos are now even more challenging to identify, increasing the necessity for advanced Deepfake detection technology. The research also creates a real/fake video dataset with face masks because the field lacks the dataset required for detection-model training. The proposed research proposes a Deepfake Face Mask Dataset (DFFMD) based on a novel Inception-ResNet-v2 with preprocessing stages, feature-based, residual connection, and batch normalization. The combination of preprocessing stages, feature-based, residual connection, and batch normalization increases the detection accuracy of deepfake videos in the presence of facemasks, unlike the traditional methods. The study�s results compared with existing state-of-the-art methods detect face-mask-Deepfakes with 99.81% accuracy compared to the traditional InceptionResNetV2 and VGG19, whose accuracy is 77.48%, and 99.25%, respectively. Future work should evaluate the accuracy of developing a subsequent experimental work for increased detection of deepfake with facemasks.;"Deepfake;deep learning;CNN;generation;detection;fake videos;neural network;mask;face mask";IEEE
157;Combining Deep Learning and Super-Resolution Algorithms for Deep Fake Detection;"N. S. Ivanov; A. V. Arzhskov; V. G. Ivanenko";2020;Deep Fake is a technique for human image synthesis based on artificial intelligence. In this article is explored the problem of Deep Fake Video content and its detection. Has been gathered information about previous attempts, analyzed methods used by different researches and considered their actuality right now. Basing on results of the discovery was designed strategy to expose Deep Fake videos that combines previous detection methods with super-resolution algorithms. Results of the research were compared with expected, so recommendations and possible way of continuing developments were given.;"deep fake detection;deep learning;neural networks;super-resolution algorithms";IEEE
158;Deep Fake Detection using Adversarial Ensemble Techniques;"B. V. Chowdary; M. Prabhakar; M. Akhil; K. Pavan; B. P. T. Reddy";2024;The rise of deepfake technology has resulted in unprecedented challenges in the field of digital media verification, posing significant threats to personal security, misinformation, and trust in digital content. In response to this pressing issue, this study presents an advanced deepfake detection system using deep learning approach. Specifically, the proposed system integrates ResNeXt and Long Short-Term Memory (LSTM) architectures to accurately identify the manipulated content. By leveraging the spatial-temporal features captured by these combined architectures, the proposed system aims to enhance the detection rate of deepfakes across various media formats. The proposed approach offers a robust solution to counteract the evolving sophistication of deepfake technology, thereby enhancing the integrity and authenticity of digital media content.;"Deepfake Detection;Deep Learning;ResNeXt;LSTM;Digital Media Verification";IEEE
159;Deepfake video detection using InceptionResnetV2;"S. Guefrechi; M. B. Jabra; H. Hamam";2022;Recently, deepfake face-swapping technology has become popular, making it easy to create ultra-realistic fake videos. Detecting the authenticity of videos is becoming increasingly important due to the potential negative impact videos can have on the world. This research is a method for developing a deep learning model, which can make a distinction between real and fake videos. Research papers on the subject of transfer learning in the domain of computer vision to take advantage of the earlier created neural network functions for image classification and to create new models based on them. Deep learning continues to evolve in both generating and detecting deepfakes. Models developed to detect deepfakes are designed using older datasets, may become outdated over time, and require new detection techniques all the time. Research results are promising with over 90% accuracy and areas for development and further development;"Deepfake;Video authenticity;Deepfake detection;Fine-tuning;InceptionResnet-V2";IEEE
163;Guardian AI: Synthetic Media Forensics through Multimodal Fusion and Advanced Machine Learning;"K. K; S. R; D. S; D. S";2024;"The burgeoning spread of synthetic media disrupts content verification and threatens online trust. This research proposes Guardian AI, a robust deepfake detection system achieving 93% accuracy by harnessing the synergistic power of facial recognition, image forensics, and machine learning. Guardian AI extracts diverse features from videos: facial recognition models analyze landmarks, expressions, and lip-syncing for inconsistencies; image forensics algorithms detect manipulated pixels, lighting patterns, and compression artifacts; and temporal analysis captures unnatural head movements and frame-to-frame motion discrepancies. These multifaceted features are then fused and fed into a rigorously trained deep learning model on multi-modal datasets of real and deepfake videos. Guardian AI classifies video inputs as real or fake, providing a confidence score for its prediction. By leveraging facial recognition's subtle inconsistency detection, image forensics' manipulation artifact identification, and machine learning's robust multi-cue integration, Guardian AI achieves exceptional accuracy and generalizability, adapting to evolving deepfake creation techniques with its diverse training data. This study signifies a significant contribution to content verification by delivering a high accuracy deepfake detection system, paving the way for a more reliable and trustworthy online environment.";"Deepfake Detection;Facial Recognition;Image Forensics;Machine Learning;Multimodal Fusion;Content Verification";IEEE
164;Hybrid Recurrent Deep Learning Model for DeepFake Video Detection;G. Jaiswal;2021;Nowadays deepfake videos are concern with social ethics, privacy and security. Deepfake videos are synthetically generated videos that are generated by modifying the facial features and audio features to impose one person�s facial data and audio to other videos. These videos can be used for defaming and fraud. So, counter these types of manipulations and threats, detection of deepfake video is needed. This paper proposes multilayer hybrid recurrent deep learning models for deepfake video detection. Proposed models exploit the noise-based temporal facial convolutional features and temporal learning of hybrid recurrent deep learning models. Experiment results of these models demonstrate its performance over stacked recurrent deep learning models.;"Deepfake detection;Hybrid Recurrent model;Deep learning;Deepfake video;video temporal feature";IEEE
165;A Detect method for deepfake video based on full face recognition;"K. Feng; J. Wu; M. Tian";2020;In recent years, with the continuous upgrading of computer hardware and the continuous development of deep learning technology, new multimedia tampering tools can make it easier for people to tamper with faces in videos. Tampered videos produced by these new tools may hardly be detected by human, so we need effective method to detect these face-tampered videos. Current popular video face tampering technologies mainly include Deepfake technology based on self-encoder and Face2face technology based on computer graphics. In this paper, we propose a new method for tamper video detection based on the full faces. Facenet algorithm is used here to compare the similarity between real and fake video faces. Finally, in the experimental part, the results showed a significant effect.;"deepfake;facenet;convolution network;machine learning";IEEE
166;Development of Deepfake Detection Techniques for Protecting Multimedia Information using Deep Learning;"N. Siva Rama Lingham; J. J. M. A. Devakanth; G. Raj; K. Gayathri; R. Janani; R. Dhanapal";2024;The development of proposed deepfake detection techniques plays a prominent role in the safeguarding the multimedia information. The various challenges are addressed using the aid of deep learning techniques. This involves hybrid optimization techniques such as particle swarm optimization and genetic algorithms. This helps to improve the accuracy and efficiency in the detection of deepfake. PSO helps in optimizing the weights and parameters of the neural network to obtain faster convergence. GA helps in obtaining potential solutions to obtain the robust deepfake detection model. The integration of deep learning with hybrid optimization involves the collection and preprocessing of the multimedia information and proceeds to an optimization algorithm. The manipulated content in the online platform are detected during the training process. The hybrid optimization tcehniques helps in obtaining model generability and achieving resilience in various attacks occurring in the deepfake generation. The integration of PSO and GA helps in the accurate detection of deepfake content through continuous training and evaluation. Thus the proposed system forms a safeguarding tool for multimedia content and helps to eliminate various risks.;"Deepfake;Deep learning techniques;Optimization algorithm;Genetic algorithm;Particle swarm optimization;Multimedia content";IEEE
168;A Measurement Study on Gray Channel-based Deepfake Detection;"S. B. Son; S. H. Park; Y. K. Lee";2021;Deepfake detection techniques have been widely studied to resolve security issues. However, existing techniques mainly focused on RGB channel-based analysis, which still shows incomplete detection accuracy. In this paper, we validate the performance of Gray channel-based deepfake detection. To compare RGB channel-based analysis and Gray channel-based analysis in deepfake detection, we quantitatively measured the performance by using popular CNN models, deepfake datasets, and evaluation indicators. Our experimental results confirm that Gray channel-based deepfake detection outperforms RGB channel-based deepfake detection in terms of accuracy and analysis time.;"deepfake detection;gray-channel analysis;deep learning;deepfake";IEEE
169;Deepfake Image Detection Using Vision Transformer Models;"B. Ghita; I. Kuzminykh; A. Usama; T. Bakhshi; J. Marchang";2024;"[none]hyphenat Deepfake images are causing an increasing negative impact on the day to day life and pose significant challenges for the society. There are various categories of deepfake images as the technology evolves and becomes more accessible. In parallel, deepfake detection methods are also improving, from basic features analysis to pairwise analysis and deep learning; nevertheless, to date, there is no consistent method able to fully detect such images. This study aims to provide an overview of existing methods of deepfake detection in the literature and investigate the accuracy of models based on Vision Transformer (VIT) when analysing and detecting deepfake images. We implement a VIT model-based deepfake detection technique, which is trained and tasted on a mixed real and deepfake images dataset from Kaggle, containing 40000 images. The results show that The VIT model scores relatively high, 89.9125 %, which demonstrates its potential but also highlights there is significant room for improvement. Preliminary tests also highlight the importance of a large dataset for training and the fast convergence of the model. When compared with other deepfake machine learning and deep learning detection methods, the performance of the ViT model is in line with prior research and warrants further investigation in order to evaluate its full potential.";"deepfake images;deepfake detection;Vision Transformer model";IEEE
171;An Improved DeepFake Detection Approach with NASNetLarge CNN;"?. ?lhan; E. Bal?; M. Karak�se";2022;Deep fake images are a new technology that has emerged with the development of computer vision and deep learning technologies in recent years. The development of these deep fake technologies has led to the production of many fake or manipulated products. Thus, the problem of detecting the deep fake has emerged and many methods have been developed to solve this problem. In this study, feature extraction and classification method on the dataset with NASNetLarge CNN deep learning model is proposed and a successful result is produced. In the proposed method, training and test datasets were created by removing facial regions from the video frames in the Celeb-DFv2 dataset. The architecture of the NASNetLarge model is explained and the success of the model is tested. According to the test results, an ACC value of 96.7% was obtained and compared with other methods. As a result, the study offers an easier model training with a smaller dataset than other methods and produces a competitive and successful result.;"deepfake;manipulation;detection;NASNetLarge;image classification;video detection";IEEE
172;Deepfake Video Detection Based on Convolutional Neural Networks;"S. R. Adnan; H. A. Abdulbaqi";2022;"The increasing use of mobile camera technology and the growth of social media using and sharing have made the generation and publishing of digital videos more suitable than ever before. However, the manipulation and fabrication of videos have decreased in recent years, because of machine learning and computer vision techniques. This study uses the detection method that applies by comparing the areas of the generated face and their surrounding areas with the Convolutional Neural Network (CNN) Model. The model was applied to the DFDC dataset with different 60 clips for real and fake. The methodology of this work passes through three stages, the first stage pass through preprocessing to convert each video into frames and detect the face in each frame and then be cropped by Haar Cascade function; in the feature's extraction stage the ResNet-50 is applied as the feature extraction model. In the last stage, the CNN classifier for detecting whether the image is fake or real. From the experiment, The Deepfake detection method detects the fake face in the video, where the detection accuracy was achieved at 98%.";"CNN;Deepfake video;DFDC;ResNet-50;Deep learning";IEEE
173;Improving Deepfake Detection by Mixing Top Solutions of the DFDC;"A. Trabelsi; M. M. Pic; J. -L. Dugelay";2022;The falsification of faces in videos is a growing phenomenon over the years. One of the most popular ways to tamper a face in a video is known as �deepfake�, Today, many tools exist to allow anyone to create a deepfake to discredit an individual or usurp an identity. Fortunately, the detection of deepfakes is an increasing topic of interest for the scientific community. As a result, many efforts have been made to develop mechanisms to automatically identify deepfake videos. In addition, several public deepfakes datasets have been built to help researchers to develop more effective detection methods. The most recent and also the most complete of these datasets is the one built by Facebook as part of the international DeepFake Detection Challenge (DFDC). Thousands of different frameworks, mainly based on deep learning, have been proposed during this challenge. The best solution that has been proposed obtains the accuracy of 82% on the DFDC dataset. However, the accuracy of this method is only 65% on unseen videos from the Internet. In this paper we analyse the five best methods of the DFDC and their complementarity. In addition, we experimented different assembly strategies (boosting, bagging and stacking) among these solutions. We show that we can achieve a large improvement $(+ 41\%$ on log loss and $+2.26\%$ on accuracy) when we carefully choose the models to be assembled with the most appropriate right merging method to use.;"deepfake detection;deepfake detection challenge;ensembling";IEEE
174;A Heterogeneous Feature Ensemble Learning based Deepfake Detection Method;"J. Zhang; K. Cheng; G. Sovernigo; X. Lin";2022;The Deepfake technique can swap the face of a person with the face of another person in an image or a video which may cause a public security problem. Recently, researchers have focused on detecting deepfake images by deep learning. However some recent works have observed that detectors trained on images produced by one deepfake model perform poorly when tested on others. In this paper we propose to detect deepfake images through heterogeneous feature ensemble learning. We first extract gray gradient features, spectrum features and texture features from real and fake face images, then integrate them into an ensemble feature vector through a flatten process, and finally adopt a back-propagation neural network to train a deepfake detector with the feature vector. Experimental results show that our approach achieves better detection accuracy compared with several state-of-the-art deepfake detectors.;"Deepfake detection;Ensemble Learning;Heterogeneous Feature;Neural Network";IEEE
176;Short And Low Resolution Deepfake Video Detection Using CNN;"A. Rahman; N. Siddique; M. J. Moon; T. Tasnim; M. Islam; M. Shahiduzzaman; S. Ahmed";2022;Recently, convincing deepfake videos are growing very fast that can delude even the trained experts. These deepfake videos have huge impacts all over the world covering the political, social, and personal lives. The state-of-the-art machine learning studies are demonstrating noticeable success to detect fake videos in high resolution and long-time video data while the same performance is not observed in low resolution and short-time clips. In this work, we have trained a convolutional neural network (CNN) that demonstrates mentionable accuracy in detecting fake videos in low-resolution and short-time video data. We have exploited Kaggle Deepfake Detection Challenge (DFDC) and the Face Forensics++ datasets in our experiment. Our model shows 94.93% accuracy in detecting fake videos for the DFDC dataset while the same is 93.2% for FaceForensics++ Dataset. We evaluated our models by different performance metrics and compared the performance with state-of-the-art methods. Our model demonstrates comparable performance.;"Deepfake Video;Machine-Learning;dlib;Convolutional Neural Network(CNN);Deepfake-Detection-Challenge(DFDC);FaceForensics++";IEEE
177;Deepfake Detection System Using Deep Neural Networks;"M. L. Saini; A. Patnaik; Mahadev; D. C. Sati; R. Kumar";2024;The rapid progress in technology and automation has enabled sophisticated manipulation of multimedia content, blurring the line between real and fabricated media. Deepfake technology, driven by deep learning and Generative Adversarial Networks (GANs), creates hyper-realistic fake content, with applications spanning video games, films, and advertising. However, this technology also carries substantial societal risks, fostering misinformation and explicit content. To mitigate these concerns, this paper presents a Deepfake detection system that utilizes deep neural networks to discern genuine from forged images. Frames are extracted from videos and face detection and face cropped are performed. LSTM and ResNext CNN are utilized to generate a feature vector. The proposed system uses the Anvil platform to design the front end and Visual Studio and Jupyter Notebook for the back end. A publicly available dataset was used to train and test the model. The proposed model achieved an impressive 86% accuracy on video dataset.;"Deepfake;Fake contents;Deep Neural Networks;Generative Adversarial Networks (GANs);Anvil Platform";IEEE
180;Explaining Deep Learning Models for Spoofing and Deepfake Detection with Shapley Additive Explanations;"W. Ge; J. Patino; M. Todisco; N. Evans";2022;Substantial progress in spoofing and deepfake detection has been made in recent years. Nonetheless, the community has yet to make notable inroads in providing an explanation for how a classifier produces its output. The dominance of black box spoofing detection solutions is at further odds with the drive toward trustworthy, explainable artificial intelligence. This paper describes our use of SHapley Additive exPlanations (SHAP) to gain new insights in spoofing detection. We demonstrate use of the tool in revealing unexpected classifier behaviour, the artefacts that contribute most to classifier outputs and differences in the behaviour of competing spoofing detection models. The tool is both efficient and flexible, being readily applicable to a host of different architecture models in addition to related, different applications. All results reported in the paper are reproducible using open-source software.;"spoofing;presentation attack detection;explainability;Shapley additive explanations;ASVspoof";IEEE
181;Employing Super Resolution to Improve Low-Quality Deepfake Detection;"A. S. Perera; A. S. Atukorale; P. Kumarasinghe";2022;The rapid progress in deepfake content generation has now come to a point where it raises significant concerns about the implications for society. Therefore, a new challenge of detecting deepfakes arises to protect individuals from potential misuse. Even though introduced detection algorithms perform well on high-quality deepfakes, detecting low-quality deepfakes has been challenging. As a remedy, researchers try to feed more training data to increase detection ability. HoWever, providing more data and processing them is not always feasible in a practical scenario. Thus, for the first time in this domain, we propose to employ super-resolution (SR) as a preprocessing step instead of feeding more data to improve low-quality deepfake detection. Extensive experiments were conducted on the FaceForensics++ deepfake dataset. Initially, three baseline models, Meso-4, MesoInception-4, and XceptionNet, were trained and tested on the dataset without any preprocessing mechanism. XceptionNet outperformed with 90.54% accuracy revealing deeper networks detect low-quality depfakes adequately. Then those baseline models were trained with SR preprocessing. To do that, we employed two SR networks, called VDSR and RSRGAN. RESRGAN+XceptionNet outperformed the previous baseline models by obtaining 96.05% accuracy, showing SR preprocessing usefulness in low-quality deepfake detection. Further experiments utilizing performance metrics, statistical tests, and visualization of activation maps showed that SR preprocessing is promising when applied to deepfake detection networks and detection algorithms experience a significant performance.;"Deepfake;deep learning (DL);detection;low-quality;super-resolution (SR)";IEEE
182;Explainable Deep-Fake Detection Using Visual Interpretability Methods;"B. Malolan; A. Parekh; F. Kazi";2020;Deep-Fakes have sparked concerns throughout the world because of their potentially explosive consequences. A dystopian future where all forms of digital media are potentially compromised and public trust in Government is scarce doesn't seem far off. If not dealt with the requisite seriousness, the situation could easily spiral out of control. Current methods of Deep-Fake detection aim to accurately solve the issue at hand but may fail to convince a lay-person of its reliability and thus, lack the trust of the general public. Since the fundamental issue revolves around earning the trust of human agents, the construction of interpretable and also easily explainable models is imperative. We propose a framework to detect these Deep-Fake videos using a Deep Learning Approach: we have trained a Convolutional Neural Network architecture on a database of extracted faces from FaceForensics' DeepFakeDetection Dataset. Furthermore, we have tested the model on various Explainable AI techniques such as LRP and LIME to provide crisp visualizations of the salient regions of the image focused on by the model. The prospective and elusive goal is to localize the facial manipulations caused by Faceswaps. We hope to use this approach to build trust between AI and Human agents and to demonstrate the applicability of XAI in various real-life scenarios.;"deep-fakes;deep-fake detection;faceswap;interpretability;explainable AI (XAI);LRP;LIME";IEEE
183;Deep Fake Face Detection using Convolutional Neural Networks;"M. Alben Richards; E. Kaaviya Varshini; N. Diviya; P. Prakash; P. Kasthuri; A. Sasithradevi";2023;More fake face image generators have emerged worldwide owing to the growth of Face Image Modification (FIM) tools like Face2Face and Deepfake, which pose a severe threat to public trust. Although there have been significant advancements in the identification of certain FIM, a reliable false face detector is still lacking. Convolutional Neural Network (CNN) tends to learn picture content representations because of the structure's relative stability. A deep fake face detection model is developed by analyzing the visual features in a face. By the use of deep learning techniques, a CNN model is developed to identify deep fakes.;"Deep fake;Convolutional Neural Network;Fake Face Detection";IEEE
184;Detecting Deepfake Videos using Face Recognition and Neural Networks;"M. A. Murugan; T. Mathu; S. J. Priya";2024;Deepfake videos created using advanced artificial intelligence techniques, pose a significant threat to digital media credibility. This project introduces a holistic strategy for identifying these videos, incorporating face recognition, feature extraction, and an innovative deep-learning model. The methodology involves pre-processing video data, extracting facial features using the face recognition library, and training a neural network model on processed face-only videos. The project filters videos based on frame count, extracts face, and creates a curated dataset for the detection model. Face-only videos are loaded and pre-processed to train a custom neural network model, which combines a pre-trained ResNext CNN with an LSTM layer for temporal feature extraction. The model is trained using Adam optimization with a cross-entropy loss function, and after completion, it has an accuracy of 95% and is capable of differentiate between fake and real videos using a confidence score.;"Deepfake video detection;celeb-df;face-recognition;LSTM;ResneXt";IEEE
190;Deepfake Detection Method Based on Face Edge Bands;"Z. Deng; B. Zhang; S. He; Y. Wang";2022;The rapid development of face forgery technology and the generation of realistic fake videos have caused serious harm to individuals, society and even the country, so it is important to detect deepfake videos. There are many detection methods available for forged videos, but the overall performance is yet to be improved and does not cope well with high quality forged images or videos. Observing that existing forgery algorithms leave synthetic forgery traces at the edges of faces when creating videos, this paper proposes a new method for detecting forged videos. It first finds the face edges from the video frames, then extracts the face edge bands as deep learning inputs and trains them based on EfficientNet-B3 to achieve effective detection of deepfake videos. Experiments show that the method in this paper can achieve more than 99.8% AUC values on all four forgery methods of the Face-Forensics++ dataset.;"deepfake;detection;face edge;Efficient-Net";IEEE
191;Detection of Deepfake Video using Deep Learning and MesoNet;"L. Rebello; L. Tuscano; Y. Shah; A. Solomon; V. Shrivastava";2023;Fraudsters are increasingly using evidence tampering to evade criminal charges and the acquisition of personal data for identity-related offenses. Deepfake is one of the most common strategies used today for identity theft and reputation defamation. To prevent the spread of these crimes, we need a system that can tell the difference between real and deep fake videos. Deep Neural Networks will be used in our system to identify and mark films as legitimate or manipulated, as well as the altered sections, by running the video through our trained Sequence Model, which can detect any discrepancies or alterations as a sequence of frames. LSTM will be used for temporal sequence analysis, and CNN will be employed for frame feature extraction. MesoNet is a neural network built primarily to identify deep fakes, but it would also be used for other purposes. MesoNet manages the noise produced by low-quality video processing, which impedes analysis. DeepFakes jeopardizes facial recognition and internet content. This deception is risky and can be exploited to impersonate a legitimate user. Our approach will propose a temporal-aware method for automatically detecting deepfake videos.;"DeepFake Detection;Deep Learning;Neural Networks;Convolution Neural Network;Recurrent Neural Network;Long Short-Term Memory;MesoNet";IEEE
192;An Efficient Deepfake Video Detection Approach with Combination of EfficientNet and Xception Models Using Deep Learning;"S. Ata?; ?. ?lhan; M. Karak�se";2022;Artificial intelligence is used in many areas and is constantly being developed. In recent years, videos made with deep fakes, which are often heard, have also developed. The use of videos made with deep fakes as blackmail in people's lives, manipulating the videos of important people to cause anxiety on people and etc. due to the fact that it poses a threat in many areas presents a big problem today. Efforts are being made to prevent this threat by detecting deep fake videos. Deep fake detection is still not fully resolved. For this reason, prominent technology companies provide support to researchers in this field and develop deep fraud detection by suggesting methods and organizing contests on most platforms such as Kaggle. In this article, a detection method is proposed to minimize the current concern of deep forgery. In the proposed method, the Xception model with high performance and speed and the EfficientNetB4 model with high accuracy were used. The proposed method aims to achieve better results and improvements in detecting fake videos.;;IEEE
193;Deepfake Detection Using Deep Learning;"P. R. S; P. D; S. G; S. R. K; G. B";2024;In recent decades, rapid advancements in AI, machine learning, and deep learning have yielded new methods and tools for manipulating multimedia. While this technology has primarily found applications in legitimate fields such as entertainment and education, there have been instances of malicious users exploiting it for unlawful or nefarious purposes. For instance, individuals have used these techniques to create highly realistic fake videos, images, or audio recordings, with the intention of spreading misinformation, propaganda, inciting political discord, promoting hate, or even engaging in harassment and blackmail. These manipulated and hyper-realistic media have gained notoriety as �Deepfakes� in recent times. The literature has documented various approaches to address the challenges posed by Deepfakes.;"Deepfake detection;video or image manipulation;digital media forensics";IEEE
194;Comparison of Different Machine Learning Algorithms for Deep Fake Detection;"Raveena; P. Punyani; R. Chhikara";2023;"Deepfake is a newly developed area of artificial intelligence technology that is widely used on social media and involves superimposing the facial features of one person over that of another. Machine learning is the primary component of deepfake creation, and it has made it possible for deepfake videos and pictures to be produced much more quickly and cheaply. Although the term ""deepfakes"" has a bad reputation, the technology is increasingly being used both professionally and personally. Although while it is still pretty new, recent technical developments make it harder and harder to distinguish between deep fakes and synthetic pictures. This study presents a comparative analysis of different algorithms, such as KNN, Support Vector Machine, Random Forest tree, Decision or Classification tree, and Na�ve Bayes algorithm. To evaluate the effectiveness of these algorithms, the dataset undergoes preprocessing before being used as input for each algorithm. Subsequently, their performance is measured by calculating and comparing metrics like F1-score, recall, precision, and accuracy.";"Machine learning algorithms;classification problem;Random Forest;Na�ve Bayes;Support Vector Machine;Decision tree;KNN";IEEE
195;Usage of Convolutional Neural Network for Deepfake Video Detection with Face-Swapping Technique;"D. Stephen; T. Mantoro";2022;Deepfakes have started to become a tool that brings a negative impact on society. There are various approaches that have been implemented in Deepfake Video detection, such as human-centered approach via dynamic prototypes, dynamic face augmentation, and usage of Neural Networks. However, some of the approaches that have been proposed only used several features, such as frame-by-frame detection. This paper will demonstrate the usage of Convolutional Neural Network (CNN) in detecting deepfake videos that are made with the face-swapping method. The aim of the study is to assess the feasibility of multiple combination between CNN architectures and their training dataset to detect deepfake videos made with face-swapping method that is taken from the Celeb-DF dataset. The assessment results in EfficientNetB4, combined with FaceForensics++, become the best model according to its detectability and false positive rate, when compared with other CNN architectures, while Xception trained with DFDC has the most minimum false positive rate, but the least detectability. Several improvements can be made to the research, such as the usage of GAN-based dataset for testing, usage of self-trained model with training dataset, usage of Siamese CNN architecture and comparison between Siamese and non-Siamese CNN architecture.;"deepfake;video detection;CNN;deep learning;EfficientNet;Xception";IEEE
196;Deep Fake Detection: Unmasking the Illusion using CNN and LSTM;"V. Niranjani; S. Aishwarya; T. Devamitra; B. Jagapreetha";2023;Concerns regarding the veracity of digital media have arisen due to the development of deepfake technology. In order to effectively combat this new threat, this study offers a novel deepfake detection strategy that combines a number of techniques, including Photoplethysmography (PPG). For the detection and classification of deepfakes, our solution combines PPG with sophisticated deep learning techniques. PPG records physiological signals, enhancing analysis of images and sounds. Convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and audio fingerprinting are used to extract features from a large dataset that was used to train the system. A thorough study showing our multi-algorithm fusion approach�s improved performance in deepfake detection over single-algorithm approaches, including measures like accuracy and precision. This study also explores its resilience against adversarial attacks and consider ethical implications. This research work represents a significant advancement in deepfake detection, emphasizing the integration of various algorithms, including PPG, for improved accuracy and resilience. It has applications in media forensics, content verification, and online security, offering a comprehensive solution to the deepfake detection challenge while promoting responsible digital content authentication.;"Deepfake;Machine Learning;Social Media;Digital harassing;Image and video analysis;Photoplethysmography (PPG);Convolutional Neural Networks (CNNs);Long Short-Term Memory (LSTM) networks";IEEE
197;A Novel Machine Learning based Method for Deepfake Video Detection in Social Media;"A. Mitra; S. P. Mohanty; P. Corcoran; E. Kougianos";2020;With the advent of deepfake videos, video forgery has become a serious threat. Videos in social media are the most common and serious targets. There are some existing works for detecting deepfake videos but very few attempts have been made for videos in social media. This paper presents a neural network based method to detect fake videos. A model, consisting of a convolutional neural network (CNN) and a classifier network is proposed. Three different structures, XceptionNet, InceptionV3 and Resnet50 have been considered as the CNN modules and a comparative study has been made. Xception Net has been chosen in the proposed model and paired with the proposed classifier for classification. We used the FaceForensics++ dataset to reach the best model. Our model integrated in the algorithm detects compressed videos in social media.;"Deepfake;Deep Learning;Depthwise Separable Convolution;Convolutional Neural Network (CNN);Transfer Learning;Social Media;Compressed Video.";IEEE
199;Detecting Deepfake Human Face Images Using Transfer Learning: A Comparative Study;"H. Vajpayee; N. Yadav; A. Raj; S. Jhingran";2023;Deepfake technology has made it easy to create realistic, manipulated videos and images, raising concerns about the potential for them to be used to spread misinformation or harm individuals. Deepfake technology has advanced significantly in recent years, making it increasingly difficult to distinguish between real and fake images. This has raised concerns about the potential for deepfake images to be used maliciously, for example, in political propaganda or cyber fraud. As a result, there is a growing need for effective methods of detecting deepfake images. So, it became important to propose an effective classification on deepfake. In this paper the authors have proposed an effective classification on deepfake images using Transfer Learning. This approach will help in classification of Real and fake through Human face images. The authors have utilized Real vs Fake Face classification dataset to apply the proposed approach. The Loss, Accuracy, Precision, Recall, AUC, and F1 Score parameters have been used to analyze the performance of proposed approaches. The outcome of this work shows the EfficientNetV2L Model with the accuracy of 99% as compared among EfficientNetV2B0-B3 and S, M, L models.;"Deep Learning (DL);EfficientNetV2L;Deepfake;Classification;Transfer learning";IEEE
200;Implementation of a Deepfake Detection System using Convolutional Neural Networks and Adversarial Training;"S. Bommareddy; T. Samyal; S. Dahiya";2023;Due to the threat of spreading erroneous information, the employment of deep convolutional neural network (CNN) techniques has resulted in an increase in the number of altered images. A trustworthy and effective mechanism for identifying false photographs is required to solve this problem. In this study, we used the V4D architecture to analyze manipulated videos and concentrated on identifying DeepFake videos in three different contexts: I identifying all types of manipulations, (ii) identifying single manipulations, and (iii) identifying cross manipulation detection, which was used to assess the videos' authenticity. To do this, we used a variety of manipulation techniques and created algorithms to classify undiscovered manipulation methods.;"Deepfakes;Deepfake Detection;Media forensics;Facial Manipulation Detection;Convolutional Neural Networks;Manipulation techniques;Generative Adversarial Networks";IEEE
201;AI-Generated Video Forgery Detection and Authentication;"A. K. Tiwari; A. Sharma; P. Rayakar; M. K. Bhavriya; Nisha";2024;"Deep learning has a variety of uses and issues it can solve in the real world, but it also has some limitations. The growing use of AI-Morped Videos is one of the most recent and complicated issues. ""AI Morphed Videos,"" which are digitally manipulated still or moving visuals, are made using deep learning techniques. In an AI Morphed Video, the target�s face is superimposed over the original image so that the altered digital data can be used for online frauds, extortion, pornography, etc. It is getting harder and harder to manually discern between true and false as deep learning develops. Therefore, research and development in the field of AI Morphed Video detection are crucial. An overview of the several AI Morphed Video detection strategies is completed in time for the classification of feature-based, temporal-based, and deep feature-based AI Morphed Video detection. The comparison research is based mostly on the key features used, including the face detection architecture, the deep learning architecture, whether it is video-based or image-based, the dataset used, the frames size, and the dataset size used. Along with the comparison, a semi-supervised GAN architecture is also proposed and built to recognize the AI Morphed Video.";"AI Morphed Video Detection;AI;DL;auto encoders;generative adversarial network;Video forgery";IEEE
202;Detection of Deep Fake Images Using Convolutional Neural Networks;"G. Aggarwal; A. K. Srivastava; K. Jhajharia; N. V. Sharma; G. Singh";2023;Images are frequently manipulated for various purposes, often serving the interests of specific parties. Given that images are commonly regarded as evidence of reality, their manipulation can significantly contribute to the spread of fake news or misleading information. Detecting such image falsifications necessitates access to extensive image data and the development of models capable of scrutinizing each pixel within an image. Furthermore, ensuring efficiency and flexibility in data training is vital to support practical applications. Big data and deep learning concepts, particularly the Convolutional Neural Network (CNN) architecture utilizing Error Level Analysis (ELA), have proven highly effective, achieving a forgery detection rate of 91.83% with convergence in just 9 epochs.;"Deep fake detection;Convolutional Neural Networks (CNNs);Image forensics;image recognition;image analysis";IEEE
206;Enhancing Deepfake Detection for Public Awareness, Law Enforcement and Legal Verification;"J. Y. Ng; S. C. Chong; K. K. Wee";2024;In recent years, as you can see the emergence of deepfake technology had raised worrying concerns in various sectors, including politics, the media industry and most importantly cybersecurity. As deep fakes they can manipulate audio and video content created using deep learning techniques. This research aims to investigate and discover the best methods to detect and uncover deep fake content which also addresses the needs for a reliable deepfake method. The study�s approach, which integrates multimodal data fusion and leverages NAS, achieved outstanding results, reaching 99.37% accuracy after 15 epochs. This performance surpasses benchmarks set by traditional CNNs and earlier GAN-based methods. Experiments were conducted using two datasets, FaceForensics++ and Celeb-DF (v2), further validating the robustness of the method. These findings underscore the effectiveness of automated deep learning in combating digital misinformation;"Deepfake;Neural Architecture Search;Machine Learning;Deep Learning;Cybersecurity";IEEE
207;Hybrid Deepfake Detection Utilizing MLP and LSTM;"J. Mallet; N. Krueger; R. Dave; M. Vanamala";2023;The growing reliance of society on social media for authentic information has done nothing but increase over the past years. This has only raised the potential consequences of the spread of misinformation. One of the growing methods in popularity is to deceive users through the use of a deepfake. A deepfake is a new invention that has come with the latest technological advancements, which enables nefarious online users to replace one's face with a computer-generated, synthetic face of numerous powerful members of society. Deepfake images and videos now provide the means to mimic important political and cultural figures to spread massive amounts of false information. Models that are able to detect these deepfakes to prevent the spread of misinformation are now of tremendous necessity. In this paper, we propose a new deepfake detection schema utilizing two deep learning algorithms: long short-term memory and multilayer perceptron. We evaluate our model using a publicly available dataset named 140k Real and Fake Faces to detect images altered by a deepfake with accuracies achieved as high as 74.7%.;"Deepfake;Machine Learning;Fake Image Detection;Long Short-Term Memory;Multilayer Perceptron";IEEE
208;Enhancing Global Security: A Robust CNN Model for Deepfake Video Detection;"M. Solaiman; M. S. Rana";2024;In recent years, the rapid advancements in machine learning (ML), artificial intelligence (AI), and deep learning (DL) have ushered in a new era of sophistication in image and video manipulation techniques. Notably, the emergence of Deepfake technology, driven by AI, has garnered substantial attention. Deepfakes involve training DL models on extensive datasets of similar faces and subsequently mapping one person's expressions onto another's face, resulting in deceptively realistic fake videos that can be virtually indistinguishable from authentic ones. The proliferation of Deepfakes poses various threats, including the potential to incite political turmoil, coerce individuals, or fabricate false terrorist incidents. This trend undermines privacy, consent, and the trustworthiness of digital media. Consequently, there is a pressing need to continually advance Deepfake detection and prevention methodologies to safeguard against their malevolent use and uphold the integrity of digital content. This paper introduces a Convolutional Neural Network (CNN) based DL model specifically developed for the classification of Deepfake video frames. Our model exhibits impressive performance, as validated by a thorough analysis on the VDFD dataset, where it achieves an outstanding average precision, recall, and F1-score of 95%, 94%, and 94%, respectively. Moreover, our model showcases its efficacy across various widely recognized Deepfake datasets, including FF++, Celeb-DF, and DFDC, with frame detection average rates for precision, recall, and F1-score ranging from 80% to 85%. These compelling results signify that our proposed CNN-based frame detection technique is a powerful tool for Deepfake detection, emphasizing the critical significance of automated Deepfake detection with an exceptionally high detection rate. This technology represents a pivotal step toward protecting against the potential misuse of Deepfakes, reinforcing the security and integrity of digital content in our modern world.;"Global Security;Deepfakes;Deepfake detection;CNN;Versatile Deepfake Dataset;Video manipulation detection";IEEE
212;Deepfake Detection Using CNN and DCGANS to Drop-Out Fake Multimedia Content: A Hybrid Approach;"K. Bansal; S. Agarwal; N. Vyas";2023;The creation of Deep Fakes, which are altered videos, audio, and photographs capable of disseminating false information and fake news and modifying sensitive records, is the result of the rapid advancements in artificial intelligence and machine learning. DeepFakes may also be used for interactive learning and visual effects in entertainment and education. As a result, numerous deep learning models, such as Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN), are being used for detection. DeepFakes detection and removal have become essential challenges. Facebook AI's Deepfake Detection Challenge (DFDC) dataset is invaluable for developing and evaluating detection techniques. While it represents serious risks, creating trustworthy detection techniques might lessen their impact and enable investigation of their possible beneficial applications. To ensure the authenticity and dependability of multimedia information in the face of the ongoing DeepFake threat, this paper emphasizes the importance of transfer learning, deep learning, and optimization techniques in building effective detection models. By doing this, we can stop the spread of fake news and information, protect the public's trust, and promote the moral and beneficial application of DeepFake technology across various fields.;"Transfer Learning;Deep Learning;Convolutional Neural Networks (CNN);Image Classification;ImageNet;Optimization Techniques";IEEE
213;Two-Branch Deepfake Detection Network Based on Improved Xception;"R. Zhang; Z. Jiang; C. Sun";2023;With the continuous development of computer technology, the level of AI technology has also been greatly improved. But it comes with growing security and ethical challenges, including deep fake faces. While current detection methods work well in high definition video, they often do not perform as well when detecting relatively low definition video. For example, the clarity of the forged video is often too low, the quality compression of the video on the social platform and the level of the user's own equipment lead to the clarity is not too high, which makes the detection accuracy need to be improved. At the same time, the quality of detection across data sets also needs to be improved. To solve these problems, this paper proposes a two-branch detection network based on improved Xception. The network consists of a whole branch that detects the whole detected video and a local branch that detects each frame of the video. The whole branch uses the improved Xception network and Gated Recurrent Unit (GRU) to detect the whole video to be detected. The local branch uses the improved Xception network and a series of data enhancement measures, including Face-Cutout, to detect every frame of the detected video. To verify the effectiveness of the algorithm, tests were performed on the FF+ dataset and the Celeb-DF dataset. The experimental results show that the detection level of the proposed method is better than other detection networks, and it has better detection performance in cross-dataset and cross-definition scenarios, which proves the effectiveness of the proposed method.;"deepfake;deep learning;attention;Xception;forgery detection";IEEE
214;Detection of Deepfake Images and Videos Using SVM, CNN, and Hybrid Approaches;"I. S. Stankov; E. E. Dulgerov";2024;The proliferation of deepfake technology, driven by advancements in artificial intelligence, particularly generative adversarial networks (GANs), has introduced new challenges in verifying the authenticity of multimedia content. Deepfakes can create highly realistic fake images and videos that are difficult to distinguish from real ones, posing significant threats to privacy, security, and information integrity. This study investigates the effectiveness of three machine learning models�Support Vector Machine (SVM), Convolutional Neural Network (CNN), and a combined CNN-SVM approach�in identifying deepfake images and videos. By leveraging a dataset containing both real and computer-generated content, we trained and evaluated each model on their ability to accurately classify these media types.;"Deepfake;SVM;CNN;Combined Approach;Image Analysis;Video Analysis;Machine Learning";IEEE
215;A Lightweight CNN for Efficient Deepfake Detection of Low-resolution Images in Frequency Domain;"S. D; R. S; S. Ravi; V. M; P. M. P. U";2024;Deepfake detection in frequency domain is extensively explored for two reasons �artifacts generated by the up-sampling layer of Generative Adversarial Networks are more prominent in the frequency domain and some image processing tasks are simpler and efficient in this domain. Traditional convolutional neural networks outperform the machine learning models for their ability to detect deepfakes of low-resolution images also. But these networks involve numerous trainable parameters resulting in huge computation cost, time and high memory requirements. This paper presents a lightweight Convolutional Neural Network (CNN) architecture that is optimized for efficient deepfake detection of low-resolution images in the frequency domain. The proposed model achieves almost the same accuracy as that of the traditional network but with the parameter requirement reduced by 92%. This renders the model suitable for use in memory-constrained and power-constrained environments such as mobile devices and other embedded systems.;"Deepfake detection;frequency domain;pixel domain;lightweight CNN;depthwise separable convolution";IEEE
216;Frequency Masking for Universal Deepfake Detection;"C. T. Doloriel; N. -M. Cheung";2024;We study universal deepfake detection. Our goal is to detect synthetic images from a range of generative AI approaches, particularly from emerging ones which are unseen during training of the deepfake detector. Universal deepfake detection requires outstanding generalization capability. Motivated by recently proposed masked image modeling which has demonstrated excellent generalization in self-supervised pre-training, we make the first attempt to explore masked image modeling for universal deepfake detection. We study spatial and frequency domain masking in training deepfake detectors. Based on empirical analysis, we propose a novel deepfake detector via frequency masking. Our focus on frequency domain is different from the majority, which primarily target spatial domain detection. Our comparative analyses reveal substantial performance gains over existing methods. Code and models are publicly available1.;"deepfake;masked image modeling;generative AI;GAN;diffusion models";IEEE
217;Deep learning based DeepFake video detection;"S. Guefrachi; M. Ben Jabra; N. A. Alsharabi; M. T. Ben Othman; Y. O. Alharabi; A. Alkholidi; H. Hammam";2023;Recent advances in DeepFake face-swapping technology have made it simple to create fake videos that appear remarkably real. Since it has been employed in numerous instances for deceit, extortion, and the falsification of facts, its widespread use has generated a huge social, security, and political risk. Its use on websites and social media has become more widespread. Detecting this crime is becoming more and more important due to the potential harm false videos may inflict on a global scale. This research offers a method for building a deep learning model that really can tell the difference between authentic and false videos. The article describes how to create new models based on the VGG16 neural network, a previously created neural network that does image categorization, using transfer learning in the computer vision field. Deep learning is still becoming better at both producing and spotting DeepFakes. DeepFake detection algorithms are developed using dated public datasets, and as a result, they may become obsolete with time. and require continual updating. The research findings are encouraging, and our results reached an accuracy rate of over 90%.;"Deep-fake detection;Video authenticity;Fine-tuning;VGG16";IEEE
219;Improving the Generalization Ability of Deepfake Detection via Disentangled Representation Learning;"J. Hu; S. Wang; X. Li";2021;Deepfake refers to a deep learning based technology which can synthesize visually realistic face images/videos. The misuse of this technology poses a great threat to the society. Although numerous approaches have been proposed to detect Deepfake forgeries, their generalization ability on unseen datasets is limited. In this paper, we propose a new approach that detects human face forgeries by automatically locating the forgery-related region to make the final decision. The proposed network contains two modules, including: the disentanglement module to extract forgery relevant information and the classification module to detect the manipulation artifacts from various regions at different scales. The experiment results on three widely used Deepfake datasets show that the proposed approach can achieve high detection accuracies and outperforms several state-of-the-arts methods especially when evaluated on the unseen datasets.;"Disentangle representation learning;Deep-fake detection;deep neural network";IEEE
221;Deep Fake Detection using Advance ConvNets2D;"K. S; V. K. A; S. P. P; P. M";2023;Even a few decades ago, it would have been impossible to foresee the widespread use of deep learning to tackle such complex issues. It has many positive applications but it can also be misused to cause harm to the society. One such challenge is deep fakes, and now more than ever, when anyone with a smartphone app can create a fake image or video, it is crucial to take measures to authenticate the content online. Visual and auditory �deepfakes� may be generated with the aid of neural networks. Deepfake mimics machine learning models with the help of Generative Adversarial Networks. Many well-known people have been affected by the rapid spread of false news stories on social media platforms like Facebook, YouTube, Twitter, etc. Artificial Neural Network (ANN) based deep fakes may appear identical to authentic images or videos before being moderated but they always have spatial and temporal signatures. A neural network has been trained to specialize in Deep fake detection can quickly identify these signs. To determine whether or not a video is deep fake, Residual Network and InceptionResNetV2 models are employed in this research.;"Neural networks;GAN;Residual Networks;Image;Video;InceptionResNet.";IEEE
222;Deepfake Video Detection System Using Deep Neural Networks;"S. R. B. R; P. Kumar Pareek; B. S; G. G";2023;A deepfake is a type of synthetic media that uses artificial intelligence and machine learning techniques to manipulate or superimpose images, videos, or audio onto existing footage in a way that appears authentic and realistic, often with the intent to deceive or mislead viewers. There are several approaches to using neural networks for deep fake detection. One approach is to use a convolutional neural network (CNN) [1] to analyze the visual artifacts in the image or video. The CNN can detect inconsistencies or anomalies in the image or video that are indicative of manipulation, such as differences in lighting or blurring at the edges of the image. ResN et-50 has been used in deepfake detection by training the network on a large dataset of real and fake videos In this paper, Resnet50 and LSTM [13] are combined to make a hybrid architecture are used in deep fake video detection as a web framework using python. Combining ResNet50 and LSTM can help to leverage the strengths of both architectures and improve the accuracy of deep fake video detection, especially for videos that involve both image-based and sequential data. A comparative analysis of different models were assessed using various datasets such as Celeb-DF, Face Forensic++ datasets.;"Convolutional Neural Network;ResNet50;LSTM;Deep Fake;GAN";IEEE
224;Enhancing Face Forgery Detection in a Decentralized Landscape: A Federated Learning Approach with ResNet;"V. Gautam; H. Maheshwari; R. G. Tiwari; A. K. Agarwal; N. K. Trivedi";2023;Recent advancements in technologies could be the reason for fake image and video generation over the internet. This may be the cause of fake identity creation over the internet for forgery. These types of acts may be the reason for security issues in society. The legacy fake forgery method is not that capable of recognizing such forgery as the methods are trained with publicly available centralized datasets and never focus on privacy and security issues and adversely influence the forgery detection. Hence, the objective of this research is to provide decentralized ways to handle these issues effectively. The issue is taken care of with an effective federated learning-based deep learning technique. In the proposal, several deep learning models were used to generate a residual feature map from the available image dataset and later federated learning was used to generate a decentralized infrastructure for collaborative client machines. The complete experiment setup is established with a publicly available dataset and various variable parameters are used such as the number of clients and round of communication. Afterward, deep learning models� performance is compared for forgery detection under federated learning environments, and it has been observed that ResNet deep learning outperforms with an accuracy rate of 87.83% in FaceForensic dataset.;"Facial Forgery Detection;Deep Learning;Feature Learning;Federated Learning;Privacy-Preserving";IEEE
225;Forensics and Analysis of Deepfake Videos;"M. T. Jafar; M. Ababneh; M. Al-Zoube; A. Elhassan";2020;The spread of smartphones with high quality digital cameras in combination with easy access to a myriad of software apps for recording, editing and sharing videos and digital images in combination with deep learning AI platforms has spawned a new phenomenon of faking videos known as Deepfake. We design and implement a deep-fake detection model with mouth features (DFT-MF), using deep learning approach to detect Deepfake videos by isolating, analyzing and verifying lip/mouth movement. Experiments conducted against datasets that contain both fake and real videos showed favorable classification performance for DFT-MF model especially when compared with other work in this area.;"Deep Learning;Python;Deepfake;Videos;Digital Forensics;Manipulation;Detection;Classification;Segmentation";IEEE
226;Preserving Visual Authenticity: Block chain-Augmented AI Frameworks for Advanced Digital Deception Recognition and Mitigation;"M. Priya; J. Murugesan; P. Bhuvaneswari; M. Rubigha; S. Lalithambikai; B. Mohanraj";2024;The rapid advancements in deep learning have given rise to sophisticated DeepFake technologies, posing significant threats to visual integrity and authenticity in digital media. This paper presents an innovative approach to DeepFake detection and mitigation by integrating blockchain technology with artificial intelligence frameworks. The proposed Blockchain-Augmented AI (BAAI) framework utilizes the immutability and decentralized nature of block chain to enhance the security and reliability of the detection process. Our method involves the development of advanced AI models for detecting DeepFakes, which are then integrated with a blockchain-based ledger to ensure the verifiability and traceability of detection results. In this proposed work, a novel integration of blockchain technology and AI designed to enhance DeepFake detection capabilities. The framework achieves a $97 \%$ accuracy rate, ensuring reliable identification of manipulated media, while maintaining a low false positive rate of 3%. These results highlight the BAAI framework�s effectiveness in minimizing erroneous detections and its robustness in safeguarding digital visual content. In the face of increasingly sophisticated DeepFake technologies, this framework offers a crucial advancement in combating digital deception.;"DeepFake Detection;Visual Integrity;Blockchain-Augmented AI (BAAI);Detection Accuracy;False Positives;Detection Precision;Media Authenticity";IEEE
229;Language-focused Deepfake Detection Using Phonemes, Mouth Movements, and Video Features;"J. Krause; A. De Souza Inacio; H. S. Lopes";2023;The potential implications of Artificial Intelligence (AI) and Deep Learning (DL) algorithms in generating highly realistic deepfake videos have raised concerns regarding the reliability of our human senses. In response to this challenge, we propose a deepfake detection system based on phonemes, the transcribed text, associated mouth movements, and video-extracted features. As a proof-of-concept, we develop a deepfake detection system specifically designed for the Portuguese language, employing three presidential candidates from the 2022 Brazilian elections. Additionally, we introduce a unique dataset comprising real and fake videos involving these three individuals and deliberately blending their identities. The extracted features consolidate relevant attributes, which we utilized to train multiple classification algorithms. Notably, our computational models demonstrate satisfactory performance when authenticating or detecting fake videos containing at least one of the trained phonemes from the Portuguese language. Hence, we conclude that deepfake detection is feasible, primarily due to the absence of natural expressions, particularly in non-English language deepfake videos. Furthermore, developing individual-guided deepfake detection systems may facilitate the authentication of videos featuring celebrities or politicians during future online events.;"Deepfake;Language-focused;Phoneme-based.";IEEE
230;Deepfake Video Detection with Facial Features and Long-Short Term Memory Deep Networks;"D. -C. Stanciu; B. Ionescu";2021;Generative models have evolved immensely in the last few years. GAN-based video and image generation has become very accessible due to open source software available to anyone, and that may pose a threat to society. Deepfakes can be used to intimidate, blackmail certain public figures or to mislead the public. At the same time, with the rising popularity of deepfakes, detection algorithms have also evolved significantly. The majority of those algorithms focus on images rather than to explore the temporal evolution in the video. In this paper, we explore whether the temporal information of the video can be used to increase the performance of state-of-the-art deepfake detection algorithms. We also investigate whether certain facial regions contain more information about the authenticity of the video by using the entire aligned face as input for our model and by only selecting certain facial regions. We use late fusion to combine those results for increased performance. To validate our solution, we experiment on 2 state-of-the-art datasets, namely FaceForensics++ [1] and CelebDF [2]. The results show that using the temporal dimension can greatly enhance the performance of a deep learning model.;"deepfake;deep learning;digital video forensics;face manipulation;facial regions;LSTM";IEEE
231;Deepfake Detection using a Two-Stream Capsule Network;"Z. Joseph; C. Nyirenda";2021;This paper aims to address the problem of Deepfake Detection using a Two-Stream Capsule Network. First we review methods used to create Deepfake content, as well as methods proposed in the literature to detect such Deepfake content. We then propose a novel architecture to detect Deepfakes, which consists of a two-stream Capsule network running in parallel that takes in both RGB images/frames as well as Error Level Analysis images. Results show that the proposed approach exhibits the detection accuracy of 73.39 % and 57.45 % for the Deepfake Detection Challenge (DFDC) and the Celeb-DF datasets respectively. These results are, however, from a preliminary implementation of the proposed approach. As part of future work, population-based optimization techniques such as Particle Swarm Optimization (PSO) will be used to tune the hyper parameters for better performance.;"Deepfake;Deepfake detection;face tampering;deep learning;convolutional neural networks;Capsule networks;Error Level Analysis";IEEE
233;Deepfake Video Detection Based on Image Source Anomaly;"Y. Wang; G. Liao";2024;In order to detect the deepfake videos, most of the effective detection approaches need huge number of samples for training, including the real and fake samples. However, the fake samples are not easy to obtain. To find the solution, this paper proposes a deepfake video detection method based on image source anomaly, which only needs the real samples for training. The proposed method uses a neural network to extract features from the face region and its eight neighbor regions, and then uses another neural network to compare the similarity between the features from face region and each one of its neighbor regions. Finally, the average similarity score is utilized as the measure to detect deepfake video. The experimental results show that the proposed method has good detection performance, which achieved the HTER of 2.75% in the DFD dataset and 2.25% in the FF++ dataset, while it needs less samples for training. Moreover, the proposed method also has good cross-datasets performance. It had the HTER of 1.22% when training in FF++ dataset and testing in DFD dataset, which indicates that it can be used in many practical scenarios.;"deepfake;image source;anormaly detection;multimedia forensics;deep learning";IEEE
234;Xception Net & Vision Transformer: A comparative study for Deepfake Detection;"D. Shah; D. Shah; D. Jodhawat; J. Parekh; K. Srivastava";2022;Deepfakes are artificial media in which an existing image consisting of a person is replaced with someone else. The creation of fake content is not new, but deepfakes are more credible because it involves the use of advanced deep learning techniques to manipulate or generate audio and visual content. In the 21st century, there have been astonishing advancements in Generative Adversarial Networks (GANs) and the use of encoder and decoder architecture [1] which have resulted in various effective methods of deepfake creation such as face-swap, lip-syncing, puppet-master and many more [2]. These methods are not only easily accessible but also get more accurate with time. Earlier deepfakes were detected with deep convolutional neural networks such as EfficientNet B7 and Xception Net, but with further advancements in deepfake generation there comes a need for better deepfake detection methods. This paper analyses the performance of Xception Net which has historically performed well with deepfake detection [3]�[5], Vision transformer [6] which is a fairly new technology and a combination of the two models. The paper proposes a combination of Xception and Vision transformer such that Xception Net is used for feature extraction from the patches and the output is then fed as a sequence to a transformer. This work is expected to assist readers to understand when to use Xception Net, Vision transformer and a combination of the two.;"DFDC (DeepFake Detection Challenge);Deepfake;Xception;Vision Transformer;Deep Learning;Deepfake Detection";IEEE
236;A New Approach to in Ensemble Method for Deepfake Detection;"S. Atas; M. Karakose";2023;With the great development of technology and deep learning gaining competence in many areas, recently forgery of images has started to pose great threats and become the main topic of most technology companies. But here, with the ongoing race between good and evil, new approaches have emerged in fraud detection. Since this technological development is bilateral, fraud detection is constantly trying to be developed and trying to catch fraud. In this regard, various approaches have emerged by many different companies and people to contribute to society. In the method we have proposed to contribute to these detection processes and to detect forgery, feature extraction is provided on images using the D-CNN model, and with these features, SVM, Estimation is done on features with Random Forest and Logistic Regression. Finally, using the Ensemble method, an estimation process is performed by taking all the estimates together with the sampling on the images. Thanks to this proposed method, the determinations made are supported in a layered way and precision is ensured at the accuracy rate.;"Deepfake Detection;Ensemble Method;D-CNN";IEEE
237;Generation And Detection of Deepfakes using Generative Adversarial Networks (GANs) and Affine Transformation;"J. Vijaya; A. A. Kazi; K. G. Mishra; A. Praveen";2023;Deepfake technology has gained significant attention and notoriety in recent years for its ability to manipulate visual and audio content, leading to widespread concerns about its potential for abuse. Deepfake videos can be created by using deep learning algorithms that enable the synthesis of facial and vocal features of a target individual onto another person, leading to convincing and often misleading videos. While the technology behind deep fakes is constantly evolving, there has been increasing interest in understanding and mitigating their potential negative impacts. Researchers and experts are exploring ways to detect and prevent the creation of malicious deep fakes while also developing ethical guidelines to regulate their use. This paper presents a deep fake project that utilizes Generative Adversarial Networks (GANs) and affine transformations to generate deep fake videos. The proposed approach takes a target image and a driving video as inputs and generates a realistic-looking deep fake video that mimics the facial expressions and movements of the driving video and combines it with the target image and also incorporates a classification model to detect whether the generated deep fake video is real or fake. The classification model will also be based on the same architecture as used in generating the fake videos and will be used to evaluate the realism and quality of the generated deep fake videos. It generates a novel approach for generating and detecting deep fake videos that can be applied to various applications, such as entertainment, education, and security. However, creating deep fakes also offers potential benefits, such as improving the entertainment industry and enhancing the quality of content creation. As technology advances, it is crucial to balance its potential benefits with its potential risks and take appropriate measures to ensure that deep fakes are used ethically and responsibly. The proposed method aims to identify the real identity of a person appearing in a video and use this information to detect whether the video is genuine or not. This identity-aware approach leverages a deep neural network architecture that combines facial recognition and face forgery detection techniques. The proposed solution has the potential to enhance the security of digital media and protect individuals from various forms of identity theft and cyber-crime.;"Deepfake;facial/vocal features;GANs;affine";IEEE
238;DeepFake Detection Based VGG-16 Model;"W. A. Jbara; J. H. Soud";2024;This DeepFake technology allows for the creation of convincing fake images and videos that are indistinguishable from real ones, which is causing widespread concern. This work introduces the state-of-the-art technology for detecting DeepFake videos, while based on the VGG-16 Convolutional Neural Network, ensuring accurate and reliable results. Data augmentation is used for performance improving and reduce the computational resources, also using Multi-task Cascaded Convolutional Networks technique for face detection. With this innovative solution, you can easily identify and detect DeepFake videos that have the potential to mislead, deceive, or manipulate viewers. The experimental results using Celeb-DF and DeepFake Face Mask datasets have greatly improved this model for fake video detectors. These datasets pass through several steps that end with the classification stage for fake face detection, the classification report including several metrics: 94.28% for accuracy, 0.1503 for loss, 0.9428 for Precision, 0.9428 for Recall, 0.9859 for AUC and 0.9428 for F1_score in evaluation model performance. The data augmentation process that used to improve the model performance and reduce computational resources. According to the initial results, VGG19 outperforms other analyzed models with a highest accuracy of 94.28%.;"Deep learning;DeepFake;MTCN;Celeb-DF-v2;DFFM;VGG-16";IEEE
239;An Experimental Evaluation on Deepfake Detection using Deep Face Recognition;"S. Ramachandran; A. V. Nadimpalli; A. Rattani";2021;Significant advances in deep learning have obtained hallmark accuracy rates for various computer vision applications. However, advances in deep generative models have also led to the generation of very realistic fake content, also known as deepfakes, causing a threat to privacy, democracy, and national security. Most of the current deepfake detection methods are deemed as a binary classification problem in distinguishing authentic images or videos from fake ones using two-class convolutional neural networks (CNNs). These methods are based on detecting visual artifacts, temporal or color inconsistencies produced by deep generative models. However, these methods require a large amount of real and fake data for model training and their performance drops significantly in cross dataset evaluation with samples generated using advanced deepfake generation techniques. In this paper, we thoroughly evaluate the efficacy of deep face recognition in identifying deepfakes, using different loss functions and deepfake generation techniques. Experimental investigations on challenging Celeb-DF and FaceForensics++ deepfake datasets suggest the efficacy of deep face recognition in identifying deepfakes over two-class CNNs and the ocular modality. Reported results suggest a maximum Area Under Curve (AUC) of 0.98 and Equal Error Rate (EER) of 7.1% in detecting deepfakes using face recognition on the Celeb-DF dataset. This EER is lower by 16.6% compared to the EER obtained for the two-class CNN and the ocular modality on the Celeb-DF dataset. Further on the FaceForensics++ dataset, an AUC of 0.99 and EER of 2.04% were obtained. The use of biometric facial recognition technology has the advantage of bypassing the need for a large amount of fake data for model training and obtaining better generalizability to evolving deepfake creation techniques.;"Deepfakes;Deep Learning;Biometrics;Face Recognition";IEEE
240;Deepfake Detection Using Graph Representation with Multi-dimensional Features;"J. Chen; W. Lin; J. Xu";2023;The proliferation of fake video poses a significant threat to the authority and authenticity of news across multiple domains. The most existing methods of deepfake detection primarily focus on identifying the face as a whole in a video, ignoring the correlation between the facial components. However, our investigation indicates that constituent potions of a face have different effects in deepfake detection. To address this issue, we divided the face in a video frame into several regions and explored the relationship between these regions. Our approach involves constructing a feature graph of this correlation, aiming to make use of the relationship and temporal characteristics between regions of a face in a deepfake video. To begin with, the features of each facial region are extracted through CNN. Subsequently, the feature graph of the entire video is constructed with these features being the vertices and the correlation being the edge. A graph neural network is finally utilized to determine whether the video has been tampered with. Our experiments on several publicly accessible datasets demonstrate that the proposed approach outperforms other state-of-the-art deepfake detection techniques in most scenarios.;"graph representation;deepfake detection;temporal characteristics";IEEE
241;CNN based Deep Learning model for Deepfake Detection;"V. Jolly; M. Telrandhe; A. Kasat; A. Shitole; K. Gawande";2022;In the recent period there has been massive progress in synthetic image generation and manipulation which significantly raises concerns for its ill applications towards society. This would result in spreading false information, leading to loss of trust in digital content. This paper introduces an automated and effective approach to get facial expressions in videos, and especially focused on the latest method used to produce hyper realistic fake videos: Deepfake. Using faceforenc++ dataset for training our model, we achieved more that 99% successful detection rate in Deepfake, Face2Face, faceSwap and neural texture. Regular image forensics techniques are usually not very useful, because of the strong deterioration of data due to the compression. Thus, this paper follows a layered approach with first detecting the subject with the help of existing facial recognition networks followed by extracting facial features using CNN, then passing through the LSTM layer, where we make use of our temporal sequence for face manipulation between frames. Finally use of the Recycle-GAN which internally makes use of generative adversarial networks to merge spatial and temporal data.;"Face Detection;FaceForensics++;DeepFake;Face2Face;FaceSwap;Neural Texture;Convolutional Neural Network (CNN);Long Short-Term Memory (LSTM)";IEEE
242;Deepfake Detection Using Custom Densenet;"V. R. Pasupuleti; P. Reddy Tathireddy; G. Dontagani; S. A. Rahim";2023;Deepfake detection has grown to be an increasingly important research area due to the potential harm that deepfakes can cause to individuals and society. In recent years, deep learning techniques have shown promising results for detecting deepfake images and videos. In this research, we provide a deep learning-based strategy using Custom DenseNet for deepfake image detection. This model used a big dataset of actual and deepfake photos to train a convolutional neural network (CNN) using the Custom DenseNet architecture. The Custom DenseNet architecture is a deep residual network that has shown excellent performance in various computer vision tasks. To categorize images as real or fake, the CNN is trained using a binary cross-entropy loss function. To evaluate the approach, we used several performance indicators including F1-score, recall, accuracy, and precision. We also contrasted our strategy with other cutting-edge deepfake detection techniques. Our test results demonstrate that our solution employing Custom DenseNet surpasses existing deepfake detection techniques in terms of accuracy, precision, recall, and F1-score. We achieved an accuracy of 97%, a precision of 95%, and an F1- score of 75%. These results demonstrate the effectiveness of our approach in detecting deepfake images. Overall, our study shows that deep learning techniques, specifically the Custom DenseNet architecture, can be highly effective in detecting deepfake images.;"deep fakes;metrics scores;CNN;DenseNet;binary cross- entropy";IEEE
243;Facial Behavior Analysis-Based Deepfake Video Detection using GAN Discriminator;"Q. Jaleel; I. H. Ali";2022;Deepfake is an artificial intelligence-based method for making fake images of people. It works by putting the existing (source) images or videos on the final (destination) images or videos. But recent improvements in deep learning have made it much easier to make fake videos that look real and are convincing with a relatively small amount of data and computing power. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Many researchers are based on discovering deep fakes that were created by traditional methods. Traditional methods of detection that look for artifacts and pixels that don't match up can't keep up. This paper can detect deepfakes that are perfectly created. It is detected by modifying the GAN algorithm and inverting its function. The discriminator model of a GAN network is used to analyze behavior, facial gestures, and the appearance of an object. The paper is divided into two stages. The first stage is to use a GAN discriminator that has been modified. It is then trained using a deepfake dataset. The second stage is to test the videos by extracting the faces. Next, run it through the GAN discriminator to see if it's a forgery. In comparison to other networks, the GAN discriminator has demonstrated its ability and accuracy in detecting fake videos. The network's accuracy in detecting and distinguishing between real and fake videos is %94.65.;"GAN;GAN discriminator;Media Forensics;DeepFake Detection;Face Detection";IEEE
244;Deepfake Detection using EfficientNet: Working Towards Dense Sampling and Frames Selection;"T. -A. To; H. -C. Luong; N. -T. Nguyen; T. -T. Nguyen; M. -T. Tran; T. -L. Do";2022;Deepfake is a controversial technology that allows the automatic generation of video content through generative adversarial networks. The emergence of Deepfake technology is problematic and sophisticated, making it more difficult to detect. In our paper, we contribute a deep-learning method to resolve that problem. We use the MTCNN face detector to extract facial images and apply data augmentation and EfficientNet for real-fake classification. We apply frame selection with the raw label prediction to tackle the fault cases and receive the final label. With the approach above applied, we utilize training and evaluation datasets from FaceForensics++ and achieve an accuracy of 62.5%.;"Deepfake Detection;Efficient Net;Dense Sampling;Frame Selection";IEEE
247;Improving DeepFake Video Detection Performance with a Noval Deep Learning Approach;"M. A. Fouda; W. El-Shafai; E. -S. M. El-Rabaie";2023;With the rise in both the quantity and sophistication of deepfake videos, the need for robust detection systems to identify potentially misleading content on social media and the internet has become paramount. However, current automated face forgery detection systems still face limitations, often demonstrating bias towards the training dataset. This research paper addresses this issue by proposing a novel approach for detecting deepfake media. We introduce a custom Visual Geometry Group (VGG16) deepfake detection method that leverages convolutional neural network architectures. To evaluate the effectiveness of our approach, we utilize the deepfake detection challenge (DFDC) dataset on Kaggle to build network models and compare the performance of our custom VGG16 method against the standard VGG16. Additionally, we investigate the impact of data augmentation techniques on the performance of Convolutional Neural Network (CNN)-based deepfake detectors, examining their effect on both VGG16 and our custom VGG16 approach using the DFDC dataset. Our results demonstrate a high level of accuracy, with precision, recall, and f1-score values of 0.983, 0.975, and 0.979, respectively, and an overall accuracy of 0.986 for deepfake detection. This study presents a promising approach to enhance the accuracy of deepfake video detection, representing a crucial step towards mitigating the potential negative impacts of deepfake technology.;"Deepfake;Deep learning;CNN;Data Augmentation;Deepfake Detection;and VGG16";IEEE
248;DeepFake Detection System using Deep Learning;"O. Ahmed; S. Fekry; A. Metwally; A. Abdelwahid; D. Khattab; A. Abdulelmagid; R. Hossieny";2023;Due to the growing usage of DeepFake technology to produce fake photos and videos, the problem of DeepFake identification has become a serious concern in recent years. With the use of this technology, fake material that is difficult to tell apart from real content may be produced. Therefore, the development of accurate DeepFake detection algorithms is essential to identify and prevent the spread of manipulated content. However, current publicly available DeepFake detection datasets suffer from a lack of diversity, with only a few actors appearing in multiple videos. This results in an oversampled training dataset, leading to model overfitting and inadequate performance when tested on new data. The overfitting problem can cause deep neural networks to focus more on facial features than on specific traits of DeepFake content, thereby reducing the model's ability to generalize. To address this issue and broaden the training dataset's variety, we suggest applying data augmentation methods like Face Cutout and Random Erase. The Face Cutout technique randomly removes a rectangular area of an image containing the face, while the Random Erase technique randomly removes a rectangular area of the image. These techniques introduce variations in the images, making it more challenging for the model to overfit and focus on specific traits of DeepFake content. We evaluated our approach using several models and achieved significant accuracy improvements using the EfficientnetV2B0 model and Random Erase augmentation.;"DeepFake;Random Erase;Face Cutout";IEEE
249;Transformer-Based Feature Compensation and Aggregation for DeepFake Detection;"Z. Tan; Z. Yang; C. Miao; G. Guo";2022;Deepfake detection has attracted increasing attention in recent years. In this paper, we propose a transformer-based framework with feature compensation and aggregation (Trans-FCA) to extract rich forgery cues for deepfake detection. To compensate local features for transformers, we propose a Locality Compensation Block (LCB) containing a Global-Local Cross-Attention (GLCA) to attentively fuse global transformer features and local convolutional features. To aggregate features of all layers for capturing comprehensive and various fake flaws, we propose Multi-head Clustering Projection (MCP) and Frequency-guided Fusion Module (FFM), where the MCP attentively reduces redundant features into a few concentrated clusters, and the FFM interacts all clustered features under the guidance of frequency cues. In Trans-FCA, besides global cues captured by transformer architecture, local details and rich forgery defects are also captured using the proposed fetaure compensation and aggregation. Extensive experiments show our method outperforms the state-of-the-art methods on both intra-dataset and cross-dataset testings (with AUCs of 99.85% on FaceForensics++ and 78.57% on Celeb-DF), which clearly demonstrates the superiority of our Trans-FCA for deepfake detection.;"Face forgery detection;transformer;deep learning";IEEE
253;Deep-Fake Finder: Uncovering Forgery Image Through Neural Network Analysis;"D. Bhargava; S. Rani; M. Singh; N. Tripathi; A. Bhargava; G. Panwar";2024;Digital images are a common form of media shared on social media, and their circulation can undermine news credibility and public trust. This research proposes a method for extracting image content, classifying it, verifying its authenticity, and identifying manipulations. With the exponential increase in social networking services, there has been a huge growth in the generation of image data, leading to the creation of fabricated images. These images are a major source of fake news, negatively impacting society. To verify the authenticity of these images, a method using a CNN deep learning model can be used. Pixel-based fake image detection can find tempering of an image up to a certain level. The raw image can be mangled in sections or as a whole, and it is necessary to recognize the type of image tampering and localize the tampered region. The image is converted into pixel format, and the RGB values are fed into the network's input layer. The output layer has two neurons for phony and genuine images, allowing us to infer if the image is phony and how likely it is to be tampered.;"Machine Learning (ML);Deep Learning (DL);Neural Networks;Forged Images;R-RANSAC;SPRT";IEEE
254;DeepFake Detection Through Key Video Frame Extraction using GAN;"L. S; K. Sooda";2022;The emergence of deepfake videos in recent years has made image falsification a real threat. A deepfake video uses deep learning technology to substitute a person's face, emotion, or speech with the face, emotion, or speech of another person. Finding such deceptive deepfake videos on social media is the first step in preventing them. A robust neural network-based technique to identify false videos is presented in this paper. An important video frame extraction approach is used to speed up the process of finding deep fake videos. A model made up of a convolutional neural network (CNN) and a classifier network consisting of GAN technology is provided. Resnet, Resnext50 and LSTM were passed over in favor of the Confusion Matrix when deciding which structure to pair with the classifier while detecting the fake video. The model is a method for detecting visual artefacts. The subsequent classifier network uses the feature vectors from the CNN module as this is the input to categorize the video whether it is fake or real one. The dataset is considered from DeepFake Detection Challenge to get the best model. The key goal is to get high accuracy without using a lot of data to train the model. In comparison to earlier efforts, the key video frame extraction method dramatically decreases computations by achieving 97.2% accuracy using the Deepfake Detection Challenge dataset.;"Convolutional Neural Network;Deepfake;LSTM;Resnet;Resnext50";IEEE
255;Developing Self-evolving Deepfake Detectors Against AI Attacks;"I. Miller; D. Lin";2022;As deep-learning based image and video manipulation technology advances, the future of truth and information looks bleak. In particular, Deepfakes, wherein a person�s face can be transferred onto the face of someone else, pose a serious threat for potential spread of convincing misinformation that is drastic and ubiquitous enough to have catastrophic real-world consequences. To prevent this, an effective detection tool for manipulated media is needed. However, the detector cannot just be good, it has to evolve with the technology to keep pace with or even outpace the enemy. At the same time, it must defend against different attack types to which deep learning systems are vulnerable. To that end, in this paper, we review various methods of both attack and defense on AI systems, as well as modes of evolution for such a system. Then, we put forward a potential system that combines the latest technologies in multiple areas as well as several novel ideas to create a detection algorithm that is robust against many attacks and can learn over time with unprecedented effectiveness and efficiency.;"deepfake;AI attack";IEEE
256;Open-Set Deepfake Detection To Fight The Unknown;"M. M. Diniz; A. Rocha";2024;In this paper, we design a new open-set method to detect deepfakes that does not assume information about the techniques behind the deepfakes generation. Contrary to existing methods, which build upon known telltales left by the deepfake creation process, we assume no prior knowledge about the sample generation, thus presenting a method for blind deepfake detection, a necessary step toward true generalization. Our methodology relies upon unsupervised learning, open-set formulations for each discovered group and, finally, relevance tests through extreme-value theory and isolation forest formulations. The results indicate that the proposed open-set technique is competitive with state-of-the-art closed-set deepfake detection methods. As a notable outcome, we achieved an AUC = 0.807, which is 5.57% higher than the baseline architecture trained using a closed-set approach. Finally, we believe our efforts herein are just a first attempt tackling this difficult problem and discuss some additional improvements for practical deployment of such systems.;"Deepfake Detection;Open-set Methods;Triplet loss";IEEE
257;Multimodal Approach for DeepFake Detection;"M. Lomnitz; Z. Hampel-Arias; V. Sandesara; S. Hu";2020;Generative Adversarial Networks (GANs) have become increasingly popular in machine learning because of their ability to mimic any distribution of data. Though GANs can be leveraged for legitimate purposes, they have increasingly been used to create manipulative and misleading synthetic media, known as deepfakes, intended for nefarious purposes. In this submission we discuss a multimodal deepfake detection solution submitted against the Facebook DeepFake Detection Challenge, a state of the art benchmark dataset and competition released at the end of 2019. Our solution incorporates information from single images and series of images, and also incorporates temporal information from audio and video data, and was ultimately ranked among the top 25% of teams.;"deep learning;deep fakes;generative adversarial networks";IEEE
258;A Hybrid Xception-LSTM Model with Channel and Spatial Attention Mechanism for Deepfake Video Detection;"D. Dagar; D. K. Vishwakarma";2023;"The great strides taken in recent times in image and video manipulation have raised serious concerns. Deepfake technology uses deep learning approaches to create highly realistic, astonishing content. Detecting such videos is the only promising defense against such fraudulent data. To counter the malicious intent of the user, a deepfake detection model is proposed that employs channel and spatial attention mechanisms(CBAM) along with Xception and LSTM pretrained models. Xception uses depthwise separable convolution to capture the latent spatial artifacts. LSTM captures the discrepancies among the manipulated sequences; hence, this hybrid ensembling of models allows the learning of powerful features. The evaluation is performed on the recently proposed Div-DF dataset consisting of varied video manipulation like face swap, facial reenactment, and lip-sync. It shows that the model works well (Accuracy~ 93 % & AUC ~ 0.98) on the diversified dataset and easily beats the score of various state-of-the-art deepfake detection and image classification models.";"deepfake detection;deepfake dataset;video manipulation detection;channel attention;spatial attention";IEEE
259;Beyond Deepfake Images: Detecting AI-Generated Videos;"D. S. Vahdati; T. D. Nguyen; A. Azizpour; M. C. Stamm";2024;Recent advances in generative AI have led to the development of techniques to generate visually realistic synthetic video. While a number of techniques have been developed to detect AI-generated synthetic images, in this paper we show that synthetic image detectors are unable to detect synthetic videos. We demonstrate that this is because synthetic video generators introduce substantially different traces than those left by image generators. Despite this, we show that synthetic video traces can be learned, and used to perform reliable synthetic video detection or generator source attribution even after H.264 re-compression. Furthermore, we demonstrate that while detecting videos from new generators through zero-shot transferability is challenging, accurate detection of videos from a new generator can be achieved through few-shot learning.;"Generative AI;Synthetic images;Synthetic Videos;Media Forensics;Deep Neural Networks;Deep Learning;synthetic image detection;synthetic video detection;video forensics;image forensics;Deepfake";IEEE
260;DeepSight: Enhancing Deepfake Image Detection and Classification through Ensemble and Deep Learning Techniques;"T. Manju; S. Kalarani";2024;in today�s digital age, deepfake images poses a significant threat to multimedia content authenticity and integrity. Detecting and classifying deepfake images with high accuracy is crucial to addressing this growing challenge. Deepfake images, generated using advanced machine learning techniques, have become a significant concern due to their potential to deceive individuals and manipulate information. This paper presents DeepSight, an innovative approach that combines ensemble learning techniques with deep learning models to enhance deepfake image detection and classification. DeepSight leverages the diversity of multiple classifiers trained on distinct feature representations extracted from the input image data. The framework begins with an initial assessment to determine whether the image has been manipulated. Subsequently, the image goes through deep feature extraction using Convolutional Neural Networks (CNNs). The resulting feature vectors are then classified using Random Forest, KNearest Neighbors, and XGBoost, with hyper-parameter optimization. Experimental evaluations on benchmark datasets demonstrate DeepSight�s superior performance compared to state-of-the-art methods, achieving higher accuracy and robustness across various deepfake generation techniques and quality levels. Notably, DeepSight achieves the highest accuracy of 97.5% when utilizing DenseNet and XGBoost. Overall, DeepSight represents a significant advancement in deepfake image detection and classification. It provides a reliable solution to address deceptive visual content in digital environments.;"Deepfake image;Ensemble learning;Machine learning;Deep learning";IEEE
261;A Comprehensive Study on Mitigating Synthetic Identity Threats Using Deepfake Detection Mechanisms;"S. Uppal; V. Banga; S. Neeraj; A. Singhal";2024;Synthetic Identity Threats (SIT) present one of the greatest risks that could undermine the integrity and security of digital systems. These threats adapt Deepfake Technology through generation of new faces, modification of facial attributes or reenactment of fake emotions on human faces. This study is a full documentation of how Deepfake Detection mechanisms can be modelled to neutralize these SIT's using various Deep Learning architectures. We also explored applications of Deepfake beyond malicious intent into forms that are less nefarious like entertainment purposes. We utilized Generative Adversarial Networks to create Deepfakes and experimented with conducting face swaps between two distinct photos as well to assess the quality of Deepfake Technology. For detection of Deepfakes, Convolution Neural Network has shown the highest accuracy of 89.36%, Inception ResNet attained an accuracy of 82.978% while Visual Geometry Group and EfficientNet were at a score of 82.8% and 83% respectively. It is evident that although the current detecting methods are competent in their abilities, the SIT environment continues to develop. Through analyzing the nuances of producing Deepfakes and comparing current quality detection methods, we hope to offer useful information on how scholars and administrators can better protect the internet from deceitful attacks of Deepfakes.;"Synthetic Identity Threats (SIT);Deepfake Detection Challenge Dataset (DFDC);Convolution Neural Network (CNN);Inception ResNet;Visual Geometry Group (VGG);EfficientNet;Generative Adversarial Networks (GAN);Deepfake Generation;Face Swapping";IEEE
263;A New Approach for Effective Medical Deepfake Detection in Medical Images;"M. Karak�se; H. Yet??; M. �e�en";2024;In today�s world, deepfake technology is being used to generate fake images, sounds, and videos from real images and sounds using deep learning and artificial intelligence techniques. It is possible to manipulate medical images with this technology. The manipulation of medical images can lead to incorrect diagnoses by medical professionals, disrupting the functioning of hospitals. As a result of these disruptions, hospitals may experience significant financial and life-threatening problems. In this study, it is aimed to obtain an effective deep learning-based method to detect manipulated medical images. Initially, two distinct datasets are created which contain Knee Osteoarthritis X-ray and lung CT scans. Data pre-processing and augmentation methods are applied for data standardization and variation. The instances in datasets are labeled as real or fake. The medical deepfake distinguish ability of YoloV3, YoloV5nu, YoloV5su, YoloV8n, YoloV8s, YoloV8m, YoloV8l, YoloV8x models tested on these datasets. In the analysis performed, all YOLO models showed almost full success in distinguishing Knee Osteoarthritis X-ray images. In lung CT scan images, although YoloV8 models generally achieved good performance, the YoloV5 models gave the best and worst results. While the best result was obtained from YoloV5su with a recall value of 0.997, the worst result was obtained from the YoloV5nu model with a recall value of 0.91. Furthermore, the best model (YoloV5su) works 60% faster than YoloV8x model, which has the second highest performance. The findings show that YoloV5su can be used for fast and accurate medical deepfake detection.;"Medical deepfake image detection;deep learning;YOLO;convolutional neural networks";IEEE
266;Optimization of DeepFake Video Detection Using Image Preprocessing;"A. Berjawi; K. Samrouth; O. Deforges";2023;Deep learning has been evolving recently which allowed it to handle complex problems like big data, computer vision, and human-level control. One of the deep learning-powered applications recently emerged is called �deepfake�. Deepfake algorithms have recently been a controversial development in Artificial Intelligence, because they use deep learning to generate fake yet realistic content based on an input dataset. As a result, many are concerned with the potential risks in terms of cyber-security as it causes threats to privacy, democracy, and national security. Multiple techniques were proposed to detect deepfake videos, however most cannot cope with the variety of the deepfake generation techniques. Therefore, in this study, we optimize one of the best existing deepfake detection methods based on Xception model. In particular, our proposed optimization scheme consists of a pre-processing phase performing advanced image enhancement on the videos in hand for highlighting the face features for better feature extraction as well fake content detection, which is preceded by a close-up dataset cleansing. Our experiments show that the proposed pre-processing optimization scheme had improvemes the performance of the Xception Binary Classifier- Inference model from 94% to 96%.;"Deep Learning;Image Processing;Deepfake;Pre-processing;Xception Binary Classifier-Inference model";IEEE
267;An effective approach for detecting deepfake videos using Long Short-Term Memory and ResNet;"S. Keerthana; N. Deepika; E. Pooja; I. Nandhini; M. Shanthalakshmi; G. R. Khanaghavalle";2024;Deep learning algorithms are becoming more potent and producing human-synthesized, undifferentiated footage is a simple process thanks to advances in computing power. A method of synthesizing human images called deep fakes is built on neural network techniques like GAN. These technologies use deep learning algorithms to overlay target pictures onto the source films, producing realistic-looking deep-fake photos and videos. In this work, we provide a novel deep-learning approach that can reliably discriminate between actual and AI-generated fake videos. In this work, we test our method on a large number of balanced and mixed datasets created by mixing various publicly available datasets, such as Face-Forensic++, Deepfake detection, Celeb DF, and other publicly available datasets as images and videos, to emulate real-time scenarios and improve model performance with real-time data by using LSTM and ResNet.;"Deep Learning;Computer Vision;Deepfake;GAN;LSTM;ResNet";IEEE
269;Comparative Analysis of Deepfake Detection Models;"O. Jannu; V. Sekar; T. Padhy; P. Padalkar";2024;Deepfakes, which leverage advanced machine learning techniques such as generative adversarial networks (GANs), pose a significant threat to the integrity of visual content and raise concerns about misinformation and identity theft. This research provides a comparative analysis of various deepfake detection models, aiming to dissect their strengths and weaknesses. Notable architectures like Xception and ResNet50 exhibit high accuracy, precision, and recall with minimal gender bias. However, the Swin Transformer, while excelling in fake image detection, faces challenges with real images, suggesting potential bias. The CNN model demonstrates subpar performance, emphasizing limitations in classifying both fake and real images effectively. MobileNet shows moderate overall performance but maintains balanced precision and recall. The study recommends an ensemble approach to combine model strengths and address individual weaknesses. Future work should focus on refining model architectures, exploring ensemble strategies, and mitigating biases in real image detection.;"Deepfakes;Deepfake Detection;Comparative Analysis;Neural Networks;Machine Learning;Ensemble Approach;Biases;Model Evaluation";IEEE
271;Deepfake Detection Based on Multi-scale RGB-Frequency Feature Fusion;"Y. Meng; X. Wang; X. Wang; Z. Liu; H. Zhou";2024;Withthe rapid advancement of Deepfake technology, Deepfake content is becoming increasingly realistic and is being widely utilized in political forgery, financial fraud, and the dissemination of false news. In order to more accurately detect Deepfake images and adapt the detection model to various compression scenarios, we propose a forgery detection model based on multi-scale Rgb-Frequency domain feature extraction. This model employs different scale size feature extraction in CNN and extracts multi-scale features in the RGB domain. Subsequently, different feature sequences are input into the Transformer decoder to establish connections between modules and perform classification. The results demonstrate that MRFD exhibits strong robustness and generalization ability when adapting to changes in compression rates. On the LQ dataset of FF++, the ACC and AUC are 90.87% and 93.87%, respectively. The ACC on HQ dataset reaches 97.54% with an AUC of 99.27%.;"Deepfake detection;CNN combined with ViT;Rgb-Frequency domain feature fusion;multi-scale feature extraction";IEEE
272;Employing Deep Learning Approaches to Detect Deepfake Attributes in Videos;"G. Malleswari; A. S. Reddy; R. Raja";2024;The combination of �fake� and deep learning techniques is known as deepfake technology. Deepfakes are created and detected using deep learning, a form of artificial intelligence. Generative adversarial networks, which are made up of two machine learning models cooperating, are used to create these deepfakes. People may grow less and less inclined to believe content that is genuine as long as deepfake photos and videos keep appearing on social media. Deepfake detection techniques are designed to discriminate between real and fake photos and videos on social media. These techniques rely on training the detection models using datasets that contain both genuine and fraudulent images or videos, highlighting the need for high-quality and diverse data for effective detection. In this research, we initially delve into the realm of deepfake technology and the associated challenges. Subsequently, we identify accessible video datasets. Following that, we employ long short-term memory for learning sequences and utilize convolutional neural networks for classifying eye states. Additionally, we leverage the eye aspect ratio to identify blinking intervals and compute the dimensions of closed and open eyes.;"Deepfake images;Generative adversarial networks;deep learning;machine learning;convolutional neural networks";IEEE
273;Deep fake Image Detection based on Modified minimized Xception Net and DenseNet;"I. Sahib; T. A. A. AlAsady";2022;This paper deals with the problem of image forgery detection because of the problems it causes. Where The Fake im-ages can lead to social problems, for example, misleading the public opinion on political or religious personages, de-faming celebrities and people, and Presenting them in a law court as evidence, may Doing mislead the court. This work proposes a deep learning approach based on Deep CNN (Convolutional Neural Network) Architecture, to detect fake images. The network is based on a modified structure of Xception net, CNN based on depthwise separable convolution layers. After extracting the feature maps, pooling layers are used with dense connection with Xception output, to in-crease feature maps. Inspired by the idea of a densenet network. On the other hand, the work uses the YCbCr color system for images, which gave better Accuracy of %99.93, more than RGB, HSV, and Lab or other color systems.;"convolutional neural network (CNN);Xception net;Densenet;depthwise separable convolution;Deep fake";IEEE
274;Unmasking the Illusion: Deepfake Detection through MesoNet;"A. Gupta; D. Pandey";2024;In today�s era of vast digital manipulation, the rise of deepfake technology poses a significant challenge to genuineness of multimedia content and introduces a profound risk to privacy, cybersecurity, and information integrity. Our research contributes to the ongoing discussion on deepfake detection, with a particular focus on assessing effectiveness of MesoNet model. It focuses on analysis of face micro-expressions and makes use of the Face2Face deepfake dataset, known for its adeptness in facial reenactment. Objectives of the research include evaluating MesoNet's efficacy by scrutinizing its performance across various parameters, fine-tuning the model for improved results, and gaining nuanced insights into its capabilities. Results reveal a notable advancement, with MesoNet achieving an accuracy of 90.4%, surpassing the previous 89.1%. Improved results after careful adjustment of activation functions and regularization parameters underscores the significance of hyperparameter optimization in deep learning models.;"CNN;deepfake;MesoNet;face swap;expression swap;Face2Face";IEEE
275;DeepFakes Detection in Videos using Feature Engineering Techniques in Deep Learning Convolution Neural Network Frameworks;"S. J. Burroughs; B. Gokaraju; K. Roy; L. Khoa";2020;In this paper, we discuss the intermediate results of our on-going study of DeepFakes detection in videos. Our core focus is in exploitation of feature engineering as a precursor filtering technique, to the deep learning-based convolution neural network (CNN) classification frameworks. In previous research, we focused on the standard deviation of the points of interest from SIFT or Scale-Invariant Feature Transform, to detect whether visual media has been compromised with misinformation. Hence, in this new approach we rely on classical frequency analysis of images that reveals different behaviors at higher frequencies. We noticed in literature review that there lies a distinct contrast of range of frequency component that emphasize important information in images [11]. We plan to use Discrete Wavelet Transform, abbreviated as DWT, and anticipate improvement of detection accuracy when used on complex and poor-quality images of FaceForensics++. The DWT features will be input to the CNN binary classification to further analyze the performance essentially when detecting this fraudulent information and to compare the detection performance against previous research which used Scale-Invariant Feature Transform.;"DeepFake;deep learning;discrete wavelet transform;frequency;cyber identity;security";IEEE
276;Deepfake Detection: A Multi-Algorithmic and Multi-Modal Approach for Robust Detection and Analysis;"S. Nailwal; S. Singhal; N. T. Singh; A. Raza";2023;In a time when deepfakes are eroding the reliability of digital media, our innovative research introduces a multi-faceted framework that achieves unprecedented levels of detection accuracy. Boasting a 97% success rate in verifying visual content and an almost unblemished 98.5% in audio analysis, our system serves as a formidable barrier against the malicious alteration of digital assets. Central to our model's stellar performance is the seamless integration of convolutional neural networks (CNNs) with ReLU activation mechanisms, all fine-tuned via stochastic gradient descent (SGD). This expertly engineered architecture is highly proficient at analyzing the nuanced spatial features of visual media, and it works in synergy with cutting-edge machine learning algorithms. For the audio detection aspect, we employ random forest algorithms, celebrated for their robustness and versatility. This ensemble learning approach adds an extra layer of complexity to the model, effectively identifying the intricate spectral and temporal characteristics of audio streams, thereby boosting the overall efficacy of our detection system. Our methodology is further fortified by meticulous data preprocessing methods, such as normalization and data augmentation, which ensure the model's robustness against a myriad of deepfake techniques. This groundbreaking research not only establishes a new benchmark in the arena of deepfake detection but also has significant ramifications for the wider field of cybersecurity and the preservation of digital authenticity. With its unmatched performance metrics, our research represents a pivotal advancement in combating the growing menace of deepfakes in today's digital society.;"deepfake detection;SGD;CNN;deep learning;random forest;ReLu;GAN";IEEE
277;Deep Fake in picture using Convolutional Neural Network;"J. N. Singh; A. Gautam; H. Tomar";2023;Deepfake is a system that combines fake pictures and videos with deep learning. Deep learning is the source of Deepfake. The unethical practice of creating falsified photographs and movies is now possible because of neoteric advances in the fields of Artificial Intelligence and Machine Learning. Today, it is very easy to create photo simulative images using generative adversarial networks. These fake images and videos are widely available on the internet and social media. It is difficult to tell which of them is real or not. These images are typically taken with the goal of stirring up social disturbance, political turmoil, or distributing false information among the general public. Viewers will easily comprehend these images because they will look to be real. Deepfake is rapidly harming individuals, communities, companies, security, religion, and democracy, according to recent studies. These videos and photographs are of astounding quality, and they have a huge social media reach. It has far-reaching effects that are destructive beyond comprehension. An extensive overview of the different deep-fake methods is provided in this publication. So, the objective of this paper is to identify these fake images using a conventional neural network. In order to address this issue, we train a model for particular datasets, produce deep fakes, and then use that model to try to identify the deep fake. An authentic and false image is required for the training process in order to train the model.;"CNN;Image Detection;RNN";IEEE
278;Robust and Generalized DeepFake Detection;"S. Yadav; S. Bommareddy; D. K. Vishwakarma";2022;Images that are manipulated are prevalent and are on the spike because of the advancement in deep convolutional neural networks (CNNs) techniques. There have been several concerns regarding the advent spread of false information. There exists a need for a reliable and robust method to detect such fake images. In this paper, analysis was done using the architecture SlowFast in detecting manipulated videos. This paper focuses on detecting DeepFake videos under three distinct scenarios, which are (i) all manipulation detection, (ii) single manipulation detection, and then (iii) cross manipulation detection used to test the veracity of the videos. The manipulation methods and designing algorithms to categorize such unknown manipulation techniques were used.;"Deepfakes;Deepfake Detection;Media forensics;Computer Vision;SOTA(State-Of-The-Art);Facial Manipulation Detection";IEEE
279;Deepfake Detection using GAN Discriminators;"S. A. Aduwala; M. Arigala; S. Desai; H. J. Quan; M. Eirinaki";2021;Deepfake videos are videos where the features of a person are replaced with the features of another person. Videos can be manipulated using powerful Deep Learning techniques. This technology may be used maliciously as a means of misinformation, manipulation, and persuasion. There are currently not many solutions to identify products of Deepfake technology, although there is significant research being conducted to tackle this problem. One often researched deep learning technology is the Generative Adversarial Network (GAN). These networks are commonly used to generate Deepfake videos but not used for their detection. In this work, we explore solutions based on GAN discriminators as a means to detect Deepfake videos. Using MesoNet as a baseline, we train a GAN and extract the discriminator as a dedicated module to detect Deepfakes. We test several discriminator architectures using multiple datasets to explore how the efficacy of the discriminator varies with different setups and training methods. Finally, we propose a model to boost the efficacy of a group of GAN discriminators using ensemble methods. Our results show that GAN discriminators, even augmented by ensemble methods, do not perform well on videos from unknown sources.;"Deepfake Detection;Generative Adversarial Networks;GAN;Discriminator;Deepfake Videos;Deep Learning;Image Processing;Feature Recognition";IEEE
280;Transfer-Learning and YOLO V7 Hybridised for Human Cropping for Deepfake Detection Algorithms;"N. Waqas; S. I. Safie; K. A. Kadir; S. Khan; A. A. Khan";2023;The advent of deep learning technology has created images and videos convincingly fake to appeal viewers enough in appearing close to real. Such image and video modalities, known as Deepfakes, can cause harm to individuals, communities, and countries. Detecting Deepfakes is essential to prevent their negative impacts, and several detection techniques that utilize deep learning algorithms have been developed over the recent past years. The algorithms reduce the target modality to dimensional latent space to include features important for subsequent reconstruction of the same modality from the developed latent distribution data. However, manual data preprocessing such as splitting frames and cropping regions from Deepfake videos for the facial features can be tedious and time-consuming. This article proposes YOLO V7 hybridised with transfer-learning to automate the cropping process in Deepfake videos and frames splitting, making it easier to extract facial features from videos. Various popular datasets have been used for Deepfake detection, and this article explores the benefits of the proposed approach. The results present a comparison of the proposed approach with state-of-the-art models from the levels of Precision, Recall, and mAP@.5 to demonstrate the robustness of the proposed technique. Notably, it is evident that our approach outperforms other models, boasting a precision value of 0.9009, a recall value of 0.8979, and an mAP@.5 value of 0.8745.;"Deepfake;YOLO;Deep learning;Transfer Learning";IEEE
281;Quick Classification of Xception And Resnet-50 Models on Deepfake Video Using Local Binary Pattern;"A. Arini; R. Broer Bahaweres; J. Al Haq";2022;The ease of deepfake videos are created indicates that there is an increasing need for authentication methods to classify deepfake videos. This issue is very sensitive, deepfakes make it possible to make someone say or do something they never said or did in a video, this puts a person�s dignity at risk. Another problem arises with the large size of the deepfake video dataset, because large datasets require longer training times and high computational specifications. This paper describes an approach to deepfake video classification using a small dataset and image processing. We propose a method that applies MTCNN (Multi-task Cascaded Convolutional Networks) to capture face data on video frames, image processing in the form of Gaussian filters and Local Binary Pattern (LBP) with Xception model for deepfake video classification and ResNet-50 as comparison. We use a dataset totaling 2000 frames from the entire Celeb-DF(V2) dataset. The results show that the proposed method, the Xception model, has better performance with an AUC value of 0.87 and an accuracy value of 0.79 compared to the ResNet-50 model.;"Video Classification;Deepfake;Xception;ResNet-50;MTCNN;Gaussian Filter;Local Binary Pattern;Small Dataset;Celeb-DF(V2)";IEEE
282;Integrating Audio-Visual Features For Multimodal Deepfake Detection;"S. Muppalla; S. Jia; S. Lyu";2023;Deepfakes are AI-generated media in which an image or video has been digitally modified. The advancements made in deepfake technology have led to privacy and security issues. Most deepfake detection techniques rely on the detection of a single modality. Existing methods for audio-visual detection do not always surpass that of the analysis based on single modalities. Therefore, this paper proposes an audio visual based method for deepfake detection, which integrates fine-grained deepfake identification with binary classification. We categorize the samples into four types by combining labels specific to each single modality. This method enhances the detection under intra-domain and cross-domain testing.;"Deepfake detection;Multi-modality deepfakes;Audio-visual feature learning";IEEE
284;4DPM: Deepfake Detection With a Denoising Diffusion Probabilistic Mask;"R. Yang; Z. Deng; Y. Zhang; X. Luo; R. Lan";2024;In the face of increasingly realistic fake human faces, research on enhancing the differences between real and fake images is valuable for improving the generalization capabilities of fake face detection models. In this letter, we propose a method called DPMask (Diffusion Probabilistic Mask) to amplify the distinctions between authentic and counterfeit human facial images. Specifically, we use a dataset consisting of real human facial images and Simplex noise to train a denoising diffusion probabilistic model for the proposed DPMask. Subsequently, we separately apply the DPMask and U-Net to real and fake human facial images to create noticeably distinct genuine and counterfeit human facial images. A lightweight classification network blue is further designed based on RepVGG to classify the newly generated real and fake human faces. Experimental results demonstrate that our model achieves high accuracy on a manually created fake face dataset (RFFD), a GAN-generated fake face dataset (Seq-DeepFake), and a DDPM-generated face dataset (HiFi-IFDL). Furthermore, the addition of DPMask significantly improves the performance of some public fake face detection models.;"DDPM;deepfake detection;DPMask;lightweight model";IEEE
285;DeepFake Detection Based on Discrepancies Between Faces and Their Context;"Y. Nirkin; L. Wolf; Y. Keller; T. Hassner";2022;We propose a method for detecting face swapping and other identity manipulations in single images. Face swapping methods, such as DeepFake, manipulate the face region, aiming to adjust the face to the appearance of its context, while leaving the context unchanged. We show that this modus operandi produces discrepancies between the two regions (e.g., Fig. 1). These discrepancies offer exploitable telltale signs of manipulation. Our approach involves two networks: (i) a face identification network that considers the face region bounded by a tight semantic segmentation, and (ii) a context recognition network that considers the face context (e.g., hair, ears, neck). We describe a method which uses the recognition signals from our two networks to detect such discrepancies, providing a complementary detection signal that improves conventional real versus fake classifiers commonly used for detecting fake images. Our method achieves state of the art results on the FaceForensics++ and Celeb-DF-v2 benchmarks for face manipulation detection, and even generalizes to detect fakes produced by unseen methods.;"Image forensics;deep learning;deep fake;face swapping;fake image detection";IEEE
286;Unmasking Deep Fakes: Detecting Low-Quality Forgeries through Unseen Artifacts;"M. Venkateshwarlu; M. Yashaswi; D. Shah; R. A. Reddy";2024;The spread of deepfakee-technology is a danger to the veracity of multimedia material, since it may be used to manipulate people's identities or spread false information. Low-quality forgeries continue to be difficult to detect because of their subtle artifacts, which elude traditional detection approaches. This is true even while deep fake detection algorithms have made significant progress in identifying high-quality forgeries. This research work presents a unique method for identifying hidden elements in low-quality forgeries, which may be used to uncover deep fakes. The proposed approach, which makes use of sophisticated machine learning algorithms and computer vision techniques, is centred on locating and taking advantage of distinctive artifacts that are introduced throughout the deep fake production process. This study provides a thorough analysis of these artefacts and show how well they can distinguish between real multimedia material and poor-quality deep fakes. The proposed technique is effective in properly detecting low-quality forgeries of photos, videos, and audio recordings. These findings are based on experiments conducted on a variety of datasets. Additionally, the proposed method's resilience is assessed against the cutting-edge deep fake creation techniques and emphasize its practical benefits in preventing the distribution of false information.;"Deepfakes;generative adversarial networks;convolution neural networks;visibility matrix;cross-entropy";IEEE
287;DeepFake Videos Detection and Classification Using Resnext and LSTM Neural Network;"S. Patel; S. K. Chandra; A. Jain";2023;Deepfake videos, which are artificial intelligence-altered videos that have acquired extensive awareness recently. Deep learning algorithms are utilized to create these deepfake films, which are meant to disseminate false information about anyone, including politicians and celebrities. These movies have been purposefully made viral in order to propagate propaganda and false information, to frighten people, and to destabilize society. It is exceedingly challenging for a casual viewer to recognize a deep fake video with the naked eye. Finding these manipulated films has been extremely difficult and requires careful attention. In order to recognize a deepfake movie, this paper, a novel methodology that combines ResNext, a Convolutional Neural Network (CNN) algorithm, with Long Short-Term Memory (LSTM), a Recurrent Neural Network (RNN) has been developed. It is found that as the number of epochs increased, the model's accuracy increased and its training loss reduced.;"Artificial Intelligence;Deepfake;Deep learning algorithm;Convolutional Neural Network (CNN);ResNext;LSTM;Recurrent Neural network (RNN)";IEEE
289;A Study On Deep Fakes Detection Using Blinks and Tracker;"V. C; K. S; R. V R; S. S; T. R";2022;Deep learning, a type of artificial intelligence (AI), replicates how the human brain processes data when processing data for tasks including speech recognition, object detection, visual object recognition, language translation, and decision-making. Generative Adversarial Network (GAN) is an outstanding generative version which can be extensively utilized in diverse applications. Recent research has indicated that it's far feasible to achieve faux face photographs with an excessive visible excellence primarily based totally in this novel version. For instance, the example may be impacted by a person's orientation, age, the hour of the day, or level of personal wellbeing. The misuse of the fake faces in photo manipulation could lead to certain ethical, moral, and legal issues. Therefore, in this work we first recommend a Convolution Neural Network (CNN) based entirely technique to find fake face photos produced by the modern-day pleasant technique, and we provide practical evidences to indicate that the proposed technique can create high-satisfactory results with a median accuracy over 87.5% which was accomplished in previous papers and projects. In order to further support the logic of our method, we also provide comparison results assessed on a few variations of the suggested CNN architecture, including the excessive by skip filter, the variety of the layer agencies, and the activation function.;"Deep Learning;Deep fake;GAN's;Cyber Security;CNN";IEEE
291;DeepFake-o-meter: An Open Platform for DeepFake Detection;"Y. Li; C. Zhang; P. Sun; L. Ke; Y. Ju; H. Qi; S. Lyu";2021;In recent years, the advent of deep learning-based techniques and the significant reduction in the cost of computation resulted in the feasibility of creating realistic videos of human faces, commonly known as DeepFakes. The availability of open-source tools to create DeepFakes poses as a threat to the trustworthiness of the online media. In this work, we develop an open-source online platform, known as DeepFake-o-meter, that integrates state-of-the-art DeepFake detection methods and provide a convenient interface for the users. We describe the design and function of DeepFake-o-meter in this work.;"Multimedia Forensics;DeepFake Detection;Software Engineering";IEEE
292;An Efficient Deep Video Model For Deepfake Detection;"R. Sun; Z. Zhao; L. Shen; Z. Zeng; Y. Li; B. Veeravalli; Y. Xulei";2023;The use of deep learning technology to manipulate images and videos of people in ways that are difficult to distinguish from the real ones, known as deepfake, has become a matter of national security concern in recent years. As a result, many studies have been carried out to detect deepfake and manipulated media. Among these studies, deep video models based on convolutional neural networks have been the preferred method for detecting deepfake in videos. This study presents a novel deep video model called Sequential-Parallel Networks (SPNet) that provides efficient deepfake detection. The SPNet model consists of a simple yet innovative sequential-parallel block that first extracts spatial and temporal features sequentially, then concatenates them together in parallel. As a result, the presented SPNet possesses comparable spatiotemporal modeling abilities as most state-of-the-art deep video methods but with lower computation complexity and fewer parameters. The efficiency of the presented SPNet is demonstrated on a large-scale deepfake benchmark in terms of high recognition accuracy and low computational cost.;"Deepfake;Deep Video Model;Sequential-Parallel Networks;Spatio-temporal Modelling";IEEE
294;Comparative Analysis and Evaluation of CNN Models for Deepfake Detection;"P. Ritter; D. Lucian; Anderies; A. Chowanda";2023;Deepfake technology has become a significant concern due to its ability to create highly realistic fake videos and images, leading to the potential deception of individuals. Detecting deepfakes has become a critical research area in computer vision and multimedia forensics. This paper presents a comparative analysis of deepfake detection models, focusing on evaluating their accuracy and robustness. Four CNN models, namely ResNet-152, MobilenetV3, Convnext Large, and EffecientNetB7, were implemented and trained using a custom dataset obtained from FaceForensics++. The models were evaluated based on training accuracy, average loss, and testing accuracy. An LSTM layer was also incorporated into each model's architecture to leverage sequential information. The results demonstrate varying performance among the models, with EfficientNet B7 achieving the highest testing accuracy of 75%. The findings of this study provide insights for future research in this critical area.;"deepfake detection;CNN models;comparative analysis;accuracy;LSTM layer";IEEE
296;Exploiting Correlation Between Facial Action Units for Detecting Deepfake Videos;"Q. H. Vu; P. Singh";2024;The potential misuse of deepfakes has led to an increase in research into deepfake detection methods. These methods employ machine learning, deep learning, and other intricate techniques to spot subtle inconsistencies in deepfake videos. However, as deepfake technology advances, the current research exposes gaps, such as inadequate performance on real-world data and susceptibility to adversarial attacks. Among various detection methodologies, the use of identity-based features like facial action units shows potential in identifying synthetic content. Given that correlations between facial features may be distinctive, they could play a crucial role in differentiating real and artificial imagery. In this study, we propose a method of high accuracy to distinguish genuine videos from deepfakes by exploiting the correlation of facial action units. Our main contributions are twofold: (1) merging identity-based techniques with traditional machine learning for deepfake detection, and (2) evaluating this approach's robustness against compression.;"Deepfake detection;action units;facial features";IEEE
297;ShuffleSR: Image Deepfake Detection Using Shuffle Transformer;"C. Yang; C. Zhu; C. Deng; Z. Xiao";2023;We proposed an improved method based on the Shuffle Transformer for facial forgery detection. The method incorporated SE (Squeeze-and-Excitation) and ROI (Region of Interest) modules. By introducing the SE module, the network's channel attention capability was enhanced and enabled the model to focus more on important feature channels. Meanwhile, the ROI module was employed to extract the region of interest corresponding to the face, enabling the network to concentrate on processing facial regions. The performance of facial forgery detection was improved as a result. Evaluations were conducted on the DFDC dataset and a custom dataset containing various forgery algorithms. The results demonstrated that the enhanced Shuffle Transformer achieved significant performance improvements in facial forgery detection and exhibited better robustness and generalization capabilities while excelling across different forgery algorithms.;"deep learning;Shuffle Transformer;facial forgery detection;region of interest";IEEE
298;Cross-Modality and Within-Modality Regularization for Audio-Visual Deepfake Detection;"H. Zou; M. Shen; Y. Hu; C. Chen; E. S. Chng; D. Rajan";2024;Audio-visual deepfake detection scrutinizes manipulations in public video using complementary multimodal cues. Current methods, which train on fused multimodal data for multimodal targets face challenges due to uncertainties and inconsistencies in learned representations caused by independent modality manipulations in deepfake videos. To address this, we propose cross-modality and within-modality regularization to preserve modality distinctions during multimodal representation learning. Our approach includes an audio-visual transformer module for modality correspondence and a cross-modality regularization module to align paired audio-visual signals, preserving modality distinctions. Simultaneously, a within-modality regularization module refines unimodal representations with modality-specific targets to retain modal-specific details. Experimental results on the public audio-visual dataset, FakeAVCeleb, demonstrate the effectiveness and competitiveness of our approach.;"Audio-visual fusion;deepfake detection;contrastive learning;representation regularization";IEEE
299;Deepfake Detection Using XceptionNet;"A. V; P. T. Joy";2023;This paper presents a precise and highly efficient method for detecting deepfakes, which have become increasingly accessible via mobile applications, posing significant threats to society. Leveraging the Xception network, a state-of-the-art convolutional neural network (CNN), we address the challenge of identifying and categorizing deepfakes in both images and videos. With deepfakes achieving unprece-dented levels of visual fidelity, traditional detection methods are inadequate. The Xception network excels in capturing intricate visual patterns and anomalies indicative of deepfake manipulation. Trained on extensive datasets encompassing both real and deepfake content, it offers exceptional generalization capabilities, enabling accurate classification of previously unseen instances. This research emphasizes the critical need for robust deep fake detection mechanisms to protect against malicious use, ensuring compliance with official rules and ethical standards, and preserving public trust. The proposed Xception- based approach holds promise in addressing this pressing challenge, providing a reliable means to distinguish deepfakes from authentic content, ultimately safeguarding the integrity of digital media and information dissemination.;"Deepfake;XceptionNet;Deep learning";IEEE
302;Forgery-Domain-Supervised Deepfake Detection With Non-Negative Constraint;"Y. Yuan; X. Fu; G. Wang; Q. Li; X. Li";2022;Fake faces produced by deepfake techniques have attracted public concerns in recent years. Deepfake detection is a binary classification task that distinguishes fake faces from real ones. As the training data for deepfake detection is usually generated from real faces via various face forgery methods, it is difficult for a single binary decision boundary to distinguish fake faces. Besides that, the learned features often involve irrelevant information for identifying fake faces that are generated from diverse forgery methods. To deal with such challenges, unlike existing approaches that regard fake detection as a binary classification, we re-model the task as a multiclass forgery-domain classification task, where each forgery method is treated as a distinct class. This simplifies the complex decision boundary brought by the diversity of forgery patterns and provides more forgery-relevant information for the learning process. In addition, we introduce a non-negative constrained learning framework composed of non-negative features and a non-negative constrained classifier (NCC) to block irrelevant features with zero weights and enhance forgery-relevant features with positive weights, leading to a sparse structure of the classifier. Furthermore, to capture subtle and discriminative forgery-relevant features, we propose an integration module over augmented faces based on cross-attention. We demonstrate that our approach achieves competitive performance and generalization ability on widely-used benchmarks through extensive experiments.;"Classifier regularization;deepfake detection;face classification;face forensics;feature integration";IEEE
304;Deepfake Detection using Inception-ResNet-V2 Network;"R. R. Rajalaxmi; S. P. P; R. A. M; P. S; D. P; G. E";2023;Deepfakes entails obscene videos in which a face can be changed with someone else's utilizing neural networks. Deepfakes are a public problem, thus developing methods to detect them is critical. With deepfake and human-level control, deep learning has already utilized to address complicated issues. Deepfake is a new branch of AI technology, which in that one's face is superimposed on another's face, which is popular on social media. Deep learning techniques were also employed in the development of software that affects national security, democracy and privacy. One of the most current applications that use deep learning is deepfakes. Algorithms for deepfake may generate fake photos and movies which are indistinguishable from real ones. As a result, the development of technology capable of automatically detecting and assessing the reliability of digital video is critical. This research describes algorithms for detecting deepfakes. By reviewing the influence of deepfakes and deepfake recognition systems, this work enables the creation of new and so many effective methodologies to cope with increasingly complex deepfakes. InceptionResNetV2 architecture in Convolutional Neural Networks (CNN) is utilized in this comparative study to distinguish real and deepfake images.;"Deep Learning;Deepfake;CNN;Inception ResNet-V2";IEEE
305;Application of spatial and Wavelet transforms for improved Deep Fake Detection;"F. Aymen; W. Hussein";2024;Deepfake technology has been controversial for the past recent years. It has been considered a double-edged sword for what it has the capability of doing. As much as deep fake technology can be beneficial in many situations, it has caused a global concern over the safety of individuals. It can be used to create inappropriate content to blackmail someone, or it can be used to fabricate fake news and cause chaos in society. Therefore, developing algorithms to detect whether any content is authentic or tampered with is crucial to protect people. With the evolution of Generative Adversarial Networks (GANs), many deepfake tools have evolved to create non-distinguishable content. This new evolution has raised the flag of the necessity to get matters into control. In this research, various new methods to detect deep fakes are proposed using the frequency analysis (Fourier transform and wavelet transform) of the frames of the videos to discriminate the footage achieving an accuracy of 92.24% using a novel CNN-LSTM model trained on Wavelet transform data. This research argues that the wavelet transform can hold information and features that can outperform training on spatial images on a custom dataset that combines many various datasets.;"Deepfake;spatial domain;frequency domain;Fourier transform;wavelet Transform;3DCNN;CNN-LSTM;Multimodal Model;Spatial-temporal Transformer";IEEE
307;Deepfake Video Detection Methods using Deep Neural Networks;"M. Kshirsagar; S. Suratkar; F. Kazi";2022;Nowadays, humans are dealing with incipient trouble known as deepfake videos, advanced with the usage of deep learning. Due to freely accessible deep fake technology equipment and inexpensive computational power, internet is flooded with fake media like fake images, videos, audios etc. Fake images and videos are causing threats to privacy, reputation and the very identity of common people. Researchers are taking efforts to develop tools using various Convolutional Neural Networks (CNNs) to automatically detect this fake media however the existing tools are not able to cope with the evolution of deep fakes. In this paper, 26 unique deep convolutional models are utilised for the task of deepfake video detection. The models can natively classify objects like table, face, humans, cars etc. However, the paper highlights the use of these models in detection of deepfake/manipulated images and videos by changing the top layer of the model with sigmoid layer hence, detecting artifacts in an image produced by Generative Adversarial Networks (GANs)[11]. Once the models are trained, the paper demonstrates the usefulness of model ensemble to improve the accuracy of proposed system and thereby making the system more reliable.;"Deep learning;deepfake detection;ensemble learning;autoencoders";IEEE
308;Deepfake Detection through Deep Learning;"D. Pan; L. Sun; R. Wang; X. Zhang; R. O. Sinnott";2020;Deepfakes allow for the automatic generation and creation of (fake) video content, e.g. through generative adversarial networks. Deepfake technology is a controversial technology with many wide reaching issues impacting society, e.g. election biasing. Much research has been devoted to developing detection methods to reduce the potential negative impact of deepfakes. Application of neural networks and deep learning is one approach. In this paper, we consider the deepfake detection technologies Xception and MobileNet as two approaches for classification tasks to automatically detect deepfake videos. We utilise training and evaluation datasets from FaceForensics++ comprising four datasets generated using four different and popular deepfake technologies. The results show high accuracy over all datasets with an accuracy varying between 91�98% depending on the deepfake technologies applied. We also developed a voting mechanism that can detect fake videos using the aggregation of all four methods instead of only one.;"DeepFake Detection;Xception;MobileNet;FaceForenscis++;Keras;TensorFlow";IEEE
310;Deepfake Detection System Using a Hybrid Model;"S. S; P. Kokil; S. D; P. A. Swamy";2023;There has been a rapid advancement in deep fake technology in recent years, which makes it increasingly difficult to detect fake images, especially those involving human faces, which have become difficult to detect. The traditional methods of detecting deep fake images are usually based on a human-crafted feature or a rule-based system, which can be easily beaten with simple cheating techniques. Intending to detect deepfake face images, we present a novel method that uses CapsNet and EfficientNet as feature extractors to detect deepfake face images. They are well suited to detect deepfake images that have undergone geometric transformations or variations as they can learn the spatial relationship between those features. Using EfficientNet, a powerful and efficient deep learning architecture, as a feature extractor, we extract high-level characteristics from an input image to create a more accurate image analysis.Based on our experiments,it was found that this method demonstrated the capability to detect various types of deep fake images with an accuracy rate of 99.64%, including those fabricated through face swapping and re-enacting. This method could be applied to a wide range of real-world applications, including in media forensics, law enforcement, and online media verification, so that it could be applied in many different contexts.;"EfficientNet;Capsule;Networks;Routing layer;Transfer learning;Deep fake";IEEE
311;A Novel Framework based on a Hybrid Vision Transformer and Deep Neural Network for Deepfake Detection;"M. Shahin; M. Deriche";2024;Generative Adversarial Networks (GANs) have enabled the creation of photo-realistic images from random noise. GAN based technologies however, led to the dissemination of synthetic images, often containing inappropriate and miss leading content, on social media. Detecting such manipulated images is crucial, yet challenging. The issue is compounded by the fact that GAN-generated images can be indistinguishable from authentic ones, rendering traditional forgery detection techniques ineffective. Deepfake images further exacerbate this problem, posing threats to news integrity, legal proceedings, and societal security. To address these challenges, we harness the potential of Vision Transformer (ViT) in conjunction with Convolutional Autoencoders (CAE) to craft innovative Framework for image analysis and deepfake detection. We introduce two distinct models, each offering unique insights into image processing. The proposed models yield excellent accuracy rate of approximately 87%, reaffirming the robustness and consistency of the proposed approach and enhanced performance compared to state of the art.;;IEEE
313;Deepfake Video Detection Based on Spatial, Spectral, and Temporal Inconsistencies Using Multimodal Deep Learning;"J. K. Lewis; I. E. Toubal; H. Chen; V. Sandesera; M. Lomnitz; Z. Hampel-Arias; C. Prasad; K. Palaniappan";2020;"Authentication of digital media has become an ever-pressing necessity for modern society. Since the introduction of Generative Adversarial Networks (GANs), synthetic media has become increasingly difficult to identify. Synthetic videos that contain altered faces and/or voices of a person are known as deepfakes and threaten trust and privacy in digital media. Deep-fakes can be weaponized for political advantage, slander, and to undermine the reputation of public figures. Despite imperfections of deepfakes, people struggle to distinguish between authentic and manipulated images and videos. Consequently, it is important to have automated systems that accurately and efficiently classify the validity of digital content. Many recent deepfake detection methods use single frames of video and focus on the spatial information in the image to infer the authenticity of the video. Some promising approaches exploit the temporal inconsistencies of manipulated videos; however, research primarily focuses on spatial features. We propose a hybrid deep learning approach that uses spatial, spectral, and temporal content that is coupled in a consistent way to differentiate real and fake videos. We show that the Discrete Cosine transform can improve deepfake detection by capturing spectral features of individual frames. In this work, we build a multimodal network that explores new features to detect deepfake videos, achieving 61.95% accuracy on the Facebook Deepfake Detection Challenge (DFDC) dataset.";"deepfake detection;deep learning;multi-modal;computer vision";IEEE
314;A New Approach to Detect Deepfake Video using Multi-Input Convolutional Neural Network;"M. A. Rahman; M. Ehsan Shahmi Chowdhury";2022;In this modern age, Deepfake videos are spreading around, having a severe impact on the social and personal lives of the general public. Efficient techniques, operating better than others, is hence in the requirement. In this research, combination of many objects like left eye, right eye and mouth shapes from image frames of videos are taken into consideration, thus achieving better accuracy than other detection techniques. In this proposal, deep learning techniques, specially the multi-input Convolution Neural Network, are executed. The proposal firstly detects the face, followed by specific objects such as left eye, right eye and mouth. Then multi-input CNN is applied that classifies the data based on eyes and mouth. After applying multi-input CNN, the accuracy increases impressively. Novel techniques are used to extract specific features like eyes, mouth. Memory storage was a concern for the proposal. Despite this, comparison with other relevant research works proved better accuracy and data analysis.;"Convolutional Neural Network;DeepFake Detection;Deep Learning;Image Frames;Video Detection";IEEE
315;Using the CNN Architecture Based on the EfficientNetB4 Model to Efficiently Detect Deepfake Images;"A. Zhalgasbayev; T. Aiteni; N. Khaimuldin";2024;This study evaluates the effectiveness of using the EfficientNetB4 model architecture for deepfake image detection and identifies the main challenges in developing an accurate model for deepfake image detection. Deepfake image detection is a complex task that requires lots of data, advanced models and new approaches for handling features in face images which shows that image is real or fake. This research is based on the Deepfake Detection Challenge (DFDC), which took place in 2019�2020, where world experts showed new approaches to solving this problem. During the research and development of the model, the best practices and experience of experts were used to identify the deepfake images.;"Deepfake;Deep Learning;EfficientNet;CNN;TensorFlow";IEEE
316;Deepfake Video Detection by Combining Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN);"Y. Al-Dhabi; S. Zhang";2021;Nowadays, people are facing an emerging problem called deepfake videos. These videos were created using deep learning technology. Some are created just for fun, while others are trying to manipulate your opinions, cause threats to your privacy, reputation, and so on. Sometimes, deepfake videos created using the latest algorithms can be hard to distinguish with the naked eye. That's why we need better algorithms to detect deepfake. The system we are going to present is based on a combination of CNN and RNN, as research shows that using CNN and RNN combined achieve better results. We are going to use a pre-trained CNN model called Resnext50. Using this, we save the time of training the model from scratch. The proposed system uses Resnext pretrained model for Feature Extraction and these extracted features are used to train the Long short-term memory (LSTM). Using CNN and RNN combined, we capture the inter frames as well as intra frames features which will be used to detect if the video is real or fake. We evaluated our method using a large collection of deepfake videos gathered from a variety of distribution sources. We demonstrate how our system may obtain competitive results while utilizing a simplistic architecture.;"Deep learning;Deepfake Detection;convolutional Neural Network (CNN);Recurrent Neural Network (RNN)";IEEE
317;Deepfake Detection with Deep Learning: Convolutional Neural Networks versus Transformers;V. L. L. Thing;2023;- The rapid evolvement of deepfake creation technologies is seriously threating media information trustworthiness. The consequences impacting targeted individuals and institutions can be dire. In this work, we study the evolutions of deep learning architectures, particularly CNNs and Transformers. We identified eight promising deep learning architectures, designed and developed our deepfake detection models and conducted experiments over well-established deepfake datasets. These datasets included the latest second and third generation deepfake datasets. We evaluated the effectiveness of our developed single model detectors in deepfake detection and cross datasets evaluations. We achieved 88.74%, 99.53%, 97.68%, 99.73% and 92.02% accuracy and 99.95%, 100%, 99.88%, 99.99% and 97.61 % AUC, in the detection of FF++ 2020, Google DFD, Celeb-DF, Deeper Forensics and DFDC deepfakes, respectively. We also identified and showed the unique strengths of CNNs and Transformers models and analysed the observed relationships among the different deepfake datasets, to aid future developments in this area.;"deepfakes;misinformation;detection;deep learning;convolutional neural networks;transformers;authenticity verification";IEEE
318;Deepfake Detection using Inception-ResnetV2;"A. Verma; D. Gupta; M. K. Srivastava";2021;"Deep learning has benefited us in resolving many complex problems. Computer vision is a subcategory of it. With the ability to find patterns from unstructured data, Deep learning has immense potential. Big techs are very keen on producing a computer with human brain-like decision-making capabilities. With all these sweeter sides comes the bitter side of it. Deepfake is one such occurrence. It creates a mask which contain properties of a particular person and can be applied to some other person. In this way the target is depicted doing deeds which he never did. With the increased capacity of a specific field i.e. Generative Adversarial Network (GAN); now we can create high-quality deepfakes. Deepfakes nowadays can easily deceive human eyes. The consequences of this can be devastating and unforeseeable. Creating chaos, privacy threats are some of the major reasons why people are questioning deepfakes. Victims� size has started including common public. What could be done is to keep a check over its spreading. This work has taken into consideration the problems that emerged by deepfakes and proposed a method to detect forgery among videos.";"Deep Learning;DeepFakes;Artificial Intelligence;Inception-ResnetV2";IEEE
319;DeepfakeStack: A Deep Ensemble-based Learning Technique for Deepfake Detection;"M. S. Rana; A. H. Sung";2020;"Recent advances in technology have made the deep learning (DL) models available for use in a wide variety of novel applications; for example, generative adversarial network (GAN) models are capable of producing hyper-realistic images, speech, and even videos, such as the so-called �Deepfake� produced by GANs with manipulated audio and/or video clips, which are so realistic as to be indistinguishable from the real ones in human perception. Aside from innovative and legitimate applications, there are numerous nefarious or unlawful ways to use such counterfeit contents in propaganda, political campaigns, cybercrimes, extortion, etc. To meet the challenges posed by Deepfake multimedia, we propose a deep ensemble learning technique called DeepfakeStack for detecting such manipulated videos. The proposed technique combines a series of DL based state-of-art classification models and creates an improved composite classifier. Based on our experiments, it is shown that DeepfakeStack outperforms other classifiers by achieving an accuracy of 99.65% and AUROC of 1.0 score in detecting Deepfake. Therefore, our method provides a solid basis for building a Realtime Deepfake detector.";"Deepfake;DeepfakeStack;GANs;Deep Ensemble Learning;Greedy Layer-wise Pretraining";IEEE
320;Detecting Deepfakes Using Deep Learning;"J. C. Dheeraj; K. Nandakumar; A. V. Aditya; B. S. Chethan; G. C. R. Kartheek";2021;"Images play an important role in defining human perception, and the power to manipulate such images gives immense power to malicious users. The new advancement in Artificial Intelligence, has altogether worked on the quality and productivity in creating counterfeit face pictures; for instance, the face manipulated by GANs is sensible to such an extent that it is hard to recognize the validness, either by the computer or by people. To improve the accuracy of recognizing facial pictures created by AI from genuine facial ones, an enhanced model has been proposed in this paper which is dependent on profound learnings like Deep Learning, Convolutional Neural Network (CNN), and Error Level Analysis (ELA). Our findings push the boundaries of understanding DeepFake detection and our solution to detect these images is based on the concepts of image error level and Deep learning. Our model uses the Convolutional Neural Network (CNN) architecture that utilizes error level analysis (ELA) to pre-process the images. We have utilized a dataset comprising on 24,000 images with equal split of real and deepfake images to traing and test our model. We were able to achieve an accuracy of 99%. The proposed model has a shorter training time and higher efficiency than most other methods for DeepFake detection.";"Convolutional Neural Network (CNN);Error Level Analysis (ELA);Deep Learning;DeepFake";IEEE
322;Deep fake Image Detection Based on Deep Learning Using a Hybrid CNN-LSTM with Machine Learning Architectures as Classifier;"O. A. H. H. Al-Dulaimi; S. Kurnaz";2024;One of the most important and difficult subjects in social communication is detecting deepfake images and videos. Deepfake techniques have developed widely, making this technology quite available and proficient enough so that there is worry about its bad application. Considering this issue, discovering fake faces is very important for ensuring security and preventing sociopolitical issues on a private and general level. Deep learning provides higher performance than typical image processing approaches when it comes to deepfake detection. This work presents construction of an artificial intelligence system, which is capable of detecting deepfake from more than one dataset. This study proposes neural network models based on deep learning using random forest (RF) and support vector machines (SVM) as classifier for deepfake detection. The use of two classifiers (RF) and (SVM) and their combination with a convolutional neural network is the first study of its kind in the field of deepfake detection in images from three open-source datasets (FaceForensics++, FaceAntiSpoofing, and iFakeFaceDB). This proposed method shows an accuracy of 96%, 87% and 52% in iFakeFaceDB, CelebA-Spoof, FaceForensics++ and respectively.;"Convolutional neural network;DeepFake detection;Machine learning";IEEE
323;Investigation Of Comparison on Modified CNN Techniques to Classify Fake Face in Deepfake Videos;"A. G. S; N. Thillaiarasu";2022;Deepfake is an advanced deep learning technology that will allow us to swap faces. With recent advancements in Neural network algorithms such as Generative Adversarial Neu- ral networks, hyper-realistic images and videos can be generated. It will be difficult to differentiate between fake and real images orvideos for naked eyes. These fake images and videos pose a real threat in various societal platforms. To reduce these issues various deep learning technologies can be used to classify deepfakes. Here we have compared three neural net models such as ResNext., Xception, and Ensemble of both. Our study has shown that the Ensemble method works better compared to others.;"GAN;ResNext;Xception;BlazeFace;CNN;En-semble;Deep Learning;Deepfake";IEEE
324;A Novel Framework for Detection of Digital Face Video Manipulation using Deep Learning;"S. Chandra; S. Saxena; S. Kumar; M. K. Chaube; S. K G; S. H. Alsamhi; E. Curry; A. Saif";2023;Digital face manipulation and classification have recently attracted the attention of academia and industry worldwide. Researchers have developed deep learning and computer vision techniques for detecting face manipulations, and it has become a challenging task to differentiate between authentic and manipulated face images manually. The challenge results in the decline of authenticity in digital media content. In this paper, we propose a framework for the classification of manipulating face images using the EfficientNet learning model. The proposed framework takes four digital facial forgeries: Face-Swap, Face-2-Face, DeepFakes, and neural textures. Multiple manipulation techniques are used to process manipulated faces, such as the Blaze-face tracking method, to determine the locations of the face images and pixel coordinates. The proposed framework is used first to identify the type of face manipulation and then to perform detection of the tampered regions in the face images. The proposed framework provided an automated benchmark that considers all four modification techniques in a realistic situation. The results show that the proposed framework outperforms existing approaches regarding accuracy and efficiency. Furthermore, the proposed framework is suitable for detecting digital face video manipulation in various applications, including forensics and security.;"Machine learning;deep learning;Face-Swap;neural textures;Face-2-Face";IEEE
325;Face forgery detection with a fused attention mechanism;"J. Wang; Y. Qi; J. Hu; J. Hu";2022;In recent years, the technology of forged faces has become more and more sophisticated, and the human eye cannot even distinguish these forged products. The fake face images or videos generated by this series of technologies are widely disseminated on the Internet, causing a serious impact on society, thus drawing attention to DeepFake detection, and more research is also inclined to this, but The current research has the problem that the extracted artifact features are relatively single, which leads to the relatively low performance of the artifact detection algorithm. To solve the limitations of the existing methods, the DeepFake detection method fused with attention mechanism is proposed, which extracts the global and local features of the face respectively. Artifact features are found in multiple regions of the face. The method is trained on the FaceForensics++ dataset, and the detection accuracy is improved in different network structures.;"DeepFake Detection;attention mechanism;feature fusion";IEEE
326;Image Feature Detectors for Deepfake Image Detection Using Transfer Learning;"K. M. A. Alheeti; S. S. Al-Rawi; H. A. Khalaf; D. Al Dosary";2021;Deepfake is heavily based on artificial intelligence and machine learning to generate audio content and visuals with an extremely high potential to deceive. In this paper, a new detection system to identify any deepfake for audio or images. In other words, transfer learning techniques are used to present an intelligent detection system of deepfake videos. In this work, a support vector machine is employed for the detection process. Outstanding results are obtained from the train and test this system with various types of images that are real or fake.;"AI;deepfake;detection;machine learning";IEEE
327;Audio-Visual Deepfake Detection System Using Multimodal Deep Learning;"A. Parikh; K. Pereira; P. Kumar; K. Devadkar";2023;With the rise of deepfake videos in today�s digital landscape, there is a pressing need to develop advanced detection and mitigation technologies. Deepfake videos, which use machine learning algorithms to manipulate and alter audiovisual content, can spread false information, create confusion, and even cause harm. To address this issue, our work leverages Deep Learning technology to process audio-visual data in real-time through a web interface, specifically a browser plugin. Our approach uses a multimodal neural network that is fed extracted audio and visual features from a video for deepfake prediction. The model achieves a maximum validation accuracy of 90 percent and is used to build an API that is responsive, and low-latency. Our end-to-end solution is implemented as a Chrome extension using JavaScript that communicates with the API. With this solution, we aim to contribute to the development of advanced deepfake detection and mitigation technologies that can help prevent the spread of false information and its potential consequences.;"Deepfakes;Computer Vision;Deep Learning;Multimodal Datasets";IEEE
329;IsSwap: Deep Fake Detection;"A. Aggarwal; S. Wadhwa; P. Gupta; N. Anand; R. Kushwah";2021;In this era of technology the intake of information through digital media has grown exponentially and it has provided people with personal motives to spread falsified information among the masses to create biased opinions and a sense of unrest. The falsified information is provided to the people especially during elections to create political unrest among the masses or simply to spread a rumour. Since most of the information consumed by people is in the form of videos, it has become a great target spot for people with malicious intent. Deep-Fake is an emerging threat to celebrities, political faces and JSON common people. The paper is aimed at overcoming the given challenge by providing a fast and reliable method to determine the authenticity of a given video. We have proposed a model for detecting deep fake videos via XceptionNet and ResNet50 together with multiple hidden layers of neural networks. The results shows that the proposed method outperformed other state-of-the-art methods in terms of precision and recall rate and performed well in predicting whether the video is fake or real.;"Deep Learning;GAN;Neural Network;Deepfake;Video Manipulation";IEEE
330;Analyzing Fairness in Deepfake Detection With Massively Annotated Databases;"Y. Xu; P. Terh�rst; M. Pedersen; K. Raja";2024;In recent years, image and video manipulations with Deepfake have become a severe concern for security and society. Many detection models and datasets have been proposed to detect Deepfake data reliably. However, there is an increased concern that these models and training databases might be biased and, thus, cause Deepfake detectors to fail. In this work, we investigate factors causing biased detection in public Deepfake datasets by (a) creating large-scale demographic and non-demographic attribute annotations with 47 different attributes for five popular Deepfake datasets and (b) comprehensively analysing attributes resulting in AI-bias of three state-of-the-art Deepfake detection backbone models on these datasets. The analysis shows how various attributes influence a large variety of distinctive attributes (from over 65M labels) on the detection performance which includes demographic (age, gender, ethnicity) and non-demographic (hair, skin, accessories, etc.) attributes. The results examined datasets show limited diversity and, more importantly, show that the utilised Deepfake detection backbone models are strongly affected by investigated attributes making them not fair across attributes. The Deepfake detection backbone methods trained on such imbalanced/biased datasets result in incorrect detection results leading to generalisability, fairness, and security issues. Our findings and annotated datasets will guide future research to evaluate and mitigate bias in Deepfake detection techniques. The annotated datasets and the corresponding code are publicly available. The code link is: https://github.com/xuyingzhongguo/DeepFakeAnnotations.;"Deepfake;deepfake detection;databases;bias;fairness;image manipulation;video manipulation";IEEE
332;Towards Measuring Fairness in AI: The Casual Conversations Dataset;"C. Hazirbas; J. Bitton; B. Dolhansky; J. Pan; A. Gordo; C. C. Ferrer";2022;This paper introduces a novel dataset to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of age, genders, apparent skin tones and ambient lighting conditions. Our dataset is composed of 3,011 subjects and contains over 45,000 videos, with an average of 15 videos per person. The videos were recorded in multiple U.S. states with a diverse set of adults in various age, gender and apparent skin tone groups. A key feature is that each subject agreed to participate for their likenesses to be used. Additionally, our age and gender annotations are provided by the subjects themselves. A group of trained annotators labeled the subjects� apparent skin tone using the Fitzpatrick skin type scale. Moreover, annotations for videos recorded in low ambient lighting are also provided. As an application to measure robustness of predictions across certain attributes, we provide a comprehensive study on the top five winners of the DeepFake Detection Challenge (DFDC). Experimental evaluation shows that the winning models are less performant on some specific groups of people, such as subjects with darker skin tones and thus may not generalize to all people. In addition, we also evaluate the state-of-the-art apparent age and gender classification methods. Our experiments provides a thorough analysis on these models in terms of fair treatment of people from various backgrounds.;"AI robustness;algorithmic fairness;deepfakes;dataset;age;gender;skin tone";IEEE
333;EfficientNets for DeepFake Detection: Comparison of Pretrained Models;"A. A. Pokroy; A. D. Egorov";2021;Rapid advances in media generation techniques have made the creation of AI-generated fake face videos more accessible than ever before. In order to accelerate the development of new ways to expose forged videos, Facebook created Deep Fake Detection Challenge (DFDC), which demonstrated multiple approaches to solve this problem. Analysis of top-performing solutions revealed that all winners used pre-trained EfficientNet networks, which was finetuned on videos containing face manipulations. Because of this observation, we decide to compare the performance of EfficientNets models within the task of detecting fake videos. For comparison, we use models, based on the highest-performing entrant of DFDC, entered by Selim Seferbekov, and the DFDC dataset as training data. Our experiments show that there is no strong correlation between model performance and its size. The best accuracy was achieved by B4 and B5 models.;"deepfake videos;deep learning;digital media forensics;detection techniques";IEEE
334;Enhancing Authenticity Verification with Transfer Learning and Ensemble Techniques in Facial Feature-Based Deepfake Detection;"N. Qazi; I. Ahmed";2024;Deepfake technology, facilitated by deep learning algorithms, has emerged as a significant concern due to its potential to deceive humans with fabricated content indistinguishable from reality. The proliferation of deepfake videos presents a formidable challenge, propagating misinformation across various sectors such as social media, politics, and healthcare. Detecting and mitigating these threats is imperative for fortifying defenses and safeguarding information integrity.This paper tackles the complexities associated with deepfake detection, emphasizing the necessity for innovative approaches given the constraints of available data and the evolving nature of forgery techniques. Our proposed solution focuses on leveraging facial features and transfer learning to discern fake videos from genuine ones, aiming to identify subtle manipulations in visual content. We systematically break down videos into frames, employ the Haar cascade algorithm for facial recognition, and utilize transfer learning to extract discriminative features. We evaluate multiple pre-trained models, including VGG16, ConvNeXtTiny, EfficientNetB0, EfficientNetB7, DenseNet201, ResNet152V2, Xception, NASNetMobile, and MobileNetV2, for feature extraction. Subsequently, we feed these features into a Deep Artificial Neural Network (DANN) for deepfake detection and employ ensemble learning to combine the strengths of the best-performing models for enhanced accuracy.We found that the ensemble model comprising ConvNextTiny, EfficientNetB0, and EfficientNetB7 showed enhanced accuracy in detecting deep fakes compared to alternative models achieving up to 98% accuracy through ensemble learning.;"Deepfake detection;video classification;Transfer learning;EfficentNetB0;DenseNet;Ensemble learning";IEEE
336;MIS-AVoiDD: Modality Invariant and Specific Representation for Audio-Visual Deepfake Detection;"V. S. Katamneni; A. Rattani";2023;Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat. Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated. In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection. Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video. Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors. We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a sig-nificant challenge to effective fusion and efficient performance. In this paper, we tackle the problem at the representation level to aid the fusion of audio and visual streams for multimodal deepfake detection. Specifically, we propose the joint use of modality (audio and visual) invariant and specific representations. This ensures that the common patterns and patterns specific to each modality representing pristine or fake content are preserved and fused for multimodal deepfake manipulation detection. Our experimental results on FakeAVCeleb and KoDF audio-visual deepfake datasets suggest the enhanced accuracy of our proposed method over SOTA unimodal and multimodal audio-visual deepfake detectors by 17.8% and 18.4%, respectively. Thus, obtaining state-of-the-art performance.;"Deepfakes;Audio-visual Deepfake Detection;Modality Invariant;Modality Specific Features";IEEE
337;Attention Guided Multi-attribute Architecture For Deepfake Detection;"R. Sharma; B. Jawade; A. Agarwal; S. Setlur; N. Ratha";2023;Deepfake content generated through visual and audio manipulations is speculated to become one of the most threatening artificial intelligence (AI) technologies capable of grave negative impact on society through identity fraud, reputation damage, and undermining of trust in large-scale political campaigns and criminal investigation procedures. A significant measure of the efforts towards solving this problem fails to generalize beyond the training data. We hypothesize that the primary reason behind the drawback is the dearth of efforts toward the exploitation of multiple channels of information from the data. Towards this goal, we investigate a multimodal paradigm exploiting an attention-informed feature generation procedure through a deep network. We further augment the supervisory signal using camera sensor fingerprints which contain additional corroboratory information for the decision-making process. We demonstrate that a non-linear transformation of the decision space augmented through multiple channels allows for a significant boost in the generalization capacity over unseen datasets or attacks. We illustrate the applicability of our framework on the widely known datasets of FaceForensics++ and CelebDF.;"Deepfake detection;Multimodal fusion;Multi-scale attention;Camera Fingerprint/Noiseprint";IEEE
338;Enhancing Social Media Security: LSTM-Based Deep Fake Video Detection;"A. Barbadekar; S. Sole; A. Shekhavat";2024;The rapid advancement of generative artificial intelligence (AI) techniques has led to the widespread creation and dissemination of deepfake videos, which convincingly manipulated media, containing fabricated content often indistinguishable from reality. Detecting such deepfake videos is a critical challenge in ensuring the originality and credibility of information in the digital age. In this paper, an approach for detecting deepfake videos using generative AI-based methods has been proposed. For this, this paper introduces a deepfake detection method using Long-short term memory (LSTM) based model. Celeb-DF (v2) has been used for this experiment. From the videos in the dataset, faces were extracted, cropped and were saved in a new video having only face images. By using ResNext, a CNN-based approach, feature extraction was performed and classification was done using the LSTM model. Highest accuracy of 95.33% was achieved using this model.;"Artificial Intelligence (AI);Generative Adversarial Networks (GAN);Long-short term memory (LSTM)";IEEE
342;Image Feature Detectors for Deepfake Video Detection;"F. F. Kharbat; T. Elamsy; A. Mahmoud; R. Abdullah";2019;Detecting DeepFake videos are one of the challenges in digital media forensics. This paper proposes a method to detect deepfake videos using Support Vector Machine (SVM) regression. The SVM classifier can be trained with feature points extracted using one of the different feature-point detectors such as HOG, ORB, BRISK, KAZE, SURF, and FAST algorithms. A comprehensive test of the proposed method is conducted using a dataset of original and fake videos from the literature. Different feature point detectors are tested. The result shows that the proposed method of using feature-detector-descriptors for training the SVM can be effectively used to detect false videos.;"DeepFake Video;HOG;ORB;BRISK;KAZE;SURF;FAST";IEEE
344;Detecting Deepfake Images: A Deep Learning Approach with Streamlit Integration;"A. Gadde; G. D. K. Kishore; T. Talari; S. L. Nunna; R. C. Nannapaneni; K. M. S. K. Vamsi";2024;According to sophisticated machine learning algorithms, deep fake technology can produce incredibly lifelike fake images and videos that may be exploited for fraud, disinformation, and public opinion manipulation. This has raised serious concerns about the technology. In response to this emerging threat, this research project proposes a deep fake detection system utilizing convolutional neural networks (CNNs) to distinguish between authentic and manipulated media. The project begins with the collection and preprocessing of a diverse dataset containing both real and fake images and videos. The dataset is then used to train a CNN model, consisting of multiple convolutional and pooling layers followed by fully connected layers, to learn discriminative features that can differentiate between genuine and manipulated media. Experimental results demonstrate the effectiveness of the proposed deep fake detection system in accurately identifying fake content with high precision, recall, and accuracy. Additionally, the system is capable of processing both individual images and video streams, enabling real-time detection of deep fake content. Overall, this research contributes to the ongoing efforts to combat the proliferation of deep fake technology by providing a robust and reliable solution for detecting manipulated media, thereby safeguarding the integrity of digital content and mitigating the potential negative consequences of deep fake misuse.;"Deep Fake Detection;Convolutional Neural Network (CNN);Multi-Layer Perceptron (MLP);Data Preprocessing;Image Dataset;TensorFlow;Model Training;Model Evaluation;Streamlit Application;Image Input;Video Input;Data Augmentation;Dropout Regularization;Serialization;Model Deployment;Binary Classification;Real vs. Fake Images;Feature Extraction;Max-Pooling;Early Stopping";IEEE
345;Multi-Definition Video Deepfake Detection via Semantics Reduction and Cross-Domain Training;"C. Wang; C. Zhao; G. Hu";2022;"The recent development of Deepfake videos directly threatens our information security and personal privacy. Although lots of previous works have made much progress on the Deepfake detection, we empirically find that the existing approaches do not perform well on the low definition (LD) and crossdefinition (high and low) videos. To address this problem, in this paper, we follow two motivations: (1) high-level semantics reduction and (2) cross-domain training. For (1), we propose the Facial Structure Destruction and Adversarial Jigsaw Loss to reduce our model to learn high-level semantics and focus on learning low-level discriminative information; For (2), we propose a domain generalization method based on adversarial learning. We conduct extensive experiments on the FaceForensics++ dataset. Results show the great effectiveness of our method and we also achieve very competitive performance against state-of-the-art methods.";"Deep Learning;Deepfake Detection";IEEE
346;Deep Fake Detection using Transfer Learning: A Comparative study of Multiple Neural Networks;"A. M; K. S. Charan; S. BN; S. Kanmani R";2024;With the proliferation of sophisticated AI techniques, the creation and dissemination of deep fake images and videos have emerged as a pressing concern in today's digital landscape. Deep fake technology employs advanced machine learning algorithms to manipulate or synthesize realistic-looking media, often with malicious intent. This study evaluates the effectiveness of various pre-trained deep learning models using transfer learning for detecting deep fake images on the Face Forensics++ dataset. The models considered include MobileN etV2, ResN et50, Inception V3, EfficientN et, Xception, NASNetMobile, and a Custom CNN. Accuracies obtained from these models are compared to assess their performance in distinguishing between real and fake images. With the highest performance in MobileNetV2 with 89% followed by ResNet50 with 83 % and other models.;"Deep Fake Detection;Pre-Trained models;Transfer Learning;Deep Fake;Neural Networks";IEEE
348;HF-Detect A Hybrid Detector for Manipulated Face Detection*;"A. Shakya; K. Jenni; M. Perumal; M. Srinivas";2023;The recent advancement of fake face creation and fake face generation motivates the development of an excellent fake face detection method that can effectively detect the difference between fake and real. Various fake detection methods are available with adequate performance, but the limitation of those available methods is they are not performing well with highly compressed images with degraded quality. Manipulation of face images is getting advanced, and becoming difficult to trust the content over the media, and generating and detection should go parallelly to balance society. Therefore we are proposing a novel approach to solve this problem which uses the hybrid model HF-Detect, which combines the advantage of the Xception network along with the F3Net.;"DeepFake Detection;Computer Vision;Deep Learning;Artificial Intelligence";IEEE
351;Interpretable-through-prototypes deepfake detection for diffusion models;"A. Aghasanli; D. Kangin; P. Angelov";2023;The process of recognizing and distinguishing between real content and content generated by deep learning algorithms, often referred to as deepfakes, is known as deepfake detection. In order to counter the rising threat of deepfakes and maintain the integrity of digital media, research is now being done to create more reliable and precise detection techniques. Deep learning models, such as Stable Diffusion, have been able to generate more detailed and less blurry images in recent years. In this paper, we develop a deepfake detection technique to distinguish original and fake images generated by various Diffusion Models. The developed methodology for deepfake detection takes advantage of features from fine-tuned Vision Transformers (ViTs), combined with existing classifiers such as Support Vector Machines (SVM). We demonstrate the proposed methodology�s ability of interpretability-through-prototypes by analysing support vectors of the SVMs. Additionally, due to the novelty of the topic, there is a lack of open datasets for deepfake detection. Therefore, to evaluate the methodology, we have also created custom datasets based on various generative techniques of Diffusion Models on open datasets (ImageNet, FFHQ, Oxford-IIIT Pet). The code is available at https://github.com/lira-centre/DeepfakeDetection.;"deepfake;stable diffusion;diffusion models;interpretability;vision transformers";IEEE
352;Scene and Texture Based Feature Set for DeepFake Video Detection;"A. N. Ramkissoon; V. Rajamanickam; W. Goodridge";2022;The existence of fake videos is a problem that is challenging today's social media-enabled world. There are many classifications for fake videos with one of the most popular being DeepFakes. Detecting such fake videos is a challenging issue. This research attempts to comprehend the characteristics that belong to DeepFake videos. In attempting to understand DeepFake videos this work investigates the characteristics of the video that make them unique. As such this research uses scene and texture detection to develop a unique feature set containing 19 data features which is capable of detecting whether a video is a DeepFake or not. This study validates the feature set using a standard dataset of the features relating to the characteristics of the video. These features are analysed using a classification machine learning model. The results of these experiments are examined using four evaluation methodologies. The analysis reveals positive performance with the use of the ML method and the feature set. From these results, it can be ascertained that using the proposed feature set, a video can be predicted as a DeepFake or not and as such prove the hypothesis that there exists a correlation between the characteristics of a video and its genuineness, i.e., whether or not a video is a DeepFake.;"Classification;DeepFakes;Features;Scene Detection;Texture Detection";IEEE
353;Deepfake Detection Techniques and Analysis;"P. Chandra; A. Verma; A. Gupta";2023;As we are in the 21st century there we are sharing our data on the public domain. Sometime our data (our images or videos) can alter and used in other ways. Deepfake is a technology that can create the fake images and videos with the help of deep learning that is a sect of the artificial intelligence. In this paper we are presenting that how we can detect the fake videos that are afloat on the public domain. We are proposing and presenting a new detection method as the comparative product of different types of deepfake detection algorithm that is implementable and scalable to higher volumes with the use of cutting-edge hardware under special conditions. We use MTCNNs and Inception ResNet models to do so.;"Generative Adversarial Nets;Deepfakes;Deep Learning";IEEE
354;An Automated Workflow For Deepfake Detection;"A. Joshi; C. P. Chavan";2023;The lightning development of Artificial Intelligence (AI) has brought significant changes to modern society, including the emergence of AI-generated art and image enhancement techniques. However, one of the most alarming consequences of AI advancement is the creation of deepfake images and videos through the use of General Adversarial Networks (GANs). As these deepfakes become increasingly convincing and widespread, there is an urgent need for measures to detect and prevent their dissemination, especially on independent social-media websites. The proposed approach results in accuracy scores comparable to and surpassing several SOTA(State-of-the-art) approaches on three benchmark datasets, while consuming considerably lesser computational overhead, and containing over 100x lesser trainable parameters which was achieved using the extraction and manipulation of geometrical features.;"Deep-fake detection;Lucas-Kande;Autonmation;Bi-LSTM;Computer Vision;Facial Landmarks";IEEE
357;Deepfake Detection: Analyzing Model Generalization Across Architectures, Datasets, and Pre-Training Paradigms;"S. A. Khan; D. -T. Dang-Nguyen";2024;As deepfake technology gains traction, the need for reliable detection systems is crucial. Recent research has introduced various deep learning-based detection systems, yet they exhibit limitations in generalising effectively across diverse data distributions that differ from the training data. Our study focuses on understanding the generalisation challenge by exploring different aspects such as deep learning model architectures, pre-training strategies and datasets. Through a comprehensive comparative analysis, we evaluate multiple supervised and self-supervised deep learning models for deepfake detection. Specifically, we evaluate eight supervised deep learning architectures and two transformer-based models pre-trained using self-supervised strategies (DINO, CLIP) on four different deepfake detection benchmarks (FakeAVCeleb, CelebDF-V2, DFDC and FaceForensics++). Our analysis encompasses both intra-dataset and inter-dataset evaluations, with the objective of identifying the top-performing models, datasets that equip trained models with optimal generalisation capabilities, and assessing the influence of image augmentations on model performance. We also investigate the trade-off between model size, efficiency and performance. Our main goal is to provide insights into the effectiveness of different deep learning architectures (transformers, CNNs), training strategies (supervised, self-supervised) and deepfake detection benchmarks. Following an extensive empirical analysis, we conclude that Transformer models surpass CNN models in deepfake detection. Furthermore, we show that FaceForensics++ and DFDC datasets equip models with comparably better generalisation capabilities, as compared to FakeAVCeleb and CelebDF-V2 datasets. Our analysis also demonstrates that image augmentations can be beneficial in achieving improved performance, particularly for Transformer models.;"Deepfake detection;image classification;convolutional neural networks;transformers;video processing";IEEE
359;Deepfake Detection via a Progressive Attention Network;"S. Guo; M. Gao; Q. Li; G. Jeon; D. Camacho";2024;The rapid advancement of deepfake technology has enabled the creation of highly realistic forged face images or videos. While deepfake technology adds entertainment to people�s lives, it also poses a potential threat to social security. Deepfake detection is a crucial technology for identifying forged images. However, existing deep learning-based models for deepfake detection often overlook subtle forged traces. To solve this problem, we propose a Progressive Attention Network (PANet). The PANet incorporates two attention modules, namely the Efficient Multi-Scale Attention Module (EMAM) and the Spatial and Channel Attention Module (SCAM), in a progressive manner. The EMAM focuses on crucial facial regions, such as the eyes, nose, and mouth, rather than the entire face. The SCAM facilitates fine-grained feature extraction. Experimental results demonstrate that the proposed method achieves state-of-the-art results on deepfake detection datasets.;"Deepfake Detection;Efficient Multi-Scale Attention;Feature Extraction;Information Disorder;Forged Traces";IEEE
360;A Comparative Study of DenseNet121 and InceptionResNetV2 model for DeepFake Image Detection;"R. Manoranjitham; S. S. Swaroop";2024;The rise of deep fake technology poses a significant challenge to societal integrity, necessitating robust detection methods. This research study investigates the effectiveness of DenseNet121 and InceptionResNetV2 deep learning models in detecting deep fake images. The study starts with the curation of the dataset and then applies different preprocessing methods to improve the quality of the dataset like scaling, normalization, and data augmentation. The DenseNet121 and InceptionResNetV2 models are trained to differentiate authentic and manipulated images based on distinctive features. DenseNet121�s dense connectivity facilitates feature reuse, enabling effective extraction of discriminative features crucial for identifying manipulated content. In contrast, InceptionResNetV2�s sophisticated architecture exploits both inception and residual connections, enhancing its ability to capture intricate patterns indicative of deep fake manipulation. The comparative analysis of performance metrics reveals InceptionResNetV2�s superiority, achieving an impressive accuracy rate of 99.78% compared to DenseNet121. These findings underscore the efficacy of leveraging existing architectures for identifying deep fake images, thereby contributing to the ongoing efforts to combat misinformation and safeguard digital content integrity.;"DenseNet121;InceptionResNetV2;Deep Learning;Deep Fake;Images";IEEE
361;DeepFake Detection using Transfer Learning;"R. Thakur; A. K. Samanta; Amrit; D. Garg";2023;A deepfake is a computer-generated fake image or video that combines images to create a new image or video that depicts an event, comment, or activity that did not actually occur. This has become a real problem nowadays to decide the originality of a video. For the same reason we are trying to create a machine learning model using transfer learning which will help us to distinguish between different videos to decide which video is real and which one is fake. For that we are using four different models and comparing their results. The overall best model is InceptionResNetV2 considering its training time and accuracy. In our results the InceptionResNetV2 performs best and gives an accuracy of 97.1 percent.;"ResNet50V2;InceptionResNetV2;NASNet;Deepfake;Inception V3;Transfer Learning";IEEE
365;Deep Fake Detection for Preventing Audio and Video Frauds Using Advanced Deep Learning Techniques;"A. O. Vaidya; M. Dangore; V. K. Borate; N. Raut; Y. K. Mali; A. Chaudhari";2024;Deepfakes allow for the automated gen- eration of fake video content, often accomplished through the use of generative adversarial networks. To address the increasing issue of deepfakes, this study focuses on constructing a model that incorporates advanced techniques. The researchers combined the ResNeXt, Long Short-Term Memory (LSTM), and ResNet architectures, selecting them based on their effectiveness in handling complex visual data and capturing temporal dependencies. Prior to detection, the dataset underwent pre-processing using the Multi-Task Cascaded Convolutional Neural Network (MTCNN), which facilitated the accurate extraction of facial regions. Importantly, the study evaluated the model across three diverse and significant datasets: the Face Forensics++ dataset (FF-DF), the Celeb-DF dataset, and the Facebook Deepfake Detection Challenge (DFDC) dataset. This comprehensive evaluation en- sured the model's ability to generalize and its suitability for real-world scenarios, as demonstrated by its exceptional detection accuracy. The combination of models employed in this study yielded highly accurate results and remained robust in the face of evolving deepfake technology.;"Preprocessing;MultiTask Cascaded Convolutional Neural Network (MTCNN);Model Architecture;ResNeXt;LSTM;ResNet;Face Forensics++;CelebDF;DFDC;Detection Accuracy";IEEE
366;A Comparative Analysis and Study of a Fast Parallel CNN Based Deepfake Video Detection Model with Feature Selection (FPC-DFM);"A. Das; L. Sebastian";2023;Deep learning is an efficient and practical method that has been widely applied in numerous fields. Videos created with swapped faces in a video, altered facial emotions, changed genders, fraudulent video content generation, and altered facial features are referred to as �DeepFake� videos. These videos are created utilizing deep learning technology called generative adversarial networks. Fake videos are used to stir up political agitation, commit acts of terrorism, and demand money. A fast Parallel CNN-based deepfake video detection model with feature selection is the new model we presented in this project (FPC-DFM). In order to identify Deepfake videos, the FPC DFM architecture uses feature extraction, feature selection, and prediction. The FPC-DFM model extracted features using three convolutional models: EfficientN et, VGG16, and ResNet as well as Principal Component Analysis (PCA)-based feature selection and Support Vector Machine-based classification. We offer a new architecture for capturing the video frame features that will be utilized to determine if the video is real or fake by utilizing deep learning techniques. In comparison to other pre-trained models like VGG16-TL, EfficientNet-TL and Resnet50-TL and our results demonstrated that FPC-DFM has the best performance and the highest accuracy of 96.50%.;"Deepfake video detection;Convolutional neural network (CNN);Principal Component Analysis;Support vector machine (SVM)";IEEE
368;Learning Face Forgery Detection in Unseen Domain with Generalization Deepfake Detector;"V. Tran; S. Lee; H. Le; B. Kim; K. Kwon";2023;Face forgery generation algorithms have advanced rapidly, resulting in a diverse range of manipulated videos and images which are difficult to identify. As a result, face manipulation using deepfake technique has a significantly increased societal anxiety and posed serious security problems. Recently, a variety of deep fake detection techniques have been presented. Convolutional neural networks (CNN) architecture are used for most of the deepfake detection models as binary classification problems. These methods usually achieve very good accuracy for specific dataset. However, when evaluated across datasets, the performance of these approaches drastically declines. In this paper, we propose a face forgery detection method to increase the generalization of the model, named Generalization Deepfake Detector (GDD). The Generalization Deepfake Detector model has ability to instantly solve new unseen domains without the requirement for model updates.;"Deepfake detection;meta learning;machine learning;deepfake dataset";IEEE
369;MobiDeep: Mobile DeepFake Detection through Machine Learning-based Corneal-Specular Backscattering;"M. Mohzary; K. J. Almalki; B. -Y. Choi; S. Song";2023;DeepFake has accomplished notable advancement with the AI-leveraged production and manipulation techniques of fictitious human facial images. Despite many benign and fun applications, the generated fake images can negatively influence the authenticity of online information by originating deception, manipulation, persecution, and seduction, defying societal quality and human rights, which becomes critical security and privacy threat in social networks. Hence, real-time DeepFake detection and limitation technologies on the mobile platform are essential to building a controlled, harmless DeepFake ecosystem. This paper presents a real-time, cloudless, lightweight mobile app for human visual DeepFake detection using machine learning technologies named MobiDeep (Mobile DeepFake Detection through Machine Learning-based Corneal-Specular Backseat-tering). MobiDeep stems from a hypothesis that the existing DeepFake creation methods, including replacement, editing, and synthesis, lack the ensemble with the reflective objects. Focusing on the most reflective area of a human face, corneal-specular backscatter images of eyes, we seek the similarity and consistency with multiple surrounding environment features, including color components, shapes, and textures. We have implemented a cross-platform mobile application to evaluate the performance using various input parameters and lightweight Deep Neural Network (DNN) architectures. The empirical results show that MobiDeep achieves high accuracy (98.7%) and rapid detection speed (less than 200 ms) in detecting sophisticated DeepFake images within a subsecond.;"DeepFake;Corneal-Specular Backscattering";IEEE
371;DeepFake Videos Detection by Using Recurrent Neural Network (RNN);"A. A. M. Albazony; H. A. Al-Wzwazy; A. S. Al-Khaleefa; M. A. Alazzawi; M. Almohamadi; S. E. Alavi";2023;"In the last few years, the increasing development of various tools to make fake videos from real videos has been raised. Thus, several models/approaches have been constructed to detect and reveals fake video. Consequently, this research is conducted to propose a new model based on combining Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and image preprocessing techniques to classify and find the fake video from the real video. To implement and evaluate the proposed model, a MATLAB simulator has been used. The deepFake Images dataset is used for evaluations. This dataset contains 135 real videos as well as 677 fake videos created using different tools on real videos. Two scenarios have been utilized to evaluate the performance of the proposed model which are; dimensions of the training data and different sizes of the training data. The results show that the proposed model has been able to provide better results than the previous model.";"Deep learning;DeepFake Detection;convolutional Neural Network (CNN);Recurrent Neural Network (RNN)";IEEE
373;Deepfake Detection Using SVM;"H. Agarwal; A. Singh; R. D";2021;In recent years the Deep generative networks have made it easy to create real face swaps in images and videos with less traces of manipulation, significantly improving the quality of these deepfakes. This improvement in fake media have gained more concern as for their use in fake terrorism, blackmail etc. This has drawn attention of both industry and government to distinguish and restrict their utilization. In spite of the way that these AI generated fake media produce realistic images upon detailed assessment, the proposed method can find some features that are unnatural which are not visible to the naked eyes. This paper uses a method known as frequency domain analysis after which a classifier will be used to differentiate the real and fake image. This paper evaluates our method on dataset of deepfake images collected from different website. Our work can show promising performance for detecting these deepfake images.;"DeepFake;Image Processing;SVM;Generative Adversarial Net;DFT;classification";IEEE
375;Deepfake Video Prediction Using Attention-Based CNN and Mel-Frequency Cepstral Coefficients;"G. S; S. G. A; J. D; A. J";2024;Deepfake technology seriously threatens the integrity of digital media since it makes it harder to detect fraudulent deepfake videos using traditional methods. In this research, we describe a unique method for audio and visual analysis utilizing Mel-Frequency Cepstral Coefficients (MFCCs) and Attention-based CNN to detect fraudulent deepfakes. Our methodology addresses the evolving field of deepfake manipulation and offers a more comprehensive and dependable detection framework by combining audio and visual modalities. Utilizing the FakeAVceleb dataset, a carefully chosen collection of audio-visual deepfake videos created especially for research is one of the keystones of our methodology. The breadth of actual and deepfake sounds and videos provided by the FakeAVceleb dataset makes it possible to test and evaluate our detection model in great detail. We use attention-based CNN to analyze extracted visual features from video frames, with a focus on regions that can be manipulated to detect subtle audio features that indicate deepfake manipulation, thereby increasing our model's overall discriminative capability. We assess how well our method works for identifying deepfake audio and video. Our results demonstrate the efficacy of combining audio and visual analysis in deepfake detection, as our model achieves promising performance metrics including an accuracy of 94.00% using the FakeAVceleb dataset.;"Deepfake Detection;Audio Analysis;Visual Analysis;Attention-based CNN;Mel-Frequency Cepstral Coefficients;Audio-Visual Integration;FakeAVCeleb";IEEE
378;Using Graph Neural Networks to Improve Generalization Capability of the Models for Deepfake Detection;"H. She; Y. Hu; B. Liu; J. Li; C. -T. Li";2024;Deepfake detection plays a key role in preventing the misuses of artificial intelligence in video editing. Current deep learning-based deepfake detection methods often perform quite well in intra-dataset testing, but they may lose good performance in cross-dataset testing. In other words, generalization capability is still a crucial problem to be resolved. In this paper, we address deepfake detection by treating an image as non-Euclidean data and representing it as a graph so as to infer the informative connections between image patches/nodes to improve the detector�s generalization capability. Specifically, we propose a graph neural network-based paradigm that casts deepfake detection as a graph binary classification problem. First, we propose a dual-branch network to extract node features from both RGB images and their color difference images (CDIs) via the Transformer-based trainable node encoder module (TNEM). Second, we adopt the adjacency matrix to establish the connections of the nodes and further optimize the graph representation by applying the adaptive threshold to the adjacency matrix. Third, multi-head graph convolutional neural networks are carried out for node feature extraction. RGB node features and CDI node features are concatenated and separately fed into the graph classifier and node classifier for forgery detection and forgery localization. Experimental results demonstrate that our method can overall outperform other state-of-the-art methods on 7 popular benchmark datasets. Notably, our model achieves the highest AUC values of 96.19%, 80.99% and 87.68% on Celeb-DF-V2, DFDC and DFDCP in turn when trained on FF++ (C23). The visualization of node classification results also provides good interpretability of our proposed approach.;"Deepfake detection;graph neural network;generalization;transformer;color difference;graph classification";IEEE
379;Deep Learning based Model for Deepfake Image Detection: An Analytical Approach;"Neha; B. Arora";2023;Recent years have witnessed great improvement in deepfake technology, spurred by advancements in deep learning models and improved processing capacity. Generative models at the cutting edge of technology have made it possible to produce convincingly realistic synthetic videos, images, and even audio recordings. Deeply fabricated media has the power to harm not just individuals but also our society, institutions, countries, religions, and others. These fake images may circulate online in low quality and contain many forms of distortion that could impair the effectiveness of detection methods. Our study employed a dataset of 140K Real and Fake images to analyse how image distortions affect the detection model using one of the deep learning models, DenseNet. This is accomplished by adding blur and noise to the original dataset and feeding it to the trained neural network to discriminate real and deepfake images. The results demonstrate that the model�s accuracy decreased with the low-quality dataset.;"Deepfake Generation;Deepfake Detection;Deep Learning;Generative Adversarial Networks;Face Manipulation;Image Distortions";IEEE
380;Exploring Generalization Capability for Video Forgery and Detection based on Generative Adversarial Network;"Y. Lin; Y. Qu; Y. Li; Z. Nie";2020;With the development of digital image processing technology based on deep learning, the potential risk of using related technologies to threaten the security of multimedia information is increasing. Because the generated human face effect largely depends on the completeness of the input sample set, most of the current deep forgery models have the problem of human side-face collapse. This paper has studied the deep forgery technology of Deepfacelab and Faceswap, and adjusts the original auto-encoder-based model architecture to a generative adversarial network. By using the harmonic mean of cross entropy and mean square error as the loss function, the improved model can reduce the probability of some frames being discarded during training. Meanwhile, by adjusting key characteristics and the weights of features in different frames, it further optimizes the cross-dataset detection performance. Experimental results have shown that the improved model can keep more facial details while still maintain high human face clarity. The detection performance is improved and the cross-dataset average error rate of the deep detection model is about 35%.;"Deepfake;Deepfake Detection;Generative Adversarial Network;Face Swap;Detection Generalization";IEEE
381;Deepfake Detection System;"S. Shrivas; A. Rai; M. Lakshmi";2024;Detecting deepfake content presents a formidable challenge, necessitating advanced methodologies. This paper proposes a holistic strategy employing Facenet_pytorch, MTCNN, and InceptionResnetV1 for robust deepfake detection. Facenet_pytorch serves as the cornerstone for facial feature recognition, while MTCNN efficiently identifies faces in images during preprocessing. InceptionResnetV1 scrutinizes visual details to detect subtle anomalies indicative of manipulation, such as unnatural facial expressions and incongruent lip synchronization. Our approach underscores the importance of maintaining a delicate balance between accurate detection and individual privacy rights. By leveraging these advanced models, we achieve significant strides in differentiating manipulated content from authentic media, contributing to the ethical deployment of deepfake detection technologies.;"MTCNN;InceptionResNetV1;FaceNet;Pytorch";IEEE
382;Video Morphing Attack Detection using Convolutional Neural Networks on Deep Fake Algorithm;"S. Boovaneswari; N. Palanivel; S. NihilRS; R. Madhavan; A. Daniyel";2024;A method called deepfake produces fake video and films with artificial or substituted faces. Deepfakes are turning into a worrying societal phenomenon because they may be used maliciously to spread harmful information, fabricate electronic convincing proof, make fake political news, and even participate in online harassment and fraud. These masks make it harder to distinguish facial features, making it more difficult to detect fake video. To detect the fake morphed video, we are using the deepfake algorithm to detect the morphed face in the video. Deepfake technology is not using to create the morphed video and also it is used to detect the video by using the CNN.As a result, more sophisticated deepfake detection technology is required. Because the field does not yet have the necessary dataset for detection-model training, the research generates a real or fake video dataset with face masks The study attempts to improve accuracy by improving CNN topologies, detecting important visual signals, and comparing model performance against various morphing strategies. Real-world application of the effect of dataset size and diversity on training is investigated. By protecting multimedia material against changing digital tampering, this research helps combat the threat posed by deepfake technology.;"Morphing Detection;CNN;Machine Learning;DFFMD;Deep Learning";IEEE
383;Inconsistency-Aware Wavelet Dual-Branch Network for Face Forgery Detection;"G. Jia; M. Zheng; C. Hu; X. Ma; Y. Xu; L. Liu; Y. Deng; R. He";2021;Current face forgery techniques can generate high-fidelity fake faces with extremely low labor and time costs. As a result, face forgery detection becomes an important research topic to prevent technology abuse. In this paper, we present an inconsistency-aware wavelet dual-branch network for face forgery detection. This model is mainly based on two kinds of forgery clues called inter-image and intra-image inconsistencies. To fully utilize them, we firstly enhance the forgery features by using additional inputs based on stationary wavelet decomposition (SWD). Then, considering the different properties of the two inconsistencies, we design a dual-branch network that predicts image-level and pixel-level forgery labels respectively. The segmentation branch aims to recognize real and fake local regions, which is crucial for discovering intra-image inconsistency. The classification branch learns to discriminate the real and fake images globally, thus can extract inter-image inconsistency. Finally, bilinear pooling is employed to fuse the features from the two branches. We find that the bilinear pooling is a kind of spatial attentive pooling. It effectively utilizes the rich spatial features learned by the segmentation branch. Experimental results show that the proposed method surpasses the state-of-the-art face forgery detection methods.;"Face forgery detection;stationary wavelet decomposition;dual-branch network;bilinear pooling";IEEE
384;DeepFake Face Detection using Machine Learning with LSTM;"T. Vignesh; P. H. Tarun; R. Parthav; V. Bhargavi";2024;Fake face images that are increasingly convincing and realistic can be created because to the development of face image manipulation (FIM) technologies like Face to Face and Deepfake, which can damage the legitimacy and trustworthiness of online content. Malicious uses of these technology include blackmailing people, posing as celebrities, and disseminating false information. As a result, creating trustworthy and strong techniques to identify FIM and safeguard the integrity of digital media is essential. Numerous current techniques utilize on models built on convolutional neural networks (CNNs), which are capable of detecting FIM by examining a face�s visual characteristics. But because these models are frequently tested and trained on certain datasets or circumstances. Furthermore, they might not be able to record the temporal information that is included in video data and can be used to identify irregularities or strange anomalies in FIM videos. We provide a novel method that uses both geographical and temporal information to detect FIM in order to get over these difficulties. We present a new type of residual network called CRNet, which is dependent on Convolutional Long Short-Term Memory (LSTM) and is capable of processing a series of consecutive pictures taken from a movie. The model can learn temporal information because to its design, which is essential for spotting oddities that occur in between frames of FIM movies. We performed extensive tests with several kinds of FIM videos from the Kaggle dataset.;"Deepfake detection;Long-Short Term Memory (LSTM);Kaggle;Residual next convolution neural network (Xception CNN);Image manipulation";IEEE
385;Deepfake and Security of Video Conferences;"A. S. U�an; F. M. Bu�ak; M. A. H. Tutuk; H. ?. Aydin; E. Semiz; ?. Bahtiyar";2021;Deep learning is widely used to create artificial contents on the Internet. Similarly, it is also used to detect fake contents. Fake frames created and integrated with deep learning algorithms are known as deepfake. Recently, malicious users tend to use deepfake to manipulate genuine contents to carry out variety of attacks. Video conferencing applications has been a significant target of the malicious users since the beginning of Covid-19 pandemic who use deepfake models to create fake virtual identities in online video conferences. We propose a lightweight deepfake detection model that may be integrated with video conference applications to detect fake faces. Experimental analyses show that the proposed model provides acceptable accuracy to detect fake images on video conferences.;"Security;Machine Learning;Deepfake;Inception-Resnet;Video Conference;Detection";IEEE
388;Employing Transfer-Learning based CNN architectures to Enhance the Generalizability of Deepfake Detection;"S. Suratkar; E. Johnson; K. Variyambat; M. Panchal; F. Kazi";2020;Advancements in machine learning have given rise to technologies and methodologies that are being put to use for immoral purposes, especially after the inception of Generative Adversarial Networks in 2014. Generative Adversarial Networks are capable of synthesizing hyper-realistic fake images and even videos. Various sophisticated machine learning techniques capable of creating ultra-realistic Deep Fake videos are being used to harass, blackmail women and children, induce political instability by spreading false, malicious propaganda which could in turn lead to social, political conflicts and outbursts with dire consequences. This poses a serious threat to personal safety and also endangers national security which calls for automated ways to detect deep fake videos. This paper proposes a method to expose such fake videos by using a CNN architecture and leveraging the technique of Transfer Learning. The proposed model implements an algorithm that uses a CNN for feature extraction from every frame in a video to train a binary classifier that learns to efficiently differentiate between real and manipulated videos. The method is evaluated against an extensive set of deepfake videos gathered from various datasets.;"Generalization;Deepfake;Convolution;Transfer learning;Models";IEEE
389;Face Forgery Detection Algorithm Based on Improved MobileViT Network;"T. Wang; X. Lu";2023;DeepFakes blur the boundaries between reality and forgery, resulting in the collapse of exiting credit system, causing immeasurable consequences for national security and social order. Through analysis of existing face forgery techniques, it is found that most generation techniques rely on random noise distribution, and global information will be lost after up sampling. Therefore, we propose a deepfake detection algorithm based on improved MobileViT, which uses CNN local space biasing and the global space representation of the Transformer network to learn the local features and global representation of forged faces, respectively. Coordinate attention is introduced to obtain directional perception and position sensitive information, making the model locate synthetic traces of fake faces better and fusion local and global representation more effectively. For the improved generalization of the model, with the GELU activation function to solve the problem of neuron death. Our model achieved 96.2% on FF++(C23) datasets, and 93.7%,94.1%,96.3%,87.9% on DF, F2F, FS, and NT datasets, respectively. Comparing with previous methods, our model has shown detection robustness and better generalization.;"Deepfake Detection;MobileViT;Coordinate Attention;GELU";IEEE
392;A deepfake video detection method based on multi-modal deep learning method;"Y. Zhang; X. Li; J. Yuan; Y. Gao; L. Li";2021;Recently, most deepfake video classification tasks depend on frame-level features and try to train deep neural networks to characterize fake videos. Although this kind of methods can achieve good results, they also waste the audio information and timing information of the deepfake video dataset. Therefore, to make better use of the audio information, we propose a multi-modal method to detect deepfake videos. The principle of our method is based on the mismatch between audio information and visual information, such as the inconsistency of mouth shape and voice. We calculate the modality dissonance score(MDS score) of videos to classify true/false videos. Extensive experiments reach 84.4% accuracy on the DFDC dataset, which demonstrates the effectiveness of our method.;"deepfake detection;multi-modality;adaptive modality dissonance;deep learning;deep neural network";IEEE
395;Fine-Grained Open-Set Deepfake Detection via Unsupervised Domain Adaptation;"X. Zhou; H. Han; S. Shan; X. Chen";2024;Deepfake represented by face swapping and face reenactment can transfer the appearance and behavioral expressions of a face in one video image to another face in a different video. In recent years, with the advancement of deep learning techniques, deepfake technology has developed rapidly, achieving increasingly realistic effects. Therefore, many researchers have begun to study deepfake detection research. However, most existing studies on deepfake detection are mainly limited to binary classification of real and fake images, rather than identifying different methods in an open-world scenario, leading to failures in dealing with unknown deepfake categories in practice. In this paper, we propose an unsupervised domain adaptation method for fine-grained open-set deepfake detection. Our method first uses labeled data from the source domain for model pre-training to establish the ability of recognizing different deepfake methods in the source domain. Then, the method uses a Network Memorization based Adaptive Clustering (NMAC) approach to cluster unlabeled images in the target domain and designs a Pseudo-Label Generation (PLG) to generate virtual class labels for unknown deepfake categories by matching the adaptive clustering results with the known deepfake categories in the source domain. Finally, we retrain the initial multi-class deepfake detection model using labeled data of the source domain and pseudo-labeled data of the target domain to improve its generalization ability to unknown deepfake classes presented in the target domain. We validate the effectiveness of the proposed method under multiple open-set fine-grained deepfake detection tasks based on three deepfake datasets (ForgerNet, FaceForensics++, and FakeAVCeleb). Experimental results show that our method has better domain generalization ability than the state-of-the-art methods, and achieves promising performance in fine-grained open-set deepfake detection.;"Deepfake detection;domain adaptation;unsupervised learning;fine-grained classification";IEEE
396;Exploiting Style Latent Flows for Generalizing Deepfake Video Detection;"J. Choi; T. Kim; Y. Jeong; S. Baek; J. Choi";2024;This paper presents a new approach for the detection of fake videos, based on the analysis of style latent vectors and their abnormal behavior in temporal changes in the generated videos. We discovered that the generated facial videos suffer from the temporal distinctiveness in the temporal changes of style latent vectors, which are inevitable during the generation of temporally stable videos with various facial expressions and geometric transformations. Our framework utilizes the StyleGRU module, trained by contrastive learning, to represent the dynamic properties of style latent vectors. Additionally, we introduce a style attention module that integrates StyleGRU-generated features with content-based features, enabling the detection of visual and temporal artifacts. We demonstrate our approach across various benchmark scenarios in deepfake detection, showing its superiority in cross-dataset and cross-manipulation scenarios. Through further analysis, we also validate the importance of using temporal changes of style latent vectors to improve the generality of deepfake video detection.;"Deepfake Detection;Face Forgery Detection";IEEE
397;Detection of Manipulated Multimedia In Digital Forensics Using Machine Learning;"P. Anvekar; A. Gudnavar; K. Naregal; S. Nagarmunoli";2024;The surge in digital media usage has spurred an uptick in multimedia manipulation., spanning images., videos., and audio. This manipulation., with its potential to spread misinformation and manipulate public opinion., poses serious threats. Detecting genuine from fake media is challenging due to the diverse tools employed. Consequently., cybercrime involving manipulated media is on the rise. Researchers are countering this issue with machine learning techniques., particularly Convolutional Neural Networks (CNNs). This paper presents an application leveraging CNN s to identify genuine and fake media., bolstered by results from experiments on real and manipulated datasets., yielding high accuracy and robustness. Deep learning models excel in detecting various manipulation types., positioning them as potent weapons against manipulated content proliferation. To ascertain the models' effectiveness., the study includes comprehensive validation., testing procedures., and robustness analyses against sophisticated manipulations., including adversarial attacks and deepfake variations. This research advances multimedia forensics., offering a holistic approach to detect manipulated media with deep learning models., underscoring CNN s' effectiveness in curbing manipulated content dissemination., and emphasizing the necessity of ongoing advancements to tackle the evolving multimedia manipulation landscape.;"Manipulated media;CNN;Machine learning;Digital forensics;Cyber security";IEEE
398;DeepFake Image Detection and Classification using EfficientNet Model;"S. Singh; P. Sarala; S. K. Chandra; M. D. Kumar";2024;Deep learning models such as Vision Transformer (VIT) and EfficientNet, have brought significant advancements to computer vision tasks like image classification, object detection, and image generation. In this paper, comparative analysis of VIT and EfficientNet models has been done with more attention of on their architectural disparities, training procedures, and performance characteristics. Deep learning models like Vision Transformer (VIT) and EfficientNet have revolutionized computer vision. VIT uses self-attention techniques instead of convolutional layers to capture global relationships but with higher computational. EfficientNet models, with compound scaling offer a trade-off between accuracy and efficiency. EfficientNet models are computationally fast with competitive accuracy and is suitable for resource-limited contexts. The paper suggests choosing the best model based on specific use cases and resource limitations. Quantitative analysis of the present work has been done using confusion matrix. It has been observed that EfficientNet models are providing higher performance ratio.;"Vision Transformer (VIT);EfficientNet;deep learning models;computer vision;image classification;object detection;comparative analysis";IEEE
399;Deepfake Image Detection using CNNs and Transfer Learning;"N. Kumar; P. P; V. Nirney; G. V";2021;Headways in deep learning has enabled the creation of fraudulent digital content with ease. This fraudulent digital content created is entirely indistinguishable from the original digital content. This close identicalness has what it takes to cause havoc. This fraudulent digital content, popularly known as deepfakes having the potential to change the truth and decay faith, can leave impressions on a large scale and even our daily lives. Deepfake is composed of two words, the first being deep: deep learning and the second being fake: fake digital content. Artificial intelligence forming the nucleus of any deepfake formulation technology empowers it to dodge most of the deepfake detection techniques through learning. This ability of deepfakes to learn and elude detection technologies is a matter of significant concern. In this research work, we focus on our efforts towards the detection of deepfake images. We follow two approaches for deepfake image detection, and the first is to build a custom CNN based deep learning network to detect deepfake images, and the second is to use the concept of transfer learning.;"Deepfakes;Error Level Analysis(ELA);Convolutinal Neural Networks (CNNs);Transfer-learning";IEEE
401;Development of a Deepfake Detection Method: Application of Frequency Analysis and Reduction of the Image Color Space to Improve Classification Accuracy;"V. Rogovoi; V. M. Korzhuk; O. A. Kokorina";2024;With the development of generative and diffusion models of neural networks, it has become possible to create high-quality realistic images that are visually indistinguishable from real photos. This expands the horizons of using technology to synthesize data and media content, however, with the help of this technology, it becomes possible to generate or replace the faces of real people using deepfake methods. Although modern deepfake recognition methods show high results on synthetic data, they suffer from the problem of false positives when working with processed images of real and synthetic faces. Moreover, resizing the image according to the input layer of classifiers based on convolutional neural networks can lead to additional distortions, which can affect the classification process. In this paper, we propose a method based on the reduction of the color palette and spectral analysis of images to improve the accuracy of the classification of deepfakes. The proposed method allowed to increase the accuracy of recognition of modified deepfakes to 99.4%.;"digital image processing;deep learning;deepfake;identity forgery";IEEE
402;Enhancing Deepfake Detection: An Ensemble Deep Learning Approach for Efficient Attribute Manipulation Identification;"S. P P; R. R R; D. A; G. R; A. R; G. B. P";2024;"The increasing use of deepfake technology by incorporating Artificial Intelligence (AI) to seamlessly replace faces in videos, poses a significant threat to individuals, societies, and national security. This research study addresses this growing concern by detecting deepfake classification with the integration of two powerful Convolutional Neural Network (CNN) models: InceptionV3 and EfficientNetB0. The existing deepfake detection systems predominantly rely on facial feature analysis, analyzing subtle inconsistencies; however, these methods are susceptible to evolving deepfake techniques. In response, the proposed ensemble model exploits the advantages of InceptionV3 and EfficientNetB0 models to capture intricate features and computational efficiency. The synergy between these models significantly enhances the accuracy upto 93% and adaptability of the proposed deepfake detection system. When compared with conventional facial feature analysis, this approach establishes a resilient defense against emerging deepfake threats. As deepfake technology continues to advance, necessitating continual research in face-based detection systems, this study proposes a cutting-edge ensemble approach that not only mitigates the risks associated with social media manipulation but also serves as a proactive measure against potential challenges in future.";"Deepfake Detection;Ensemble Learning;Facial Feature Analysis;Attribute Manipulation;Efficient Net;Inception Net";IEEE
404;DeepFake Detection on Publicly Available Datasets using Modified AlexNet;"D. Xie; P. Chatterjee; Z. Liu; K. Roy; E. Kossi";2020;"Deep learning has been applied successfully in many areas, including computer vision, natural language processing, cyber physical systems and big data analytics. Recently, a synthesis of deep leaning techniques has been deployed to create fake images and videos that are not easily distinguishable from the real ones; this technology is known as DeepFakes. In this paper, we looked at various DeepFakes related datasets and created a model in order to identify whether a frame of a video is fake or real. This is important as videos can be easily manipulated in a way that can spread misinformation, and that can cause major problems in the world today, especially if the videos have political implications. In order to create a model, we utilize a modified AlexNet constructed of an arrangement of 6 layers: convolution2d, max pooling, dense, flatten, activation and dropout layers. UADFV, FaceForensics++, and Celeb-DF are the 3 datasets used in this research. There are many publicly available datasets, however, we found the UADFV, FaceForensics++ and Celeb-DF to be the most convenient in how the data was formatted. All data for each dataset was organized into videos of varying classes. While the UADFV dataset is straightforward and only has 2 classes: real and fake, the FaceForensics++ dataset looks at the various kinds of video manipulations and has 5 different classes. Our model was able to achieve a 9S.73% accuracy when identifying whether a video is real or fake on the UADFV dataset, a slightly adjusted version was able to accomplish an 87.49% accuracy with the FaceForenisics++dataset, and reached 98.85% accuracy on the Celeb-df dataset.";"Image Manipulation;Deep Learning;DeepFakes;UADFV;FaceForensics;AlexNet";IEEE
405;Deepfake Detection Models Based on Machine Learning Technologies;"K. Smelyakov; Y. Kitsenko; A. Chupryna";2024;The paper is devoted to efficiency evaluation of modern deepfake detection models based on convolutional neural networks (CNN). In the context of rapid development of digital technologies and increasing volume of information on the internet, the relevance of detecting fake images, videos, and textual materials becomes increasingly significant. Fake content, spread through social networks and other platforms, can have serious consequences, ranging from individual malicious attacks to manipulations of public opinion on a global level. We have built and trained several models for detecting fake content using convolutional neural networks. The training was performed using Deepfake Detection Challenge Dataset. During the study, we carried out the comparative analysis of the created models. Obtained results were compared with a number of recent publications.;"Deepfake;Convolutional Neural Network;Face detection;EfjicientNet;Effectiveness";IEEE
407;EfficientNetB0 Ensemble Model for Unified Deepfakes Detection;"S. A. Minhas; S. Mushtaq; A. Javed";2023;In recent years, we have witnessed the generation of exceptional authentic deepfake images and videos due to the availability of cutting-edge Artificial Intelligence and deep learning techniques. Deepfakes represent synthetic multimedia content used to propagate disinformation for defamation, political unrest, manipulating elections, committing crimes, etc. In this paper, we present a novel ReLU-Swish EfficientNet (RSE-Net) for deepfakes detection. Our proposed RSE-Net is capable of reliably detecting deepfakes videos that are generated using different techniques. Our model leverages an ensemble of EfficientNet architectures, which are combined using a fusion technique to enhance the model�s performance in detecting deepfakes. We suggested the ReLU activation in conv2D layers in place of regular Swish activation in EfficientNetB0 first variant as ReLU is computationally more efficient and reduces the risk of overfitting. We evaluated our model on two large-scale challenging deepfake datasets: FaceForensics ++ and CelebDF. Our RSE-Net attained an average accuracy of 99.7% on the FaceForensics++ dataset, and 96.09% on the CelebDF dataset. Furthermore, our model generalizes well and effectively detects deepfake videos in realworld scenarios. Thus, it is a valuable tool for analyzing and detecting potentially manipulated content.;"Deepfake detection;Celeb-DF;FaceForensics ++;Ensemble model;Fused-EfficientNet";IEEE
412;DeepFake Video Detection Using Machine Learning and Deep Learning Techniques;"L. Sarala; C. Sridevi; R. A. Chowdary; M. H. G. P. Gargeye";2024;The current issue facing the community is determining the legitimacy of online content, including movies and pictures generated by machine learning, in light of the development of Generative adversarial networks (GAN) and other deep learning-based DeepFake approaches. There is an extraordinary chance that we may severe violations of fundamental human rights combined with an inevitable, fundamental shift in the way people interact in society. Evidence of misinformation and manipulation of news headlines, medical (dis)information, and invasions of privacy have already been demonstrated. The objective of this proposed project is to efficiently identify DeepFake photos using an online image database. The categorization of real from false photos using convolutional neural networks and data from a sizable internet database is the main topic of this study. Our comparison of three distinct convolutional neural networks was our goal. 1) DenseNet, 2) VGG Face and 3) personalized CNN structure. Future research will examine whether real and false pictures cluster independently using unsupervised clustering techniques or auto-encoders. It would also involve using CNN visualization techniques to give our models more interpretability and transparency.;"Convolution neural networks (CNN);Generative Adversarial Networks (GAN);DeepFake;VGG Face;DenseNet;Artificial neural network (ANN)";IEEE
413;Deep Fake Face Detection using Efficient Convolutional Neural Networks;"M. Umadevi; S. B. Krishna; N. S. Kumar";2024;Deep fake content, especially in images and videos, is spreading at an unprecedented rate. Fake content are generated with the help of advanced deep learning (DL) algorithms such as GANs, autoencoders, and variation autoencoders. This fake content spreads misinformation, causing a severe impact on society by degrading the trustworthiness of content on social media. Mitigating the risk of these techniques can be done by utilizing the power of one of the DL models, which is CNN. This research study focuses on analysing various Deep-Fake (DF) identification techniques that are trained on various datasets with a small number of samples. The proposed work demonstrates an efficient CNN model and three other CNN pre-trained models through transfer learning on a large dataset available on Kaggle, consisting of 140k images of faces. The proposed CNN model achieved a high accuracy of 96%, while DenseNet121 reached 97%. Both EfficientNetB0 and MobileNet demonstrated even higher performance, each achieving an accuracy of 98% within 15 epochs.;"Deep-Fakes (DF);Deep Learning (DL);CNN: Convolutional Neural Networks;GAN: Generative Adversarial Neural Network;Autoencoders";IEEE
414;Deep Fake and Digital Forensics;"H. Alshammari; K. Elleithy";2023;Deepfakes have posed a significant challenge to digital forensics, and there is an increasing need for high accuracy deepfake (DF) detection models in real-world scenarios. This research examines and fine-tunes the MesoNet model to improve its performance on a large dataset of 140K authentic and manipulated images. The original MesoNet model achieved an accuracy of 87.1%. However, after fine-tuning and optimizing the model�s weights, the accuracy improved to 96.20%. This was accompanied by a sensitivity of 97.48% and a specificity of 94.75%, indicating that the model is highly effective at detecting genuine images and accurately identifying forged ones. This research contributes to the advancement of DF detection mechanisms in real-world scenarios.;"Digital forensics;AI forensics;Data science and digital forensics;Deep fake;Face swapping";IEEE
418;An Efficient Algorithm for Fake Video Detection;"N. Nibras; S. Fahim; S. Sakib; S. U. Rashid; A. Rahman";2024;In recent times, the circulation of fake videos has caused significant uproar among the general people. Fake videos have caused considerable inconvenience in the daily lifestyle of some people. The intervention of fake videos is now regarded as a serious obstacle due to its manipulating and convincing power. Researchers and scientists have been trying to implement different methods and techniques to overcome this new technical barrier. Various procedures and algorithms have been implemented, which showed a wide variety of results in controlling and defeating this technological hazard. However, it is yet to be concluded on which method should be followed to stop fake videos from causing us problems. This is due to the broad range of results achieved by them and the deficiencies that these methods contain. None of these methods produced the perfect protection in all aspects of fake videos. Hence, our project emphasizes on detecting fake videos by implementing algorithms that will provide the most efficient and accurate result. In our project, a video will be uploaded in the web application, which will then undergo different machine learning techniques which will involve filtering, feature extraction, and classification. Finally, after completing the procedure, the output will be displayed whether the video is fake or real. According to our model, the accuracy rate achieved was 83.456%, 87.349% and 88.965% for the length of sequence 10, 20 and 40 respectively. The best accuracy was achieved when the length of sequence is 40.;"Convolutional neural network;Deepfake video;Machine learning;Recursive neural network";IEEE
419;Deepfake Facial Recognition for Video Clips;"Adarsh; N. Bhaal; G. Padmapriya";2024;The accessibility of deep learning tools has fueled the rise of convincing Deepfake videos. This research focuses on developing and evaluating an advanced Deepfake Facial Recognition system, integrating Long Short-Term Memory (LSTM) and ResNeXt CNNs. Utilizing CNNs for frame-level facial feature extraction and LSTM for temporal dependencies, the system excels in discerning nuanced manipulations. Extensively tested on diverse Deepfake content, our findings demonstrate the system's considerable accuracy in distinguishing between authentic and manipulated facial features. The integrated LSTM enhances sensitivity to subtle manipulations often overlooked by frame-based methods, while the ResNeXt CNN architecture improves overall precision. Rigorously evaluated on a diverse set of Deepfake-containing video clips, the system proves highly effective. The research also addresses challenges in Deepfake facial recognition, exploring potential countermeasures and contributing valuable insights to the development of robust systems mitigating risks associated with manipulated video content. The FaceForensic++ dataset model stands out with its remarkable precision, achieving an impressive accuracy rate of 97.76%. Meanwhile, the Celeb-DF dataset model has also performed admirably, boasting a competitive accuracy score of 93.97%.;"Deepfake Video Detection;ResNext CNN;LSTM";IEEE
420;Video Integrity Detection with Deep Learning;"C. R; A. V. R; P. R";2024;In today's digital age, ensuring information integrity against deepfakes is essential. This project addresses this challenge by developing a scalable video integrity detection system through the fusion of convolutional neural networks (CNNs) for analyzing video frames and recurrent neural networks (RNNs) for temporal behavior. The model incorporates advanced architectures designed to capture subtle inconsistencies and manipulation artifacts, leveraging cutting-edge techniques for enhanced detection compared to traditional methods. Its adaptability is enhanced through the utilization of domain adaptation and adversarial training strategies, ensuring durability against evolving manipulation techniques. Designed for real-time capabilities, the system is optimized for efficient inference, enabling proactive identification and mitigation of manipulated content on online platforms. Expected outcomes include achieving high accuracy in discriminating real from manipulated videos, promoting improved trust and transparency in the digital media landscape. By providing a reliable means to verify the integrity of video content, the system contributes to a more trustworthy and secure digital ecosystem. This multi-modal fusion approach, coupled with advanced architectures, effectively addresses the necessity for identifying and controlling the spread of manipulated video content.;"Deep learning;Video integrity detection;Convolutional neural networks (CNNs);Recurrent neural networks (RNNs);Deepfake (DF);Adversarial training;Long Short-Term Memory (LSTM);ResNeXt";IEEE
423;Detection of Facial Forgery in Digital Images;"H. A. Khan; S. Tehsin; M. Humayun; G. N. Alwakid";2023;Detection of facial forgery in images and videos is a complex and challenging task. For the last years, different methods have been employed to detect facial forgeries. However, facial forgeries are still very challenging to detect. In this paper, a modern facial forgery detection method is presented which automatically detects facial forgeries in videos and images. The proposed method classifies fake and original videos and images. To classify the images, deep learning model, Inception-ResNet has been adopted. The proposed method is validated on publicly available Deepfake TIMIT dataset and effective results have been reported.;"Facial Forgery;Deepfake;Image Forensics;Fake Image;deep learning";IEEE
424;Robust Frame-Level Detection for Deepfake Videos With Lightweight Bayesian Inference Weighting;"L. Zhou; C. Ma; Z. Wang; Y. Zhang; X. Shi; L. Wu";2024;Deepfake threatens the authenticity of the information in artificial intelligence Internet of Things (IoT) systems. Recently, several deepfake detection methods have been proposed in academia and industry for securing the authenticity of visual information in the face of artificial intelligence advances. Frame-level detection methods, a widely employed security method against deepfake, have a small model size and offer real-time responsiveness, despite basing their classification decision only on the information contained within the frame they are evaluating. We propose a new lightweight frame-level detection technique based on Bayesian inference weighting (BIW) to improve the robustness of existing frame-level detection models. Our proposed BIW technique employs the Naive Bayesian algorithm to estimate the reliability of any candidate model�s detection results. Comprehensive experiments were conducted on the attacked data sets by four designed video interference approaches and edge computing platform, showing that BIW enhances the robustness of all the baselines and improves their detection accuracy with a real-time response.;"Bayesian inference;deepfake video;frame-level detection;IoT security";IEEE
427;MCL: Multimodal Contrastive Learning for Deepfake Detection;"X. Liu; Y. Yu; X. Li; Y. Zhao";2024;Advancements in computer vision and deep learning have led to difficulty in distinguishing Deepfake and real videos. In particular, forgery audios are also generated to accompany fake videos and make them more realistic, which makes Deepfake detection more difficult. Existing Deepfake detection methods that use multimodal information ignore the representation gap between different modalities, resulting in limited performance. To address this problem, in this paper, a novel Deepfake detection method utilizing multimodal contrastive learning (MCL) is proposed to better explore intra-modal and cross-modal forgery clues. To reduce the cross-modal gap and explore multimodal forgery artifacts, a cross-modal contrastive learning strategy is designed to learn a compositional embedding from multimodal information, which facilitates pulling together representations across uni-modalities and multi-modalities. Moreover, to supplement the intra-frame forgery clues mining ability of the video network, the frame knowledge is distilled to the video network without adding additional computation. Specifically, to mine intra-modal clues, three modality features are first extracted from audio, frame and video, respectively. Secondly, the audio and frame features are separately composed with the video feature to derive two cross-modal representations. Subsequently, these cross-modal features are contrastive with the intra-modal features to reduce cross-modal gap. By jointly pulling together the unimodal and multimodal features through MCL, a more effective representation that contains intra-modal and cross-modal forgery artifacts can be learned. Finally, a noise-based feature augmentation (NFA) module is proposed to adaptively perturb the audio-visual feature and further improve generalization performance. Extensive experiments demonstrate that the proposed framework outperforms SOTA methods.;"Deepfake detection;contrastive learning;knowledge distillation";IEEE
430;Joint Audio-Visual Deepfake Detection;"Y. Zhou; S. -N. Lim";2021;"Deepfakes (""deep learning"" + ""fake"") are videos synthetically generated with AI algorithms. While they could be entertaining, they could also be misused for falsifying speeches and spreading misinformation. The process to create deepfakes involves both visual and auditory manipulations. Exploration on detecting visual deepfakes has produced a number of detection methods as well as datasets, while audio deepfakes (e.g. synthetic speech from text-to-speech or voice conversion systems) and the relationship between the video and audio modalities have been relatively neglected. In this work, we propose a novel visual / auditory deepfake joint detection task and show that exploiting the intrinsic synchronization between the visual and auditory modalities could benefit deepfake detection. Experiments demonstrate that the proposed joint detection framework outperforms independently trained models, and at the same time, yields superior generalization capability on unseen types of deepfakes.";"Image and video manipulation detection and integrity methods;Vision + other modalities";IEEE
431;Improved Deepfake Video Detection Using Convolutional Vision Transformer;"D. W. Deressa; P. Lambert; G. Van Wallendael; S. Atnafu; H. Mareen";2024;Deepfakes are hyper-realistic videos in which the faces are replaced, swapped, or forged using deep-learning models. This potent media manipulation techniques hold promise for applications across various domains. Yet, they also present a significant risk when employed for malicious intents like iden-tity fraud, phishing, spreading false information, and executing scams. In this work, we propose a novel and improved Deepfake video detector that uses a Convolutional Vision Transformer (CViT2), which builds on the concepts of our previous work (CViT). The CViT architecture consists of two components: a Convolutional Neural Network that extracts learnable features, and a Vision Transformer that categorizes these learned features using an attention mechanism. We trained and evaluted our model on 5 datasets, namely Deepfake Detection Challenge Dataset (DFDC), $\mathbf{FaceForensics++} \ (\text{FF}++)$ I, Celeb-DF v2, Deep-fakeTIMIT, and TrustedMedia. On the test sets unseen during training, we achieved an accuracy of 95 %, 94.8 %, 98.3 % and 76.7% on the DFDC, $\mathbf{FF ++}$, Celeb-DF v2, and TIMIT datasets, respectively. In conclusion, our proposed Deepfake detector can be used in the battle against misinformation and other forensic use cases.;"Deepfake Video Detection;Vision Transformer;Convolutional Neural Network;Misinformation Detection;Mul-timedia Forensics";IEEE
433;Analyzing Deep Learning Models� Generalization Ability Under Different Augmentations on Deepfake Datasets;"I. Huseynli; S. Varli";2021;Deepfakes allow users to manipulate the identity of a person in a video or an image. Improvements on GAN-based techniques also generate more realistic and hard to detect fake faces. This threatens individuals and decreases trust in social media platforms. In this work, our goal is to report eight different models� learning ability on, by far, the largest fake face dataset - DFDC. The models� generalization ability was tested on the DFDC test set and Celeb-DF-v2 dataset. Effect of the various cut-out like augmentations to the learning was also reported.;"deepFake;dFdc;face manipulation;digital video forensics";IEEE
434;A Visually Interpretable Forensic Deepfake Detection Tool Using Anchors;"K. Jayakumar; N. Skandhakumar";2022;"�Deepfakes� have seen a dramatic rise in recent times and are becoming quite realistic and indistinguishable with the advancement of deepfake generation techniques. Promising strides have been made in the deepfake detection area even though it is a relatively new research domain. Majority of current deepfake detection solutions only classify a video as a deepfake without providing any explanations behind the prediction. However, these works fail in situations where transparency behind a tool�s decision is crucial, especially in a court of law, where digital forensic investigators maybe called to testify if a video is a deepfake with evidence; or where justifications behind tool decisions plays a key role in the jury�s verdict. Explainable AI (XAI) has the power to make deepfake detection more meaningful, as it can effectively help explain why the detection tool classified the video as a deepfake by highlighting forged super-pixels of the video frames. This paper proposes the use of �Anchors� XAI method, a model-agnostic high precision explainer to build the prediction explainer model, that can visually explain the predictions of a deepfake detector model built on top of the EfficientNet architecture. Evaluation results show that Anchors fair better than LIME in terms of producing visually explainable and easily interpretable explanations and produces an anchor affinity score of 70.23%. The deepfake detector model yields an accuracy of 91.92%.";"Deepfake Detection;XAI;Computer Vision;Deep Neural Networks;Anchors;Digital Media Forensics";IEEE
436;Constructing New Backbone Networks via Space-Frequency Interactive Convolution for Deepfake Detection;"Z. Guo; Z. Jia; L. Wang; D. Wang; G. Yang; N. Kasabov";2024;The serious concerns over the negative impacts of Deepfakes have attracted wide attentions in the community of multimedia forensics. The existing detection works achieve deepfake detection by improving the traditional backbone networks to capture subtle manipulation traces. However, there is no attempt to construct new backbone networks with different structures for Deepfake detection by improving the internal feature representation of convolution. In this work, we propose a novel Space-Frequency Interactive Convolution (SFIConv) to efficiently model the manipulation clues left by Deepfake. To obtain high-frequency features from tampering traces, a Multichannel Constrained Separable Convolution (MCSConv) is designed as the component of the proposed SFIConv, which learns space-frequency features via three stages, namely generation, interaction and fusion. In addition, SFIConv can replace the vanilla convolution in any backbone networks without changing the network structure. Extensive experimental results show that seamlessly equipping SFIConv into the backbone network greatly improves the accuracy for Deepfake detection. In addition, the space-frequency interaction mechanism does benefit to capturing common artifact features, thus achieving better results in cross-dataset evaluation. Our code will be available at https://github.com/EricGzq/SFIConv.;"Deepfake detection;space-frequency interactive convolution;backbone network;manipulation traces";IEEE
437;FGSM Adversarial Attack Detection On Deepfake Videos;"S. N. Mohamed; A. A. Ahmed; W. Elsersy";2024;Our goal in this work is to create robust detection models that will counter the danger of adversarial attacks on deepfake videos. We selected a subset of the FaceForensics++ dataset, consisting of 1600 movies evenly divided into actual and fake categories, in order to overcome computational limitations.For FGSM attack detection, we used two sophisticated deep learning models: ResNet50 and Xception. In order to enhance the models' capacity to identify pertinent characteristics, we preprocessed the dataset prior to training by removing frames and concentrating on facial areas. We also added several intensities of FGSM adversarial attacks to improve the dataset's durability and diversification. The outcomes of our experiments were encouraging. With very little loss, the Xception model demonstrated remarkable performance, attaining high accuracies of 98.85% in training, 98.58% in validation, and 93.75% in testing. Never-theless, the ResNet50 model encountered difficulties, exhibiting reduced training, validation, and testing accuracies of 85.26%, 83.18%, and 82.50%, coupled with increased losses. Overall, by offering useful techniques for identifying misleading content, our research strengthens the authenticity and reliability of videos.;;IEEE
438;Demystifying Attention Mechanisms for Deepfake Detection;"A. Das; S. Das; A. Dantcheva";2021;Manipulated images and videos, i.e., deepfakes have become increasingly realistic due to the tremendous progress of deep learning methods. However, such manipulation has triggered social concerns, necessitating the introduction of robust and reliable methods for deepfake detection. In this work, we explore a set of attention mechanisms and adapt them for the task of deepfake detection. Generally, attention mechanisms in videos modulate the representation learned by a convolutional neural network (CNN) by focusing on the salient regions across space-time. In our scenario, we aim at learning discriminative features to take into account the temporal evolution of faces to spot manipulations. To this end, we address the two research questions �How to use attention mechanisms?�, and �What type of attention is effective for the task of deepfake detection?� Towards answering these questions, we provide a detailed study and experiments on videos tampered by four manipulation techniques, as included in the FaceForensics++ dataset. We investigate three scenarios, where the networks are trained to detect (a) all manipulated videos, (b) each manipulation technique individually, as well as (c) the veracity of videos pertaining to manipulation techniques not included in the train set.;;IEEE
439;Towards Generalized Deepfake Detection With Continual Learning On Limited New Data;"H. Huang; N. Sun; X. Lin; N. Moustafa";2022;Advancements in deep learning make it increasingly easy to produce highly realistic fake images and videos (also known as deepfakes), which could undermine trust in public discourse and pose threats to national and economic security. Despite the diligent efforts in developing deepfake detection techniques, existing approaches often generalize poorly when the characteristics of new data and tasks differ significantly from the ones involved in their initial training phase. The detectors' limited generalizability hinders their widespread adoption if they cannot handle unseen manipulations in an open set. A promising remedy is to endow the deepfake detectors with the capability of lifelong learning from the new data to improve themselves. However, it is not uncommon in real-world scenarios that the amount of training data associated with a certain deepfake algorithm is limited. Therefore, the effectiveness and agility of a continual learning scheme depend heavily on its ability to learn from limited new data. In this work, we propose a deepfake detection approach that combines spectral analysis and continual learning methods to pave the way towards generalized deepfake detection with limited new data. The experimental results on five datasets of deepfakes show that our proposed approach generalizes well on unseen datasets. Furthermore, it effectively addresses catastrophic forgetting despite limited new data, with the average forgetting rate reduced by 35.04% and the average accuracy improved by 22.45% as compared to without continual learning.;"deepfake detection;spectral analysis;continual learning;generalization;limited data";IEEE
440;Efficientnet-Based Deep Learning Approach for Video Forgery Detection and Authentication;"V. Gowri Priyaa; M. Jaya Harrish; M. Udhayakumar; N. Jothieswaran; K. Dinesh";2024;The technological advancements in artificial intelligence have made it a lot easier to create forged videos that are difficult to distinguish from reality. Fake videos also called deep fakes are created with greater accuracy and precision. Detecting and removing fake data on the internet can prevent misinformation and rumors from spreading. To achieve this, detection methods must be robust, generalized, fast, and accurate enough to detect fake data. In this paper, deepfakes are created using Generative Adversarial Network (GAN) and used for dataset training. The deepfakes are found to be different from real ones by various parameters like facial expressions, irregularities in the image, etc. This project focuses on detecting the manipulated face of the person in a frame using the EfficientNet B4 algorithm. The EfficientNet B4 model is more accurate than EfficientNet B0 and less complex than EfficientNet B7. The modified EfficientNet B4 outperforms the existing EfficientNet B0 in terms of accuracy. The probabilities of deep fakes in each frame are calculated and on average the video is detected as real or fake. This model demonstrates a very successful detection rate of more than 92%. Finally, modified EfficientNet B4 is compared with other models� performance.;"Deepfake;EfficientNet;Compound scaling;Generator;Discriminator";IEEE
442;Detecting Deepfake Videos via Frame Serialization Learning;"X. Zhou; Y. Wang; P. Wu";2020;Deepfake, a video forgery technique based on Generative Adversarial Network (GAN), has been proved to be a serious threat to the public security. The images and videos generated with it can even fool human eyes. In this paper, we propose a deep learning-based method to hunt Deepfake videos. A 3D-ResNext based model is developed to effectively learn the leverageable difference between fake videos and benign ones from multiple serialized frames. Furthermore, to address the information loss in compressed videos, the data enhancement technique is introduced in data preprocessing to collect sufficient training samples from public datasets, e.g., FaceForensics++, DeepFakeDetection and DFDC. The experiments demonstrated that our method has good performance and generalization ability in the task of Deepfake videos detection.;"Deepfakes;deep learning;ResNext;3D-ResNext;WS-DAN";IEEE
450;Enhancing Deepfake Detection With Diversified Self-Blending Images and Residuals;"Q. Liu; Z. Xue; H. Liu; J. Liu";2024;The advancement of deep forgery technology has significantly impacted the credibility of media content, making the detection of deep forgeries crucial for ensuring media security. Although research on deepfake detection methods has been progressively advancing, current approaches predominantly rely on detecting and identifying artifacts. As deep forgery technology continually improves, high-quality synthetic images and those produced through reconstruction methods have become increasingly sophisticated, rendering artifact and trace detection methods somewhat limited. To address this issue, we introduce a deep forgery detection method that integrates deep neural networks with fine-grained artifact features. Our proposed method simulates diverse facial synthesis data by employing facial color conversion, facial frequency domain conversion, and facial mask deformation and blurring. This trains the deepfake detection model to adapt to various synthesis techniques. The classifier model is trained using multiple perturbations of authentic images, with fine-grained artifact features ensuring the stability of the detection process. Our approach achieves superior accuracy and AUC values on the FF++ and WildDeepfake datasets, demonstrating its effectiveness and adaptability in detecting deep forgeries.;"Deep learning;deepfake;synthetic data;image forensics";IEEE
453;Fairness Evaluation in Deepfake Detection Models using Metamorphic Testing;"M. Pu; M. Y. Kuan; N. T. Lim; C. Y. Chong; M. K. Lim";2022;Fairness of deepfake detectors in the presence of anomalies are not well investigated, especially if those anomalies are more prominent in either male or female subjects. The primary motivation for this work is to evaluate how deepfake detection model behaves under such anomalies. However, due to the black-box nature of deep learning (DL) and artificial intelligence (AI) systems, it is hard to predict the performance of a model when the input data is modified. Crucially, if this defect is not addressed properly, it will adversely affect the fairness of the model and result in discrimination of certain sub-population unintentionally. Therefore, the objective of this work is to adopt metamorphic testing to examine the reliability of the selected deepfake detection model, and how the transformation of input variation places influence on the output. We have chosen MesoInception-4, a state-of-the-art deepfake detection model, as the target model and makeup as the anomalies. Makeups are applied through utilizing the Dlib library to obtain the 68 facial landmarks prior to filling in the RGB values. Metamorphic relations are derived based on the notion that realistic perturbations of the input images, such as makeup, involving eyeliners, eye shadows, blushes, and lipsticks (which are common cosmetic appearance) applied to male and female images, should not alter the output of the model by a huge margin. Furthermore, we narrow down the scope to focus on revealing potential gender biases in DL and AI systems. Specifically, we are interested to examine whether MesoInception-4 model produces unfair decisions, which should be considered as a consequence of robustness issues. The findings from our work have the potential to pave the way for new research directions in the quality assurance and fairness in DL and AI systems.;"Metamorphic testing;fairness testing;robustness testing;oracle problem";IEEE
454;Tensor-Based Deepfake Detection in Scaled and Compressed Images;"S. Concas; G. Perelli; G. L. Marcialis; G. Puglisi";2022;When deepfakes are widespread on chatting platforms, they are expected to be subject to heavy resizing and compressing steps. In this paper, we present a tensor-based representation of compressed and resized images. Tensor embeds DCT features computed on multi-scaled and multi-compressed versions of the input facial image. Moreover, a custom deep-architecture is designed and trained on the proposed representation. Experimental results show its pros and cons with respect to state-of-the-art methods.;"Deepfake;face;biometric";IEEE
455;Deepfake Detection Using EfficientNet and XceptionNet;"B. Yasser; J. Hani; S. El-Gayar; O. Amgad; N. Ahmed; H. M. Ebied; H. Amr; M. Salah";2023;The increasing prevalence of manipulated media, particularly deepfake videos, poses significant challenges in distinguishing real from fake content. This paper addresses the issue of detecting deepfake videos using advanced CNN architectures such as EfficientNet-B4 and XceptionNet. The FF++ and Celeb-DF (v2) datasets are used to compare real and fake videos. The methodology involves preprocessing the Celeb- DF dataset by extracting frames and isolating faces, training the models, and evaluating their performance using log loss and Area Under the Curve (AUC) metrics. The study shows that both models are effective in accurately classifying real and fake videos and highlights the importance of continuously updating deepfake detection algorithms in response to evolving deepfake generation techniques.;"Deepfake Detection;Extracting Frames;cropping faces;accuracy;XceptionNet;EfficientNet";IEEE
457;Human vs. Automatic Detection of Deepfake Videos Over Noisy Channels;"S. S. Prasad; O. Hadar; T. Vu; I. Polian";2022;Identification of DeepFake video content is a challenging scientific problem that addresses a growing societal concern. We investigate the relationship between DeepFake detection by humans and by automatic methods based on state-of-the-art deep learning algorithms. The main novelty of our work is the consideration of videos that are transmitted through noisy channels and arrive with distortions. This reflects many practical environments, including surveillance based on cameras connected via noisy wireless links and videoconferencing in driving vehicles. We conduct a user study with 192 probands who classify real (genuine) and DeepFake videos with and without various classes of distortions. We find that today's deep neural networks (DNNs) outperform humans by far, whereas humans are heavily distracted by random noise from the channel. Moreover, DNNs are robust under distortions, achieving perfect classification on distorted data even when trained on distortion-free content. It appears that the human visual system and DNNs are approaching the DeepFake classification problem quite differently and their respective strengths and weaknesses are largely uncorrelated.;"DeepFake Detection;Deep Learning;Noisy Channels";IEEE
458;Enhancing Deepfake Detection using SE Block Attention with CNN;"S. Dasgupta; J. Mason; X. Yuan; O. Odeyomi; K. Roy";2024;In the digital age, Deepfake present a formidable challenge by using advanced artificial intelligence to create highly convincing manipulated content, undermining information authenticity and security. These sophisticated fabrications surpass traditional detection methods in complexity and realism. To address this issue, we aim to harness cutting-edge deep learning methodologies to engineer an innovative deepfake detection model. However, most of the models designed for deepfake detection are large, causing heavy storage and mem-ory consumption. In this research, we propose a lightweight convolution neural network (CNN) with squeeze and excitation block attention (SE) for Deepfake detection. The SE block module is designed to perform dynamic channel-wise feature recalibration. The SE block allows the network to emphasize informative features and suppress less useful ones, which leads to a more efficient and effective learning module. This module is integrated with a simple sequential model to perform Deepfake detection. The model is smaller in size and it achieves competing accuracy with the existing models for deepfake detection tasks. The model achieved an overall classification accuracy of 94.14% and AVC-ROC score of 0.985 on the Style GAN dataset from the Diverse Fake Face Dataset. Our proposed approach presents a promising avenue for combating the Deepfake challenge with minimal computational resources, developing efficient and scalable solutions for digital content verification.;"SE Block;CNN;Deepfake Detection;Entire Face Synthesis";IEEE
459;Comparative Analysis of Deepfake Video Detection Using Inception Net and Efficient Net;"G. R. E; M. E; G. K. C; T. Bellam; B. P; K. Rengaraju";2022;Human beings have the most distinctive feature that is human face. We can exchange somebody faces with anybody else's faces that appear realistic because many have another type of algo is based upon deepfake tech. Deepfake videos / photos is revolutionary subdual of AI tech by using someones human face can overwrite of someones face. More generously, with many different methods based on productive pictures. Unwillingly the overuse of smartphone and organizing by multiple internet web using AI manipulated data is reaching quicker in something which can we see in the 20th century, global danger is made up by these products Deepfakes are digital manipulation techniques that use machine learning to produce misleading videos. Identification is most difficult part to find from the original. Previously, CNN networks were used to perform identify the deep fake verification. Due to the increasing popularity of deep fakes identification of real one is more important find ways to detect manipulated videos that are presented as real ones. In this project, we will study different methods that can be used to detect such images as well as videos. This study shows that they can also be done using a convolutional algorithm known as Efficient Net and Inception Net. In this Paper, we compare various versions of Convolutional Inception Net with various versions of convolutional Efficient Net combined with Vision Transformers and different Data files to obtain best possible results in Deepfake detection. To get the highly accurate percentage to identify the video is fake or real by using efficient net and by inception net. tract);"Deepfake;Inception net;Efficient net;CNN;Vision Transformers";IEEE
460;AVFF: Audio-Visual Feature Fusion for Video Deepfake Detection;"T. Oorloff; S. Koppisetti; N. Bonettini; D. Solanki; B. Colman; Y. Yacoob; A. Shahriyari; G. Bharaj";2024;With the rapid growth in deepfake video content, we re-quire improved and generalizable methods to detect them. Most existing detection methods either use uni-modal cues or rely on supervised training to capture the dissonance be-tween the audio and visual modalities. While the former disregards the audio-visual correspondences entirely, the lat-ter predominantly focuses on discerning audio-visual cues within the training corpus, thereby potentially overlooking correspondences that can help detect unseen deepfakes. We present Audio- Visual Feature Fusion (AVFF), a two-stage cross-modal learning method that explicitly captures the correspondence between the audio and visual modalities for improved deepfake detection. The first stage pursues representation learning via self-supervision on real videos to capture the intrinsic audio-visual correspondences. To extract rich cross-modal representations, we use contrastive learning and autoencoding objectives, and introduce a novel audio-visual complementary masking and feature fusion strategy. The learned representations are tuned in the second stage, where deepfake classification is pursued via super-vised learning on both real and fake videos. Extensive exper-iments and analysis suggest that our novel representation learning paradigm is highly discriminative in nature. We report 98.6% accuracy and 99.1% AUC on the FakeAVCeleb dataset, outperforming the current audio-visual state-of-the-art by 14.9% and 9.9%, respectively.;"video deepfake detection;representation learning;audio visual;multimodal";IEEE
464;3D Attention Network for Face Forgery Detection;"Z. Ma; X. Mei; J. Shen";2023;With the rapid development of face forgery techniques, a large number of face synthesis videos are widely spread on the Internet, which threatens the security and trustworthiness of digital content online. It is necessary to develop face forgery detection methods. Many existing methods use only 2D CNNs to detect video frames. There are few 3D networks designed for face forgery detection. In this work, we propose to use 3D CNN for video-level face forgery detection and add a lightweight attention module to construct a 3D attention network. The network extracts both spatial and temporal features. The attention maps generated by the attention module focus on several forged regions of the fake face. To avoid the discrepancy of different regions affecting the detection results, a global attention pool is designed to replace the global average pool. The experiments implemented on FaceForensics++ show that our model achieves great accuracy and exceeds most existing methods. Cross-dataset evaluation implemented on Celeb-DF verifies that our model has strong transferability and generalization ability.;"Face forgery detection;DeepFake detection;Face forgery;Digital video forensics;3D convolutional neural network";IEEE
465;DeepFake Detection by Analyzing Convolutional Traces;"L. Guarnera; O. Giudice; S. Battiato";2020;The Deepfake phenomenon has become very popular nowadays thanks to the possibility to create incredibly realistic images using deep learning tools, based mainly on ad-hoc Generative Adversarial Networks (GAN). In this work we focus on the analysis of Deepfakes of human faces with the objective of creating a new detection method able to detect a forensics trace hidden in images: a sort of fingerprint left in the image generation process. The proposed technique, by means of an Expectation Maximization (EM) algorithm, extracts a set of local features specifically addressed to model the underlying convolutional generative process. Ad-hoc validation has been employed through experimental tests with naive classifiers on five different architectures (GDWCT, STARGAN, ATTGAN, STYLEGAN, STYLEGAN2) against the CELEBA dataset as ground-truth for non-fakes. Results demonstrated the effectiveness of the technique in distinguishing the different architectures and the corresponding generation process.;;IEEE
466;Deepfake Detection using Multi-path CNN and Convolutional Attention Mechanism;"R. B. P.; M. S. Nair";2022;Image and video forgery using cutting-edge deep learning techniques has become one of the major issues in the social networking era. Media manipulation in which one person�s face is swapped out for another�s or has additional features added is referred to as deepfakes. Despite the fact that it has many beneficial purposes, fraudsters generally utilise it to create celebrity porn, revenge porn, and fake news, among other things. One of the biggest risks that deepfake presents is that people�s belief in the reality of many things may decline. The motivation behind deepfake detection is the need to prove that the real thing is real and the fake thing is fake. In this paper a multi-CNN approach for detecting deepfakes is being proposed. Here, a multipath convolutional neural network (CNN) with three modules is used, each of which is stacked with a convolutional block attention mechanism. The first two modules in the dual-path paradigm are a Resnet module and a Densenet module. The Resnet component enables for feature reuse while Densenet allows for the investigation of new features. The parallel InceptionResnet module contains a one-dimensional feature reduction module with residual connections. When the performance of the proposed model is compared with that of four deep learning based approaches, it is found that the proposed method gave the best outcomes, with an accuracy and F1-score of 0.940 and 0.939, respectively.;"deepfake detection;deep learning;feature extraction;attention mechanism;classifier";IEEE
467;Using the Swin-Transformer for Real & Fake Data Recognition in PC-Model;J. Park;2024;Recently, due to the rapid development of generative AI technologies, the use of AI-generated images has increased significantly, making the distinction between real and fake images crucial. Generative images may be used in various ways such as data training and fast image generation, but a potential for misuse, such as in Deep fake or spreading false information, still exists. This study explores a novel model using the architecture ofSwin-Transformer to distinguish between fake and real images generated based on CNN (Convolutional Neural Networks) and GAN (Generative Adversarial Networks). The Swin-Transformer, a successor model of Vision in Transformer (ViT), applies the structure of the Transformer, which has shown outstanding performance in natural language processing, to the field of images and demonstrates excellent pixel-level segmentation performance. Real and fake images require detailed pixel-level analysis, in which the Swin-Transformer exhibits higher accuracy. Improving the performance of distinguishing between real and fake images is expected to set limits on indiscreet image generation, bringing further effects such as preventing the indiscriminate use of AI images through program-based discrimination/legal sanctions.;"Artificial Intelligence;Convolution Neural Network;Generative Adversarial Network;Real&Fake";IEEE
470;Deepfake Detection in Media Files - Audios, Images and Videos;"B. F. Nasar; S. T; E. R. Lason";2020;Recent advancement in deep learning has applied to solve various complex problems ranging from big data analytic to computer vision and human-level control. One among them is the deepfake technology which becomes a real threat to privacy, democracy, and national security. Deepfake is hyper-realistic digitally manipulated videos to depict people saying and doing things that never actually happened. This technology has been used in many fields in film industries for recreating videos without re-shooting, awareness video generation such as creating voices of those who have lost theirs or updating episodes of movies without re-shooting them at very low cost. This technology has many harmful usages in social media, pornographic sites, etc. to deface peoples which largely dominate the positive side of this application of deep learning. Also, the creation and spreading of these videos are increasing rapidly along all fields of media files. Therefore, it is very much important to develop efficient tools that can automatically detect the deepfake in these videos and thus reduce the public harm caused by such videos. In the early stages of deepfake detection, traditional technologies like signal processing, image processing, lip-syncing, etc were used but this provides very little accuracy when combined with the recent technologies of deep learning. So, here a system is proposed that can automatically detect the deepfake in media files such as images, videos, and audios. This uses an image processing approaches combined with deep learning which detects the inconsistency that exists in fake media.;"GAN;CNN;LSTM";IEEE
471;Unsupervised Learning-Based Framework for Deepfake Video Detection;"L. Zhang; T. Qiao; M. Xu; N. Zheng; S. Xie";2023;"With the continuous development of computer hardware equipment and deep learning technology, it is easier for people to swap faces in videos by currently-emerging multimedia tampering tools, such as the most popular deepfake. It would bring a series of new threats of security. Although many forensic researches have focused on this new type of manipulation and achieved high detection accuracy, most of which are based on supervised learning mechanism with requiring a large number of labeled samples for training. In this paper, we first develop a novel unsupervised detection manner for identifying deepfake videos. The main fundamental behind our proposed method is that the face region in the real video is taken by the camera while its counterpart in the deepfake video is usually generated by the computer; the provenance of two videos is totally different. Specifically, our method includes two clustering stages based on Photo-Response Non-Uniformity (PRNU) and noiseprint feature. Firstly, the PRNU fingerprint of each video frame is extracted, which is used to cluster the full-size identical source video (regardless of its real or fake). Secondly, we extract the noiseprint from the face region of the video, which is used to identify (re-cluster for the task of binary classification) the deepfake sample in each cluster. Numerical experiments verify our proposed unsupervised method performs very well on our own dataset and the benchmark FF++ dataset. More importantly, its performance rivals that of the supervised-based state-of-the-art detectors.";"Deepfake detection;unsupervised learning;video clustering;PRNU;noiseprint";IEEE
472;Improved Generalizability of Deep-Fakes Detection using Transfer Learning Based CNN Framework;"P. Ranjan; S. Patil; F. Kazi";2020;Deep-Fakes are emerging as a significant threat to society, with potential to become weapons of mass disinformation and chaos. Simple tools provide ways to produce such digital forgeries at a large scale which makes it crucial to develop counter-attacking approaches for detection of these Deep-Learning based manipulations. This work analyzes a Transfer Learning based Convolutional Neural Network framework for the task of Deep-Fake Detection on three of the latest released datasets � DeepFakeDetection (DFD), Celeb-DF, and DeepFakeDetectionChallenge (DFDC) Preview. Additionally, a custom dataset of high-quality Deep-Fakes is compiled and used for evaluation of models. The intuition behind Transfer Learning for Deep-Fakes Detection is explored using the Explainable-AI technique of visualizing intermediate activations to provide interpretability. The critical problem of dataset shift and its effect on domain adaptation is explored by comparing cross-dataset test accuracies, with and without the usage of Transfer Learning. The results of this work indicate that even though Deep-Fake Detection is a highly domain specific task, there is a significant improvement in performance in terms of both single-domain classification accuracy and generalizability by utilizing Transfer Learning.;"deep-fakes;digital forgeries;manipulation detection;convolutional neural network;transfer learning;generalizability;dataset shift;domain adaptation";IEEE
476;Utilizing Data Augmentation Methods to Generalize DeepFake Classifier;"J. G. Pho; C. A. Gouw; H. Lucky; D. Suhartono";2024;DeepFakes are fabricated audiovisual media. As technology advances, the tools for making DeepFakes have increased. Due to this, making DeepFakes are more accessible to a lot of people. As a result, some people use it irresponsibly such as hoaxes and scams. To combat this, a reliable DeepFake detector is needed. EfficientNet-B0has been used and has the highest success rate in detecting DeepFakes. Moreover, utilizing dynamic face cutout has only been proven to increase the accuracy rate of detecting DeepFakes. Because of this, we decide to implement EfficientNet-B0and face augmentation with the hopes of having a reliable DeepFake detection model. For comparison, three experiments using three different models were done. The three models include EfficientNet-B0 with Multi-task Cascaded Convo-lutional Networks (MTCNN), EfficientNet-B0 with MTCNN and Face-CutOut, and EfficientNet-B0 with MTCNN and a common data augmentation method. The experiments showed that The EfficientNet-B0and MTCNN model yielded the best results, reaching above the 90% mark on the Accuracy, AUC-ROC, and Fl-Score. When face augmentation was implemented, the results faced a slight decrease of around 1% on the Accuracy, AUC-ROC, and Fl-Score compared to the model using only EfficientNet-B0 and MTCNN. However, the EfficientNet-B0 and MTCNN model implemented with Face-Cutout has the best AUC-ROC score, above the model using only EfficientNet-B0 and MTCNN, which has a score of 97.82%. The results demonstrate that data augmentation is effective in enhancing model generalization.;"EfficientNet-B0 DeepFake classifier;Multi-task Cascaded Convolutional Networks (MTCNN);Face-Cutout Data augmentation";IEEE
478;Motion Magnified 3-D Residual-in-Dense Network for DeepFake Detection;"A. Mehra; A. Agarwal; M. Vatsa; R. Singh";2023;Driven by the advances in deep learning, highly photo-realistic techniques capable of switching the identity and expression of faces have emerged. Cheap access to computing has brought such technology within the reach of anyone with a computer and Internet including people with sinister motives. To detect these forgeries, we present a novel compression resilient approach for deepfake detection in videos. The proposed approach employs motion magnification as a pre-processing step to amplify temporal inconsistencies common in forged videos. Utilizing these processed videos, we propose the 3D Residual-in-Dense ConvNet, which captures low level spatiotemporal features, which help classify a video as pristine or forged. The proposed method yields more than 93% average detection accuracy on the high compression variant of the FaceForensics++ dataset and achieves state-of-the-art performance on multiple benchmarks across the FaceForensics++ and CelebDF datasets. Further, we study the behavior of deepfake detection algorithms across ethnicities and demonstrate how the proposed method reduces the inherent bias against minority ethnicities prevalent in existing algorithms.;"Deepfake;motion magnification;security;face recognition";IEEE
480;DeepFake-o-meter v2.0: An Open Platform for DeepFake Detection;"Y. Ju; C. Sun; S. Jia; S. Hou; Z. Si; S. K. Datta; L. Ke; R. Zhou; A. Nikolich; S. Lyu";2024;Deepfakes, as AI-generated media, have increasingly threatened media integrity and personal privacy with realistic yet fake digital content. This work introduces an open-source and user-friendly online platform, DeepFake-O-Meter v2.0, that integrates state-of-the-art methods for detecting DeepFake images, videos, and audio. Built upon DeepFake-O-Meter v1.0, we have significantly upgraded and improved the platform architecture design, including user interaction, detector integration, job balancing, and security management. The platform aims to offer everyday users a convenient service for analyzing DeepFake media using multiple state-of-the-art detection algorithms. It ensures secure and private delivery of the analysis results. Furthermore, it serves as an evaluation and benchmanrking platform for researchers in digital media forensics to compare the performance of multiple algorithms on the same input. We have also conducted a detailed usage analysis based on the collected data to gain deeper insights into our platform's statistics. This involves analyzing four-month trends in user activity and evaluating the processing efficiency of each detector.;;IEEE
482;Implementation of Deep Learning Method for Forgery Detection on Social Media;"A. Kohapare; K. Dhongade; R. Sukare; P. Maidamwar";2024;In recent years, the surge in misinformation and rapid technological advancements has significantly increased the prevalence of media manipulation. The advent of AI-altered videos and sophisticated news content poses a serious threat to media integrity, particularly as these manipulations proliferate on social media platforms, creating challenges in discerning authenticity. The accessibility and user-friendliness of deepfake technology have compounded the issue, making the distinction between genuine and fabricated content increasingly challenging. This presents substantial risks, ranging from the dissemination of false information to fostering a general sense of scepticism toward online visuals. This research aims to comprehensively analyze the process of creating deepfakes and assess their broader societal impact, while also proposing potential solutions to mitigate this problem. The methodology employed has achieved accuracy of 87% that involves utilizing ResN ext, a CNN architecture with LS TM, to analyse fake videos, and error level analysis followed by CNN algorithm to analyse fake images, this research outlines the specific steps and procedures involved in this analytical process.;"Convolutional Neural Network;Deepfake Detection;Erroe Level Analysis;ResNext";IEEE
484;MD-CSDNetwork: Multi-Domain Cross Stitched Network for Deepfake Detection;"A. Agarwal; A. Agarwal; S. Sinha; M. Vatsa; R. Singh";2021;The rapid progress in the ease of creating and spreading ultra-realistic media over social platforms calls for an urgent need to develop a generalizable deepfake detection technique. It has been observed that current deepfake generation methods leave discriminative artifacts in the frequency spectrum of fake images and videos. Inspired by this observation, in this paper, we present a novel approach, termed as MD-CSDNetwork, for combining the features in the spatial and frequency domains to extract a shared discriminative representation for classifying deepfakes. MD-CSDNetwork is a novel cross-stitched network with two parallel branches carrying spatial and frequency information, respectively. We hypothesize that these multi-domain input data streams can be considered as related supervisory signals and can ensure better performance and generalization. Further, the concept of cross-stitch connections is utilized where they are inserted between the two branches to learn an optimal combination of domain-specific and shared representations from other domains automatically. Extensive experiments are conducted on the popular benchmark datasets. We report improvements over all the manipulation types in the FaceForensics++ dataset and comparable results with state-of-the-art methods for cross-database evaluation on the Celeb-DF dataset and the Deepfake Detection Dataset.;;IEEE
488;Data Augmentation for Convolutional Neural Network DeepFake Image Detection;"A. Jellali; I. B. Fredj; K. Ouni";2023;We need to develop a technique for better identifying deepfakes because they can distort our perception of reality. This study offers a brand-new forensic technique for spotting falsified facial photos. We made advantage of the Kaggle- provided �real-and - fake- facial-detection� dataset. We are able to distinguish between probable facial alterations based on CNN's design. Thanks to data augmentation approaches, the results exhibit performances that are equivalent to those of previous works. The proposed approach fared better for this binary categorization into fake or real faces than the other cutting-edge studies. Our accuracy is close to 99 percent.;"CNN;Deepfakes Detection;Deep Learning;Data Augmentation;Faces Manipulations";IEEE
490;In-The-Wild Deepfake Detection using Adaptable CNN Models with Visual Class Activation Mapping for Improved Accuracy;"M. S. Saealal; M. Z. Ibrahim; M. I. Shapiai; N. Fadilah";2023;Deepfake technology has become increasingly sophisticated in recent years, making detecting fake images and videos challenging. This paper investigates the performance of adaptable convolutional neural network (CNN) models for detecting Deepfakes. In-the-wild OpenForensics dataset was used to evaluate four different CNN models (DenseNet121, ResNet18, SqueezeNet, and VGG11) at different batch sizes and with various performance metrics. Results show that the adapted VGG11 model with a batch size of 32 achieved the highest accuracy of 94.46% in detecting Deepfakes, outperforming the other models, with DenseNet121 as the second-best performer achieving an accuracy of 93.89% with the same batch size. Grad-CAM techniques are utilized to visualize the decision-making process within the models, aiding in understanding the Deepfake classification process. These findings provide valuable insights into the performance of different deep learning models and can guide the selection of an appropriate model for a specific application.;"deepfake;deep learning;convolution neural network;batch size;Grad-CAM visualization";IEEE
492;An Approach of Fake Videos Detection Based on Haar Cascades and Convolutional Neural Network;"A. Jellali; I. Ben Fredj; K. Ouni";2023;Because deep fakes might skew our impression of the truth, we need to come up with a method for better spotting them. This paper proposes a new forensic technique to detect manipulated facial images from videos. It is based on CNNs architecture that can distinguish possible face manipulations in the �real-and-fake-face-detection� dataset offered by Kaggle. The results obtained highlight comparable performances with the state-of-the-art methods. It showed an accuracy of approximately 99 % for this binary classification into fake or real faces. Then to validate this model we added a human face detection technique using the Haar Cascade method to this model in order to detect the manipulated videos from Deep Fake Detection Challenge (DFDC) dataset and we achieve an accuracy of 91 correct predictions out of 100 total videos.;"CNN;Deepfakes Detection;Deep Learning;Haar-Cascade;Data Augmentation;Faces Manipulations;Fake and real videos";IEEE
494;SWYNT: Swin Y-Net Transformers for Deepfake Detection;"F. Khalid; M. H. Akbar; S. Gul";2023;Nowadays, less technical individuals can create false videos by only source and target images, using deepfakes generation tools and methodologies. Distributing false information on social media and other concerns related to the deepfakes have thus significantly increased. To deal with the challenges posed by incorrect details, efficient Deepfakes detection algorithms must be developed considering the tremendous advancement in deepfakes generating techniques. Existing techniques are not reliable enough to find deepfakes, especially when the videos are made with various deepfakes generation methods. The Swin Y-Net Transformers (SWYNT) architecture we created in this paper can visually discriminate between natural and artificial faces. The architecture uses a Swin transformer, encoder, and decoder in a U -Net architecture with a classification branch to build a model that can classify and segment deepfakes. The segmentation process creates segmentation masks and helps train the classifier. We have evaluated our suggested method using the extensive, standard, and diverse FaceForensics++ (FF++) and the Celeb-DF dataset. The generalizability evaluation of our process, which is part of the performance evaluation, reveals the model's promising performance in identifying deepfakes videos generated using various methodologies on both large-scale datasets.;"Celeb-DF;Deepfake;Deepfake Detection;FaceForensics++;Swin Transformer;Swim Y-Net;U-Net";IEEE
496;Attending Generalizability in Course of Deep Fake Detection by Exploring Multi-task Learning;"P. Balaji; A. Das; S. Das; A. Dantcheva";2023;This work explores various ways of exploring multi-task learning (MTL) techniques aimed at classifying videos as original or manipulated in cross-manipulation scenario to attend generalizability in deep fake scenario. The dataset used in our evaluation is FaceForensics++, which features 1000 original videos manipulated by four different techniques, with a total of 5000 videos. We conduct extensive experiments on multi-task learning and contrastive techniques, which are well studied in literature for their generalization benefits. It can be concluded that the proposed detection model is quite generalized, i.e., accurately detects manipulation methods not encountered during training as compared to the state-of-the-art.;;IEEE
497;Investigating the Impact of Visual Attention Models in Face Forgery Detection;"A. Yadav; D. K. Vishwakarma";2023;With the recent rise of realistic face manipulation methods, building robust face tampering detection methods has become more important than ever before. Visual attention has played an important role in highlighting discriminative regions within input which is important for making accurate predictions. This manuscript presents a comparative study of several recently proposed visual attention models for the problem of face forgery detection. Specifically, five visual attention models namely, coordinate, selective kernel, triplet, CoT, and shuffle attention have been tested by integrating with a baseline deep learning model. The modified visually attentive architectures are trained and tested on popular public benchmark dataset FaceForensics++. The experimental results achieved by different attention approaches are compared. Additionally, the computational costs involved in each type of attention have also been discussed specifying the accuracy and computation tradeoff. Experimental results prove that Triplet Attention performs best by achieving accuracy scores of 0.9543 and 0.7190 on DF and NT categories of the FF++ dataset. Triplet attention is also extremely lightweight with only 1200 trainable parameters compared to the other attention modules under study.;"Visual attention;Face forgery;Face tampering;deepfake;attention;detection";IEEE
498;Eff-YNet: A Dual Task Network for DeepFake Detection and Segmentation;"E. Tjon; M. Moh; T. -S. Moh";2021;Advances in generative models and manipulation techniques have given rise to digitally altered videos known as deepfakes. These videos are difficult to identify for both humans and machines. Modern detection methods exploit various weaknesses in deepfake videos, such as visual artifacts and inconsistent posing. In this paper, we describe a novel architecture called Eff-YNet designed to detect visual differences between altered and unaltered areas. The architecture combines an EfficientNet encoder and a U-Net with a classification branch into a model capable of both classifying and segmenting deepfake videos. The task of segmentation helps train the classifier and also produces useful segmentation masks. We also implement ResNet 3D to detect spatiotemporal inconsistencies. To test these models, we run experiments against the Deepfake Detection Challenge dataset and show improvements over baseline classification models. Furthermore, we find that an ensemble of these two approaches improves performance over a single approach alone.;"Deepfake detection;computer vision;deep learning;image segmentation;image classification;U-Net";IEEE
502;Detection of DeepFake Videos Using Computer Vision and Deep Learning;"A. Rahman; F. Rahman; T. Labib; E. I. Uschash; S. J. Chowdhury Adiba; D. Z. Karim";2023;"DeepFakes are one of the most alarming concepts in this era of Metaverse and technological advancement. DeepFakes are artificially-generated manipulated photos or videos using Deep learning, Generated Adversarial Network (GAN), autoencoder-decoder pairing structure etc. There are several other Deepfaking tools such as; FaceSwap, DeepFace-Lab, DFaker, DeepFake-tensorflow etc. DeepFakes can become concerning if it is used for political purpose, committing fraud, spreading misinformation, pornography, defamation on social media etc. As a result, it is obvious that DeepFakes can be very distressing on the wrong hand if not detected properly. To address this issue, our research aims to develop effective methods for DeepFake video detection, focusing on deep learning approaches, and computer vision techniques. We deployed a dataset consisting of both real and fake videos, obtained from DeepFake Detection Challenge (DFDC) and FaceForensics++. To detect the fake videos, we followed the method of employing temporal feature and exploring visual artifacts within frames. Employing temporal feature uses LSTM and CNN whereas visual artifacts within frames mostly employs deep learning method to detect DeepFakes. We ensembled LSTM and CNN to detect DeepFakes successfully. ResNeXt101_32x8d have been used to extract features and a custom CNN model is added with LSTM for better accuracy for detecting DeepFake. Our ensemble model, which combines LSTM and CNN, successfully detects Deepfakes with an accuracy of 94.05%. Through further improvements and the implementation of learning rate schedulers, such as CosineAnnealingLR, CyclicLR, MultiStepLR, and ReduceLRonPlateau, we achieved even higher accuracy. Among these schedulers, MultiStepLR demonstrated the highest accuracy of 95.33%.";"DeepFake;CNN;LSTM;LR Scheduler";IEEE
503;Deepfake Detection From Face-swapped Videos Using Transfer Learning Approach;"M. T. Hasan Fuad; F. Bin Amin; S. M. Masudul Ahsan";2023;Deepfakes are synthetic media created using artificial intelligence and machine learning techniques. Deepfakes are produced by employing a generative model to alter photos, videos, or sounds and then producing a new piece of media that mimics the original. With improvements in AI technology and the availability of significant computer resources, deepfake production has become increasingly feasible. Although there are many potential uses for deepfakes in the domains of entertainment, art, and research, they also present significant ethical and security issues. Deepfakes have the potential to influence people and spread false information, which could have detrimental effects on both the individual and the larger society. To stop malicious exploitation, it's crucial to create methods for spotting deepfakes and to control their use. This paper focuses on proposing a model for detecting deepfake videos with higher accuracy on a created dataset and the existing state-of-the-art dataset. A transfer learning based model has been proposed for deepfake detection. Wide ResNet and CNN have been implemented in the proposed model. The proposed model has been tested on both the created dataset of 121 videos and 3762 videos from Deepfake Detection Challenge dataset and achieved 83.47% and 82.4% accuracy respectively which is better than other pretrained models. High computational requirement has been one of the major challenges of this work.;"Deepfake;synthetic facial image;transfer learning;deep learning;detection";IEEE
504;Quality-based Artifact Modeling for Facial Deepfake Detection in Videos;"S. Concas; S. M. La Cava; R. Casula; G. Orr�; G. Puglisi; G. L. Marcialis";2024;"Facial deepfakes are becoming more and more realistic, to the point that it is often difficult for humans to distinguish between a fake and a real video. However, it is acknowledged that deepfakes contain artifacts at different levels; we hypothesize a connection between manipulations and visible or non-visible artifacts, especially where the subject�s movements are difficult to reproduce in detail. Accordingly, our approach relies on different quality measures, No-Reference (NR) and Full-Reference (FR), over the detected faces in the video. The measurements allow us to adopt a frame-by-frame approach to build an effective matrix-based representation of a video sequence. We show that the results obtained by this basic feature set for a neural network architecture constitute the first step that encourages the empowerment of this representation, aimed to extend our investigation to further deepfake classes. The FaceForensics++ dataset is chosen for experiments, which allows the evaluation of the proposed approach over different deepfake generation algorithms.";"Deepfakes;deepfake detection;quality;quality measures;face patches";IEEE
508;How Close Are Other Computer Vision Tasks to Deepfake Detection?;"H. H. Nguyen; J. Yamagishi; I. Echizen";2023;In this paper, we challenge the conventional belief that supervised ImageNet-trained backbones have strong generalizability and are suitable for use as feature extractors in deepfake detection models. We present a new measurement, �backbone separability,� for visually and quantitatively assessing a backbone�s raw capacity to separate data in an unsupervised manner. We also present a systematic benchmark for determining the correlation between deepfake detection and other computer vision tasks using backbones from pre-trained models. Our analysis shows that before fine-tuning, face recognition backbones are more closely related to deepfake detection than other backbones. Additionally, backbones trained using self-supervised methods are more effective in separating deepfakes than those trained using supervised methods. After fine-tuning all backbones on a small deepfake dataset, we found that self-supervised backbones deliver the best results, but there is a risk of overfitting. Our results provide valuable insights that should help researchers and practitioners develop more effective deepfake detection models.;;IEEE
509;Deep Fake Image Classification Engine Using Inception-ResNet-V1 Network;"K. D; S. S. Narayanan; M. I. M; A. Yekopalli; S. K. S";2024;The goal of this project is to develop a real or fake facial image classification system using deep learning techniques. The main focus is on the InceptionResnetVl model pretrained on the VGGFace2 dataset and Kaggle DeepFake Classification Dataset for face classification. The application uses the facenet_pytorch library to perform face detection and preprocessing. Main features of the project include predicting the authenticity of a given facial image as either �real� or �fake�. This is achieved by implementing the InceptionResnetVl model, which is fine-tuned for binary classification with a single output representing the probability of authenticity. The system is designed to run on the GPU when available, enabling faster computing. Grad-CAM (gradient-weighted class activation mapping) technique is used to ensure the explainability of classification decisions. This method creates class activation maps that visually highlight the regions of the input image that influenced the classification decision. The Grad-CAM printout is then superimposed on the original facial image, creating an interpretable visualization of the model's decision-making process. The Gradio user interface is used for the interactive presentation of the project. Users can upload their face and get real vs. false predictions and visual explanations generated by the Grad-CAM algorithm. The user interface also displays a confidence score for each forecast, giving users an idea of how reliable the model is. In general, this project provides a comprehensive system to classify real and fake faces, and the proposed method reaches the accuracy of 97% both in training and testing.;"Deep Learning;InceptionResnetVl;VGGFace2;Kaggle;Binary Classification;Face Detection;Grad-CAM;Gradio Interface";IEEE
511;Deepfake Face Detection Using Deep InceptionNet Learning Algorithm;"P. Theerthagiri; G. b. Nagaladinne";2023;Deepfakes is digital manipulation techniques that use deep learning to produce deepfake (misleading) images and videos. Identifying deepfake images is the most difficult part of finding the original. Due to the increasing reputation of deep fakes, identifying original images and videos is more crucial to detect manipulated videos. This paper studies and experiments with different methods that can be used to detect fake and real images and videos. The Convolutional Neural Network (CNN) algorithm named InceptionNet has been used to identify deep fakes. A comparative analysis was performed in this work based on various convolutional Networks. This work uses the dataset from Kaggle with 401 videos of train sample and 3745 images were generated by augmentation process. The results were evaluated with the metrics like accuracy and confusion matrix. The results of the proposed model produces better results in terms of accuracy with 93 % on identifying deep fake images and videos;"Deepfake;Inception net;CNN(Convolutional Neural Network);Vision Transformers";IEEE
513;Swapping Face Images Based on Augmented Facial Landmarks and Its Detection;"C. Sadu; P. K. Das";2020;Facial landmark points that are precisely extracted from the face images improve the performance of many applications in the domains of computer vision and graphics. Face swapping is one of such applications. With the availability of sophisticated image editing tools and the use of deep learning models, it is easy to create swapped face images or face swap attacks in images or videos even for non-professionals. Face swapping transfers a face from a source to a destination image, while preserving photo realism. It has potential applications in computer games, privacy protection, etc. However, it could also be used for fraudulent purposes. In this paper, we propose an approach to create face swap attacks and detect them from the original images. The augmented 81-facial landmark points are extracted for creating the face swap attacks. The feature descriptors Weighted Local Magnitude Patterns (WLMP) and Support Vector Machines (SVM) are utilized for the swapped face images detection. The performance of the proposed approach is demonstrated by different types of SVM classifiers on a real-world dataset. Experimental results show that the proposed system effectively does face swapping and detection with an accuracy of 95%.;"Face Landmark Points;Face Swap;Face Swap Attack Detection";IEEE
514;Identification of Deepfakes using Strategic Models and Architectures;"S. R. Nallapati; D. Dommeti; S. Medhalavalasa; K. K. Bonku; P. V. V. S. Srinivas; D. Bhattacharyya";2023;Deepfake technology has been rapidly evolving and expanding in recent years. It has become increasingly easy to manipulate multimedia content, making it harder to detect what is real and what is manipulated. The research aims to explore how neural networks can be used to detect deepfake in multimedia, helping to protect users from potentially malicious and deceptive content. The aim is to explore what neural networks are, how they can be used to detect deepfakes and the potential implications of this technology. The research also aims to evaluate the advantages and disadvantages of using neural networks for deepfake detection. As the world of deepfake technology continues to evolve, this research will provide an overview of the latest developments in deepfake detection and their potential impact. The goal of this research is to use neural networks to detect deepfakes and to identify suspicious content to alert users. This could help protect users from being exposed to malicious content and help content producers ensure the integrity of their work. As deepfake technology continues to evolve, neural networks may become an essential tool for quickly and accurately detecting deepfakes in multimedia. The research explores topics like, CNN, 3D CNN, GATED RECURRENT UNIT and Architectures like Xception, VGG16, InceptionV3 and ResNet50V2. The outcomes are graphically represented and analyzed. the comparative stratification of the approach is done to analyze and detect deepfakes.;"Deepfake Detection;Deep Learning;Convolutional Neural Network;Gated Recurrent Unit;Image Noise Patterns";IEEE
515;Transfer Learning Strategies for Detecting Passive and GAN-Generated Image Forgeries with Pretrained Neural Networks;"S. Kaman; A. Makandar";2024;Image forgeries poses significant challenge in the area of digital forensics and security. Detecting forgeries created with more advanced image manipulation techniques especially those generated by Generative Adversarial Networks (GANs) has become critical task. Deep learning powered techniques appears to be most relevant in detecting digital forgeries. Hence, this study is an attempt to investigate the effectiveness of transfer learning using pretrained neural networks such as Alexnet, VGG16, Resnet50, InceptionV3, MobilenetV2 and EfficientNetB4 for detection of both passive and GAN-generated image forgeries. Experiments have been conducted on standard datasets like CASIA2.0 for passive forgeries and 140k real and fake faces for GAN-generated forgeries. Evaluated the efficacy of each pretrained model by considering the impact of fine-tuning and early stopping on overall detection performance. Performance analysis is done with the help of accuracy and loss curves as well as by considering precision, recall, f1 score and accuracy score values. Compared the model�s ability in detecting both passive and GAN-generated image forgeries.;"Transfer learning;Image forgery Detection;Deep Learning;Passive forgery;Pretrained neural networks;GANs;Fine-tuning;Early stopping;Deepfake";IEEE
516;On the Exploitation of DCT-Traces in the Generative-AI Domain;"O. Pontorno; L. Guarnera; S. Battiato";2024;Deepfakes represent one of the toughest challenges in the world of Cybersecurity and Digital Forensics, especially considering the high-quality results obtained with recent generative AI-based solutions. Almost all generative models leave unique traces in synthetic data that, if analyzed and identified in detail, can be exploited to improve the generalization limitations of existing deepfake detectors. In this paper we analyzed deepfake images in the frequency domain generated by both GAN and Diffusion Model engines, examining in detail the underlying statistical distribution of Discrete Cosine Transform (DCT) coefficients. Recognizing that not all coefficients contribute equally to image detection, we hypothesize the existence of a unique �discriminative fingerprint�, embedded in specific combinations of coefficients. To identify them, Machine Learning classifiers were trained on various combinations of coefficients. In addition, the Explainable AI (XAI) LIME algorithm was used to search for intrinsic discriminative combinations of coefficients. Finally, we performed a robustness test to analyze the persistence of traces by applying JPEG compression. The experimental results reveal the existence of traces left by the generative models that are more discriminative and persistent at JPEG attacks. Code and dataset are available at github/opontorno/dcts_analysis_deepfakes.;"Synthetic Traces;Deepfakes;Multimedia Forensics";IEEE
517;Coexistence of Deepfake Defenses: Addressing the Poisoning Challenge;"J. Park; L. H. Park; H. E. Ahn; T. Kwon";2024;As Generative Adversarial Networks advance, deepfakes have become increasingly realistic, thereby escalating societal, economic, and political threats. In confronting these heightened risks, the research community has identified two promising defensive strategies: proactive deepfake disruption and reactive deepfake detection. Typically, proactive and reactive defenses coexist, each addressing the shortcomings of the other. However, this paper brings to the fore a critical yet overlooked issue associated with the simultaneous deployment of these deepfake countermeasures. Genuine images gathered from the Internet, already imbued with disrupting perturbations, can lead to data poisoning in the training datasets of deepfake detection models, thereby severely affecting detection accuracy. We propose an improved training framework to address this problem in deepfake detection models. Our approach involves purifying the disrupting perturbations in disruptive images using a backward process of the denoising diffusion probabilistic model (DDPM). Images purified using our DDPM-based technique closely mimic the original, unperturbed images, thereby enabling the successful generation of deepfake images for training purposes. Moreover, our purification process outperforms DiffPure, a prominent adversarial purification method, in terms of speed. While conventional defensive techniques struggle to preserve detection accuracy in the face of a poisoned training dataset, our framework markedly reduces this accuracy drop, thus achieving superior performance across a range of detection models. Our experiments demonstrate that deepfake detection models trained using our framework exhibit an increase in detection accuracy ranging from 11.24%p to 45.72%p when compared to models trained with the DiffPure method. Our implementation is available at https://github.com/seclab-yonsei/Anti-disrupt.;"Deepfake;deepfake detection;deepfake disruption;data poisoning;adversarial purification";IEEE
519;Deepfake detection for preventing Audio and Video frauds using Advanced Deep Learning Techniques;"R. Bharadwaj; S. Ratnaparkhi; R. Rajpurohit; K. Rahate; R. Pandita; S. Thosar";2023;Deepfakes, powered by generative adversarial networks (GANs), automate the creation of deceptive videos. To combat this menace, the study assembles an advanced model that fuses ResNeXt, Long Short-Term Memory (LSTM), and ResNet architectures, renowned for their efficacy in handling visual and temporal aspects, for the detection of deepfakes in audio and video content. Pre-processing, facilitated by a Multi-Task Cascaded-Convolutional Neural Network (MTCNN), accurately extracts facial regions. The model undergoes rigorous evaluation across three key datasets which are, FaceForensics++(FF-DF), Celeb-DF, and Facebook Deepfake Detection Challenge (DFDC), affirming its real-world readiness and exceptional accuracy. The combined models consistently deliver highly precise results, maintaining their robustness against evolving deepfake technologies.;"Deepfakes;GANs;MTCNN;Facial region extraction;ResNeXt;LSTM;ResNet;FaceForensics++;Celeb-DF;DFDC";IEEE
520;DeepfakeUCL: Deepfake Detection via Unsupervised Contrastive Learning;"S. Fung; X. Lu; C. Zhang; C. -T. Li";2021;Face deepfake detection has seen impressive results recently. Nearly all existing deep learning techniques for face deepfake detection are fully supervised and require labels during training. In this paper, we design a novel deepfake detection method via unsupervised contrastive learning. We first generate two different transformed versions of an image and feed them into two sequential sub-networks, i.e., an encoder and a projection head. The unsupervised training is achieved by maximizing the correspondence degree of the outputs of the projection head. To evaluate the detection performance of our unsupervised method, we further use the unsupervised features to train an efficient linear classification network. Extensive experiments show that our unsupervised learning method enables comparable detection performance to state-of-the-art supervised techniques, in both the intra- and inter-dataset settings. We also conduct ablation studies for our method.;;IEEE
521;ConTrans-Detect: A Multi-Scale Convolution-Transformer Network for DeepFake Video Detection;"W. Sun; Y. Ma; H. Zhang; R. Wang";2023;With the recent advancement of generative deep learning technologies, DeepFakes are the outcome of the manipulation to generate synthetic images, such as swapping a person's face in a video with another face in another video. Nowadays, deep generative models make it easy to generate fake videos, which is hard to detect. Existing methods have utilized Convolutional Neural Networks (CNNs) to identify manipulated regions for DeepFake video detection. However, these methods might not entirely tackle the difficulties of learning low-level spatial features and capturing temporal variations in temporal information, which are crucial for face forgery detection. Therefore, we propose a Convolution-Transformer Deepfake Detection (ConTrans-Detect) model, comprising a multi-scale CNN module for spatial feature representation and a multi-branch Transformer for temporal feature modeling. The multi-scale CNN module uses 3D Inception block to extract multi-scale low-level features (e.g., edges, corners, and angles) from videos. The multi-branch Transformer module consists of multi-stream Transformer layers, each taking different temporal resolutions and spatial feature dimensions as input to perceive various motion variations. Our model achieves an AUC of 0.929 and 0.920 f1 score, surpassing several state-of-the-art performances on the DeepFake Detection Challenge Datasets (DFDC).;"Convolutional neural network;Vision transformer;DeepFake video detection;Security;Privacy";IEEE
523;Improving Deepfake Detection Generalization by Invariant Risk Minimization;"Z. Yin; J. Wang; Y. Xiao; H. Zhao; T. Li; W. Zhou; A. Liu; X. Liu";2024;The abuse of deepfake techniques has raised serious concerns about social security and ethical problems, which motivates the development of deepfake detection. However, without fully addressing the domain gap issue, existing deepfake detection methods still show weak generalization ability among datasets belonging to different domains with domain-specific characteristics like identities and generation methods, limiting their practical applications. In this article, we propose the Invariant Domain-oriented Deepfake Detection method (ID$_{3}$), which improves the generalization of deepfake detection on multiple domains through invariant risk minimization, a novel learning paradigm that addresses the domain gap problem by jointly training a purified invariant predictor and learning an aligned invariant representation. To train a purified invariant predictor, we design the Domain Refinement Data Augmentation strategy with self-face-swapping and region-erasing approaches, which suppresses domain-specific features and encourages the models to focus on critical domain-invariant characteristics. To learn an aligned invariant representation, we propose the Domain Calibration Batch Normalization approach with multiple BN branches, which normalizes input features from different domains into aligned representations during both training and testing. Extensive experiments on multiple datasets demonstrate that our framework can boost the deepfake detection generalization ability and outperform other baselines by large margins. Our codes can be found here.;"Deepfake detection;invariant risk minimization;model generalization";IEEE
525;Shallow- and Deep- fake Image Manipulation Localization Using Deep Learning;"J. Zhang; H. Tohidypour; Y. Wang; P. Nasiopoulos";2023;Forged image localization is an important research task, as such images may have a tremendous impact of various aspects of society. Images can be manipulated using image editing tools (known as �shallowfakes�) or, recently, artificial intelligence techniques (�deepfakes�). While there are many existing works that are designed for manipulated areas localization on either shallow- or deep-fake images, there is no single solution that works for both cases. In this paper, we propose the first solution that can perform the localization task on both shallow- and deep-fake images, with high inference accuracy. The dataset and code are available at: https://github.com/zjbthomas/ShallowDeepFakesLocalization.;"Image manipulation;Manipulation localization;shallowfakes;deepfakes";IEEE
527;Impact of Video Processing Operations in Deepfake Detection;"Y. Lu; T. Ebrahimi";2023;The detection of digital face manipulation in video has attracted extensive attention due to the increased risk to public trust. To counteract the malicious usage of such techniques, deep learning-based deepfake detection methods have been developed and have shown impressive results. However, the performance of these detectors is often evaluated using benchmarks that hardly reflect real-world situations. For example, the impact of various video processing operations on detection accuracy has not been systematically assessed. To address this gap, this paper first analyzes numerous real-world influencing factors and typical video processing operations. Then, a more systematic assessment methodology is proposed, which allows for a quantitative evaluation of a detector�s robustness under the influence of different processing operations. Moreover, substantial experiments have been carried out on three popular deepfake detectors, which give detailed analyses on the impact of each operation and bring insights to foster future research.;;IEEE
529;Contrastive Knowledge Transfer for Deepfake Detection with Limited Data;"D. Li; W. Zhuo; W. Wang; J. Dong";2022;Nowadays forensics methods have shown remarkable progress in detecting maliciously crafted fake images. However, without exception, the training process of deepfake detection models requires a large number of facial images. These models are usually unsuitable for real world applications because of their overlarge size and inferiority in speed. Thus, performing data-efficient deepfake detection is of great importance. In this paper, we propose a contrastive distillation method that maximizes the lower bound of mutual information between the teacher and the student to further improve student�s accuracy in a data-limited setting. We observe that models performing deepfake detection, different from other image classification tasks, have shown high robustness when there is a drop in data amount. The proposed knowledge transfer approach is of superior performance compared with vanilla few samples training baseline and other SOTA knowledge transfer methods. We believe we are the first to perform few-sample knowledge distillation on deepfake detection.;;IEEE
531;Multi-Label Deepfake Classification;"I. P. Singh; N. Mejri; V. D. Nguyen; E. Ghorbel; D. Aouada";2023;In this paper, we investigate the suitability of current multi-label classification approaches for deepfake detection. With the recent advances in generative modeling, new deepfake detection methods have been proposed. Nevertheless, they mostly formulate this topic as a binary classification problem, resulting in poor explainability capabilities. Indeed, a forged image might be induced by multi-step manipulations with different properties. For a better interpretability of the results, recognizing the nature of these stacked manipulations is highly relevant. For that reason, we propose to model deepfake detection as a multi-label classification task, where each label corresponds to a specific kind of manipulation. In this context, state-of-the-art multi-label image classification methods are considered. Extensive experiments are performed to assess the practical use case of deepfake detection.;"Deepfake detection;Multi-Label Classification;Stacked Manipulations";IEEE
533;Facial Forgery-Based Deepfake Detection Using Fine-Grained Features;"A. V. Nadimpalli; A. Rattani";2023;Facial forgery by deepfakes has caused major se-curity risks and raised severe societal concerns. As a counter-measure, a number of deepfake detection methods have been proposed. Most of them model deepfake detection as a binary classification problem using a backbone convolutional neural network (CNN) architecture pretrained for the task. These CNN-based methods have demonstrated very high efficacy in deepfake detection with the Area under the Curve (AUC) as high as 0.99. However, the performance of these methods degrades signifi-cantly when evaluated across datasets and deepfake manipulation techniques. This draws our attention towards learning more subtle, local, and discriminative features for deepfake detection. In this paper, we formulate deepfake detection as a fine-grained classification problem and propose a new fine-grained solution to it. Specifically, our method is based on learning subtle and generalizable features by effectively suppressing background noise and learning discriminative features at various scales for deepfake detection. Through extensive experimental validation, we demonstrate the superiority of our method over the published research in cross-dataset and cross-manipulation generalization of deepfake detectors for the majority of the experimental scenarios.;"Cross-Manipulation Generalization;Deepfakes;Fine-Grained Classification;Facial Manipulations";IEEE
534;A Novel Approach to Detect Face Fraud Detection Using Artificial Intelligence;"S. Senthil Pandi; M. S. Monesh; B. Lingesh";2024;The main aim of this research is to identify and prevent fraudulent activities which can be achieved through AI related to facial recognition systems. Nowadays the usage of facial recognition systems is very high, and in the same way the scams by fraudsters are also increased in this research by using AI bots instead of humans. The main motive of this research is to identify the misuse of facial recognition technology. The proposed method using CNN (Convolutional Neural Network) protects the individual privacy of people and their data. It detects whether the character in the image is an AI made or real human. This helps to ensure that only authorized people can use their information. Some of the sectors which use facial recognition systems are security, law enforcement, financial services, education, government services, retail. if unauthorized people access the above-mentioned sectors, the result will be imperiling. This method takes an image as an input and then python is used to process the image, importing a CV library to do this job. Next, we use deep learning models in python to identify whether the character in the image is AI generated or real human. The Computational Intelligence and Photography Lab at Yonsei University assembled a publicly available dataset for this work. Images of both real and fake human faces can be found in the Yonsei University Computational Intelligence and Photography Lab's database. The performance of the proposed system is measured using accuracy, precision and sensitivity. Experimental results shows that CNN based face recognition system outperforms.;"Authorization;CNN;Data Protection;Facial recognition";IEEE
535;Application of Ensembles of Neural Networks for Deepfake Recognition;"M. Yadryshnikova; A. Latipova";2023;At the moment, the creation of deepfakes for various activities is widespread: sometimes for the sake of humor, and sometimes for malicious purposes. In the second case, such deepfakes can potentially harm a person. Neural networks trained to recognize deepfakes can become an actual tool for combating malicious fakes. This article proposes neural network architectures which can be used in the task of recognizing photo and video deepfakes, describes the datasets that can help in training neural networks for the task, and determines what pre-processing is needed for different datasets. Particular attention is paid to possible options for combining the results of several trained models. The architectures of neural networks Inception-Resnet and Xception were chosen as the basis, the conceptual features of these architectures were described, and their practical testing was carried out in the problem of classifying deepfakes. A method of ensembling models is chosen for better results.;"deep learning;artificial intelligence;deepfake;ensemble of neural networks";IEEE
536;MINTIME: Multi-Identity Size-Invariant Video Deepfake Detection;"D. A. Coccomini; G. K. Zilos; G. Amato; R. Caldelli; F. Falchi; S. Papadopoulos; C. Gennaro";2024;In this paper, we present MINTIME, a video deepfake detection method that effectively captures spatial and temporal inconsistencies in videos that depict multiple individuals and varying face sizes. Unlike previous approaches that either employ simplistic a-posteriori aggregation schemes, i.e., averaging or max operations, or only focus on the largest face in the video, our proposed method learns to accurately detect spatio-temporal inconsistencies across multiple identities in a video through a Spatio-Temporal Transformer combined with a Convolutional Neural Network backbone. This is achieved through an Identity-aware Attention mechanism that applies a masking operation on the face sequence to process each identity independently, which enables effective video-level aggregation. Furthermore, our system incorporates two novel embedding schemes: (i) the Temporal Coherent Positional Embedding, which encodes the temporal information of the face sequences of each identity, and (ii) the Size Embedding, which captures the relative sizes of the faces to the video frames. MINTIME achieves state-of-the-art performance on the ForgeryNet dataset, with a remarkable improvement of up to 14% AUC in videos containing multiple people. Moreover, it demonstrates very robust generalization capabilities in cross-forgery and cross-dataset settings. The code is publicly available at: https://github.com/davide-coccomini/MINTIME-Multi-Identity-size-iNvariant-TIMEsformer-for-Video-Deepfake-Detection.;"Deepfake detection;computer vision;deep learning;vision transformers;convolutional neural networks";IEEE
537;ISTVT: Interpretable Spatial-Temporal Video Transformer for Deepfake Detection;"C. Zhao; C. Wang; G. Hu; H. Chen; C. Liu; J. Tang";2023;With the rapid development of Deepfake synthesis technology, our information security and personal privacy have been severely threatened in recent years. To achieve a robust Deepfake detection, researchers attempt to exploit the joint spatial-temporal information in the videos, like using recurrent networks and 3D convolutional networks. However, these spatial-temporal models remain room to improve. Another general challenge for spatial-temporal models is that people do not clearly understand what these spatial-temporal models really learn. To address these two challenges, in this paper, we propose an Interpretable Spatial-Temporal Video Transformer (ISTVT), which consists of a novel decomposed spatial-temporal self-attention and a self-subtract mechanism to capture spatial artifacts and temporal inconsistency for robust Deepfake detection. Thanks to this decomposition, we propose to interpret ISTVT by visualizing the discriminative regions for both spatial and temporal dimensions via the relevance (the pixel-wise importance on the input) propagation algorithm. We conduct extensive experiments on large-scale datasets, including FaceForensics++, FaceShifter, DeeperForensics, Celeb-DF, and DFDC datasets. Our strong performance of intra-dataset and cross-dataset Deepfake detection demonstrates the effectiveness and robustness of our method, and our visualization-based interpretability offers people insights into our model.;"Deepfake detection;video transformer;deep learning interpretability";IEEE
541;Ensemble Learning Model for Face Swap Detection;"K. Samrouth; N. Beuve; O. Deforges; N. Bakir; W. Hamidouche";2024;Deepfake videos become now one of the top research topics because of their high spreading rate on social media. Faceswap, a particular type of Deepfake, consists in swapping faces of two persons in a video. Hence, face swapping can have malicious uses, such as falsifying privacy, interfering with political campaigns, terrorism, and threatening the social stability of the countries. Thus, early detection of this fake content is a primary task to limit their spread. Multiple approaches for DeepFake detection exist in the literature. The most recent and best ones are Identity-Aware and Mesoscopic features-based approaches. However, each of these approaches presents particular limitations. Therefore, in this paper, we propose to take the best out of these two recent approaches and to optimize the performance and robustness of Deepfake content detection. In particular, we propose an Ensemble Learning model based on combining the best two methods from the two aforementioned most recent approaches of detection. Our experiments show that our proposed ensemble model improved the performance and robustness of Deepfake detection to reach an accuracy of 95%.;"Deepfake;Face Swap detection;Deep Learning;Ensemble Learning";IEEE
542;A Hybrid approach for Deepfake Detection using CNN-RNN;"S. Antad; V. V. Arthamwar; R. K. Deshmukh; A. U. Chame; H. P. Chhangani";2024;"Reliable deepfake detection of falsified videos generated by deep learning is still a pressing challenge with its growing popularity. Deep adversarial neural networks, which educate on film and target faces to ahead facial resources and facial expressions to targets, underneath DF can without difficulty idiot facial recognition structures the usage of revealed, 3-D photos mask, or video recordings from the valid consumer�s face to sensors. We make significant contributions, including building adaptive datasets, comparing primitive and deep models for training, and tunable CNN-RNN tools. The overall evaluation model shows that the results are better than the findings of the most advanced methods. It was acknowledged that Deep faking today greatly impacts our environment; It is done by placing faces on original images/videos using deep neural networks. Together with the sharing of other misinformation via digital social networks, deepfake has formed digital fakery, which has become a real problem of negative social impact and as such there is a great need for successful measures to be taken to examine Deep Fakes [1]. The approach in this research generalizes by capturing physical cues in body shape and size. Our method combines CNN for spatial analysis, capturing facial features and skin texture, and LSTM and RNN for temporal analysis, monitoring expression progress. This method provides stable performance on complex deepfake videos. The modular design allows for future expansion, such as the integration of audio analysis.";"CNN-Convolutional Neural Network;LSTMShort Term Neural Network;Recurrent Neural Network (RNN);Hybrid deep learning";IEEE
545;Self-supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection;"L. Chen; Y. Zhang; Y. Song; L. Liu; J. Wang";2022;Recent studies in deepfake detection have yielded promising results when the training and testing face forgeries are from the same dataset. However, the problem remains challenging when one tries to generalize the detector to forgeries created by unseen methods in the training dataset. This work addresses the generalizable deepfake detection from a simple principle: a generalizable representation should be sensitive to diverse types of forgeries. Following this principle, we propose to enrich the �diversity� of forgeries by synthesizing augmented forgeries with a pool of forgery configurations and strengthen the �sensitivity� to the forgeries by enforcing the model to predict the forgery configurations. To effectively explore the large forgery augmentation space, we further propose to use the adversarial training strategy to dynamically synthesize the most challenging forgeries to the current model. Through extensive experiments, we show that the proposed strategies are surprisingly effective (see Figure 1), and they could achieve superior performance than the current state-of-the-art methods. Code is available at https://github.com/liangchen527/SLADD.;"Computer vision for social good; Face and gestures";IEEE
546;A Comparative Analysis of Fake Image Detection in Generative Adversarial Networks and Variational Autoencoders;"M. Berrahal; M. Boukabous; I. Idrissi";2023;The rise of deep fake technology has led to growing concerns about its potential misuse for propaganda, disinformation, and even cybercrimes. Deep fake detection has thus become a crucial research area to prevent the spread of fake content and protect digital authenticity. This research investigates the detection of fake human face images using deep learning models. The study utilizes a combination of the CelebA-HQ and FFHQ datasets to create real image labels. Two generative models, a Style-based generator and a Variational Autoencoder, are trained to generate GAN-fake and VAE-fake images, respectively. The deep learning models are then trained and evaluated using both real and fake images. The research focuses on two scenarios: binary net and multi-class net. In the binary net scenario, ResNet50 achieves the highest accuracy of 99.34%, along with excellent precision, recall, and F1-score. VGG16 and VGG19 also perform well in distinguishing between fake and real images. In the multi-class net scenario, ResNet50 again achieves the highest accuracy of 95.25% and balanced F1-score. VGG16 and VGG19 maintain competitive performance, while other models show slightly lower accuracy. These results provide insights into the effectiveness of different deep learning models for detecting fake human face images. ResNet50 consistently performs well in both scenarios, while VGG16 and VGG19 offer reliable alternatives.;"Deepfake;Deep Learning;Convolutional Neural Network;Generative Adversarial Net;Variational Autoencoders";IEEE
549;Implicit Identity Driven Deepfake Face Swapping Detection;"B. Huang; Z. Wang; J. Yang; J. Ai; Q. Zou; Q. Wang; D. Ye";2023;In this paper, we consider the face swapping detection from the perspective of face identity. Face swapping aims to replace the target face with the source face and generate the fake face that the human cannot distinguish between real and fake. We argue that the fake face contains the explicit identity and implicit identity, which respectively corresponds to the identity of the source face and target face during face swapping. Note that the explicit identities of faces can be extracted by regular face recognizers. Particularly, the implicit identity of real face is consistent with the its explicit identity. Thus the difference between explicit and implicit identity of face facilitates face swapping detection. Following this idea, we propose a novel implicit identity driven framework for face swapping detection. Specifically, we design an explicit identity contrast (EIC) loss and an implicit identity exploration (IIE) loss, which supervises a CNN backbone to embed face images into the implicit identity space. Under the guidance of EIC, real samples are pulled closer to their explicit identities, while fake samples are pushed away from their explicit identities. More-over, IIE is derived from the margin-based classification loss function, which encourages the fake faces with known target identities to enjoy intra-class compactness and inter-class diversity. Extensive experiments and visualizations on several datasets demonstrate the generalization of our method against the state-of-the-art counterparts.;"Humans: Face;body;pose;gesture;movement";IEEE
550;Enhancing General Face Forgery Detection via Vision Transformer with Low-Rank Adaptation;"C. Kong; H. Li; S. Wang";2023;Nowadays, forgery faces pose pressing security concerns over fake news, fraud, impersonation, etc. Despite the demonstrated success in intra-domain face forgery detection, existing detection methods lack generalization capability and tend to suffer from dramatic performance drops when deployed to unforeseen domains. To mitigate this issue, this paper designs a more general fake face detection model based on the vision transformer(ViT) architecture. In the training phase, the pretrained ViT weights are freezed, and only the Low-Rank Adaptation(LoRA) modules are updated. Additionally, the Single Center Loss(SCL) is applied to supervise the training process, further improving the generalization capability of the model. The proposed method achieves state-of-the-arts detection performances in both cross-manipulation and cross-dataset evaluations.;"Forgery face detection;generalization";IEEE
553;Fake Face2Face Video Detection Using a Novel Scene and Texture Based Feature Set;"A. N. Ramkissoon; V. Rajamanickam; W. Goodridge";2023;The existence of fake videos is a problem that is challenging today's social media-enabled world. There are many classifications for fake videos with one of the most popular being Face2Face. Detecting such fake videos is a challenging issue. This research attempts to comprehend the characteristics that belong to Face2Face videos. In attempting to understand Face2Face videos this work investigates the characteristics of the video that make them unique. As such this research uses scene and texture detection to develop a unique feature set containing 19 data features which is capable of detecting whether a video is a Face2Face or not. This study validates the feature set using a standard dataset of the features relating to the characteristics of the video. These features are analysed using a classification machine learning model. The results of these experiments are examined using four evaluation methodologies. The analysis reveals positive performance with the use of the ML method and the feature set. From these results, it can be ascertained that using the proposed feature set, a video can be predicted as a Face2Face or not and as such prove the hypothesis that there exists a correlation between the characteristics of a video and its genuineness, i.e., whether or not a video is a Face2Face.;"Classification;Face2Face;Features;Scene Detection;Texture Detection";IEEE
554;A Continual Deepfake Detection Benchmark: Dataset, Methods, and Essentials;"C. Li; Z. Huang; D. P. Paudel; Y. Wang; M. Shahbazi; X. Hong; L. Van Gool";2023;There have been emerging a number of benchmarks and techniques for the detection of deepfakes. However, very few works study the detection of incrementally appearing deepfakes in the real-world scenarios. To simulate the wild scenes, this paper suggests a continual deepfake detection benchmark (CDDB) over a new collection of deepfakes from both known and unknown generative models. The suggested CDDB designs multiple evaluations on the detection over easy, hard, and long sequence of deepfake tasks, with a set of appropriate measures. In addition, we exploit multiple approaches to adapt multiclass incremental learning methods, commonly used in the continual visual recognition, to the continual deepfake detection problem. We evaluate existing methods, including their adapted ones, on the proposed CDDB. Within the proposed benchmark, we explore some commonly known essentials of standard continual learning. Our study provides new insights on these essentials in the context of continual deepfake detection. The suggested CDDB is clearly more challenging than the existing benchmarks, which thus offers a suitable evaluation avenue to the future research. Both data and code are available at https://github.com/Coral79/CDDB.;"Algorithms: Image recognition and understanding (object detection;categorization;segmentation);Computational photography;image and video synthesis;Machine learning architectures;formulations;and algorithms (including transfer;low-shot;semi-;self-;and un-supervised learning)";IEEE
556;Adversarially Robust Deepfake Video Detection;"A. Devasthale; S. Sural";2022;Fake videos have been in circulation on mainstream media since long. However, with increased popularity of online social networks, it is becoming many times easier to spread such videos and achieve virality. Recent advancements in deep learning has further fuelled this menace as the so called deepfake videos are hard to differentiate from the genuine ones. While deepfake video detection techniques attempt to identify the fake videos from real videos, these are now being subjected to adversarial attacks, thus undermining their efficacy. In this paper, we show that accuracy of deepfake detectors can be considerably improved by incorporating an adversarial learning step during model building. We use a recently proposed deep network architecture, namely VGG19, as deepfake detector supplemented with adversarial training using Iterative Fast Gradient Sign Method (I-FGSM). To further improve non-adversarial accuracy ensemble of models were used. Extensive experiments on a large deepfake video corpus under different white box adversarial attacks demonstrate significant adversarial robustness of the proposed method.;"Deepfake Video;Adversarial Attack;Deep Learning;Adversarial Training;Face Manipulation";IEEE
557;Deepfake Face Extraction and Detection Using MTCNN-Vision Transformers;"R. Singh; K. Ashwini; B. Chandu Priya; K. Pavan Kumar";2024;Deepfake detection is a major problem nowadays. The deepfake detection can be done using face extraction and detection. Strong solutions for face extraction and detection are required in light of the growing prevalence of deepfake technology. This paper combines Vision Transformers with Multi-Task Cascaded Convolutional Networks (MTCNN) to propose a novel method. This approach leverages the real-time face identification skills of MTCNN and the long-range dependency capture ability of Vision Transformers to improve the accuracy of detecting manipulated faces in deepfake footage. We carry out extensive experiments on several deepfake datasets, demonstrating the efficacy of the suggested hybrid strategy. The proposed model findings show that this approach performs better than conventional face identification techniques, particularly when dealing with situations where minor facial alterations are involved. This integration strikes a good compromise between computing efficiency and precision, which makes it a viable option for practical uses. The proposed MT-VIT (Multi-Task Vision Transformer) model provides good accuracy as compared to other state-of-the-art like Residual Networks, Mobile Net, CNN, and Meso-Net.;"multitask cascaded convolutional neural network (MTCNN);vision transformer (VIT);deepfake detection";IEEE
558;Fused Swish-ReLU Efficient-Net Model for Deepfakes Detection;"H. Ilyas; A. Javed; M. M. Aljasem; M. Alhababi";2023;With the rapid development of sophisticated deepfakes generation methods, the realism of fake content has reached the level where it becomes difficult for human eyes to identify such high-quality fake images/videos, thus increasing the demand for developing deepfakes detection methods. The diversity in deepfakes images/videos in terms of ethnicity, illumination condition, skin tone, age, background setting, and generation algorithms makes the detection task quite difficult. To better address the aforementioned challenges, we present a novel Swish-ReLU Efficient-Net (SRE-Net) that is robust to the identification of deepfakes generated using different face-swap and face-reenactment techniques. More precisely, we fused two EfficienNet-b0 models, one with the ReLU and the other with the Swish activation function along with layer freezing to achieve better detection results. Our SRE-Net attained the average accuracy and precision of 96.5% and 97.07% on the FaceForensics++ dataset, and 88.41% and 91.28% on the DFDC-preview dataset. The high detection results demonstrate the effectiveness of SRE-Net while detecting the deepfakes generated using different manipulation algorithms.;"Deepfakes detection;fused Swish-ReLU Efficient-Net;FaceForensics++;DFDC-preview";IEEE
559;Fighting Deepfake by Residual Noise Using Convolutional Neural Networks;"M. C. El Rai; H. Al Ahmad; O. Gouda; D. Jamal; M. A. Talib; Q. Nasir";2020;In the last few years, the easy access to images and videos shared online have been continuously increased. The generative adversarial networks using deep learning leads to create very realistic deepfake videos by playing with the digital content of images and videos. The spread of such deepfake videos on social media networks urged the international community to consider seriously its danger and accordingly encouraged the researchers around the world to develop powerful deepfake detection methods. Many approaches are available in the recent literature. In this paper, the proposed approach is based on exploiting the residual noise which is the difference between original image and its denoised version. The study of residual noise has shown effectiveness in deep-fake detection with regards to its distinctive and discriminative features which can be effectively captured by convolutional neural networks with transfer learning. The performance of our approach is evaluated on two datasets: low-resolution video sequences of the FaceForensics++ and high-resolution videos from Kaggle Deepfake Detection challenge (DFDC). The obtained results show relevant accuracy in comparison with other competitive methods.;"Deepfake;Authentic Detection;Residual noise;Transfer Learning;Convolutional Neural Networks";IEEE
561;Comparison Multi Transfer Learning Models for Deep Fake Image Recognizer;"N. A. Rosli; S. N. H. Sheikh Abdullah; A. N. Zamani; A. Ghazvini; N. S. Md Othman; N. A. A. A. Muariff Tajuddin";2021;The advancement of technologies nowadays cause image digitally to become essential as an official document many available applications used for image editing. Those applications have become a threat to detect image authenticity when dealing with an abundance of digital image evidence in cyber court. Hence, many researchers realize the importance of image authentication fields as deep fake is a powerful weapon for spreading misinformation on the digital platform. Deep learning has known to obtain relevant attributes automatically in placing handcrafted features in a deep network against other single-layer networks. The objective of the research is to compare two models from Convolutional Neural Network (CNN), which are VGG19 dan ResNet50 in deep learning with transfer learning for image fake detector. A total of 1500 random images consisting of 450 forgery images from the IEEE Image Forensics Challenge in 2013 were tested on the splicing technique. From this research, we used two transfer learning techniques to identify tamper images from image splicing. Based on model VGG16 and ResNet50 transfer learning, the accuracy achieved about 94.65% and 95.08%, respectively.;"deep learning;neural network;deep fake a transfer learning";IEEE
564;Hearing and Seeing Abnormality: Self-Supervised Audio-Visual Mutual Learning for Deepfake Detection;"C. -S. Sung; J. -C. Chen; C. -S. Chen";2023;The recent development of deepfakes has resulted in serious threats to society, such as spreading misinformation, defamation, etc. Although recent deepfake detection methods are capable of achieving satisfactory results for seen forgeries, the performance drops significantly for unseen ones. With proper supervised pretraining on auxiliary tasks as prior, the situation can be improved, but the requirement to collect a large number of additional annotations for these tasks may restrict the further development of a generalized deep-fake detector. To address this issue, we propose an Audio-Visual Temporal Synchronization for Deepfake Detection framework for detecting deepfakes that maintains reasonable detection capabilities for unseen ones. The primary objective of our framework is to determine whether there has been a forgery by evaluating the consistency between the sound and the faces in a video clip, together with the relationship between the two features. First, the spatiotemporal feature extraction network is pretrained in a self-supervised manner by exploiting the audio-visual temporal synchronization task to build up a rich representation based on the temporal synchronization relationship between the audio and its corresponding video. For pretraining, we use only real data and carefully selected negative samples with contrastive loss to train the model. A temporal classifier network is used to determine whether or not the video has been manipulated using the representations obtained from the pretrained feature extraction networks. To prevent the model from overfitting to certain manipulation-specific artifacts, we froze the feature extraction networks and only trained the final classifier network on forged data. Extensive experiments on unseen forgery categories and unseen datasets have shown the effectiveness of our method to achieve state-of-the-art results.;"Self-supervised Learning;Audio-Visual;Deep-fake Detection";IEEE
565;Faster Than Lies: Real-time Deepfake Detection using Binary Neural Networks;"R. Lanzino; F. Fontana; A. Diko; M. R. Marini; L. Cinque";2024;Deepfake detection aims to contrast the spread of deep-generated media that undermines trust in online content. While existing methods focus on large and complex models, the need for real-time detection demands greater efficiency. With this in mind, unlike previous work, we introduce a novel deepfake detection approach on images using Binary Neural Networks (BNNs) for fast inference with minimal accuracy loss. Moreover, our method incorporates Fast Fourier Transform (FFT) and Local Binary Pattern (LBP) as additional channel features to uncover manipulation traces in frequency and texture domains. Evaluations on COCOFake, DFFD, and CIFAKE datasets demonstrate our method�s state-of-the-art performance in most scenarios with a significant efficiency gain of up to a 20� reduction in FLOPs during inference. Finally, by exploring BNNs in deepfake detection to balance accuracy and efficiency, this work paves the way for future research on efficient deepfake detection.;"deepfake;binary neural network;deep learning;efficiency;fft;lbp;real-time;flops;bnn;neural network";IEEE
568;Deepfake Video Detection through Optical Flow Based CNN;"I. Amerini; L. Galteri; R. Caldelli; A. Del Bimbo";2019;"Recent advances in visual media technology have led to new tools for processing and, above all, generating multimedia contents. In particular, modern AI-based technologies have provided easy-to-use tools to create extremely realistic manipulated videos. Such synthetic videos, named Deep Fakes, may constitute a serious threat to attack the reputation of public subjects or to address the general opinion on a certain event. According to this, being able to individuate this kind of fake information becomes fundamental. In this work, a new forensic technique able to discern between fake and original video sequences is given; unlike other state-of-the-art methods which resorts at single video frames, we propose the adoption of optical flow fields to exploit possible inter-frame dissimilarities. Such a clue is then used as feature to be learned by CNN classifiers. Preliminary results obtained on FaceForensics++ dataset highlight very promising performances.";"Deepfake;Optical flow;Video forensics;CNN";IEEE
570;Fake face detection based on deep learning and frequency domain processing;"M. Wang; P. Fan; T. Yang";2023;With the rapid development of artificial intelligence, various advanced image generation and processing methods continue to emerge. In terms of fake face images, most are generated by methods based on generative adversarial networks (GANs). The increasing spread of fake face images may cause social problems such as misleading public opinion or damage to personal reputation. In this paper,we proposes a facial synthesis detection method based on deep learning and frequency domain processing. In this method, the Facenet network is used to extract facial features from images and enhance them during the extraction process. Then, fast Fourier transform (FFT) is used to analyze the extracted facial features in the frequency domain, and ResNet50 network is used to extract frequency domain features from the obtained information. Finally, the extracted facial feature vectors and image frequency domain features are fused, and the image is classified based on the obtained fusion features. This method was experimented on a 16-class dataset and achieved good detection results, compared with the optimal facial feature detection model and frequency domain feature detection model.;"Deep learning;frequency domain processing;Fast Fourier Transform;feature fusion";IEEE
572;Realtime Deepfake Detection using Video Vision Transformer;"A. Doshi; A. Venkatadri; S. Kulkarni; V. Athavale; A. Jagarlapudi; S. Suratkar; F. Kazi";2022;Practically, Deepfake technology has given people access to generate fake videos that look like real content using neural networks, and can further create misconceptions and deceit about the innocuous elements of society. This technology can prove fatal not only to national security but on an international level. Existing methodologies that apply deep learning to automatically extract salient and discriminative features to detect Deepfakes based on typical CNN-LSTM models tend to have their shortcomings. Having said that, we propose a system that extracts Spatio-Temporal features and achieves Real-Time Deepfake detection using Transformers. For the end user, a web application was developed, which with utmost simplicity allows the uploading of a video that will be further authenticated within the application and, at the same time, features the authentication of live meetings.;"Image Processing;Deep Learning;Vision Transformer;Video Vision Transformer";IEEE
574;Recurrent Convolutional Structures for Audio Spoof and Video Deepfake Detection;"A. Chintha; B. Thai; S. J. Sohrawardi; K. Bhatt; A. Hickerson; M. Wright; R. Ptucha";2020;Deepfakes, or artificially generated audiovisual renderings, can be used to defame a public figure or influence public opinion. With the recent discovery of generative adversarial networks, an attacker using a normal desktop computer fitted with an off-the-shelf graphics processing unit can make renditions realistic enough to easily fool a human observer. Detecting deepfakes is thus becoming important for reporters, social media platforms, and the general public. In this work, we introduce simple, yet surprisingly efficient digital forensic methods for audio spoof and visual deepfake detection. Our methods combine convolutional latent representations with bidirectional recurrent structures and entropy-based cost functions. The latent representations for both audio and video are carefully chosen to extract semantically rich information from the recordings. By feeding these into a recurrent framework, we can detect both spatial and temporal signatures of deepfake renditions. The entropy-based cost functions work well in isolation as well as in context with traditional cost functions. We demonstrate our methods on the FaceForensics++ and Celeb-DF video datasets and the ASVSpoof 2019 Logical Access audio datasets, achieving new benchmarks in all categories. We also perform extensive studies to demonstrate generalization to new domains and gain further insight into the effectiveness of the new architectures.;"Convolution;deep learning;deepfake;entropy;spoof";IEEE
575;DeepFake Detection using a frame based approach involving CNN;"A. Ajoy; C. U. Mahindrakar; D. Gowrish; V. A";2021;This paper proposes a novel model to detect Deep-Fakes, which are hyper-realistic fake videos generated by advanced AI algorithms involving facial superimposition. With a growing number of DeepFakes involving prominent political figures that hold a lot of social capital, their misuse can lead to drastic repercussions. These videos can not only be used to circulate false information causing harm to reputations of individuals, companies and countries, but also has the potential to cause civil unrest through mass hysteria. Hence it is of utmost importance to detect these DeepFakes and promptly curb their spread. We therefore propose a CNN-based model that learns inherently distinct patterns that change between a DeepFake and a real video. These distinct features include pixel distortion, inconsistencies with facial superimposition, skin colour differences, blurring and other visual artifacts. The proposed model has trained a CNN (Convolutional Neural Network), to effectively distinguish DeepFake videos using a frame-based approach based on aforementioned distinct features. Herein, the proposed work demonstrates the viability of our model in effectively identifying Deepfake faces in a given video source, so as to aid security applications employed by social-media platforms in credibly tackling the ever growing threat of Deepfakes, by effectively gauging the authenticity of videos, so that they may be flagged or ousted before they can cause irreparable harm.;;IEEE
577;A Multi-color Spatio-Temporal Approach For Detecting DeepFake;"S. Waseem; S. R. Abu-Bakar; Z. Omar; B. A. Ahmed; S. Baloch";2022;The current surge in hyper-realistic faces created artificially using DeepFakes necessitates media forensics solutions suited to video streams and perform reliably with a low false alarm rate at the video level. The paper proposes a spatial and temporal aware pipeline to detect DeepFake videos automatically. Our method employed a two-stream convolutional neural network to extract local spatial and temporal features independently. These features are then fed to fully connected layers to classify whether a video has been subject to manipulation. The proposed method has been evaluated against FaceForensics++, DFTIMIT, and DFD benchmarks. Our suggested technique demonstrates encouraging performance in this task;"DeepFake;Autoencoder;GAN;Face-swap;Face-re-enactment";IEEE
578;Hybrid Model for Detecting Deepfake Videos;"R. A C; K. P Nihal; K. Mishra; M. Sahithi P; P. A V; H. S Jagadeesh";2023;Innovations that can produce Deepfake videos are developing quickly. These videos are simple to and leave no obvious signs of alteration. Even though forensic detection in high-quality video datasets has produced fantastic results, there is always a need for more research into the forensics of compressed videos. Compressed videos are common in unofficial forums, such as those on Facebook, WeChat, and Instagram. Therefore, a crucial challenge is how to identify compressed Deepfake videos. In this project, we propose a two-stream method to compute each frame of compressed Deepfake videos. The compressed data has lot of unwanted data which needs to be trimmed, the proposed model performs the filtering to remove the unwanted data on each frame. When combined with scores from the two streams, our proposed technique performs better than the existing techniques in compressed mode.;"Deepfake;Mesonet;Resnet;Compressed videos;Face2Face";IEEE
582;LLM-Enhanced Deepfake Detection: Dense CNN and Multi-Modal Fusion Framework for Precise Multimedia Authentication;"S. E. VP; C. M. S; R. Dheepthi";2024;The increasing ubiquity of deepfake technology presents a serious risk to the legitimacy and reliability of multimedia material across a number of sectors, from identity verification to news distribution. Current deepfake detection methods frequently have trouble identifying minor manipulations and are unable to keep up with the latest generation techniques, which creates a serious vulnerability in the defence against the improper use of synthetic media. Using Dense Convolutional Neural Networks (Dense CNN) and Multi-Modal Fusion, this study presents a novel method for deepfake detection. Our Dense CNN architecture which draws inspiration from Dense Net improves sensitivity to complex manipulations while optimizing feature reuse through dense connectivity patterns, thereby mitigating the shortcomings of existing systems. Our suggested approach dynamically combines temporal and visual modalities, enhanced by Multi-Modal Fusion, to offer a comprehensive contextual knowledge that enhances detection accuracy. After thorough tests on several datasets, our method performs exceptionally well and is particularly good at identifying advanced deepfake variations. Our suggested methodology improves the state-of-the-art in deepfake identification by addressing the shortcomings of current systems and providing a reliable response to the urgent problems brought on by the malicious usage of synthetic media in practical applications. Adding Large Language Models (LLMs) is essential to improving the accuracy of the system. To add another level of scrutiny, LLMs are deliberately used to characterize and analyze portions of multimedia information that are vulnerable to manipulation.;"Deepfake Detection;Multimedia;Dense CNN;Large Language Model;dense connectivity patterns;Multi-Modal fusion";IEEE
583;Towards Intrinsic Common Discriminative Features Learning for Face Forgery Detection Using Adversarial Learning;"W. Zhuang; Q. Chu; H. Yuan; C. Miao; B. Liu; N. Yu";2022;Existing face forgery detection methods usually treat face forgery detection as a binary classification problem and adopt deep convolution neural networks to learn discriminative features. The ideal discriminative features should be only related to the real/fake labels of facial images. However, we observe that the features learned by vanilla classification networks are correlated to unnecessary properties, such as forgery methods and facial identities. Such phenomenon would limit forgery detection performance especially for the generalization ability. Motivated by this, we propose a novel method which utilizes adversarial learning to eliminate the negative effect of different forgery methods and facial identities, which helps classification network to learn intrinsic common discriminative features for face forgery detection. To leverage data lacking ground truth label of facial identities, we design a special identity discriminator based on similarity information derived from off-the-shelf face recognition model. Extensive experiments demonstrate the effectiveness of the proposed method under both intra-dataset and cross-dataset evaluation settings.;"Forgery detection;adversarial learning";IEEE
584;Interactive Two-Stream Network Across Modalities for Deepfake Detection;"J. Wu; B. Zhang; Z. Li; G. Pang; Z. Teng; J. Fan";2023;As face forgery techniques have become more mature, the proliferation of deepfakes may threaten the security of human society. Although existing deepfake detection methods achieve good performance for in-dataset evaluation, it remains to be improved in the generalization ability, where the representation of the imperceptible artifacts plays a significant role. In this paper, we propose an Interactive Two-Stream Network (ITSNet) to explore the discriminant inconsistency representation from the perspective of cross-modality. In particular, the patch-wise Decomposable Discrete Cosine Transform (DDCT) is adopted to extract fine-grained high-frequency clues, and information from different modalities communicates with each other via a designed interaction module. To perceive the temporal inconsistency, we first develop a Short-term Embedding Module (SEM) to refine subtle local inconsistency representation between adjacent frames, and then a Long-term Embedding Module (LEM) is designed to further refine the erratic temporal inconsistency representation from the long-range perspective. Extensive experimental results conducted on three public datasets show that ITSNet outperforms the state-of-the-art methods both in terms of in-dataset and cross-dataset evaluations.;"Deepfake detection;inconsistency representation;cross-modality learning";IEEE
588;Protecting Celebrities from DeepFake with Identity Consistency Transformer;"X. Dong; J. Bao; D. Chen; T. Zhang; W. Zhang; N. Yu; D. Chen; F. Wen; B. Guo";2022;In this work we propose Identity Consistency Transformer, a novel face forgery detection method that focuses on high-level semantics, specifically identity information, and detecting a suspect face by finding identity inconsistency in inner and outer face regions. The Identity Consistency Transformer incorporates a consistency loss for identity consistency determination. We show that Identity Consistency Transformer exhibits superior generalization ability not only across different datasets but also across various types of image degradation forms found in real-world applications including deepfake videos. The Identity Consistency Transformer can be easily enhanced with additional identity information when such information is available, and for this reason it is especially well-suited for detecting face forgeries involving celebrities.11Code will be released at https://github.com/LightDXY/ICT_DeepFake;"Recognition: detection;categorization;retrieval; Face and gestures";IEEE
591;Learning Self-Consistency for Deepfake Detection;"T. Zhao; X. Xu; M. Xu; H. Ding; Y. Xiong; W. Xia";2021;We propose a new method to detect deepfake images using the cue of the source feature inconsistency within the forged images. It is based on the hypothesis that images� distinct source features can be preserved and extracted after going through state-of-the-art deepfake generation processes. We introduce a novel representation learning approach, called pair-wise self-consistency learning (PCL), for training ConvNets to extract these source features and detect deepfake images. It is accompanied by a new image synthesis approach, called inconsistency image genera-tor (I2G), to provide richly annotated training data for PCL. Experimental results on seven popular datasets show that our models improve averaged AUC over the state of the art from 96.45% to 98.05% in the in-dataset evaluation and from 86.03% to 92.18% in the cross-dataset evaluation.;"Fairness;accountability;transparency;and ethics in vision;Faces";IEEE
592;Deepfake Detection with Clustering-based Embedding Regularization;"K. Zhu; B. Wu; B. Wang";2020;In recent months, AI-synthesized face swapping videos referred to as deepfake have become an emerging problem. False video is becoming more and more difficult to distinguish, which brings a series of challenges to social security. Some scholars are devoted to studying how to improve the detection accuracy of deepfake video. At the same time, in order to conduct better research, some datasets for deepfake detection are made. Companies such as Google and Facebook have also spent huge sums of money to produce datasets for deepfake video detection, as well as holding deepfake detection competitions. The continuous advancement of video tampering technology and the improvement of video quality have also brought great challenges to deepfake detection. Some scholars have achieved certain results on existing datasets, while the results on some high-quality datasets are not as good as expected. In this paper, we propose new method with clustering-based embedding regularization for deepfake detection. We use open source algorithms to generate videos which can simulate distinctive artifacts in the deepfake videos. To improve the local smoothness of the representation space, we integrate a clustering-based embedding regularization term into the classification objective, so that the obtained model learns to resist adversarial examples. We evaluate our method on three latest deepfake datasets. Experimental results demonstrate the effectiveness of our method.;"face swapping;deepfake detection;clustering-based;regularization";IEEE
594;Multi-attentional Deepfake Detection;"H. Zhao; T. Wei; W. Zhou; W. Zhang; D. Chen; N. Yu";2021;"Face forgery by deepfake is widely spread over the internet and has raised severe societal concerns. Recently, how to detect such forgery contents has become a hot research topic and many deepfake detection methods have been proposed. Most of them model deepfake detection as a vanilla binary classification problem, i.e, first use a backbone network to extract a global feature and then feed it into a binary classifier (real/fake). But since the difference between the real and fake images in this task is often subtle and local, we argue this vanilla solution is not optimal. In this paper, we instead formulate deepfake detection as a fine-grained classification problem and propose a new multi-attentional deepfake detection network. Specifically, it consists of three key components: 1) multiple spatial attention heads to make the network attend to different local parts; 2) textural feature enhancement block to zoom in the subtle artifacts in shallow features; 3) aggregate the low-level textural feature and high-level semantic features guided by the attention maps. Moreover, to address the learning difficulty of this network, we further introduce a new regional independence loss and an attention guided data augmentation strategy. Through extensive experiments on different datasets, we demonstrate the superiority of our method over the vanilla binary classifier counterparts, and achieve state-of-the-art performance. The models will be released recently at https://github.com/yoctta/multiple-attention.";;IEEE
595;Exploiting spatiotemporal inconsistencies to detect deepfake videos in the wild;"A. Khedkar; A. Peshkar; A. Nagdive; M. Gaikwad; S. Baudha";2022;Cyberspace is an emerging battlefield and deepfakes are being constantly weaponized by malicious actors. With rapid advancements in media synthesis technologies, detecting deepfakes is becoming increasingly difficult. The following paper presents a unified approach focusing on the fusion of Convolutional Neural Networks and Long Short Term Memory Networks for spatial and temporal analysis of deepfake videos. This study compares the performance of the most prevalent and frequently used deepfake detection methods- convolutional neural networks (CNN) and convolutional neural networks combined with long-short term memory networks (CNN-LSTM) with our architecture on a combined dataset consisting of videos from Face Forensics++ and Deepfake Detection Challenge Dataset, which consists of multiple types of manipulated media- Deepfakes, Faceswaps, Neural Textures, Face Shifter and Face2Face. We find that our architecture provides a 2.5% increase in detection accuracy over the most frequently used current deepfake detection method (CNN-LSTM).;"Deepfake Detection;Image Processing;Deep learning;GAN;Generalization;Interpretation";IEEE
596;Domain Generalization for Face Forgery Detection by Style Transfer;"T. Kim; J. Choi; H. Cho; H. Lim; J. Choi";2024;Although deep fake detection models have made significant progress, the challenge of performance degradation remains yet for unseen datasets. To address this, we introduce a novel data generalization approach using style transfer to generate images in various domains. Utilizing style transfer, we create a new domain where domain-specific information is eliminated and subsequently train our model on the new domain. Our approach enhances the generalization performance of the detector by adding the style-transferred images to train the deepfake detector. Through the experiments, we confirm that the performance on the trained dataset remains unchanged while achieving an improvement of 8.8% on an unseen dataset. Therefore, We verify the effectiveness of the style-transferred images for generalizing the performance upon unseen datasets.;"Deepfake detection;forgery detection;data augmentation;style transfer";IEEE
597;DeepFake Face Image Detection based on Improved VGG Convolutional Neural Network;"X. Chang; J. Wu; T. Yang; G. Feng";2020;"DeepFake can forge high-quality tampered images and videos that are consistent with the distribution of real data. Its rapid development causes people's panic and reflection. In this paper we presents an improved VGG network named NA-VGG to detect DeepFake face image, which was based on image noise and image augmentation. Firstly, In order to learn the tampering artifacts that may not be seen in RGB channels, SRM filter layer is used to highlight the image noise features; Secondly, the image noise map is augmented to weaken the face features. Finally, the augmented noise images are input into the network to train and judge whether the image is forged. The experimental results using the Celeb-DF dataset have shown that NA-VGG made great improvements than other state-of-the-art fake image detectors.";"DeepFake;Image Detection;VGG";IEEE
598;Deep Residual Learning for Unmasking DeepFake;"T. Bikku; K. Bhargavi; J. Bhavitha; Y. Lalithya; T. Vineetha";2023;"Recently, DeepFake has gained a lot of popularity, any multimedia output created with deep learning technology that appears realistic to viewers is referred to as ""DeepFake."" Despite the positive developments of DeepFake, it has been a significant contributor to threats to an individual's privacy because it allows for the indiscernible swapping of one person's face for another without that person's permission. Additionally, it is simple for hostile actors to influence public events like elections by disseminating false information and harming national security. Therefore, identifying such DeepFake is a critical yet difficult challenge. The separation of DeepFake contents from genuine ones using the human eye has always been a challenging process, but recent research has demonstrated the use of several technologies to provide positive results for the same, but with certain limits. In order to highlight the benefits and drawbacks of the various algorithms utilized for DeepFake production and detection, the paper provides a thorough analysis of the methods employed. The proposed work focuses on using Inception-Resnet V2 to detect deep fakes and packages those advantages of deep learning for this purpose. Here the frames are collected from the uploaded video and divide it into the required number of frames in order to detect deepfakes. The subject's face is then extracted from the video using python face recognition modules. The proposed model, which has been trained on a variety of frame sequences, to determine whether the video is real or a deep fake with 95% accuracy.";"Convolutional Neural Networks;Inception network;Residual connections;DeepFake";IEEE
599;FAClue: Exploring Frequency Clues by Adaptive Frequency-Attention for Deepfake Detection;"W. Liang; Y. Wu; J. Wu; J. Xu";2023;"Detecting fake faces produced by face forgery technologies attracts intensive attention in recent years. Deep learning approaches have shown their effectiveness in deepfake detection task. Some previous deep learning-based methods exploit forgery artifacts in spatial domain but easily overfit the specific forgery patterns. Therefore, some works utilize additional frequency domain information to obtain generalized features. We consider to improve the frequency-based methods in two aspects: 1) extracting discriminative frequency features comprehensively; 2) mining complementary features in different domains sufficiently. In this paper, we propose a dual-stream network named FAClue for deepfake detection, which extracts comprehensive frequency information to complement spatial domain features. Specifically, the FAClue consists of three main components. A Frequency-Attention Extractor (FAE) is proposed to adaptively highlight prominent frequency bands from both global and local perspectives. A RGB-Frequency Complementary Enhancement (RFCE) module is developed to mine complementary information between RGB and frequency domains in an explicit manner. A Frequency Guided Attention (FGA) module is designed to fuse different domain features and generate discriminative features for detection. Extensive experiments on three benchmark datasets demonstrate the FAClue achieves competitive performance compared with state-of-the-art methods.";"Deepfake Detection;Frequency Domain;Attention Mechanism;Feature Fusion";IEEE
600;DiffSeg: Towards Detecting Diffusion-Based Inpainting Attacks Using Multi-Feature Segmentation;"R. A. Frick; M. Steinebach";2024;With the advancements made in deep learning over the past years, creating convincing media manipulations has become easy and accessible than ever before. In particular, diffusion models such as Stable-Diffusion allow users to synthesize realistic images based on a given text input. Apart from synthesizing entirely new images, diffusion models can also be used to make edits to images using inpainting. To combat the spread of disinformation and illegal content created with diffusion-based inpainting, this paper presents a new detection method based on multi-feature segmentation. Apart from information derived from the raw pixel values, noise, and frequency information are also exploited to detect and localize regions that have been subject to editing. Evaluation results strongly suggest that the proposed method can achieve high mIoU and AUC scores, outperforming state-of-the-art methods, even for syntheses generated by unseen diffusion models, or highly compressed images.;"Deepfake Detection;Inpainting Detection;Diffusion Models;Media Forensics";IEEE
601;MRE-Net: Multi-Rate Excitation Network for Deepfake Video Detection;"G. Pang; B. Zhang; Z. Teng; Z. Qi; J. Fan";2023;The current social media is flooded with hyper realistic face-synthetic videos due to the explosion of DeepFake technology that has brought a serious impact on human society security, which calls for further exploring on deepfake video detection methods. Existing methods attempt to isolated capture spatial artifacts or extract the homogeneous temporal inconsistency to detect deepfake video, but little attention has been paid to the exploitation of dynamic spatial-temporal inconsistency. To mitigate this issue, in this paper, we propose a novel Multi-Rate Excitation Network (MRE-Net) to effectively excite dynamic spatial-temporal inconsistency from the perspective of multiple rates for deepfake video detection. The proposed MRE-Net is composed of two components: Bipartite Group Sampling (BGS) and multiple rate branches. The BGS draws the entire video into multiple bipartite groups with different rates to cover various face motion dynamic evolution. We further design multiple rate branches to capture both short-term and long-term spatial-temporal inconsistency from corresponding bipartite groups of BGS. Concretely, for the early stages of the multi-rate branches, Momentary Inconsistency Excitation (MIE) module is developed to encode the spatial artifacts and intra-group short-term temporal inconsistency. Meanwhile, for the last stages of the multi-rate branches, Longstanding Inconsistency Excitation (LIE) module is constructed to perceive inter-group long-term temporal dynamics. Extensive experiments and visualizations conducted on four popular datasets demonstrate the effectiveness of the proposed method against state-of-the-art deepfake detection methods.;"Deepfake detection;momentary inconsistency;longstanding inconsistency";IEEE
602;PUDD: Towards Robust Multi-modal Prototype-based Deepfake Detection;"A. L. Pellcier; Y. Li; P. Angelov";2024;"Deepfake techniques generate highly realistic data, making it challenging for humans to discern between actual and artificially generated images. Recent advancements in deep learning-based deepfake detection methods, particularly with diffusion models, have shown remarkable progress. However, there is a growing demand for real-world applications to detect unseen individuals, deepfake techniques, and scenarios. To address this limitation, we propose a Prototype-based Unified Framework for Deepfake Detection (PUDD). PUDD offers a detection system based on similarity, comparing input data against known prototypes for video classification and identifying potential deepfakes or previously unseen classes by analyzing drops in similarity. Our extensive experiments reveal three key findings: (1) PUDD achieves an accuracy of 95.1% on Celeb-DF, outperforming state-of-the-art deepfake detection methods; (2) PUDD leverages image classification as the upstream task during training, demonstrating promising performance in both image classification and deepfake detection tasks during inference; (3) PUDD requires only 2.7 seconds for retraining on new data and emits 105 times less carbon compared to the state-of-the-art model, making it significantly more environmentally friendly.";;IEEE
603;Deepfake Detection With Combined Unsupervised-Supervised Contrastive Learning;"J. Zheng; Y. Zhou; X. Hu; Z. Tang";2024;The malicious dissemination of fake images has caused a societal trust crisis, deepfake detection becomes a hot topic now. Through existing detection methods achieve good results in intra-dataset, their performance are poor for unknown manipulations or datasets. To deal with this problem, this paper proposes a new deepfake detection model with combined unsupervised-supervised contrastive learning. By combining unsupervised contrastive learning and supervised contrastive learning with deepfake detection together, the model can discover the essence of fake images from both individual and class features. In addition, a multi-scale attention fusion module is proposed, which helps to enhance the model stability by fusion global and local features of the image. Finally, lots of experiments prove that our method has good performance and generalization ability in intra-dataset, cross-dataset and cross-manipulation scenarios.;"deepfake detection;contrastive learning;supervised contrastive learning;combined unsupervised-supervised contrastive learning";IEEE
604;Deepfake Detection via Combining Channel and Spatial Attention;"A. E. BAYAR; C. TOPAL";2023;Today, as the widespread use of deepfake technologies weakens the credibility of digital media content, deepfake detection of digital content has become an important issue. Detection of fake content is critical in order to prevent the risk of disinformation that may occur with the rapid spread of manipulated content produced with this technology over the internet. This study proposes a neural network that uses channel and spatial attention mechanisms for the detection of deepfake images. This proposed network is trained with a common dataset by combining DeepfakeTIMIT and VidTIMIT datasets. Compared with models such as InceptionV3, ResNet50 and VGG19, higher accuracy, precision, recall and F1 scores were obtained. This network with attention mechanisms has classified the detection of deepfake images with up to 99% success. The findings of this study will provide an important step in the detection of deep forged images and offer a potential solution for a wider range of applications.;"Deepfake;convolutional neural network;channel- wise and spatial attention";IEEE
605;Fighting Fake News: Two Stream Network for Deepfake Detection via Learnable SRM;"B. Han; X. Han; H. Zhang; J. Li; X. Cao";2021;Benefitting from the development of deep generative networks, modern fake news generation methods called Deepfake rapidly go viral over the Internet, calling for efficient detection methods. Existing Deepfake detection methods basically use binary classification networks trained on frame-level inputs and lack leveraging temporal information in videos. Besides, the accuracy of these methods will rapidly decrease when processing low-quality data. In this work, we propose a two-stream network to detect Deepfake in video level with the capability of handling low-quality data. The proposed architecture firstly divides the input video into segments and then feeds selected frames of each segment into two streams: The first stream takes RGB information as input and tries to learn the semantic inconsistency. The second stream parallelly leverages noise features extracted by spatial rich model (SRM) filters. Additionally, our experiments found that traditional SRM filters with fixed weights contribute insignificant improvement, we thus design novel learnable SRM filters, which can better fit the noise inconsistency in tampered regions. Segmental fusion and stream fusion are conducted at last to combine the information from segments and streams. We evaluate our algorithm on the existing largest Deepfake dataset FaceForensics++ and the experimental results show that we obtain state-of-the-art performance.;"Multimedia forensics;deep learning;fake news;Deepfake;SRM";IEEE
608;Exposing the Limits of Deepfake Detection using novel Facial mole attack: A Perceptual Black- Box Adversarial Attack Study;"Q. U. Ain; A. Javed; K. M. Malik; A. Irtaza";2024;Recently, we have observed an exponential growth in highly realistic deepfake videos, which are often used to spread disinformation, defame individuals, and even influence political outcomes. To combat these manipulated videos, researchers have proposed various deepfake detection techniques. Recent research has revealed that these detection techniques are vulnerable to different adversarial attacks. This paper examines the vulnerability of deepfake detectors to adversarial black-box attacks in terms of performing penetration testing to expose the existing defense benchmarks of current deepfake detectors. We present a perceptual facial mole black-box adversarial attack on deepfake detectors, where the attacker has limited knowledge of the architecture and settings of the detector. The proposed attack is visually natural and transferable based on the attention distraction mechanism, which distracts the model-shared attention patterns from the region of interest to other regions. We illustrate the efficacy of our attack on multiple cutting-edge deepfake detectors. This attack demonstrates that small perceptible perturbations that are visually natural on the facial face can disrupt and reduce the accuracy of the detectors significantly, up to 40.3%, with the highest success rate of 48.7%. Our findings highlight the necessity for proposing effective deepfake detectors that are resistant to black-box attacks.;"Adversarial attack;Black-box attack;Deepfakes detection;Facial Mole attack";IEEE
609;Improving Generalization in Facial Manipulation Detection Using Image Noise Residuals and Temporal Features;"M. Atamna; I. Tkachenko; S. Miguet";2023;The high visual quality of modern deepfakes raises significant concerns about the trustworthiness of digital media and makes facial tampering detection more challenging. Although current deep learning-based deepfake detectors achieve excellent results when tested on deepfake images or image sequences generated using known methods, generalization�where a trained model is tasked with detecting deepfakes created with previously unseen manipulation techniques�is still a major challenge. In this paper, we investigate the impact of training spatial and spatio-temporal deep learning network architectures in the image noise residual domain using spatial rich model (SRM) filters on generalization performance. To this end, we conduct a series of tests on the manipulation methods of the FaceForensics++, DeeperForensics-1.0 and Celeb-DF datasets, demonstrating the value of image noise residuals and temporal feature exploitation in tackling the generalization task.;"Deepfake detection;video manipulation detection;image forensics;steganalysis features";IEEE
611;Fusing Global and Local Features for Generalized AI-Synthesized Image Detection;"Y. Ju; S. Jia; L. Ke; H. Xue; K. Nagano; S. Lyu";2022;With the development of the Generative Adversarial Networks (GANs) and DeepFakes, AI-synthesized images are now of such high quality that humans can hardly distinguish them from real images. It is imperative for media forensics to develop detectors to expose them accurately. Existing detection methods have shown high performance in generated images detection, but they tend to generalize poorly in the real-world scenarios, where the synthetic images are usually generated with unseen models using unknown source data. In this work, we emphasize the importance of combining information from the whole image and informative patches in improving the generalization ability of AI-synthesized image detection. Specifically, we design a two-branch model to combine global spatial information from the whole image and local informative features from multiple patches selected by a novel patch selection module. Multi-head attention mechanism is further utilized to fuse the global and local features. We collect a highly diverse dataset synthesized by 19 models with various objects and resolutions to evaluate our model. Experimental results demonstrate the high accuracy and good generalization ability of our method in detecting generated images. Our code is available at https://github.com/littlejuyan/FusingGlobalandLocal.;"AI-synthesized Image Detection;Image Forensics;Feature Fusion;Attention Mechanism";IEEE
613;FAMM: Facial Muscle Motions for Detecting Compressed Deepfake Videos Over Social Networks;"X. Liao; Y. Wang; T. Wang; J. Hu; X. Wu";2023;As a face manipulation technique, the misuse of Deepfakes poses potential threats to the state, society, and individuals. Several countermeasures have been proposed to reduce the negative effects produced by Deepfakes. Current detection methods achieve satisfactory performance in dealing with uncompressed videos. However, videos are generally compressed when spread over social networks because of limited bandwidth and storage space, which generates compression artifacts and the detection performance inevitably decreases. Hence, how to effectively identify compressed Deepfake videos over social networks becomes a significant problem in video forensics. In this paper, we propose a facial-muscle-motions-based (FAMM) framework to solve the problem of compressed Deepfake video detection. Specifically, we first locate faces from consecutive frames and extract landmarks from the face images. Then, continuous facial landmarks are utilized to construct facial muscle motion features by modeling the five sensory and face regions. Finally, we fuse the diverse forensic knowledge using Dempster-Shafer theory and provide the final detection results. Furthermore, we demonstrate the effectiveness of FAMM through analyzing mutual information, compression procedure, and facial landmarks for compressed Deepfake videos. Theoretical analyses illustrate that compression does not affect facial muscle motion feature construction and the differences in designed features exist between the real and Deepfake videos. Extensive experimental results conclude that the proposed method outperforms the state-of-the-art methods in detecting compressed Deepfake videos. More importantly, FAMM achieves comparable detection performance on compressed videos that are over real-world social networks.;"Multimedia forensics;compressed deepfake videos;facial muscle movements;social networks";IEEE
615;Deepfakes Examiner: An End-to-End Deep Learning Model for Deepfakes Videos Detection;"H. Ilyas; A. Irtaza; A. Javed; K. M. Malik";2022;Deepfakes generation approaches have made it possible even for less technical users to generate fake videos using only the source and target images. Thus, the threats associated with deepfake video generation such as impersonating public figures, defamation, and spreading disinformation on media platforms have increased exponentially. The significant improvement in the deepfakes generation techniques necessitates the development of effective deepfakes detection methods to counter disinformation threats. Existing techniques do not provide reliable deepfakes detection particularly when the videos are generated using different deepfakes generation techniques and contain variations in illumination conditions and diverse ethnicities. Therefore, this paper proposes a novel hybrid deep learning framework, InceptionResNet-BiLSTM, that is robust to different ethnicities and varied illumination conditions, and able to detect deepfake videos generated using different techniques. The proposed InceptionResNet-BiLSTM consists of two components: customized InceptionResNetV2 and Bidirectional Long-Short Term Memory (BiLSTM). In our proposed framework, faces extracted from the videos are fed to our customized InceptionResNetV2 for extracting frame-level learnable features. The sequences of features are then used to train a temporally aware BiLSTM to classify between the real and fake video. We evaluated our proposed approach on the diverse, standard, and largescale FaceForensics++ (FF++) dataset containing videos manipulated using different techniques (i.e., DeepFakes, FaceSwap, Face2Face, FaceShifter, and NeuralTextures) and the FakeA VCeleb dataset. Our method achieved an accuracy greater than 90% on DeepFakes, FaceSwap, and Face2Face subsets. Performance and generalizability evaluation highlights the effectiveness of our method for detecting deepfake videos generated through different techniques on diverse FF++ and FakeA VCeleb datasets.;"Bidirectional LSTM;Deepfakes Detection;FaceForensics++;FakeAVCeleb;InceptionResNetV2;Puppet-master;Face-swap";IEEE
616;Improving the Efficiency and Robustness of Deepfakes Detection through Precise Geometric Features;"Z. Sun; Y. Han; Z. Hua; N. Ruan; W. Jia";2021;Deepfakes is a branch of malicious techniques that transplant a target face to the original one in videos, resulting in serious problems such as infringement of copyright, confusion of information, or even public panic. Previous efforts for Deepfakes videos detection mainly focused on appearance features, which have a risk of being bypassed by sophisticated manipulation, also resulting high model complexity and sensitiveness to noise. Besides, how to mine the temporal features of manipulated videos and exploit them is still an open question. We propose an efficient and robust framework named LRNet for detecting Deepfakes videos through temporal modeling on precise geometric features. A novel calibration module is devised to enhance the precision of geometric features, making it more discriminative, and a two-stream Recurrent Neural Network (RNN) is constructed for sufficient exploitation of temporal features. Compared to previous methods, our proposed method is lighter-weighted and easier to train. Moreover, our method has shown robustness in detecting highly compressed or noise corrupted videos. Our model achieved 0.999 AUC on FaceForensics+ + dataset. Meanwhile, it has a graceful decline in performance (-0.042 AUC) when faced with highly compressed videos.1;;IEEE
617;DeepVision: Deepfakes Detection Using Human Eye Blinking Pattern;"T. Jung; S. Kim; K. Kim";2020;In this paper, we propose a new approach to detect Deepfakes generated through the generative adversarial network (GANs) model via an algorithm called DeepVision to analyze a significant change in the pattern of blinking, which is a voluntary and spontaneous action that does not require conscious effort. Human eye blinking pattern has been known to significantly change according to the person's overall physical conditions, cognitive activities, biological factors, and information processing level. For example, an individual's gender or age, the time of day, or the person's emotional state or degree of alertness can all influence the pattern. As a result, Deepfakes can be determined through integrity verification by tracking significant changes in the eye blinking patterns in deepfakes by means of a heuristic method based on the results of medicine, biology, and brain engineering research, as well as machine learning and various algorithms based on engineering and statistical knowledge. This means we can perform integrity verification through tracking significant changes in the eye blinking pattern of a subject in a video. The proposed method called DeepVision is implemented as a measure to verify an anomaly based on the period, repeated number, and elapsed eye blink time when eye blinks were continuously repeated within a very short period of time. DeepVision accurately detected Deepfakes in seven out of eight types of videos (87.5% accuracy rate), suggesting we can overcome the limitations of integrity verification algorithms performed only on the basis of pixels.;"Cyber security;deep-fake;GANs;deep learning";IEEE
619;Attention-Guided Supervised Contrastive Learning for Deepfake Detection;"S. Waseem; S. A. Rahman Bin Syed Abu Bakar; B. A. Ahmed";2024;Recent advancements in face deepfake detection have shown impressive results. However, prior studies typically used crossentropy loss to approach face manipulation detection as a classification problem. Approaches based on cross-entropy loss prioritize category distinctions over capturing the underlying differences between real and fake faces, which restricts the model's capacity to generalize to unseen datasets. As original image or video can closely resemble the deepfake in terms of appearance, making it challenging to distinguish them, we propose to utilize the differences in the representation space to develop a generalizable detector. In this paper, we present an attention-guided supervised contrastive learning approach for deepfake detection, aiming to leverage differences in the representation space and prioritize disparities between classes rather than focusing solely on categories. By using supervised contrastive learning, the model learns to create a discriminative representation by contrasting between classes, while an attention module directs the model to relevant features for each class and filters out irrelevant features. This method learns features from a wide variety of deepfake images, thus improving the accuracy of deepfake detection in unseen datasets. Experimental results show the effectiveness of our attention-guided supervised contrastive learning deepfake detector on benchmark datasets such as FF++, Celeb-DF, DFD and DFDC-P.;"Deepfake;Generalization;Contrastive learning;Attention";IEEE
620;Model-Agnostic Method: Exposing Deepfake Using Pixel-Wise Spatial and Temporal Fingerprints;"J. Yang; Y. Sun; M. Mao; L. Bai; S. Zhang; F. Wang";2023;Deepfake poses a serious threat to the reliability of judicial evidence and intellectual property protection. Existing detection methods either blindly utilize deep learning or use biosignal features, but neither considers spatial and temporal relevance of face features. These methods are increasingly unable to resist the growing realism of fake videos and lack generalization. In this paper, we identify a reliable fingerprint through the consistency of AR coefficients and extend the original PPG signal to 3-dimensional fingerprints to effectively detect fake content. Using these reliable fingerprints, we propose a novel model-agnostic method to expose Deepfake by analyzing temporal and spatial faint synthetic signals hidden in portrait videos. Specifically, our method extracts two types of faint information, i.e., PPG features and AR features, which are used as the basis for forensics in temporal and spatial domains, respectively. PPG allows remote estimation of the heart rate in face videos, and irregular heart rate fluctuations expose traces of tampering. AR coefficients reflect pixel-wise correlation and spatial traces of smoothing caused by up-sampling in the process of generating fake faces. Furthermore, we employ two ACBlock-based DenseNets as classifiers. Our method provides state-of-the-art performance on multiple deep forgery datasets and demonstrates better generalization.;"Auto-regressive (AR);deep learning;deepfake detection;fingerprint;photoplethysmography (PPG);temporal and spatial";IEEE
625;DFCP: Few-Shot DeepFake Detection via Contrastive Pretraining;"B. Zou; C. Yang; J. Guan; C. Quan; Y. Zhao";2023;Abuses of forgery techniques have created a considerable problem of misinformation on social media. Although scholars devote many efforts to face forgery detection (a.k.a DeepFake detection) and achieve some results, two issues still hinder the practical application. 1) Most detectors do not generalize well to unseen datasets. 2) In a supervised manner, most previous works require a considerable amount of manually labeled data. To address these problems, we propose a simple contrastive pertaining framework for DeepFake detection (DFCP), which works in a finetuning-after-pretraining manner, and requires only a few labels (5%). Specifically, we design a two-stream framework to simultaneously learn high-frequency texture features and high-level semantics information during pretraining. In addition, a video-based frame sampling strategy is proposed to mitigate potential noise data in the instance-discriminative contrastive learning to achieve better performance. Experimental results on several downstream datasets show the state-of-the-art performance of the proposed DFCP, which works at frame-level (w/o temporal reasoning) with high efficiency but outperforms video-level methods.;"Face Forgery Detection;DeepFake;Self-supervised Learning;Contrastive Learning";IEEE
627;An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape;"S. M. Abdullah; A. Cheruvu; S. Kanchi; T. Chung; P. Gao; M. Jadliwala; B. Viswanath";2024;Deepfake or synthetic images produced using deep generative models pose serious risks to online platforms. This has triggered several research efforts to accurately detect deepfake images, achieving excellent performance on publicly available deepfake datasets. In this work, we study 8 state-of-the-art detectors and argue that they are far from being ready for deployment due to two recent developments. First, the emergence of lightweight methods to customize large generative models, can enable an attacker to create many customized generators (to create deepfakes), thereby substantially increasing the threat surface. We show that existing defenses fail to generalize well to such user-customized generative models that are publicly available today. We discuss new machine learning approaches based on content-agnostic features, and ensemble modeling to improve generalization performance against user-customized models. Second, the emergence of vision foundation models�machine learning models trained on broad data that can be easily adapted to several downstream tasks�can be misused by attackers to craft adversarial deepfakes that can evade existing defenses. We propose a simple adversarial attack that leverages existing foundation models to craft adversarial samples without adding any adversarial noise, through careful semantic manipulation of the image content. We highlight the vulnerabilities of several defenses against our attack, and explore directions leveraging advanced foundation models and adversarial training to defend against this new threat.;"deepfake image;foundation models;generative models;deepfake detection";IEEE
628;Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors;"N. T. Lim; M. Yi Kuan; M. Pu; M. K. Lim; C. Yong Chong";2022;Deepfakes utilise Artificial Intelligence (AI) techniques to create synthetic media where the likeness of one person is replaced with another. There are growing concerns that deepfakes can be maliciously used to create misleading and harmful digital contents. As deepfakes become more common, there is a dire need for deepfake detection technology to help spot deepfake media. Present deepfake detection models are able to achieve outstanding accuracy (>90%). However, most of them are limited to within-dataset scenario. Most models do not generalise well enough in cross-dataset scenario. Furthermore, state-of-the-art deepfake detection models rely on neural network-based classification models that are known to be vulnerable to adversarial attacks. Motivated by the need for a robust deepfake detection model, this study adapts metamorphic testing (MT) principles to help identify potential factors that could influence the robustness of the examined model, while overcoming the test oracle problem in this domain. Metamorphic testing is specifically chosen as the testing technique as it fits our demand to address learning-based system testing with probabilistic outcomes from largely black-box components, based on potentially large input domains. We performed our evaluations on MesoInception-4 and TwoStreamNet models, which are the state-of-the-art deepfake detection models. This study identified makeup application as an adversarial attack that could fool deepfake detectors. Our experimental results demonstrate that both the MesoInception-4 and TwoStreamNet models degrade in their performance by up to 30% when the input data is perturbed with makeup.;;IEEE
629;Boosting Deep Feature Fusion-Based Detection Model for Fake Faces Generated by Generative Adversarial Networks for Consumer Space Environment;"F. Alrowais; A. Abbas Hassan; W. Sulaiman Almukadi; M. H. Alanazi; R. Marzouk; A. Mahmud";2024;In the consumer space, deep fakes refer to highly realistic, AI-generated images, audio, or videos that mimic real people generated by cutting-edge technologies such as Generative Adversarial Networks (GANs). In the digital age, recognizing and detecting deepfakes is a critical problem. The most common solutions for deepfake creation are those based on GANs, which can efficiently manipulate multimedia data or create from scratch. GANs comprise two neural networks, a Generator (G) and a Discriminator (D), that concurrently work during competition. The generator generates artificial data, whereas the discriminator calculates the authenticity of generated and real data. This adversarial procedure causes the generator to generate more realistic content. Identifying deep fakes produced by GANs using deep learning (DL) includes leveraging complex neural networks to detect subtle anomalies and artefacts that GANs accidentally introduce. Convolutional Neural Network (CNN) are very effective for these tasks, as they learn to discern inconsistencies and complex features in image textures, lighting, and facial features frequently missed by human eyes. This CNN model is trained on a massive database of fake and authentic images, allowing them to detect minor defects. This study presents a Deep Feature Fusion-based Fake Face Detection Generated by Generative Adversarial Networks (DF4D-GGAN) technique for Consumer Space Environment. The goal of the DF4D-GGAN technique is to detect the presence of real or deepfake images generated by DL. In the DF4D-GGAN technique, the Gaussian filtering (GF) approach is used for preprocessing the input images. Besides, the feature fusion process uses EfficientNet-b4 and ShuffleNet. Moreover, the hyperparameter selection of the DL models is performed by an improved slime mould algorithm (ISMA). Finally, an extreme learning machine (ELM) classifier has been employed to proficiently recognize real and fake images. To validate the results of the DF4D-GGAN technique, a series of simulations were made on benchmark datasets. The results stated that the DF4D-GGAN technique gains improved results over other models.;"Consumer space;deepfake image detection;generative adversarial network;slime mould algorithm;image processing;CNN";IEEE
630;Faux Reality Detector;"S. K. R; S. A; V. R; S. K. M; S. J";2024;With the advent of a new era in digital content creation, deep learning and generative models have completely changed the way we interact with multimedia. Strong generative adversarial networks (GANs) have been developed, but this has led to grave worries about the potential for malevolent usage. Deep fakes, which are produced by GAN and are hyper-realistic digital forgeries that might be used to spread incorrect information and fool people, pose a serious threat to civilization. As a result, developing reliable and effective deep fake detection algorithms has become an important study area. The major goal of this project is to create and deploy a deep fake detection system that can accurately identify between authentic and false images. Such fake faces can be recognized using a deep learning architecture based on CNNs (Convolutional Neural Networks). Such fake faces can be identified with practically perfect accuracy using a deep learning architecture based on CNNs (Convolutional Neural Networks). based on the fact that the textures of real faces and synthetic ones are very different. The comprehensive research and analysis carried out to understand the fundamental concepts underlying deep fake generation and detection are described in this paper.;"Generative A dversa ria I Networks;Fake detection;Deep learning architecture and Convolutional Neural Network";IEEE
634;Towards Spatio-temporal Collaborative Learning: An End-to-End Deepfake Video Detection Framework;"W. Guo; S. Du; H. Deng; Z. Yu; L. Feng";2023;With the rapid development of facial tampering techniques, the deepfake detection task has attracted widespread social concerns. Most existing video-based methods adopt temporal convolution to learn temporal discontinuities directly, where they might neglect to explore both local detail mutation and inconsistent global expression semantics in the temporal dimension. This makes it difficult to learn more discriminative forgery cues. To mitigate this issue, we introduce a novel deepfake video detection framework specifically designed to capture fine-grained traces of tampering. Concretely, we first present a Multi-layered Feature Extraction module (MFE) that constructs comprehensive spatio-temporal representations by stitching different levels of features together. Afterward, we propose a Bidirectional temporal Artifact Enhancement module (BAE), which exploits local differences between adjacent frames to enhance frame-level features. Moreover, we present a Cross temporal Stride Aggregation strategy (CSA) to mine inconsistent global semantics and adaptively obtain multi-timescale representations. Extensive experiments on several benchmarks demonstrate that the proposed method outperforms state-of-the-art performance compared to other competitive approaches.;"Deepfake Detection;Spatio-temporal Modeling;Face Forensics;Deep Learning";IEEE
635;TruFor: Leveraging All-Round Clues for Trustworthy Image Forgery Detection and Localization;"F. Guillaro; D. Cozzolino; A. Sud; N. Dufour; L. Verdoliva";2023;In this paper we present TruFor, a forensic framework that can be applied to a large variety of image manipulation methods, from classic cheapfakes to more recent manipulations based on deep learning. We rely on the extraction of both high-level and low-level traces through a transformer-based fusion architecture that combines the RGB image and a learned noise-sensitive fingerprint. The latter learns to embed the artifacts related to the camera internal and external processing by training only on real data in a self-supervised manner. Forgeries are detected as deviations from the expected regular pattern that characterizes each pristine image. Looking for anomalies makes the approach able to robustly detect a variety of local manipulations, ensuring generalization. In addition to a pixel-level localization map and a whole-image integrity score, our approach outputs a reliability map that highlights areas where localization predictions may be error-prone. This is particularly important in forensic applications in order to reduce false alarms and allow for a large scale analysis. Extensive experiments on several datasets show that our method is able to reliably detect and localize both cheapfakes and deepfakes manipulations outperforming state-of-the-art works. Code is publicly available at https://grip-unina.github.io/TruFor/;Computer vision for social good;IEEE
636;ForgeryNIR: Deep Face Forgery and Detection in Near-Infrared Scenario;"Y. Wang; C. Peng; D. Liu; N. Wang; X. Gao";2022;Deep face forgery and detection is an emerging topic due to the development of GANs. Face forgery detection relies greatly on existing databases for evaluation and adequate training examples for data-hungry machine learning algorithms. However, considering the wide application of face recognition in near-infrared scenarios, there is no publicly available face forgery database that includes near-infrared modality currently. In this paper, we present an attempt at constructing a large-scale dataset for face forgery detection in the near-infrared modality and propose a new forgery detection method based on knowledge distillation named cross-modality knowledge distillation aiming to use a teacher model which is pre-trained on the visible light-based (VIS) big data to guide the student model with a small amount of near-infrared (NIR) data. The proposed near-infrared face forgery dataset, named ForgeryNIR, contains a total of over 50,000 real and fake identities. A number of perturbations are applied to help simulate real-world scenarios. All source images in ForgeryNIR are collected from CASIA NIR-VIS 2.0, and fake images are generated via multiple GAN techniques. The proposed dataset fills the gap of face forgery detection research in the near-infrared modality. A comprehensive study on six representative detection baselines is conducted to evaluate the performance of face forgery detection algorithms in the NIR domain. We further construct a hard testing set, named ForgeryNIR+, which contains forged images that have bypassed existing face forgery detection methods. The proposed datasets will be publicly available and aim to help boost further research on face forgery detection, as well as NIR face detection and recognition.;"Near-infrared face;face forgery detection;deepfake";IEEE
637;Exposing Deepfake Videos by Tracking Eye Movements;"M. Li; B. Liu; Y. Hu; Y. Wang";2021;It has recently become a major threat to the public media that fake videos are rapidly spreading over the Internet. The advent of Deepfake, a deep-learning based toolkit, has facilitated a massive abuse of improper synthesized videos, which may influence the media credibility and human rights. A worldwide alert has been set off that finding ways to detect such fake videos is not only crucial but also urgent. This paper reports a novel approach to expose deepfake videos. We found that most fake videos are markedly different from the real ones in the way the eyes move. We are thus motivated to define four features that could well capture such differences. The features are then fed to SVM for classification. It is shown to be a promising approach that without high dimensional features and complicated neural networks, we are able to achieve competitive results on several public datasets. Moreover, the proposed features could well participate with other existing methods in the confrontation with deepfakes.;;IEEE
638;Efficient Identification of DeepFake Images using CNN;"N. C. Gowda; V. H N; D. R. Ramani";2024;"The development of Deepfakes has become more prevalent with the rise of Generative Adversarial Networks (GANs). Deepfakes are synthetically created, modified images that have been made to look real; they pose severe social concerns with privacy an d security issues. To solve these issues, this paper offers a novel method to detect Deepfakes in photographs using a Convolutional Neural Network (CNN) architecture. To detect whether a image has been altered or not, the suggested method examines many aspects of the image. The proposed methods are tested using a sizable benchmark dataset of Deepfakes and non-Deepfakes, and were able to identify modified images with high precision. The strategy is resistant to a variety of manipulations, including those intended to trick cutting-edge detection techniques. It is found that proposed strategy will improve digital media's security and credibility while helping mitigate any possible problems of Deepfake images.";"DeepFake;Generative Adversarial Networks (GANs);Deeplearning;Convolutional Neural Network (CNN)";IEEE
639;GAN Generated Fake Human Face Image Detection;"S. Shilaskar; M. Talewar; S. Tak; S. Goud";2024;In recent years, Generative Adversarial Networks (GANs) have revolutionized the generation of synthetic data that closely mimics real-world distributions. This research paper focuses on detecting fake human face images generated through GANs. The paper provides a thorough analysis of the current state of GAN-generated fake human face detection and proposes a novel method for robust detection. Existing detection methods often struggle with newly emerging GAN architectures, lack generalization capabilities, and are prone to adversarial attacks. In this paper, authors propose an efficient Convolutional Neural Network (CNN) architecture that detects StyleGAN3-generated fake human faces. To enhance the robustness of the model the algorithm employs a series of filters to extract image data, performs grayscale normalization and convolutional operations to find out whether the images are fake or real with more accuracy. The outcomes of the experiments demonstrate that the approach outperforms the current systems in terms of robustly identifying fake images. Authors achieved an accuracy of 99.42%. This system can be integrated into social media platforms to identify fake profile pictures or deepfake images that are often used for impersonation or spreading misinformation.;"GANs;Convolutional Neural Network;StyleGAN3;Deep Learning;Fake Human Face Detection";IEEE
645;Image Animations on Driving Videos with DeepFakes and Detecting DeepFakes Generated Animations;"Y. S. Malik; N. Sabahat; M. O. Moazzam";2020;The concept of image animation is to create a video or animation such that an object from an image is animated as per the motion of driving video. We plan to analyze with minor modifications of an existing framework which does this without any information beforehand about the object which is to be animated. To achieve that, we train our dataset on a set of images and videos for the objects of same category, for example (face, body, street views) etc. Some recent applications of neural networks (CNN) have proved to form realistic human heads. Realistic talking heads can be created by training the dataset of large number of images and videos. A source image of a person can be animated on target poses of a person (driving video), by keeping the appearance and body of the person. However, on the parallel side, there are advancements in the development of systems which are capable of detecting DeepFakes generated videos and animations as it is a crucial security concern. We did experiments on Image Animation to achieve talking heads, Image generations with conditional generative adversarial networks for DeepFakes Generations and the results were realistic. Moreover, we implemented a DeepFake Detector XceptionNet with minor modifications which achieved 95% accuracy on detecting DeepFakes. At last, we implemented a newly introduced technique in which the DeepFake generation is perturbed through which it can easily fool the deepfake detector. XceptionNet was able to achieve less than 30% accuracy on detecting DeepFakes generations when they were perturbed.;"DeepFakes;Image Animation;DeepFakes Generations;Detection of DeepFakes;GANS;Adversarial Attacks;Fooling DeepFake Detectors";IEEE
646;Forgery Face Image Detection Based on Improved Capsule Network;"Y. Liu; Q. Qin; W. Yang; A. Wu; W. Ma; J. Zhang";2022;Face forgery technologies may have a significant adverse impact on individual privacy and national political security. In this paper, a simple but effective method for detecting forgery face image based on improved capsule network is proposed. More specifically, we first adopt the part of per-trained VGG19 to extract latent features for better classification. Then, the improved capsule network architecture makes use of exponential linear unit (ELU) instead of the traditional rectified linear unit (ReLU) to improve the learning speed and convergence properties. Moreover, the effective attention mechanisms are embedded into the improved capsule network for further improving the detecting accuracy performance. Experimental results on four famous face forgery datasets demonstrate that the proposed framework outperforms other state-of-the-art approaches.;"Forgery face detection;VGG-19;Capsule network;ELU;Attention mechanism";IEEE
647;Digital Image Forensic Analyzer to Detect AI-generated Fake Images;"G. Monkam; J. Yan";2023;In recent years, the widespread use of smartphones and social media has led to a surge in the amount of digital content available. However, this increase in the use of digital images has also led to a rise in the use of techniques to alter image contents. Therefore, it is essential for both the image forensics field and the general public to be able to differentiate between genuine or authentic images and manipulated or fake imagery. Deep learning has made it easier to create unreal images, which underscores the need to establish a more robust platform to detect real from fake imagery. However, in the image forensics field, researchers often develop very complicated deep learning architectures to train the model. This training process is expensive, and the model size is often huge, which limits the usability of the model. This research focuses on the realism of state-of-the-art image manipulations and how difficult it is to detect them automatically or by humans. We built a machine learning model called G-JOB GAN, based on Generative Adversarial Networks (GAN), that can generate state-of-the-art, realistic-looking images with improved resolution and quality. Our model can detect a realistically generated image with an accuracy of 95.7%. Our near future aim is to implement a system that can detect fake images with a probability of odds of 1- P, where P is the chance of identical fingerprints. To achieve this objective, we have implemented and evaluated various GAN architectures such as Style GAN, Pro GAN, and the Original GAN.;"Adversarial Networks;GANs;Classification;CNN;Deep Learning";IEEE
649;Face Morphing Detection in Social Media Content;"A. Agarwal; N. Ratha";2024;"Face being an active medium of communication is a significant part of our social media life; however, faces are vulnerable to manipulations. Among various manipulations, face morphing is a well-known tampering technique that aims to generate images containing information from more than one identity. Morphed images are heavily used for various malicious purposes including sarcasm, money laundering, and pornography. For many of the above harmful purposes, these manipulated images are uploaded on social media platforms where they can further go through tampering using social-media filters. Interestingly, the existing morph attack detection works have not addressed social media�s impact on deceiving face morph detectors. In this research, for the first time, we have generated authentic (or real) and face-morphed images impacted by one of the premium features of social media platforms known as filtering. We have used 13 Instagram filters and performed an extensive study on the proposed social-media morphed dataset. It is demonstrated that these filters can radically reduce the morph detection performances of several popular deep-learning classifiers. Therefore, to effectively address the concerns of face morphing and social media filtering, we propose a robust ViT-CNN architecture to advance the morph image detection performance.";"Digital Threats;Face Morphing;Social-Media Filters;Robust Morph Detector";IEEE
651;Exploring Deepfake Detection: A Comparative Study of CNN Models;"Raveena; R. Chhikara; P. Punyani";2024;The rapid advancement of deep learning methodologies has given rise to worries regarding the misuse of hyper-realistic multimedia due to the introduction of deepfake content created by generative adversarial network (GAN) models. Deepfakes, which include altered audio and/or video clips that are nearly identical to real ones, can be used maliciously for things like propaganda, cybercrimes, and political campaigns. To address this challenge, a comparison is conducted involving several CNN models, like EfficientNetB0, VGG-16, DenseNet121, VGG-19, MobileNetV2, ResNet50, InceptionV3, and Xception for deepfake detection. The models are trained using transfer learning technique and by fine-tuning them on the dataset using various hyperparameters. The performance analysis was performed on six cases in which the optimizer, learning rate, batch size, and epochs were adjusted. By exploring this comparative study, a contribution is made to the development of more robust solutions for detecting deepfakes. A thorough analysis of different pre-trained models is conducted and verified, based on the reported outcomes, ResNet50 outperforms the other models. The evaluation of the model's performance involves the comparison of various metrics that have been identified, such as Accuracy, Precision, AUC-ROC curve, and F1-score.;"Deepfakes;Deep-Learning;Convolution Neural Networks";IEEE
654;Fake Image Detection Using An Ensemble of CNN Models Specialized For Individual Face Parts;"A. Kawabe; R. Haga; Y. Tomioka; Y. Okuyama; J. Shin";2022;With the rapid increase of deep learning technology, creating human face images with artificial intelligence (AI) is becoming easier. Those generated images are coming up to images that humans cannot distinguish from authentic ones. It is essential to realize an accurate method to detect such fake images to avoid abusing them. In this paper, we propose a fake image detection using an ensemble model of convolutional neural network (CNN) models that focus on deepfake detection of individual face parts. Our results show that a combination of deepfake detection based on different face parts is effective. This idea can be adopted on partially manipulated deepfake images/videos.;"deepfake;deep learning;ensemble learning";IEEE
655;A Graph Neural Network Model for Live Face Anti-Spoofing Detection Camera Systems;"J. Xu; W. Lin; W. Fan; J. Chen; K. Li; X. Liu; G. Xu; S. Yi; J. Gan";2024;As the demand for the Internet of Things (IoT) grows, it becomes crucial to possess systems capable of detecting any data leakage used for authentication. Within IoT camera systems based on facial bio-metric recognition, there is a risk of deepfake bypassed facial feature authentication due to the widespread use of deepfake video technologies, such as DeepFaceLive and expression manipulation. Traditional face anti-spoofing (FAS) detection techniques may struggle to detect real-time deepfake videos within IoT contexts. Moreover, constrained by the scale of FAS detection data sets, current detection models primarily focus on recognizing the entire face in videos, neglecting the intercomponent correlations of facial features. However, our investigation indicates that different parts of the face have varying impacts on deepfake detection. To address this issue, we segment the face into several regions within video frames and explore the relationships between these regions. Our approach involves constructing feature graphs that represent such correlations, aiming to leverage the relationships between facial regions and the temporal characteristics of real-time facial manipulation videos for use in live facial detection cameras. Initially, features for each facial region are extracted via convolutional neural networks (CNNs). Subsequently, with these features as vertices and their correlations as edges, a feature graph of the entire video is constructed. Ultimately, a graph neural network (GNN) is employed to determine whether the video has been tampered with. Experiments conducted on several publicly accessible data sets demonstrate that our proposed method outperforms other state-of-the-art FAS detection techniques in most scenarios. Thus, the aforementioned advanced GNN model exhibits exceptional performance in real-time deepfake detection tailored for live facial detection cameras.;"Camera systems;deep learning;graph neural network (GNN);live face anti-spoofing (FAS) detection";IEEE
661;Deepfake video detection using CNN and RNN with OPTICAL FLOW features;"E. M. Sathwik Reddy; A. Pavan Kumar; P. Swetha";2024;"Recent developments in machine learning have produced new technologies that make it simple to produce ""deepfake"" videos�videos with convincing face swaps and minimal evidence of editing. It's easy to imagine scenarios in which these realistic fake videos are exploited to cause violent protests, blackmail someone, or fabricate terrorist incidents. Digital content that has been synthesized is used to create extremely realistic-looking fake videos that fool viewers. Generative Adversarial Networks (GAN), a type of deep generative algorithm, are frequently used to do such tasks. By using this technique, realistic contents are synthesized that are highly challenging for conventional detection techniques to identify. Most of the time, discriminators based on convolutional neural networks (CNNs) are used to identify such modified media. Since the technique primarily concentrates on the spatial characteristics of each frame of video and is unable to learn time-related data obtained from inter-frame interactions, we utilized an optical flow-based feature extraction approach to extract time-related features, which are then used for classification. The foundation of this model is the integration of RNN and CNN with optical flow feature architecture.";"CNN;Resnet50;RNN;LSTM;Optical flow;support vector machine";IEEE
662;Detecting Deepfake Videos using Attribution-Based Confidence Metric;"S. Fernandes; S. Raj; R. Ewetz; J. S. Pannu; S. Kumar Jha; E. Ortiz; I. Vintila; M. Salter";2020;Recent advances in generative adversarial networks have made detecting fake videos a challenging task. In this paper, we propose the application of the state-of-the-art attribution based confidence (ABC) metric for detecting deepfake videos. The ABC metric does not require access to the training data or training the calibration model on the validation data. The ABC metric can be used to draw inferences even when only the trained model is available. Here, we utilize the ABC metric to characterize whether a video is original or fake. The deep learning model is trained only on original videos. The ABC metric uses the trained model to generate confidence values. For, original videos, the confidence values are greater than 0.94.;;IEEE
663;Learning Meta Model for Strong Generalization Deepfake Detection;"D. Huang; Y. Zhang";2024;Although deepfake technology is neutral, it can be maliciously used by criminals to cause serious security issues. These deepfake videos generated by deep learning technology are no different from real videos, posing a major threat to personal privacy and information credibility. Existing deepfake detection models face a core challenge: most models have limited generalization capabilities, and often have unsatisfactory detection results in the face of increasingly complex forgery technologies. To solve this problem, we introduce a two-stream deepfake detection model. One stream leverages the Video Swin Transformer to identify inter-frame discontinuities, a common anomaly in deepfakes. While another stream utilizes deep convolutional neural networks to detect facial texture inconsistencies, another telltale sign of a fake face. Furthermore, we use an improved meta-learning method called meta-learning for deepfake detection (MLDD) to train our model, which enhances the model�s adaptability and ability to quickly learn from multiple deepfake styles. Experimental results demonstrate that our model has superior performance and strong generalization compared to state-of-the-art existing techniques.;"deepafake detection;meta learning;two-stream network;CDC-Xception;video swin transformer";IEEE
664;Multimodaltrace: Deepfake Detection using Audiovisual Representation Learning;"M. Anas Raza; K. Mahmood Malik";2023;By employing generative deep learning techniques, Deepfakes are created with the intent to create mistrust in society, manipulate public opinion and political decisions, and for other malicious purposes such as blackmail, scamming, and even cyberstalking. As realistic deepfake may involve manipulation of either audio or video or both, thus it is important to explore the possibility of detecting deepfakes through the inadequacy of generative algorithms to synchronize audio and visual modalities. Prevailing performant methods, either detect audio or video cues for deepfakes detection while few ensemble the results after predictions on both modalities without inspecting relationship between audio and video cues. Deepfake detection using joint audiovisual representation learning is not explored much. Therefore, this paper proposes a unified multimodal framework, Multimodaltrace, which extracts learned channels from audio and visual modalities, mixes them independently in IntrAmodality Mixer Layer (IAML), processes them jointly in IntErModality Mixer Layers (IEML) from where it is fed to multilabel classification head. Empirical results show the effectiveness of the proposed framework giving state-of-the-art accuracy of 92.9% on the FakeAVCeleb dataset. The cross-dataset evaluation of the proposed framework on World Leaders and Presidential Deepfake Detection Datasets gives an accuracy of 83.61% and 70% respectively. The study also provides insights into how the model focuses on different parts of audio and visual features through integrated gradient analysis.;;IEEE
665;Low-Quality Deepfake Detection via Unseen Artifacts;"S. Chhabra; K. Thakral; S. Mittal; M. Vatsa; R. Singh";2024;The proliferation of manipulated media over the Internet has become a major source of concern in recent times. With the wide variety of techniques being used to create fake media, it has become increasingly difficult to identify such occurrences. While existing algorithms perform well on the detection of such media, limited algorithms take the impact of compression into account. Different social media platforms use different compression factors and algorithms before sharing such images and videos, which amplifies the issues in their identification. Therefore, it has become imperative that fake media detection algorithms work well for data compressed at different factors. To this end, the focus of this article is detecting low-quality fake videos in the compressed domain. The proposed algorithm distinguishes real images and videos from altered ones by using a learned visibility matrix, which enforces the model to see unseen imperceptible artifacts in the data. As a result, the learned model is robust to loss of information due to data compression. The performance is evaluated on three publicly available datasets, namely Celeb-DF, FaceForensics, and FaceForensics++, with three manipulation techniques, viz., Deepfakes, Face2Face, and FaceSwap. Experimental results show that the proposed approach is robust under different compression factors and yields state-of-the-art performance on the FaceForensics++ and Celeb-DF datasets with 97.14% classification accuracy and 74.45% area under the curve, respectively.;"Artifacts;compression;deepfake";IEEE
668;UCF: Uncovering Common Features for Generalizable Deepfake Detection;"Z. Yan; Y. Zhang; Y. Fan; B. Wu";2023;Deepfake detection remains a challenging task due to the difficulty of generalizing to new types of forgeries. This problem primarily stems from the overfitting of existing detection methods to forgery-irrelevant features and method-specific patterns. The latter has been rarely studied and not well addressed by previous works. This paper presents a novel approach to address the two types of overfitting issues by uncovering common forgery features. Specifically, we first propose a disentanglement framework that decomposes image information into three distinct components: forgery-irrelevant, method-specific forgery, and common forgery features. To ensure the decoupling of method-specific and common forgery features, a multi-task learning strategy is employed, including a multi-class classification that predicts the category of the forgery method and a binary classification that distinguishes the real from the fake. Additionally, a conditional decoder is designed to utilize forgery features as a condition along with forgery-irrelevant features to generate reconstructed images. Furthermore, a contrastive regularization technique is proposed to encourage the disentanglement of the common and specific forgery features. Ultimately, we only utilize the common forgery features for the purpose of generalizable deepfake detection. Extensive evaluations demonstrate that our framework can perform superior generalization than current state-of-the-art methods.;;IEEE
674;Digital Image Forgery Detection Using Deep Learning;"B. P. Kumar; V. M. Vinayagam; S. A. Babu; C. Guruparthasarthi; G. Janardhan; M. Deepthi";2024;Image manipulation, falsification, and deepfake production have become major concerns in the era of digital media. In order to combat false information and online fraud, this project seeks to develop a technology that can identify altered or counterfeit photos. In this work, we present a model for detecting image forgeries based on the Xception architecture, which we have combined with a Flask-based web application. The model undergoes 20 epochs of training, with accuracy and loss metrics tracked throughout. The training process reveals a consistent improvement in accuracy, starting at 55% and reaching an impressive 97.7% by the 20th epoch. Validation accuracy follows a similar trend, beginning at 52.29% and reaching 81.92% at the conclusion of training. Concurrently, both training and validation loss values decrease, indicating the model's learning capacity and ability to generalize. The integration of the model into a Flask web application allows users to interact with the forgery detection system. The TensorFlow optimization, utilizing oneAPI Deep Neural Network Library (oneDNN) with AVX and AVX2 instructions, enhances CPU performance during model execution. The Flask web application provides a user-friendly interface for users to submit images and receive real-time predictions on their authenticity. The model's predictions on a sample set demonstrate its efficacy in distinguishing between real and fake images. The confusion matrix further validates the model's performance, highlighting its capability to make accurate classifications.;"Deep Learning;Xception;CNN. Digital image";IEEE
676;Face Forgery Detection Based On Segmentation Network;"Y. Zhou; A. Luo; X. Kang; S. Lyu";2021;Recent progress in facial manipulation technologies have made it hard to distinguish the sophisticated face swapped images/videos. Due to the diversity of generation software and data sources, it is extremely challenging to devise an efficient generality framework. Instead of regarding the detection process as a vanilla binary classification task, we proposed a detection framework based on pixel-level classification. Considering that the acquisition of real pixel-level ground-truth is somehow expensive or even impractical, we proposed a pseudo ground-truth generation pipeline with prior knowledge of facial manipulation. Besides, we added a new module into the neural network to capture frequency clues, while the ablation experiment verified the effectiveness of this module. The experimental results on several public datasets demonstrated that our proposed framework is effective and superior to other existing similar detection networks.;"face swapped images/videos;pixel-level classification;pseudo ground-truth generation;frequency clues";IEEE
677;DeepDistAL: Deepfake Dataset Distillation using Active Learning;"M. S. Rana; M. Nur Nobi; A. Sung";2024;In the rapidly evolving landscape of artificial intelligence (AI), particularly in the Deepfake domain, largescale datasets play a pivotal role in ensuring performance, including the model�s accuracy, robustness, trustworthiness, etc. However, the increasing size and intricacy of the datasets impose a growing demand for computational resources and amplify the cost and duration of model building. To mitigate the challenge, dataset distillation provides a solution. For the Deepfake detection problem, noteworthy datasets such as VDFD, FaceForensics++, DFDC, and Celeb-DF underscore the indispensability of extensive data for ensuring model robustness. Nevertheless, the computational requirement associated with these datasets presents significant obstacles. This paper describes a data distillation method utilizing Active Learning to reduce dataset size while retaining essential data qualities. The proposed method facilitates efficient model training selecting representative samples by capturing the most salient features, thereby enabling effective performance in resource-constrained environments. The study encompasses developing a data distillation algorithm tailored for Deepfake detection, rigorous experimentation with a major Deepfake dataset to validate its efficacy, and a comprehensive comparison of the model performance trained on distilled versus original datasets. Through thorough analysis, we demonstrate the practicality and effectiveness of our proposed method in alleviating computational demands without compromising detection accuracy.;"Deepfake;Dataset Distillation;Active Learning;DeepDistAL;VDFD";IEEE
680;Exposing Fake Faces Through Deep Neural Networks Combining Content and Trace Feature Extractors;"E. Kim; S. Cho";2021;With the breakthrough of computer vision and deep learning, there has been a surge of realistic-looking fake face media manipulated by AI such as DeepFake or Face2Face that manipulate facial identities or expressions. The fake faces were mostly created for fun, but abuse has caused social unrest. For example, some celebrities have become victims of fake pornography made by DeepFake. There are also growing concerns about fake political speech videos created by Face2Face. To maintain individual privacy as well as social, political, and international security, it is imperative to develop models that detect fake faces in media. Previous research can be divided into general-purpose image forensics and face image forensics. While the former has been studied for several decades and focuses on extracting hand-crafted features of traces left in the image after manipulation, the latter is based on convolutional neural networks mainly inspired by object detection models specialized to extract images' content features. This paper proposes a hybrid face forensics framework based on a convolutional neural network combining the two forensics approaches to enhance the manipulation detection performance. To validate the proposed framework, we used a public Face2Face dataset and a custom DeepFake dataset collected on our own. Experimental results using the two datasets showed that the proposed model is more accurate and robust at various video compression rates compared to the previous methods. Throughout class activation map visualization, the proposed framework provided information on which face parts are considered important and revealed the tempering traces invisible to naked eyes.;"Convolutional neural networks;DeepFake;Face2Face;fake face detection;fake face image forensics;multi-channel constrained convolution;transfer learning";IEEE
684;A Comprehensive Evaluation of Fake Face Recognition Scheme using Artificial Intelligence Oriented Learning Scheme;"S. Subashree; R. Rose S; A. S. Valarmathy; P. Joseph; P. J. Dennis; S. Ravi";2024;Fake face recognition has emerged as a critical area of research due to the proliferation of synthetic media and its potential misuse in various domains. This study presents a thorough evaluation of a novel Fake Face Recognition Scheme utilizing Artificial Intelligence Oriented Learning Scheme (AIOLS) coupled with Generative Adversarial Network (GAN)-GoogleNet integration. The aim is to discern authentic facial images from synthetic or tampered ones with high accuracy. In this research, we employed a dataset comprising a diverse range of authentic and synthetic facial images. The proposed scheme incorporates the power of GANs for generating synthetic facial images and leverages GoogleNet, a state-of-the-art deep convolutional neural network, for discriminative feature extraction. The integration within the AIOLS framework facilitates efficient learning and adaptation to complex patterns present in fake facial images. The evaluation of our scheme was conducted through rigorous experimentation on the dataset, employing various performance metrics. Notably, the accuracy obtained was measured at an impressive 96.7%, signifying the effectiveness of our approach in distinguishing between real and fake facial images. Additionally, other metrics such as precision, recall, and F1-score were also computed to provide a comprehensive assessment of the scheme's performance.;"Fake face recognition;Artificial Intelligence Oriented Learning Scheme (AIOLS);GAN-GoogleNet integration;synthetic media;facial image authentication";IEEE
687;Fake Video Detection Model Using Hybrid Deep Learning Techniques;"O. S. A. Aboosh; A. N. Hassan; D. K. Sheet";2023;The world is witnessing great developments daily in the field of graphics and computer vision. Now, it�s possible to create fake videos with very realistic faces. Thus, discrimination between original and fake videos has become a major challenge, which caused serious threats to both the individual and society. Usually, the traditional image forensic technicalities are not appropriate to classify videos because of data compression that damages it. Thus, this research focused on the use of hybrid deep learning models that based on convolutional neural networks (CNN) and recurrent neural networks (RNN) methods for fake video detection. The inceptionV3 model was used to extract facial features from the frames, then these features were used to train simpleRNN and Gated Recurrent Unit (GRU) models to classify video. Most deepfake detection works fails when tested on a new dataset, especially those that are real and close to reality. Therefore, the most realistic dataset which produced �in the wild� was chosen in this research. The deepfake detection challenge (DFDC) dataset was used to evaluate the proposed models. Where these models achieved a high detection accuracy, 98.5% for SimpleRNN and 98.9% for GRU. Also, the models achieved 0.979 and 0.986 of AUC respectively.;"DeepFake;FaceSwap;Face2Face;Gated Recurrent Unit;InceptionV3;Recurrent Neural Network";IEEE
688;End-to-End Reconstruction-Classification Learning for Face Forgery Detection;"J. Cao; C. Ma; T. Yao; S. Chen; S. Ding; X. Yang";2022;Existing face forgery detectors mainly focus on specific forgery patterns like noise characteristics, local textures, or frequency statistics for forgery detection. This causes specialization of learned representations to known forgery patterns presented in the training set, and makes it difficult to detect forgeries with unknown patterns. In this paper, from a new perspective, we propose a forgery detection frame-work emphasizing the common compact representations of genuine faces based on reconstruction-classification learning. Reconstruction learning over real images enhances the learned representations to be aware of forgery patterns that are even unknown, while classification learning takes the charge of mining the essential discrepancy between real and fake images, facilitating the understanding of forgeries. To achieve better representations, instead of only using the encoder in reconstruction learning, we build bipartite graphs over the encoder and decoder features in a multi-scale fashion. We further exploit the reconstruction difference as guidance of forgery traces on the graph output as the final representation, which is fed into the classifier for forgery detection. The reconstruction and classification learning is optimized end-to-end. Extensive experiments on large-scale benchmark datasets demonstrate the superiority of the proposed method over state of the arts.;"Face and gestures; Biometrics";IEEE
690;A Hybrid CNN-LSTM model for Video Deepfake Detection by Leveraging Optical Flow Features;"P. Saikia; D. Dholaria; P. Yadav; V. Patel; M. Roy";2022;Deepfakes are the synthesized digital media in order to create ultra-realistic fake videos to trick the spectator. Deep generative algorithms, such as, Generative Adversarial Networks(GAN) are widely used to accomplish such tasks. This approach synthesizes pseudo-realistic contents that are very difficult to distinguish by traditional detection methods. In most cases, Convolutional Neural Network(CNN) based discriminators are being used for detecting such synthesized media. However, it emphasise primarily on the spatial attributes of individual video frames, thereby fail to learn the temporal information from their inter-frame relations. In this paper, we leveraged an optical flow based feature extraction approach to extract the temporal features, which are then fed to a hybrid model for classification. This hybrid model is based on the combination of CNN and recurrent neural network (RNN) architectures. The hybrid model provides effective performance on open source data-sets such as, DFDC, FF++ and Celeb-DF. This proposed method shows an accuracy of 66.26%,91.21% and 79.49% in DFDC, FF++, and Celeb-DF respectively with a very reduced No of sample size of $\leq 100$ samples(frames). This promises early detection of fake contents compared to existing modalities.;;IEEE
691;Generalizing Face Forgery Detection with High-frequency Features;"Y. Luo; Y. Zhang; J. Yan; W. Liu";2021;Current face forgery detection methods achieve high accuracy under the within-database scenario where training and testing forgeries are synthesized by the same algorithm. However, few of them gain satisfying performance under the cross-database scenario where training and testing forgeries are synthesized by different algorithms. In this paper, we find that current CNN-based detectors tend to overfit to method-specific color textures and thus fail to generalize. Observing that image noises remove color textures and expose discrepancies between authentic and tampered regions, we propose to utilize the high-frequency noises for face forgery detection. We carefully devise three functional modules to take full advantage of the high-frequency features. The first is the multi-scale high-frequency feature extraction module that extracts high-frequency noises at multiple scales and composes a novel modality. The second is the residual-guided spatial attention module that guides the low-level RGB feature extractor to concentrate more on forgery traces from a new perspective. The last is the cross-modality attention module that leverages the correlation between the two complementary modalities to promote feature learning for each other. Comprehensive evaluations on several benchmark databases corroborate the superior generalization performance of our proposed method.;;IEEE
692;Deepfake Video Detection using Neural Networks;"M. Jiwtode; A. Asati; S. Kamble; L. Damahe";2022;Over the past few years, free mobile application tools on Artificial Intelligence and deep learning have made it easy to create reliable face exchanges in a video called �DeepFake� (DF) video that leaves a little hint of traces to check if its fake. Creating a computerized edited video has been demonstrated for quite a long time by actually taking advantage of enhanced visual effects. Recently, Artificial Intelligence has led to a rise in fake content and the ability to access free tools to create it. These purported AI-engineered media are normally called DeepFake(DF). Making a DF with a computerized AI tool is a simple job. However, with regards to identifying this DF, it's a major challenging dispute. Preparing the calculations and training the model to distinguish DF is difficult. The challenge to train an algorithm model to spot the DeepFake (DF) is not simple. We have tried recognizing DF with the use of CNN and RNN. The framework utilizes a CNN for feature extraction at the frame level. The model uses features extracted from the frame level to train the RNN, which then learns to classify videos according to their temporal inconsistencies. Anticipated results, when compared with a large number of hoax videos, were gathered from standard datasets. Using a simple architecture, we will show you how this errand can make your framework accurate.;"Artificial Intelligence;RNN;CNN;Hoax Video Detection;DeepFakes";IEEE
696;Deepfake Detection by Exploiting Surface Anomalies: The Surfake Approach;"A. Ciamarra; R. Caldelli; F. Becattini; L. Seidenari; A. Del Bimbo";2024;"The ever-increasing use of synthetically generated content in different sectors of our everyday life, one for all media information, poses a strong need for deepfake detection tools in order to avoid the proliferation of altered messages. The process to identify manipulated content, in particular images and videos, is basically performed by looking for the presence of some inconsistencies and/or anomalies specifically due to the fake generation process. Different techniques exist in the scientific literature that exploit diverse ad-hoc features in order to highlight possible modifications. In this paper, we propose to investigate how deepfake creation can impact on the characteristics that the whole scene had at the time of the acquisition. In particular, when an image (video) is captured the overall geometry of the scene (e.g. surfaces) and the acquisition process (e.g. illumination) determine a univocal environment that is directly represented by the image pixel values; all these intrinsic relations are possibly changed by the deepfake generation process. By resorting to the analysis of the characteristics of the surfaces depicted in the image it is possible to obtain a descriptor usable to train a CNN for deepfake detection: we refer to such an approach as SurFake. Experimental results carried out on the FF + + dataset for different kinds of deep-fake forgeries and diverse deep learning models confirm that such a feature can be adopted to discriminate between pristine and altered images; furthermore, experiments witness that it can also be combined with visual data to provide a certain improvement in terms of detection accuracy.";;IEEE
697;A video is worth more than 1000 lies. Comparing 3DCNN approaches for detecting deepfakes;"Y. Wang; A. Dantcheva";2020;Manipulated images and videos have become increasingly realistic due to the tremendous progress of deep convolutional neural networks (CNNs). While technically intriguing, such progress raises a number of social concerns related to the advent and spread of fake information and fake news. Such concerns necessitate the introduction of robust and reliable methods for fake image and video detection. Towards this in this work, we study the ability of state of the art video CNNs including 3D ResNet, 3D ResNeXt, and I3D in detecting manipulated videos. We present related experimental results on videos tampered by four manipulation techniques, as included in the FaceForensics++ dataset. We investigate three scenarios, where the networks are trained to detect (a) all manipulated videos, as well as (b) separately each manipulation technique individually. Finally and deviating from previous works, we conduct cross-manipulation results, where we (c) detect the veracity of videos pertaining to manipulation-techniques not included in the train set. Our findings clearly indicate the need for a better understanding of manipulation methods and the importance of designing algorithms that can successfully generalize onto unknown manipulations.;;IEEE
698;Benchmarking Joint Face Spoofing and Forgery Detection With Visual and Physiological Cues;"Z. Yu; R. Cai; Z. Li; W. Yang; J. Shi; A. C. Kot";2024;"Face anti-spoofing (FAS) and face forgery detection play vital roles in securing face biometric systems from presentation attacks (PAs) and vicious digital manipulation (e.g., deepfakes). Despite satisfactory performance upon large-scale data and powerful deep models, recent advances in face spoofing and forgery detection approaches usually focus on 1) unimodal visual appearance or physiological (i.e., remote photoplethysmography (rPPG)) cues; and 2) separated feature representation for FAS or face forgery detection. On one side, unimodal appearance and rPPG features are respectively vulnerable to high-fidelity face 3D mask and video replay attacks, inspiring us to design reliable multi-modal fusion mechanisms for generalized FAS. On the other side, there are rich common features across FAS and face forgery detection tasks (e.g., periodic rPPG rhythms and vanilla appearance for bonafides), providing solid evidence to design a joint FAS and face forgery detection system in a multi-task learning fashion. In this paper, we establish the first joint face spoofing and forgery detection benchmark using both visual appearance and physiological rPPG cues. To enhance the rPPG periodicity discrimination, we design a two-branch physiological network using both facial spatio-temporal rPPG signal map and its continuous wavelet transformed counterpart as inputs. To mitigate the modality bias and improve the fusion efficacy, we conduct a weighted batch and layer normalization for both appearance and rPPG features before multi-modal fusion. We also investigate prevalent deep models, feature fusion strategies and multi-task learning configurations for joint face spoofing and forgery detection. We find that the generalization capacities of both unimodal (appearance or rPPG) and multi-modal (appearance+rPPG) models can be obviously improved via joint training on these two tasks. We hope this new benchmark will facilitate the future research of both FAS and deepfake detection communities.";"Face anti-spoofing;face forgery detection;deepfake;rPPG;fusion;joint training;multi-task learning";IEEE
702;OpenForensics: Large-Scale Challenging Dataset For Multi-Face Forgery Detection And Segmentation In-The-Wild;"T. -N. Le; H. H. Nguyen; J. Yamagishi; I. Echizen";2021;The proliferation of deepfake media is raising concerns among the public and relevant authorities. It has become essential to develop countermeasures against forged faces in social media. This paper presents a comprehensive study on two new countermeasure tasks: multi-face forgery detection and segmentation in-the-wild. Localizing forged faces among multiple human faces in unrestricted natural scenes is far more challenging than the traditional deepfake recognition task. To promote these new tasks, we have created the first large-scale dataset posing a high level of challenges that is designed with face-wise rich annotations explicitly for face forgery detection and segmentation, namely Open-Forensics. With its rich annotations, our OpenForensics dataset has great potentials for research in both deepfake prevention and general human face detection. We have also developed a suite of benchmarks for these tasks by conducting an extensive evaluation of state-of-the-art instance detection and segmentation methods on our newly constructed dataset in various scenarios.;"Datasets and evaluation;Faces;Image and video manipulation detection and integrity methods";IEEE
706;Multimodal Cognitive Learning for Media Forgery Detection: A Comprehensive Framework Combining Random Forest and Deep Ensemble Architectures (Xception, ResNeXt) across Image, Video, and Audio Modalities;"A. Abirami; S. Bhuvaneswari; K. Krithika; I. Nithyasree; B. Prashithaa Abhirami";2023;Deepfake content has become more prevalent in the age of quickly evolving technology, which has significantly undermined the reliability and integrity of digital media. An integrated multimodal deepfake detection system is presented in this study as a response to the ubiquitous threat posed by altered photos, videos, and audio recordings. The image deepfake detection module examines visual data for telltale signs of manipulation using Convolutional Neural Networks (CNNs), Xception, and ResNeXT. This module successfully distinguishes between real and fake photos by carefully examining pixel-level attributes and contextual data. With the use of spatiotemporal CNNs (Xception & ResNeXT), it parses video frames to find minute discrepancies, making it possible to accurately identify deepfake films. This multi-modal system is finished with the addition of deepfake audio detection. This module excels in differentiating between authentic and faked audio recordings using Mel spectrograms and Convolutional Neural Networks, adding to a thorough protection against audio deepfakes. Additionally, a unifying framework has been provided that effectively unifies these three detection modules, boosting the system�s effectiveness and performance as a whole. The solution has been thoroughly assessed using measures like accuracy, F1 score, ROC curve, and AUC, and the model structures for in-depth comprehension. This multi-modal deepfake detection technology acts as a crucial precaution in a time when false information is widely disseminated, enabling consumers to distinguish fact from fiction across numerous media types. This study highlights the importance of integrated solution in maintaining the legitimacy of digital content in today�s information-driven world while also showcasing its technological capability.;"Deepfake detection;Multi-modal system;Image manipulation;Video forgery;Audio spoofing;Convolutional Neural Networks (CNNs);Xception;ResNeXT;Spatiotemporal analysis;Mel spectrograms;F1 score;ROC curve;AUC";IEEE
707;Detecting Deepfakes using CNN and LSTM;"R. Chinchalkar; R. Sinha; M. Kumar; N. Chauhan; S. Deokar; S. Gonge";2023;"Deepfake, a face-swapping method that has been abused recently, has caused a great deal of public worry. Effective countermeasures are required because several deepfake videos, sometimes known as ""deepfakes,"" have already been created and posted online. Therefore, Deepfake detection is going to be a promising defense against deep fakes. It is quite easy to imagine cases in which these convincing tampered videos are exploited to foment political unrest, extort money, or stage terrorist attacks. In this study, a pipeline is suggested for identifying and classifying deepfake videos. Our system uses convolutional neural networks (CNNs) to retrieve frame-level characteristics. Then, a recurrent neural network (RNN-LSTM) is built using these features to determine if a video has been altered or not. We study, analyze and compare various methodologies and ours on a vast cluster of deep fake videos from various video sources. We present how our system can complete this task effectively with comparative results while utilizing a straight forward architecture.";"deepfakes;facial manipulation;deep learning";IEEE
710;Convolutional Neural Network Based on Diverse Gabor Filters for Deepfake Recognition;"A. H. Khalifa; N. A. Zaher; A. S. Abdallah; M. W. Fakhr";2022;Media synthesis and manipulation has reached unprecedented levels of realism owing to the proliferation of deep learning. Deepfake has been the de-facto tool for media manipulation. Although this technology has potential in the entertainment industry, its threats include political manipulation and bypassing biometric security systems. As a result, deepfake detection has garnered widespread attention among research communities. The intuition is to use deep learning to fix the problems created by deep learning. Although convolutional neural networks have shown their dominance in the filed of pattern recognition, the receptive field-model size dilemma still persists along with the lack of interpretation for such models. While the traditional Gabor function was proposed to fix these problems, it can only generate limited linear Gabor filters which makes it optimal for limited data and applications. The contribution of this paper is quadruple: (i) proposing a unified Gabor function capable of generating linear, elliptical, and circular Gabor filters. (ii) leveraging the back-propagation learning framework to incorporate the proposed function in convolutional neural networks and generate adaptive Gabor filters. (iii) presenting a dual scale large receptive field network for deepfake image recognition. (iv) demonstrating where the proposed model stands in terms of performance and architecture size compared to state-of-the-art models. The proposed model is evaluated on four benchmark datasets: Celeb-DF (v2), DeepFake Detection Challenge Preview, FaceForensics++ and Wilddeepfake. Experimental results show that the proposed adaptive Gabor filters reduce the model size by 64.9% compared to adaptive weighted filters without performance reduction.;"Compact neural networks;image classification;image forensics;learnable filters;pattern recognition";IEEE
712;Classification of Deepfake Videos Using Pre-trained Convolutional Neural Networks;"M. Masood; M. Nawaz; A. Javed; T. Nazir; A. Mehmood; R. Mahum";2021;The advancement of Artificial Intelligence (AI) has brought a revolution in the field of information technology. Furthermore, AI has empowered the new applications to run with minimum resources and computational cost. One of such applications is Deepfakes, which produces extensively altered and modified multimedia content. However, such manipulated visual data imposed a severe threat to the security and privacy of people and can cause massive sect, religious, political, and communal stress around the globe. Now, the face-swapped base visual content is difficult to recognizable by humans through their naked eyes due to the advancement of Generative adversarial networks (GANs). Therefore, identifying such forgeries is a challenging task for the research community. In this paper, we have introduced a pipeline for identifying and detecting person faces from input visual samples. In the second step, several deep learning (DL) based approaches are employed to compute the deep features from extracted faces. Lastly, a classifier namely SVM is trained over these features to classify the data as real or manipulated. We have performed the performance comparison of various feature extractors and confirmed from reported results that DenseNet-169 along with SVM classifier outperforms the rest of the methods.;"deepfakes;deep-learning;visual manipulations;convolutional neural networks";IEEE
716;Deepfake: Classifiers, Fairness, and Demographically Robust Algorithm;"A. Agarwal; N. Ratha";2024;Deepfake detection research has seen tremendous success and has achieved remarkably high performance on a few existing datasets. However, the significant drawback of the existing works is the generalizability of the detection algorithms under cross-datasets and cross-attack/manipulation settings. On top of that, another critical bottleneck of deepfake detection literature is the understanding of the fairness quotient of these algorithms. One big reason for such a less explored domain is the unavailability of deep fake datasets covering multiple ethnicities and genders with proper annotations. For example, the popular deepfake detection datasets such as FaceForensics++ and Celeb-DF are highly biased toward Caucasian ethnicity. Recently, a multi-ethnicity multi-modal dataset namely FakeAVCeleb has been released which can fulfill this gap. Henceforth by utilizing the potential of this dataset, we have performed the fairness study of deepfake detection algorithms. For that, several image classifiers are selected which range from deep convolutional neural networks to handcrafted image feature extraction to vision transformers. The experiments performed using such a wide variety of classifiers reveal that the deepfake detectors are not fair and can detect one ethnicity with high accuracy but fail miserably on others. For instance, the performance of one of the popular deepfake detection networks namely XceptionNet shows a reduction of more than 30% when dealing with different ethnicities and genders. Not only ethnicity or gender but also the type of classifiers have a huge impact on the performance. We assert that the proposed study can help in building a fair, robust, and accurate deepfake classifier utilizing insightful findings that can help in the selection of an effective and robust backbone architecture.;;IEEE
717;Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection;"A. Haliassos; R. Mira; S. Petridis; M. Pantic";2022;"One of the most pressing challenges for the detection of face-manipulated videos is generalising to forgery methods not seen during training while remaining effective under common corruptions such as compression. In this paper, we examine whether we can tackle this issue by harnessing videos of real talking faces, which contain rich information on natural facial appearance and behaviour and are readily available in large quantities online. Our method, termed RealForensics, consists of two stages. First, we exploit the natural correspondence between the visual and auditory modalities in real videos to learn, in a self-supervised cross-modal manner, temporally dense video representations that capture factors such as facial movements, expression, and identity. Second, we use these learned representations as targets to be predicted by our forgery detector along with the usual binary forgery classification task; this encourages it to base its real/fake decision on said factors. We show that our method achieves state-of-the-art performance on cross-manipulation generalisation and robustness experiments, and examine the factors that contribute to its per-formance. Our results suggest that leveraging natural and unlabelled videos is a promising direction for the development of more robust face forgery detectors.";"Computer vision for social good; Face and gestures; Representation learning; Self-& semi-& meta- Video analysis and understanding";IEEE
718;A Deepfake Face Video Authentication Method Based on Spatio-temporal Fusion Features;"B. Li; S. Zhou; Z. Zhang; J. Yin";2023;With the wide spread of deepfake face videos, it has brought huge hidden dangers of trust to national security and social stability. In this paper, the authentication model framework of deepfake face video with spatio-temporal fusion features is proposed. Through three improvements including collecting mixed training samples, training two 2D deep convolutional neural networks with face center clipping images and using 3D deep convolutional neural networks to utilize the inter-frame consistency information, the authentication success rate of deepfake face video is improved. In the experiment two video forgery methods FaceSwap and Deepfakes were selected in the Faceforences ++ dataset to identify the deepfake video of facial feature area and facial edge area, which obtained certain results. Further breakthroughs are expected in the future through the integration of multi-modal data features and the use of large-scale pre-trained models.;"deepfakes;face video authentication;spatio-temporal fusion;mixed training samples";IEEE
719;BiHPF: Bilateral High-Pass Filters for Robust Deepfake Detection;"Y. Jeong; D. Kim; S. Min; S. Joe; Y. Gwon; J. Choi";2022;The advancement in numerous generative models has a two-fold effect: a simple and easy generation of realistic synthesized images, but also an increased risk of malicious abuse of those images. Thus, it is important to develop a generalized detector for synthesized images of any GAN model or object category, including those unseen during the training phase. However, the conventional methods heavily depend on the training settings, which cause a dramatic decline in performance when tested with unknown domains. To resolve the issue and obtain a generalized detection ability, we propose Bilateral High-Pass Filters (BiHPF), which amplify the effect of the frequency-level artifacts that are generally found in the synthesized images of generative models. Also, to find the properties of the general frequency-level artifacts, we develop an additional method to adversarially extract the artifact compression map. Numerous experimental results validate that our method outperforms other state-of-the-art methods, even when tested with unseen domains.;"Vision Systems and Applications Deep Learning -> Adversarial Learning; Adversarial Attack and Defense Methods; Deep Learning -> Neural Generative Models; Autoencoders; GANs; Security/Surveillance";IEEE
721;Identifying Deepfake Faces with ResNet50-Keras using Amazon EC2 DL1 Instances powered by Gaudi Accelerators from Habana Labs;"S. Pradhan; R. Shah; R. Shah; A. Goenka";2022;With the emergence of deepfake technology, it has become exponentially more difficult to identify real content from the artificially generated on social media. To counter the ill-effects of online deepfake content, we propose an application to predict if a given facial image is real or generated virtually via deepfake technology. We train a custom ResNet50-Keras model on the new AWS EC2 DL1 Instances powered by Gaudi accelerators developed by Habana Labs (an Intel company) and integrate the instance with Amazon's S3 bucket. With the model saved as an h5 file, we make a RestAPI using FastAPI. The API takes an input image, converts it into a JSON request, and passes it to the backend. Faces extracted from these images are passed through various pre-processing methods and finally to the model that classifies them to be either a deepfake or not and generates a face mesh accordingly. The model combines the processed faces into a single image sent back as a response to the client that changes the stateHooks to display the desired result. Further, we have summarized the results obtained when detecting such manipulated images.;"habana;gaudi;aws ec2 dl1;resnet50;faceforensics;tensorflow;keras;deepfake;mediapipe;facial landmark;react;fastapi;restful api";IEEE
722;Celeb-DF: A Large-Scale Challenging Dataset for DeepFake Forensics;"Y. Li; X. Yang; P. Sun; H. Qi; S. Lyu";2020;AI-synthesized face-swapping videos, commonly known as DeepFakes, is an emerging problem threatening the trustworthiness of online information. The need to develop and evaluate DeepFake detection algorithms calls for datasets of DeepFake videos. However, current DeepFake datasets suffer from low visual quality and do not resemble DeepFake videos circulated on the Internet. We present a new large-scale challenging DeepFake video dataset, Celeb-DF, which contains 5,639 high-quality DeepFake videos of celebrities generated using improved synthesis process. We conduct a comprehensive evaluation of DeepFake detection methods and datasets to demonstrate the escalated level of challenges posed by Celeb-DF.;;IEEE
726;Faceswap Deepfakes Detection using Novel Multi-directional Hexadecimal Feature Descriptor;"Qurat-ul-ain; A. Javed; K. Mahmood Malik";2022;"With the growing number of sophisticated deep learning algorithms and fake video generation applications, it is now possible to create highly realistic deepfake videos. Faceswap is the most commonly employed deepfakes approach, which is challenging to detect due to variations in the facial skin tone, illumination conditions, presence of accessories like glasses on the face, compression artifacts, etc. Existing local texture descriptors have achieved better performance on face recognition applications; however, they compute only the limited directional information while ignoring the magnitude details. This motivated us to develop a robust local texture descriptor to extract more directional and magnitude details from the adjacent pixels to effectively represent the video frames. For this purpose, we proposed a robust multi-directional hexadecimal feature descriptor (MDHFD) by combining the local hexadecimal pattern (LHeXDP) and Local Adjacent Neighborhood Magnitude Pattern (LANMP). LHeXDP calculates the orientation-based pattern by computing 1st- and 2nd-order derivatives at 0�, 45�, 90�, and 135� angles from each center pixel. LANMP computes the magnitude information from each central pixel to its adjacent pixels in horizontal, vertical, diagonal, and diagonal-back directions. Histograms of both the LHeXDP and LANMP are fused to compute a multi-directional feature vector, which is used to train a support vector machine to classify between the original or faceswap deepfakes video. We measured the performance of our system on the challenging faceswap subset of a diverse and large-scale Face Forensic++ and World Leaders datasets. Experimental results illustrate that the proposed method outperforms state-of-art methods for the detection of faceswap deepfakes.";"Deepfakes;faceswap;LHeXDP;LANMP;magnitude-based patterns;orientation-based patterns;SVM";IEEE
727;Detection Enhancement for Various Deepfake Types Based on Residual Noise and Manipulation Traces;"J. Kang; S. -K. Ji; S. Lee; D. Jang; J. -U. Hou";2022;As deepfake techniques become more sophisticated, the demand for fake facial image detection continues to increase. Various deepfake detection techniques have been introduced but detecting all types of deepfake images with a single model remains challenging. We propose a technique for detecting various types of deepfake images using three common traces generated by deepfakes: residual noise, warping artifacts, and blur effects. We adopted a network designed for steganalysis to detect pixel-wise residual-noise traces. We also consider landmarks, which are the primary parts of the face where unnatural deformations often occur in deepfake images, to capture high-level features. Finally, because the effect of a deepfake is similar to that of blurring, we apply features from various image quality measurement tools that can capture traces of blurring. The results demonstrate that each detection strategy is efficient, and that the performance of the proposed network is stable and superior to that of existing detection networks on datasets of various deepfake types.;"Deepfake forensics;image forensics;residual noise;warping artifact;image quality measurement";IEEE
733;CYBORG: Blending Human Saliency Into the Loss Improves Deep Learning-Based Synthetic Face Detection;"A. Boyd; P. Tinsley; K. Bowyer; A. Czajka";2023;Can deep learning models achieve greater generalization if their training is guided by reference to human perceptual abilities? And how can we implement this in a practical manner? This paper proposes a training strategy to ConveY Brain Oversight to Raise Generalization (CYBORG). This new approach incorporates human-annotated saliency maps into a loss function that guides the model�s learning to focus on image regions that humans deem salient for the task. The Class Activation Mapping (CAM) mechanism is used to probe the model�s current saliency in each training batch, juxtapose this model saliency with human saliency, and penalize large differences. Results on the task of synthetic face detection, selected to illustrate the effectiveness of the approach, show that CYBORG leads to significant improvement in accuracy on unseen samples consisting of face images generated from six Generative Adversarial Networks across multiple classification network architectures. We also show that scaling to even seven times the training data, or using non-human-saliency auxiliary information, such as segmentation masks, and standard loss cannot beat the performance of CYBORG-trained models. As a side effect of this work, we observe that the addition of explicit region annotation to the task of synthetic face detection increased human classification accuracy. This work opens a new area of research on how to incorporate human visual saliency into loss functions in practice. All data, code and trained models used in this work are offered with this paper.;"Algorithms: Biometrics;face;gesture;body pose;Machine learning architectures;formulations;and algorithms (including transfer;low-shot;semi-;self-;and un-supervised learning);Psychology and cognitive science";IEEE
734;Demystifying deepfakes using deep learning;"R. K. Singh; P. V. Sarda; S. Aggarwal; D. K. Vishwakarma";2021;Manipulation of images, videos and audios using face edit apps and web services have long been in use, since decades but recent advances in deep learning has led to rising AI generated fake images and videos with swapped faces, lip synced audios and puppet masters, popularly known as Deepfakes. Generated primarily using one of the following two approaches namely, Autoencoders and Generator Adversarial Networks which rests on trained deep neural networks, deepfakes offer unprecedented challenges. The degree of realism achieved by deep learning powered deepfakes increases with increasing amounts of data i.e, fake images and videos readily available on the internet at disposal to train GANs. Deepfake algorithms create media leaving a bare margin of difference between the authentic or original source and the forged or deepfaked targets. Thus, new mechanisms and techniques to detect and filter out such deepfakes is the need of the hour.This paper exploits two powerful deep learning based CNN architectures namely, Inception-Resnet-v2 and XceptionNet for detecting the deepfakes. The proposed approach not only outshines the existing approaches in terms of efficiency and accuracy but also offers the best in terms of the given space and time complexity.;"Auto-encoders;DFDC;FaceForensics++;GAN;Inception-ResNet-v2;MesoNet;XceptionNet";IEEE
735;IIN-FFD: Intra-Inter Network for Face Forgery Detection;"Q. Zhou; Z. Zhou; Z. Bao; W. Niu; Y. Liu";2024;Since different kinds of face forgeries leave similar forgery traces in videos, learning the common features from different kinds of forged faces would achieve promising generalization ability of forgery detection. Therefore, to accurately detect known forgeries while ensuring high generalization ability of detecting unknown forgeries, we propose an intra-inter network (IIN) for face forgery detection (FFD) in videos with continual learning. The proposed IIN mainly consists of three modules, i.e., intra-module, inter-module, and forged trace masking module (FTMM). Specifically, the intra-module is trained for each kind of face forgeries by supervised learning to extract special features, while the inter-module is trained by self-supervised learning to extract the common features. As a result, the common and special features of the different forgeries are decoupled by the two feature learning modules, and then the decoupled common features can be utlized to achieve high generalization ability for FFD. Moreover, the FTMM is deployed for contrastive learning to further improve detection accuracy. The experimental results on FaceForensic++ dataset demonstrate that the proposed IIN outperforms the state-of-the-arts in FFD. Also, the generalization ability of the IIN verified on DFDC and Celeb-DF datasets demonstrates that the proposed IIN significantly improves the generalization ability for FFD.;"deep learning;information security;image classfication;neural networks;face forgery;face forgery detection";IEEE
736;Deep Learning model-based Multimedia forgery detection;"Y. Shah; P. Shah; M. Patel; C. Khamkar; P. Kanani";2020;Images and videos can be spread very conveniently using social media platforms like WhatsApp and Facebook. The authenticity of this information cannot be verified easily but it spreads swiftly. Fake images or videos are a new threat for people as they spread false information and rumors. Advances in technology have given rise to several techniques that can easily generate fake images or videos. Deepfakes and spliced images are some of the results of such advances. They pose a great menace to the internet Tackling and detecting such an entity is a tricky task. Our paper portrays a technique to detect such entities. It will assist people in detecting bogus content and have confidence on the legitimacy of the content on the internet We present a description of CNN based approach and evaluate its results. The drawbacks of the traditional approach have been minimized using Inception Residual Network architecture based CNNs.;"Deepfake;Convolutional Neural Networks;error level analysis;fake images;Inception Networks;Residual Networks";IEEE
737;Analysis and Comparison of Deepfakes Detection Methods for Cross-Library Generalisation;"C. Wang; H. Sharifzadeh; S. Varastehpour; I. Ardekani";2023;The rise of generative artificial intelligence (GenAI) has made it increasingly possible to use Deepfakes technology to generate fake pictures and videos. While this technology has benefits, it also has downsides such as spreading misinformation and endangering public interests. To address this issue, researchers have proposed various deep forgery detection algorithms and have achieved remarkable results. However, a common problem regarding these detection methods is that while in-library detection can usually achieve high accuracy, their performance is significantly degraded in cross-library detection. This indicates a severe problem of insufficient generalisation ability.To better compare the performance differences between various detection methods, this paper analyses the detection performance of the six established models of Two-stream, MesoNet, HeadPose, FWA, VA, and Multi-task. To ensure consistency, we employ a uniform evaluation framework as a benchmark for comparison. We conduct extensive intra-library and cross-library tests to evaluate these methods� generalisation ability by utilising accuracy and error rate as key evaluation criteria for our experiments. Additionally, we further explore areas for improvement by analysing the impact of data augmentation, dataset partitioning, and threshold selection on the performance of these detection methods. Our comparative experiments are conducted on three existing fake face video datasets, including FaceForensics++, DeepfakeTIMIT, and Celeb-DF.Our research findings indicate the database partitioning method has a direct impact on the detector�s performance, and to enhance generalisation performance, the database should be divided person-based manually. The effectiveness of data augmentation techniques in improving cross-library performance is generally limited, and setting the threshold directly using source domain data often leads to a high error rate in the target domain. The findings of this paper provide insights into the development of more effective detection methods to combat the harmful effects of Deepfakes.;"Deepfakes;Detection Methods;Generalisation;Cross-Library";IEEE
738;How Do the Hearts of Deep Fakes Beat? Deep Fake Source Detection via Interpreting Residuals with Biological Signals;"U. A. Ciftci; ?. Demir; L. Yin";2020;Fake portrait video generation techniques have been posing a new threat to the society with photorealistic deep fakes for political propaganda, celebrity imitation, forged evidences, and other identity related manipulations. Following these generation techniques, some detection approaches have also been proved useful due to their high classification accuracy. Nevertheless, almost no effort was spent to track down the source of deep fakes. We propose an approach not only to separate deep fakes from real videos, but also to discover the specific generative model behind a deep fake. Some pure deep learning based approaches try to classify deep fakes using CNNs where they actually learn the residuals of the generator. We believe that these residuals contain more information and we can reveal these manipulation artifacts by disentangling them with biological signals. Our key observation yields that the spatiotemporal patterns in biological signals can be conceived as a representative projection of residuals. To justify this observation, we extract PPG cells from real and fake videos and feed these to a state-of-the-art classification network for detecting the generative model per video. Our results indicate that our approach can detect fake videos with 97.29% accuracy, and the source model with 93.39% accuracy.;;IEEE
739;Learning Patch-Channel Correspondence for Interpretable Face Forgery Detection;"Y. Hua; R. Shi; P. Wang; S. Ge";2023;Beyond high accuracy, good interpretability is very critical to deploy a face forgery detection model for visual content analysis. In this paper, we propose learning patch-channel correspondence to facilitate interpretable face forgery detection. Patch-channel correspondence aims to transform the latent features of a facial image into multi-channel interpretable features where each channel mainly encoders a corresponding facial patch. Towards this end, our approach embeds a feature reorganization layer into a deep neural network and simultaneously optimizes classification task and correspondence task via alternate optimization. The correspondence task accepts multiple zero-padding facial patch images and represents them into channel-aware interpretable representations. The task is solved by step-wisely learning channel-wise decorrelation and patch-channel alignment. Channel-wise decorrelation decouples latent features for class-specific discriminative channels to reduce feature complexity and channel correlation, while patch-channel alignment then models the pairwise correspondence between feature channels and facial patches. In this way, the learned model can automatically discover corresponding salient features associated to potential forgery regions during inference, providing discriminative localization of visualized evidences for face forgery detection while maintaining high detection accuracy. Extensive experiments on popular benchmarks clearly demonstrate the effectiveness of the proposed approach in interpreting face forgery detection without sacrificing accuracy. The source code is available at https://github.com/Jae35/IFFD.;"Face forgery detection;interpretable representation learning;patch-channel correspondence";IEEE
740;Detecting Manipulated Facial Videos: A Time Series Solution;"Z. Zhang; C. Mal; B. Ding; M. Gao";2021;We propose a new method to expose fake videos based on a time series solution. The method is based on bidirectional long short-term memory (Bi-LSTM) backbone architecture with two different types of features: Face-Alignment and Dense-Face-Alignment, in which both of them are physiological signals that can be distinguished between fake and original videos. We choose 68 landmark points as the feature of Face-Alignment and Pose Adaptive Feature (PAF) for Dense-Face-Alignment. Based on these two facial features, we designed two deep networks. In addition, we optimize our network by adding an attention mechanism that improves detection precision. Our method is tested over benchmarks of Face Forensics/Face Forensics++ dataset and show a promising performance on inference speed while maintaining accuracy with state-of art solutions that deal against DeepFake.;"face manipulation detection;image/video analysis;deep learning;pattern recognization";IEEE
743;Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to Adversarial Examples;"S. Hussain; P. Neekhara; M. Jere; F. Koushanfar; J. McAuley";2021;Recent advances in video manipulation techniques have made the generation of fake videos more accessible than ever before. Manipulated videos can fuel disinformation and reduce trust in media. Therefore detection of fake videos has garnered immense interest in academia and industry. Recently developed Deepfake detection methods rely on Deep Neural Networks (DNNs) to distinguish AI-generated fake videos from real videos. In this work, we demonstrate that it is possible to bypass such detectors by adversarially modifying fake videos synthesized using existing Deepfake generation methods. We further demonstrate that our adversarial perturbations are robust to image and video compression codecs, making them a real-world threat. We present pipelines in both white-box and black-box attack scenarios that can fool DNN based Deepfake detectors into classifying fake videos as real.;;IEEE
744;Transformer And Node-Compressed Dnn Based Dual-Path System For Manipulated Face Detection;"Z. Luo; S. -I. Kamata; Z. Sun";2021;"Deep neural networks (DNNs) have extensively promoted data generation development; the quality of these generated content has achieved an impressive new level. Therefore, manipulated content, especially facial manipulation, is a growing concern for online information legitimacy. Most current deep learning-based methods depend on local features sampled by convolutional kernels and lack knowledge globally. To address the problem, we propose a dual-path pipeline using Neural Ordinary Differential Equations (NODE) based neural network and facial-feature biased transformer to deal with the visual content from a different view. The transformer path could link these landmarks in a long-range, moreover, we adopt an attention guided augmentation based self-ensemble for more robust performance. Extensive experiments show that our system could surpass several commonly used approaches in terms of video-level accuracy and AUC with better interpretability.";"Image forensics;DeepFake detection;neural network;face manipulation";IEEE
745;Lips Don't Lie: A Generalisable and Robust Approach to Face Forgery Detection;"A. Haliassos; K. Vougioukas; S. Petridis; M. Pantic";2021;Although current deep learning-based face forgery detectors achieve impressive performance in constrained scenarios, they are vulnerable to samples created by unseen manipulation methods. Some recent works show improvements in generalisation but rely on cues that are easily corrupted by common post-processing operations such as compression. In this paper, we propose LipForensics, a detection approach capable of both generalising to novel manipulations and withstanding various distortions. LipForensics targets high-level semantic irregularities in mouth movements, which are common in many generated videos. It consists in first pretraining a spatio-temporal network to perform visual speech recognition (lipreading), thus learning rich internal representations related to natural mouth motion. A temporal network is subsequently finetuned on fixed mouth embeddings of real and forged data in order to detect fake videos based on mouth movements without overfitting to low-level, manipulation-specific artefacts. Extensive experiments show that this simple approach significantly surpasses the state-of-the-art in terms of generalisation to unseen manipulations and robustness to perturbations, as well as shed light on the factors responsible for its performance.;;IEEE
746;DeepFake Image Detection Using Adaptive Discriminator Augmentation (ADA);"D. A. Talib; A. A. Abed";2023;The proliferation of Deepfake technology, driven by artificial intelligence (AI), poses a growing threat as it facilitates the dissemination of hate speech and misinformation through convincingly fabricated images. Deepfakes, a subdomain of AI, manipulate and superimpose one person's face onto another's, exploiting the power of machine learning to create deceptive content at an unprecedented pace and affordability. Despite the controversial nature of Deepfakes, their use is expanding both commercially and collectively. This paper offers an in-depth investigation into the effectiveness of StyleGAN2-ADA in identifying fake images, with a particular focus on detecting Deepfakes. We propose a novel GAN Discriminator model designed to enhance the accuracy of this detection process. Our model's training dataset comprises an extensive collection of 76,400 images from the FFHQ dataset. In our experimental evaluation, we subjected our model to 100 fake images, achieving an impressive detection rate of 95.71 %. This remarkable outcome underscores the efficacy of our approach in identifying Deepfakes. Furthermore, our technique demonstrates exceptional precision in distinguishing between real and fake images, promising a robust defense against the harmful impact of AI-generated fake content.;"DeepFake images;Detection Fake;Image datasets;StyleGAN2-ADA;Adaptive Discriminator Augmentation";IEEE
748;Towards the Detection of AI-Synthesized Human Face Images;"Y. Lu; T. Ebrahimi";2024;Over the past years, image generation and manipulation have achieved remarkable progress due to the rapid development of generative AI based on deep learning. Recent studies have devoted significant efforts to address the problem of face image manipulation caused by deepfake techniques. However, the problem of detecting purely synthesized face images has been explored to a lesser extent. In particular, the recent popular Diffusion Models (DMs) have shown remarkable success in image synthesis. Existing detectors struggle to generalize between synthesized images created by different generative models. In this work, a comprehensive benchmark including human face images produced by Generative Adversarial Networks (GANs) and a variety of DMs has been established to evaluate both the generalization ability and robustness of state-of-the-art detectors. Then, the forgery traces introduced by different generative models have been analyzed in the frequency domain to draw various insights. The paper further demonstrates that a detector trained with frequency representation can generalize well to other unseen generative models.;"Synthetic face image;detection;GANs;diffusion models;frequency analysis";IEEE
749;AI vs. Human Vision: A Comparative Analysis for Distinguishing AI-Generated and Natural Images;"R. Purohit; Y. Sane; D. Vaishampayan; S. Vedantam; M. Singh";2024;Today�s data-driven generation has led to remarkable advancements in technology. However, as there are two sides to a coin, technology too has both its advantages and disadvantages. The expansion of AI has given rise to �Deepfake� which involves skillful superimposing of person�s face with another person�s face which is very dangerous and it is used to produce morphed images and disseminate fake videos which has led to cyberbullying, financial fraud and cybersecurity risks. Our goal is to correctly determine authentic images by classifying them into AI generated v/s real images.We have used �PyGoogle� image library for creation of dataset for AI images and for the real image dataset we have used our own camera to capture real images. We have used CNN model on both the dataset and observed that accuracy of Google images dataset is 88 percent and that of the own dataset is 81 percent. For evaluating the performance of our model we have created Confusion Matrix for the same.;"AI images;Image Classification;CNN";IEEE
752;Detection of Synthesized Videos using CNN;"R. V. Saraswathi; M. Gadwalkar; S. S. Midhun; G. N. Goud; A. Vidavaluri";2022;Deepfake refers to changing a person's face or their facial emotions. Many fake videos are being overused and going viral in a matter of seconds. Deep learning is used to generate fake videos and images. Deepfakes are synthetic media in which the people who appear there are not real. Increasingly sophisticated technology makes it difficult to distinguish between real and fake videos and images. This will make both men and women more concerned about their safety. It is essential to create a model that can distinguish between real and fake videos in order to maintain and respect everyone's right to privacy. In this research, a Deep Learning Approach is used to offer a framework to identify these Deepfake's, a convolutional neural network architecture will be trained using a database of faces that were taken out of a mixed dataset.;"Deepfake;ResNext;Long Short-Term Memory;Convolutional Neural Network";IEEE
754;SDHF: Spotting DeepFakes with Hierarchical Features;"T. Liang; P. Chen; G. Zhou; H. Gao; J. Liu; Z. Li; J. Dai";2020;DeepFake videos are widely distributed on social media platforms, which has seriously affected the authenticity of digital media content, calling for robust DeepFake detection methods. Although numerous detection methods are formulated as frame-based binary classification, less attention has been paid to aggregate the features over individual frames to get a video-based judgement. We observed that for the detection of DeepFake videos, three different level forgery features from frame, clip and video can complement each other. We also found that discrete, large interval sampling strategy is more suitable for DeepFake detection, which can sample more complex video scenes, including multiple subjects, diverse facial expressions and head poses. In this work, we propose a hierarchical framework, using 2D convolutional neural networks for frame-level features extraction followed by a 1D convolutional aggregator to extract clip-level and video-level features, which can comprehensively exploit three different levels of features to make decisions. Evaluation was performed on four datasets, including DFDC, Celeb-DF, FaceForensics++ and UADFV, which provides competitive results compared to other methods. Experimental results of cross-test demonstrate that our hierarchical framework has excellent generalization performance in the face of unknown datasets.;"DeepFake detection;Hierarchical features";IEEE
756;LIED: A Lightweight and Ensemble learning approach for fake face Detection;"R. Budhiraja; M. Kumar; M. K. Das; A. S. Bafila; S. Singh";2023;For many years, machine learning problems have primarily been driven by the availability and quality of data. Being the key, data has been equally vulnerable and got a savior in the form of generative adversarial networks (GANs) which opened the floodgates for generating almost any type of real, yet synthetic data. Human face became one of the initial victims to this superior technology, where in highly realistic and convincing fake content is generated using deep learning technologies or ��DeepFakes��. Taking a giant leap forward from manipulating facial attributes, to be now able to swap expressions seamlessly and even generate new (non-existent) synthetic faces poses a grave threat not only to chosen few, but for the entire society. This upshoot has been reciprocated with significant efforts and investments for its detection, but the techniques are often marred with either lower accuracies, or, higher computation costs. This is where convolutional reservoir networks (CoRN) come to rescue owing to their lightweight nature, able to do ensemble feature extraction and its generalization ability. This paper investigates, implements and demonstrates the application of CoRN based architectures to the task of human fake face detection. The steep performance improvements as evident from our results further ratify the effectiveness of this approach, which is also shown to perform exceedingly well against smaller datasets.;"DeepFake Detection;Fake Face Detection;Convolutional Reservoir Networks;Convolution Neural Networks;Reservoir Computing;Ensemble Feature Extraction";IEEE
757;On the Vulnerability of Deepfake Detectors to Attacks Generated by Denoising Diffusion Models;"M. Ivanovska; V. �truc";2024;The detection of malicious deepfakes is a constantly evolving problem that requires continuous monitoring of de-tectors to ensure they can detect image manipulations gen-erated by the latest emerging models. In this paper, we in-vestigate the vulnerability of single-image deepfake detec-tors to black-box attacks created by the newest generation of generative methods, namely Denoising Diffusion Models (DDMs). Our experiments are run on FaceForensics++, a widely used deepfake benchmark consisting of manipulated images generated with various techniques for face iden-tity swapping and face reenactment. Attacks are crafted through guided reconstruction of existing deepfakes with a proposed DDM approach for face restoration. Our findings indicate that employing just a single denoising diffusion step in the reconstruction process of a deepfake can signif-icantly reduce the likelihood of detection, all without intro-ducing any perceptible image modifications. While training detectors using attack examples demonstrated some effectiveness, it was observed that discriminators trained on fully diffusion-based deepfakes exhibited limited generalizability when presented with our attacks.;;IEEE
758;Revealing Image Deepfakes: A Convolutional Neural Network Approach Leveraging VGG-16 Mode;"V. Ajay Kumar; S. Birudu; K. Sirisha; B. Chaitanya Mouli; K. Hemanth; P. Adesh";2024;Digital image forgery has become a prevalent issue in modern technology-driven sphere, where sophisticated editing tools allow malicious users to create misleading and deceptive visual content. To deal with this growing problem, deep learning techniques have emerged as a powerful tool for both preventing and detecting digital image manipulation. In the proposed project focussing on developing deep learningbased forgery detection methods that can accurately identify manipulated images and to localize the forged part in the image using different methodologies, including VGG-16 which is a standard deep Convolutional Neural Networks (CNN),U-net, to build robust detection models capable of detecting a wide range of forgery techniques. Evaluating the effectiveness of our proposed forgery detection model, then building a comprehensive dataset consisting of authentic and forged images with diverse manipulation techniques. Furthermore, the proposed project addresses the challenge of detecting forged images that are altered to bypass existing detection mechanisms.;"Deep Learning;CNN (Convolutional neural network);VGG-16 (Visual Geometry Group) model;U-net;Image Forgery";IEEE
762;A Face Forgery Video Detection Model Based on Knowledge Distillation;"H. Liang; Y. Leng; J. Luo; J. Chen; X. Guo";2024;With the rapid evolution of artificial intelligence (AI), face forgery videos have proliferated, posing significant societal challenges. Traditional detection methods struggle with poor generalization and cross-database accuracy, unable to address subtle features and variations in face images across scales and compression levels. This paper reviews current face forgery detection methods, identifying key limitations. It introduces a novel model enhancing features through knowledge distillation, optimizing generalization and robustness via a unique loss function and temperature adjustment strategy. Additionally, a Discrete Cosine Transform with multi-scale and multi-compression capabilities (DCTMS) is integrated, enriching texture and detail capture. Experimental results on deepfake datasets demonstrate the efficacy of the proposed methods, achieving high detection accuracy and robustness across diverse scenarios, including cross-database experiments. This study contributes valuable insights and techniques to advance the field of face forgery detection, addressing risks associated with manipulated video content.;"face forgery detection;deep learning;knowledge distillation;discrete cosine transform";IEEE
764;DeepFake Video Detection;"A. M. Saber; M. T. Hassan; M. S. Mohamed; R. ELHusseiny; Y. M. Eltaher; M. Abdelrazek; Y. M. Kamal Omar";2022;"Recently, deepfake face-swapping techniques are widely used, which allow to easily create buinesslike fake videos. Determining the rightfulness of a video is becoming increasingly important due to the potential distructive impact it can have on the world. we used more than technique and compared between them to detect fake videos. we applied different techniques like YOLO-CRNN, LSTM and in this paper, we compared between them in some techniques EfficientNet-B5 is used to pluck out the spatial options of those faces they are fed as a batch of input series into a two-way long- and short-term memory (BiLSTM) to extract temporal characteristics. The scheme is then tested on a a huge new dataset in; CelebDFFaceForencics++ (c23), based on a mash-up of two well-known records; FaceForencies++ (c23) and CelebDF. Achieved Area Under Receiver Operating Characteristic (AUROC) curve 89.35% result, 89.38 accuracy, 83.13% recovery, 85.54% accuracy and 84.23 F1-measure to insert data focus.";"CNN;Deepfake;RNN;YOLO-CRNN;RELU;CelebDF;FaceForenciscs++";IEEE
766;MMGANGuard: A Robust Approach for Detecting Fake Images Generated by GANs Using Multi-Model Techniques;"S. Ali Raza; U. Habib; M. Usman; A. Ashraf Cheema; M. Sajid Khan";2024;Recent advances in Generative Adversarial Networks (GANs) have produced synthetic images with high visual fidelity, making them nearly indistinguishable from human-created images. These synthetic images referred to as deepfakes, have become a major source of misinformation due to social media. Technology is advancing rapidly, so reliable methods for distinguishing real from fake images are needed. The current detection mechanisms require image forensics tools such as error level analysis (ELA), and clone detection to detect manipulated images. These approaches are limited because they require forensics expertise to use, are manual in application nature, and are unscalable, creating a need for a framework for a scalable tool that experts and non-experts can use to combat the spread of manipulated images and preserve digital visual information authenticity. We approach this problem with a multi-model ensemble framework using the transfer learning method to effectively detect fake images. The proposed approach named Multi-Model GAN Guard (MMGANGuard)integrates four models into an ensemble framework to identify GAN-generated image characteristics to improve deepfake detection. The Gram-Net architecture, ResNet50V2, and DenseNet201 models are used with co-occurrence matrices using transfer learning for MMGANGuard. Through comprehensive experiments, the proposed model demonstrates promising results in detecting the deepfake with high accuracy on the StyleGAN dataset. For automated detection of deepfake-generated images, the proposed model exceeded 97% accuracy, 98.5% TPR, 98.4% TPR, and 95.6% TPR in these evaluations, eliminating the need for manual assessment which is promising for future research in this domain.;"Deep fake;data analytics;deep learning;GANs;StyleGAN;detection;multi-model";IEEE
767;Trans-DF: A Transfer Learning-based end-to-end Deepfake Detector;"M. Patel; A. Gupta; S. Tanwar; M. S. Obaidat";2020;With the advent of information and communication technologies, there have been breakthrough developments in the field of Artificial Intelligence (AI). Moreover, increasing computation power and decreasing processing times, new applications are being developed at great speeds. One such application is Deepfakes, which tackles the increased manipulated and forged media content. But these fake images and videos hamper the security and privacy of individuals and can have large-scale religious, communal, or political implications that may prove to be catastrophic for a nation. The face swapped content at times can be identified by human observation, but with the use of Generative adversarial networks (GANs), such forged content can be developed with is hard to be identified even by humans. Hence, detecting such videos and images is a challenging task for researchers. Motivated from these gaps, in this paper, we propose a pipeline for detecting and extracting human faces from videos, process them to extract features from them, and then classify them as real or fake. The results of the proposed model achieved an accuracy of 90.2% for classifying fake images from real ones.;"Deepfakes;Classification;Feature Extraction;Random Forest;VGG;ResNet;Inception;MobileNet;DenseNet";IEEE
768;DeePhy: On Deepfake Phylogeny;"K. Narayan; H. Agarwal; K. Thakral; S. Mittal; M. Vatsa; R. Singh";2022;Deepfake refers to tailored and synthetically generated videos which are now prevalent and spreading on a large scale, threatening the trustworthiness of the information available online. While existing datasets contain different kinds of deepfakes which vary in their generation technique, they do not consider progression of deepfakes in a �phylogenetic� manner. It is possible that an existing deepfake face is swapped with another face. This process of face swapping can be performed multiple times and the resultant deepfake can be evolved to confuse the deepfake detection algorithms. Further, many databases do not provide the employed generative model as target labels. Model attribution helps in enhancing the explainability of the detection results by providing information on the generative model employed. In order to enable the research community to address these questions, this paper proposes DeePhy, a novel Deepfake Phylogeny dataset which consists of 5040 deep-fake videos generated using three different generation techniques. There are 840 videos of one-time swapped deep-fakes, 2520 videos of two-times swapped deepfakes and 1680 videos of three-times swapped deepfakes. With over 30 GBs in size, the database is prepared in over 1100 hours using 18 GPUs of 1,352 GB cumulative memory. We also present the benchmark on DeePhy dataset using six deep-fake detection algorithms. The results highlight the need to evolve the research of model attribution of deepfakes and generalize the process over a variety of deepfake generation techniques. The database is available at: http://iab-rubric.org/deephy-database;;IEEE
771;Enhancing Interpretability in AI-Generated Image Detection with Genetic Programming;"M. Lin; L. Shang; X. Gao";2023;IGC can produce realistic AI-generated images that challenge human perception. Detecting AI-generated content is critical, which has prompted the technology to tell apart real images from the generated ones. However, the existing methods, such as CNND, LGrad, lack interpretability. Unlike traditional image classification, it is crucial to know why the image can be considered as AI-generated. We introduce a novel AI-generated image detector based on genetic programming (GP), prioritizing both interpretability and classification accuracy. This application of GP in this context emphasizes the need for interpretability in AI-generated content identification. Our GP-based approach not only achieves competitive classification accuracy but also provides transparent decision-making processes, bridging the interpretability gap. This method enhances trust and understanding in the AI-generated image detection process. Through extensive experiments, we highlight the potential of GP-based detectors for this unique task. This research contributes to improving the transparency and reliability of AI-generated image detection, holding implications for computer vision and image forensics. Our work emphasizes the pivotal role of interpretability in distinguishing AI-generated content and offers insights into the inner workings of such models and also achieves a good generation ability.;"AI-generated image detection;Genetic Programming;Interpretability;Transparency";IEEE
773;Detecting Deepfakes Using GAN Manipulation Defects in Human Eyes;"E. Tchaptchet; E. F. Tagne; J. Acosta; R. Danda; C. Kamhoua";2024;"The Deepfake phenomenon is very important nowadays because there are possibilities to create very real images that can fool anyone, thanks to deep learning tools based on generative adversarial networks (GAN). These images are used as profile images on social media, aimed here at creating discord and scams internationally. In this work, we show that these images can be detected by a multitude of imperfections present in the synthetized eyes such as the irregular shape of the pupil and the difference between the corneal reflections of the two eyes. These imperfections are caused by the absence of physical/physiological constraints in most GAN models. We are developing a two tier architecture able of detecting these deepfake images. It starts with an automatic segmentation method of the eye pupil to check the shape. Then, for pupils of non-standard shape, the whole image is taken, transformed into gray level and then passed into an architecture that extracts and compares the corneal specular reflections of two eyes. Experimenting with a large set of real image data from the Flickr-Faces-HQ dataset and fake styleGAN2 images demonstrates the effectiveness of our method. Our method has good stability for physiological properties during deep learning; therefore, it is robust as some of the single-class deepfake detection methods. The results of the experiments on the selected datasets demonstrate greater precision compared to other methods.";"Adversarial machine learning;Deepfake;face generation;GAN";IEEE
775;On the use of Stable Diffusion for creating realistic faces: from generation to detection;"L. Papa; L. Faiella; L. Corvitto; L. Maiano; I. Amerini";2023;The mass adoption of diffusion models has shown that artificial intelligence (AI) systems can be used to easily generate realistic images. The spread of these technologies paves the way to previously unimaginable creative uses while also raising the possibility of malicious applications. In this work, we propose a critical analysis of the overall pipeline, i.e., from creating realistic human faces with Stable Diffusion v1.5 [1] to recognizing fake ones. We first propose an analysis of the prompts that allow the generation of extremely realistic faces with a human-in-the-loop approach. Our objective is to identify the text prompts that drive the image generation process to obtain realistic photos that resemble everyday portraits captured with any camera. Next, we study how complex it is to recognize these fake contents for both AI-based models and non-expert humans. We conclude that similar to other deepzfake creation techniques, despite some limitations in generalization across different datasets, it is possible to use AI to recognize these contents more accurately than non-expert humans would.;"Computer vision;Deepfake detection;Diffusion models;Prompt engineering;Security";IEEE
776;Exposing Lip-syncing Deepfakes from Mouth Inconsistencies;"S. K. Datta; S. Jia; S. Lyu";2024;A lip-syncing deepfake is a digitally manipulated video in which a person�s lip movements are created convincingly using AI models to match altered or entirely new audio. Lipsyncing deepfakes are a dangerous type of deepfakes as the artifacts are limited to the lip region and more difficult to discern. In this paper, we describe a novel approach, LIP-syncing detection based on mouth INConsistency (LIPINC), for lip-syncing deepfake detection by identifying temporal inconsistencies in the mouth region. These inconsistencies are seen in the adjacent frames and throughout the video. Our model can successfully capture these irregularities and outperforms the state-of-the-art methods on several benchmark deepfake datasets. Code is available at https://github.com/skrantidatta/LIPINC.;"DeepFake detection;Lip-syncing deepfakes;Spatial-temporal inconsistency";IEEE
777;Audio-Visual Temporal Forgery Detection Using Embedding-Level Fusion and Multi-Dimensional Contrastive Loss;"M. Liu; J. Wang; X. Qian; H. Li";2024;Audio-visual deepfake detection is the process of identifying and detecting deepfakes that have been generated using both audio and visual content with AI algorithms. Most existing methods primarily focus on the overall authenticity while neglecting the position of forgeries in time. This can be particularly problematic, as even a small alteration in a clip can significantly impact its meaning. Such brand new attacks are dangerous and how to tackle such attacks remains an open question. In this paper, we present a novel neural network-based model to tackle the temporal forgery detection (TFD) problem. It consists of new audio and visual encoders with cross-modal attention for embedding extraction, and an embedding-level fusion mechanism with self-attention for forgery localization. Besides, a multi-dimensional contrastive loss is proposed which helps the model not only to capture audio-visual inconsistency for deepfake detection but also to exploit temporal inconsistency by coherently constraining the extracted embeddings. Extensive experiments on the LAV-DF dataset show that the presented method outperforms several state-of-the-art temporal forgery localization methods by up to 23.4% on AP@0.5 and 13.8% on AR@100. In addition, we also show the effectiveness of the proposed model on deepfake detection.;"Audio-visual deepfake detection;temporal forgery localization;embedding-level fusion;multi-dimensional contrastive;audio-visual inconsistency";IEEE
782;Hierarchical Frequency-Assisted Interactive Networks for Face Manipulation Detection;"C. Miao; Z. Tan; Q. Chu; N. Yu; G. Guo";2022;Recently, face manipulation techniques have caused increasing trust concerns in our society. Although current face manipulation detection methods achieve impressive performance regarding intra-dataset evaluation, they are struggling to improve the generalization and robustness ability. To address this issue, we propose a novel Hierarchical Frequency-assisted Interactive Networks (HFI-Net) to explore comprehensive frequency-related forgery cues for face manipulation detection. At first, we formulate HFI-Net as a dual-branch network to take full advantage of both CNN and transformer for capturing local details and global context information, respectively. Considering the forged faces are easy to show flaws in the frequency domain, a novel Frequency-based Feature Refinement (FFR) module is proposed to learn frequency-based attention from RGB features. FFR module emphasizes forgery cues and suppresses the pristine semantics information by keeping middle-high frequency features while discarding the low-frequency ones. Based on FFR, we further develop a co- sharing Global-Local Interaction (GLI) module to conduct frequency-assisted interactions while capturing complementarity among dual branches. Lastly, we further implement the GLI module in each stage of the network to effectively explore multi-level frequency artifacts. Extensive experiments are conducted on several popular benchmarks including FaceForensics++, Celeb-DF, DeepFake-TIMIT, DFDC, UADFV, and DeeperForensics-1.0, which shows that our model outperforms the state-of-the-art, especially in unseen datasets, manipulations, and perturbations evaluation.;"Face manipulation detection;frequency;transformer;CNN";IEEE
786;A Novel Facial Manipulation Detection Method Based on Contrastive Learning;"Z. Ma; P. Xu; X. Mei; J. Shen";2022;Nowadays, numerous synthesized face-swapping videos generated by face forgery algorithms have become an emerging problem, which promotes facial manipulation detection to be a significant topic. With the development of face forgery algorithms, some fake face images or videos generated by those strong forgery algorithms are very realistic, which have brought much difficulty to facial manipulation detection. In this paper, we present a novel facial manipulation detection method based on contrastive learning. We analyze the texture features of manipulated facial images and propose to compare and learn the features of the whole face and the center face in order to get more general features. We calculate the similarity and distribution distance between the whole face and the center face. The experiments implemented on FaceForensics++ dataset demonstrate that the proposed method achieves outstanding results and can learn the general features.;"Facial Manipulation Detection;Face Forgery Detection;Contrastive Learning;Siamese Network;Deep learning";IEEE
787;TruceNet: A CNN-Based Model for Accurate Classification of DeepFake Images;"D. Rao; K. Utturwar; T. Shelke; A. Patil; E. Sarda";2023;With the rise of GANs, the prevalence of Deepfakes has increased, resulting in significant privacy, security, and social concerns. To tackle this issue, we propose TruceNet, a novel approach that utilizes a CNN architecture to detect Deepfakes in images. Our method analyzes various image features to determine if manipulation has occurred. Through experiments on a comprehensive dataset of Deepfakes and non-Deepfakes, we evaluate TruceNet's effectiveness. Our CNN architecture achieves high detection accuracy, outperforming state-of-the-art methods. TruceNet exhibits robustness against common Deepfake manipulations such as face swapping, expression modification, and Neural Texture Synthesis. It consistently achieves an average accuracy of 94.2% in correctly classifying manipulated images, maintaining a precision of 95% across different manipulation scenarios. The research findings highlight TruceNet's significant contribution in mitigating Deepfake risks and enhancing digital media security and trustworthiness. By accurately detecting Deepfakes, TruceNet offers a reliable solution to combat the growing threat posed by manipulated images.;"CNN;DeepFake;TruceNet;Classification;ResNet";IEEE
789;Deepfake Forensics via an Adversarial Game;"Z. Wang; Y. Guo; W. Zuo";2022;With the progress in AI-based facial forgery (i.e., deepfake), people are concerned about its abuse. Albeit effort has been made for training models to recognize such forgeries, existing models suffer from poor generalization to unseen forgery technologies and high sensitivity to changes in image/video quality. In this paper, we advocate robust training for improving the generalization ability. We believe training with samples that are adversarially crafted to attack the classification models improves the generalization ability considerably. Considering that AI-based face manipulation often leads to high-frequency artifacts that can be easily spotted (by models) yet difficult to generalize, we further propose a new adversarial training method that attempts to blur out these artifacts, by introducing pixel-wise Gaussian blurring. Plenty of empirical evidence show that, with adversarial training, models are forced to learn more discriminative and generalizable features. Our code: https://github.com/ah651/deepfake_adv.;"Deepfake forensics;adversarial training;data augmentation;generalization ability";IEEE
794;Statistics-Aware Audio-Visual Deepfake Detector;"M. Astrid; E. Ghorbel; D. Aouada";2024;"In this paper, we propose an enhanced audio-visual deep detection method. Recent methods in audio-visual deepfake detection mostly assess the synchronization between audio and visual features. Although they have shown promising results, they are based on the maximization/minimization of isolated feature distances without considering feature statistics. Moreover, they rely on cumbersome deep learning architectures and are heavily dependent on empirically fixed hyperparameters. Herein, to overcome these limitations, we propose: (1) a statistical feature loss to enhance the discrimination capability of the model, instead of relying solely on feature distances; (2) using the waveform for describing the audio as a replacement of frequency-based representations; (3) a post-processing normalization of the fakeness score; (4) the use of shallower network for reducing the computational complexity. Experiments on the DFDC and FakeAVCeleb datasets demonstrate the relevance of the proposed method.";"deepfake detector;multi-modal;audiovisual;distribution;similarity";IEEE
797;Controllable Guide-Space for Generalizable Face Forgery Detection;"Y. Guo; C. Zhen; P. Yan";2023;Recent studies on face forgery detection have shown satisfactory performance for methods involved in training datasets, but are not ideal enough for unknown domains. This motivates many works to improve the generalization, but forgery-irrelevant information, such as image background and identity, still exists in different domain features and causes unexpected clustering, limiting the generalization. In this paper, we propose a controllable guide-space (GS) method to enhance the discrimination of different forgery domains, so as to increase the forgery relevance of features and thereby improve the generalization. The well-designed guide-space can simultaneously achieve both the proper separation of forgery domains and the large distance between real-forgery domains in an explicit and controllable manner. Moreover, for better discrimination, we use a decoupling module to weaken the interference of forgery-irrelevant correlations between domains. Furthermore, we make adjustments to the decision boundary manifold according to the clustering degree of the same domain features within the neighborhood. Extensive experiments in multiple in-domain and cross-domain settings confirm that our method can achieve state-of-the-art generalization.;;IEEE
799;Detection of Authenticity - of Content for Forensics Using Forenshield;"P. Govindarajan; A. S. P; S. K. S; A. Tesfahun";2023;The rampant spread of deepfake videos, a significant threat to media integrity, occurs widely on social media and news platforms. Detecting Deepfakes is a formidable challenge. The proposed study involves a novel algorithm to detect the deepfake. The model comprises of various pre-existing classifiers and a novel algorithm named ForenShield � which detects the deepfakes with an accuracy of 97%. The proposed novel technique works on voting strategy and it outperforms all the pre-existing classifiers, exhibiting the models excellence through the same.;"Deepfake;ForenShield;Voting Strategy;Classifiers";IEEE
800;Cross-Dataset Face Manipulation Detection;"B. Bekci; Z. Akhtar; H. K. Ekenel";2020;Easily available recent face image/video manipulation techniques and tools are now being utilized to generate highly realistic manipulated videos known as DeepFakes, which can fool face recognition systems and humans. Thus, it is vital to devise precise manipulation detection methods. Despite the progress, existing mechanisms are limited to the datasets or manipulation types. In this paper, to increase the performance under unseen data and manipulations, a DeepFakes detection framework using metric learning and steganalysis rich models is presented. Extensive empirical analysis on three publicly available datasets, namely, FaceForensics++, CelebDF, and DeepFakeTIMIT, were carried out to evaluate the generalization capability of the proposed approach. The framework attained 5% to 15% accuracy gains under unseen manipulations.;"Deep Learning;Metric Learning;DeepFake;Generalization;Face Manipulation";IEEE
801;Real, Fake and Synthetic Faces - Does the Coin Have Three Sides?;"S. Naeem; R. Al-Sharawi; M. R. Khan; U. Tariq; A. Dhall; H. Al Nashash";2024;With the ever-growing power of generative artificial intelligence, deepfake and artificially generated (synthetic) media have continued to spread online, which creates various ethical and moral concerns regarding their usage. To tackle this, we thus present a novel exploration of the trends and patterns observed in real, deepfake and synthetic facial images. The proposed analysis is done in two parts: firstly, we incorporate eight deep learning models and analyze their performances in distinguishing between the three classes of images. Next, we look to further delve into the similarities and differences between these three sets of images by investigating their image properties both in the context of the entire image as well as in the context of specific regions within the image. ANOVA test was also performed and provided further clarity amongst the patterns associated between the images of the three classes. From our findings, we observe that the investigated deep-learning models found it easier to detect synthetic facial images, with the ViT Patch-16 model performing best on this task with a class-averaged sensitivity, specificity, precision, and accuracy of 97.37%, 98.69%, 97.48%, and 98.25%, respectively. This observation was supported by further analysis of various image properties. We saw noticeable differences across the three category of images. This analysis can help us build better algorithms for facial image generation, and also shows that synthetic, deepfake and real face images are indeed three different classes.;;IEEE
803;Improving Generalization by Commonality Learning in Face Forgery Detection;"P. Yu; J. Fei; Z. Xia; Z. Zhou; J. Weng";2022;This paper proposes a commonality learning strategy for face video forgery detection to improve the generalization. Considering various face forgery methods could leave certain similar forgery traces in videos, we attempt to learn the common forgery features from different forgery databases, so as to achieve better generalization in the detection of unknown forgery methods. Firstly, the Specific Forgery Feature Extractors (SFFExtractors) are trained separately for each of given forgery methods. We utilize the U-net structure and consider the triplet loss, location loss, classification loss, and automatic weighted loss to ensure the detection ability of SFFExtractors on the corresponding forgery methods. Next, the Common Forgery Feature Extractor (CFFExtractor) is trained under the supervision of SFFExtractors to explore the commonality of the forgery traces caused by different forgery methods. The extracted common forgery feature is expected to have a good generalization. The experimental results on FaceForensic++ show that the SFFExtractors outperform many state-of-the-arts in face forgery detection. The generalization performance of the CFFExtractor is verified on FaceForensic++, DFDC, and CelebDF. It is proved that commonality learning can be an effective strategy to improve generalization.;"Deep learning;deepfake;face swapping;video forensics;generalization ability";IEEE
805;Deepfake Catcher: Can a Simple Fusion be Effective and Outperform Complex DNNs?;"A. Agarwal; N. Ratha";2024;Despite having completely different configurations, deep learning architectures learn a specific set of features that are common across architectures. For example, the initial few layers learn the low-level edge features from the images. Based on this fact, in this research, we have showcased the potential of deep neural network fusion for simple and effective deepfake detection. The advantage of building an architecture in such a manner is to build a low-power-consuming and accurate defense that can be deployed on mobile devices. To utilize the pre-trained knowledge and obtain downstream task-specific knowledge, we have identified a breakpoint in different networks and divided the obtained knowledge of a network into fixed and adaptive information. We have kept the fixed knowledge intact while modifying the adaptive knowledge along with entirely new knowledge for the deepfake detection task. In the end, the decision of multiple deep architectures trained based on their breakpoint are combined for improved performance. Extensive comparisons performed with existing state-of-the-art architectures demonstrate the effectiveness of the proposed deepfake detection algorithm. The proposed algorithm not only surpasses the existing state-of-the-art (SOTA) algorithms but also needs low computational power. We have further challenged the proposed algorithm by evaluating it by collecting real-world deepfake images.;;IEEE
809;Generative Adversarial Ensemble Learning for Face Forensics;"J. -Y. Baek; Y. -S. Yoo; S. -H. Bae";2020;The recent advance of synthetic image generation and manipulation methods allows us to generate synthetic face images close to real images. On the other hand, the importance of identifying the synthetic face images increases more and more to protect personal privacy from those. Although some deep learning-based image forensic methods have been developed recently, it is still challenging to distinguish synthetic images generated by recent image generation and manipulation methods such as the deep fake, face2face, and face swap. To resolve this challenge, we propose a novel generative adversarial ensemble learning method. We train multiple discriminative and generative networks based on the adversarial learning. Compared to the conventional adversarial learning, our method is however more focused on improving the discrimination ability rather than image generation one. To this end, we improve the discriminabilty by ensembling outputs from different two discriminators. In addition, we train two generators in order to generate general and hard synthetic images. By ensemble learning of all the generators and discriminators, we improve the discriminators by using the generated synthetic face images, and improve the generators by passing the combined feedback of the discriminators. On the FaceForensics benchmark challenge, we thoroughly evaluate our methods by comparing the recent methods. We also provide the ablation study to prove the effectiveness and usefulness of our method.;"Digital image forensics;generative adversarial ensemble learning;deep learning;synthetic image detection;face image";IEEE
810;Multi-scale Feature Learning with Graph Attention Network for Face Forgery Detection;"Y. Su; W. Lin; J. Xu; X. Liu";2024;Face forgery videos, known as Deepfakes, are widely spread on social media with great potential threat, making the detection of forged face videos is crucial. Commonly, forgery video detection methods are based on Convolutional Neural Networks or Transformer, which treats images as grid or sequence structures for binary classification discrimination. Since face objects are usually not regularly shaped quadrilaterals, treating them as grid or sequence structures is redundant and inflexible, thus losing useful information. Based on this, we propose a new perspective to represent facial images as graph structures, which are fed into Graph Neural Network to learn the intrinsic relationships of facial regions for deep forgery detection. In addition, we propose a feature fusion module to learn artifact information in the frequency domain for a more comprehensive facial feature representation to further improve the reliability of our model. Extensive experiments on several benchmark databases demonstrate the effectiveness and robust generalization ability of our method compared with many state-of-the-art methods.;"Face Forgery Detection;Multi-attention;GNN;Deep Learning";IEEE
814;Video Face Manipulation Detection Through Ensemble of CNNs;"N. Bonettini; E. D. Cannas; S. Mandelli; L. Bondi; P. Bestagini; S. Tubaro";2021;"In the last few years, several techniques for facial manipulation in videos have been successfully developed and made available to the masses (i.e., FaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in video sequences with incredibly realistic results and a very little effort. Despite the usefulness of these tools in many fields, if used maliciously, they can have a significantly bad impact on society (e.g., fake news spreading, cyber bullying through fake revenge porn). The ability of objectively detecting whether a face has been manipulated in a video sequence is then a task of utmost importance. In this paper, we tackle the problem of face manipulation detection in video sequences targeting modern facial manipulation techniques. In particular, we study the ensembling of different trained Convolutional Neural Network (CNN) models. In the proposed solution, different models are obtained starting from a base network (i.e., EfficientNetB4) making use of two different concepts: (i) attention layers; (ii) siamese training. We show that combining these networks leads to promising face manipulation detection results on two publicly available datasets with more than 119000 videos.";"deepfake;video forensics;deep learning;attention";IEEE
816;Exploiting temporal information to prevent the transferability of adversarial examples against deep fake detectors;"D. Lin; B. Tondi; B. Li; M. Barni";2022;The diffusion of AI tools capable of generating realistic DeepFakes (DF) videos raises serious threats to face-based biometric recognition systems. For this reason, several detectors based on Deep Neural Networks (DNNs) have been developed to distinguish between real and DF videos. Despite their good performance, these methods suffer from vulnerability to adversarial attacks. In this paper, we argue that it is possible to increase the resilience of DNN-based DF detectors against black-box adversarial attacks by exploiting the temporal information contained in the video. By using such information, in fact, the transferability of adversarial examples from a source to a target model is significantly decreased, making it difficult to launch an attack without accessing the target network. To back this claim, we trained two convolutional neural networks (CNNs) to detect DF videos, and measured their robustness against black-box, transfer-based, attacks. We also trained two detectors by adding to the CNNs a long short-term memory (LSTM) layer to extract temporal information. Then, we measured the transferability of adversarial examples to-wards the LSTM-networks. The results we got suggest that the methods based on temporal information are less prone to black-box attacks.;;IEEE
817;Dual Attention Network Approaches to Face Forgery Video Detection;"Y. -X. Luo; J. -L. Chen";2022;Forged videos are commonly spread online. Most have malicious content and cause serious information security problems. The most critical issue in deepfake detection is the identification of traces of tampering in fake videos. This study designs a Dual Attention Forgery Detection Network (DAFDN), which embeds a spatial reduction attention block (SRAB) and a forgery feature attention module (FFAM) to the backbone network. DAFDN embeds the two proposed attention mechanisms and enables the convolution neural network to extract peculiar traces left by images� warping. This study uses two benchmark datasets, DFDC and FaceForensics++, to compare the performance of the proposed DAFDN with other methods. The results show that the proposed DAFDN mechanism achieves AUC scores of 0.911 and 0.945 in the datasets DFDC and FaceForensics++, respectively. These results are better than those of previously developed methods, such as XceptionNet and EfficientNet-related methods.;"Deepfake;forgery video detection;dual attention neural network;convolutional neural network;information security";IEEE
820;AI-Generated Image Detection With Wasserstein Distance Compression and Dynamic Aggregation;"Z. Lyu; J. Xiao; C. Zhang; K. -M. Lam";2024;With the rapid advancement of generative models, image detectors for AI-generated content have become an increasingly necessary technology in computer vision, attracting significant attention from researchers. This technology aims to detect whether an image is naturally generated by imaging systems (e.g., digital cameras) or generated by advanced AI techniques. Despite the promising performance achieved by recent fake detection methods, they are typically trained on millions of redundant images with similar characteristics, leading to inefficient training. Furthermore, the performances of existing detectors often deteriorate when the training datasets are imbalanced. To address these challenges, we propose a novel AI-generated image detector based on dynamic aggregation and information compression with the Wasserstein distance. Experimental results show that our proposed method significantly outperforms state-of-the-art models that generalize across different generative models, with an increase of $\mathbf{+ 1. 8 6 \%}$ average accuracy and $\mathbf{+ 0. 1 4 \%}$ average precision, while substantially reducing the training time. On imbalanced datasets, our proposed method leads to a $\mathbf{+ 1 4. 4 6 \%}$ accuracy improvement, clearly demonstrating its robustness on imbalanced datasets.;"Fake Image Detection;Efficient Training";IEEE
823;Reverse Engineering of Generative Models: Inferring Model Hyperparameters From Generated Images;"V. Asnani; X. Yin; T. Hassner; X. Liu";2023;State-of-the-art (SOTA) Generative Models (GMs) can synthesize photo-realistic images that are hard for humans to distinguish from genuine photos. Identifying and understanding manipulated media are crucial to mitigate the social concerns on the potential misuse of GMs. We propose to perform reverse engineering of GMs to infer model hyperparameters from the images generated by these models. We define a novel problem, �model parsing�, as estimating GM network architectures and training loss functions by examining their generated images � a task seemingly impossible for human beings. To tackle this problem, we propose a framework with two components: a Fingerprint Estimation Network (FEN), which estimates a GM fingerprint from a generated image by training with four constraints to encourage the fingerprint to have desired properties, and a Parsing Network (PN), which predicts network architecture and loss functions from the estimated fingerprints. To evaluate our approach, we collect a fake image dataset with 100 K images generated by 116 different GMs. Extensive experiments show encouraging results in parsing the hyperparameters of the unseen models. Finally, our fingerprint estimation can be leveraged for deepfake detection and image attribution, as we show by reporting SOTA results on both the deepfake detection (Celeb-DF) and image attribution benchmarks.;"Reverse engineering;fingerprint estimation;generative models;deepfake detection;image attribution";IEEE
825;Detecting DeepFakes: A Deep Convolutional Neural Network Approach with Depth Wise Separable Convolutions;"R. V. Reddy; A. Nethi; S. Sukhija; Y. Gupta";2023;This paper presents a deep learning based approach for detecting deepfake images and videos. With the rise of free and easily accessible software tools, such as GANs, creating deep-fakes has become effortless. However, detecting these deepfakes has proven to be a significant challenge. Our method uses a deep convolutional neural network architecture that involves depth-wise separable convolutions to classify whether an image or video is real or fake. We trained and evaluated our model on the CelebDF V2 dataset, achieving high accuracy rates of 98.8% and 97.4% for image and video classification, respectively. Our work is a significant contribution towards mitigating the spread of deepfakes, and we plan to expand our research to detect AI-generated audio in future work. We also propose the development of an online browser extension to make our detection method accessible to the general public and to integrate it into various social media and messaging platforms to prevent the spread of deepfakes.;"deepfakes;generative adversarial networks (GANs);computer vision;machine learning;artificial intelligence;image and video manipulation;misinformation and disinformation;social media";IEEE
827;Finding Facial Forgery Artifacts with Parts-Based Detectors;"S. Schwarcz; R. Chellappa";2021;Manipulated videos, especially those where the identity of an individual has been modified using deep neural networks, are becoming an increasingly relevant threat in the modern day. In this paper, we seek to develop a generalizable, explainable solution to detecting these manipulated videos. To achieve this, we design a series of forgery detection systems that each focus on one individual part of the face. These parts-based detection systems, which can be combined and used together in a single architecture, meet all of our desired criteria - they generalize effectively between datasets and give us valuable insights into what the network is looking at when making its decision. We thus use these detectors to perform detailed empirical analysis on the FaceForensics++, Celeb-DF, and Facebook Deep-fake Detection Challenge datasets, examining not just what the detectors find but also collecting and analyzing useful related statistics on the datasets themselves.;;IEEE
832;A reliable solution to detect deepfakes using Deep Learning;"H. K. Vedamurthy; R. V; G. S P";2022;Recently, it has become simple to produce trustworthy face video exchanges that leave a few signs of deception thanks to in-depth free reading software tools (DF). Despite decades of effective use of visual effects in digital video deception, recent developments in in-depth learning have significantly improved the genuine nature of misleading content and the accessibility that can be achieved with it. This is referred to as AI-synthesized media or DF in short. Making DF is a simple task that uses practical tools. However, it is a significant difficulty if these DFs are discovered, because it is hard to train the algorithm for identifying DF. CNNs and RNNs have helped us come closer to DF. The Convolutional Neural Network (CNN) is used by the system to extract features at the individual level. The continuous neural network (RNN) states learn to recognize whether or not a video is being deceived and be able to spot temporary anomalies among the frames given by DF's creative tools thanks to these capabilities. An extensive collection of pseudo-videos gathered from a common data source is the anticipated outcome. We demonstrate how our method can produce a competitive outcome in this work that is simple to utilize.;"Deep fake;ResNext;CNN;RNN;GAN;LSTM";IEEE
834;Detection of Morphed Face, Body, Audio signals using Deep Neural Networks;"D. Gharde; M. P. A; S. N; S. K. S";2022;Deepfakes have been a hot topic in the field of deep learning. It is typically used to alter the face or body of a person to create a fake image or video. With the rise of internet, the number of fake content especially deepfakes have increased exponentially. There have already been cases of these causing conflict and hatred among people. To keep this misinformation regulated, there needs to be a way to distinguish deepfakes from the rest. We therefore have come up with a model to classify deepfakes from pristine, accurately and quickly, so that anyone can upload an image/video to know whether it is genuine or not. The parameters taken into consideration for classifying deepfakes are face, audio and body language. The model for face consists of MMOD-CNN Face detector for pre-processing the input, which is then passed on to a Temporal Convolutional Network (TCN) to predict. For audio deepfake detection, audio converted into a spectrogram is passed to a ResNet50V2 followed by a TCN to predict. The Body Language model uses a vanilla TCN to predict if its a deepfake video or not.;"TCN;MMOD;ResNet50V2;CNN;Conditional GAN;deepfakes;deep-learning;temporal convolution";IEEE
837;An Architecture for the detection of GAN-generated Flood Images with Localization Capabilities;"J. Wang; O. Alamayreh; B. Tondi; M. Barni";2022;In this paper, we address a new image forensics task, namely the detection of fake flood images generated by ClimateGAN architecture. We do so by proposing a hybrid deep learning architecture including both a detection and a localization branch, the latter being devoted to the identification of the image regions manipulated by ClimateGAN. Even if our goal is the detection of fake flood images, in fact, we found that adding a localization branch helps the network to focus on the most relevant image regions with significant improvements in terms of generalization capabilities and robustness against image processing operations. The good performance of the proposed architecture is validated on two datasets of pristine flood images downloaded from the internet and three datasets of fake flood images generated by ClimateGAN starting from a large set of diverse street images.;;IEEE
838;Crafting A Panoptic Face Presentation Attack Detector;"S. Mehta; A. Uberoi; A. Agarwal; M. Vatsa; R. Singh";2019;With the advancements in technology and growing popularity of facial photo editing in the social media landscape, tools such as face swapping and face morphing have become increasingly accessible to the general public. It opens up the possibilities for different kinds of face presentation attacks, which can be taken advantage of by impostors to gain unauthorized access of a biometric system. Moreover, the wide availability of 3D printers has caused a shift from print attacks to 3D mask attacks. With increasing types of attacks, it is necessary to come up with a generic and ubiquitous algorithm with a panoptic view of these attacks, and can detect a spoofed image irrespective of the method used. The key contribution of this paper is designing a deep learning based panoptic algorithm for detection of both digital and physical presentation attacks using Cross Asymmetric Loss Function (CALF). The performance is evaluated for digital and physical attacks in three scenarios: ubiquitous environment, individual databases, and cross-attack/cross-database. Experimental results showcase the superior performance of the proposed presentation attack detection algorithm.;;IEEE
841;Exposing Deep Fakes Using Inconsistent Head Poses;"X. Yang; Y. Li; S. Lyu";2019;In this paper, we propose a new method to expose AI-generated fake face images or videos (commonly known as the Deep Fakes). Our method is based on the observations that Deep Fakes are created by splicing synthesized face region into the original image, and in doing so, introducing errors that can be revealed when 3D head poses are estimated from the face images. We perform experiments to demonstrate this phenomenon and further develop a classification method based on this cue. Using features based on this cue, an SVM classifier is evaluated using a set of real face images and Deep Fakes.;"Media Forensics;DeepFake Detection;Head Pose Estimation";IEEE
842;Detection of GAN-Synthesized street videos;"O. Alamayreh; M. Barni";2021;Research on the detection of AI-generated videos has focused almost exclusively on face videos, usually referred to as deepfakes. Manipulations like face swapping, face reenactment and expression manipulation have been the subject of an intense research with the development of a number of efficient tools to distinguish artificial videos from genuine ones. Much less attention has been paid to the detection of artificial non-facial videos. Yet, new tools for the generation of such kind of videos are being developed at a fast pace and will soon reach the quality level of deepfake videos. The goal of this paper is to investigate the detectability of a new kind of AI-generated videos framing driving street sequences (here referred to as DeepStreets videos), which, by their nature, can not be analysed with the same tools used for facial deepfakes. Specifically, we present a simple frame-based detector, achieving very good performance on state-of-the-art DeepStreets videos generated by the Vid2vid architecture. Noticeably, the detector retains very good performance on compressed videos, even when the compression level used during training does not match that used for the test videos.;"DeepStreets;DeepFake;GANs;XceptionNet;Vid2vid;Video Forensics";IEEE
844;Deepfake Classification For Human Faces using Custom CNN;"A. M. Kalemullah; P. P; S. V";2024;This paper emphasizes the urgent need for effective deepfake classification methods, particularly for human faces, due to the escalating threat of this technology. The research proposes a comprehensive approach using a Convolutional Neural Network (CNN) model and two Transfer Learning models (ResNet-50 and EfficientNet B7) to address this challenge. It investigates the synthesis of realistic-looking facial manipulations and their societal impacts, highlighting the importance of accurate classification in mitigating these effects. The study evaluates and compares the proposed models' accuracy in detecting manipulated facial content, analyzing their strengths and limitations. Overall, the paper provides a timely exploration of deepfake classification, offering practical solutions to enhance digital security and trustworthiness.;"Deepfake;Facial Manipulation;Convolution Neural Network;Transfer Learning;Resnet-50 and EfficientNet B7";IEEE
847;Detection of AI-Generated Images From Various Generators Using Gated Expert Convolutional Neural Network;"R. Ahmad Fattah Saskoro; N. Yudistira; T. Noor Fatyanosa";2024;The rapid advancement of artificial intelligence (AI), particularly in text-to-image generative models, has led to a proliferation of synthetic images. This progress, while remarkable, raises concerns about misuse in fraudulent activities. To address this issue, we propose a Convolutional Neural Network (CNN)-based approach for classifying AI-generated images from multiple generators. We introduce a gated CNN model that leverages mixed datasets for improved training efficiency and performance. This approach eliminates the need for extensive tuning with each new dataset and mitigates the risk of catastrophic forgetting. Our experiments demonstrate that the gated CNN model slightly outperforms traditional single CNN models, providing a more robust solution for identifying AI-generated images. This paper presents a comprehensive comparison of methods and offers insights into enhancing the classification of AI-generated images.;"AI-generated images;CNN;gated network;image classification";IEEE
849;On the Detection of Digital Face Manipulation;"H. Dang; F. Liu; J. Stehouwer; X. Liu; A. K. Jain";2020;Detecting manipulated facial images and videos is an increasingly important topic in digital media forensics. As advanced face synthesis and manipulation methods are made available, new types of fake face representations are being created which have raised significant concerns for their use in social media. Hence, it is crucial to detect manipulated face images and localize manipulated regions. Instead of simply using multi-task learning to simultaneously detect manipulated images and predict the manipulated mask (regions), we propose to utilize an attention mechanism to process and improve the feature maps for the classification task. The learned attention maps highlight the informative regions to further improve the binary classification (genuine face v. fake face), and also visualize the manipulated regions. To enable our study of manipulated face detection and localization, we collect a large-scale database that contains numerous types of facial forgeries. With this dataset, we perform a thorough analysis of data-driven fake face detection. We show that the use of an attention mechanism improves facial forgery detection and manipulated region localization.;;IEEE
852;Multimodal Forgery Detection Using Ensemble Learning;"A. Hashmi; S. A. Shahzad; W. Ahmad; C. W. Lin; Y. Tsao; H. -M. Wang";2022;The recent rapid revolution in Artificial Intelligence (AI) technology has enabled the creation of hyper-realistic deepfakes, and detecting deepfake videos (also known as AI-synthesized videos) has become a critical task. The existing systems generally do not fully consider the unified processing of audio and video data, so there is still room for further improvement. In this paper, we focus on the multimodal forgery detection task and propose a deep forgery detection method based on audiovisual ensemble learning. The proposed method consists of four parts, namely a Video Network, an Audio Network, an Audiovisual Network, and a Voting Module. Given a video, the proposed multimodal and ensemble learning system can identify whether it is fake or real. Experimental results on a recently released multimodal FakeAVCeleb dataset show that the proposed method achieves 89% accuracy, significantly outperforming existing models.;;IEEE
857;Exposing Deepfake Frames through Spectral Analysis of Color Channels in Frequency Domain;"M. A. Amin; Y. Hu; H. She; J. Li; Y. Guan; M. Z. Amin";2023;Highly realistic deepfakes are generated by employing generative neural networks, even to the point that it is difficult for humans to tell them apart from the real ones. Nowadays they are one of the causes of misrepresentation or misinformation regarding different subjects. The detection of deepfake content is very important. It can be analyzed in different domains, such as spatial domain and frequency domain, or by employing combinations of them. In this work, we first took inspiration from traditional image forensics and performed a comprehensive frequency spectrum analysis on the deepfake frames and their context color channels to detect spectral anomalies and statistical features. We then use the frequency spectrum statistical features to distinguish between pristine and deepfake content using both unsupervised and supervised learning approaches. Finally, we scrutinize the trained deepfake detection models� generalization capability from the perspective of suggested statistical features across different deepfake datasets and methods. Our analysis demonstrated the effectiveness of statistical features by identifying real and deepfake content with high accuracy, surpassing the performance of several state-of-the-art methods.;"Deepfakes;Statistical Features;Spectrum Analysis;Image Forensics;Generalization Capability";IEEE
861;Detect and Locate: Exposing Face Manipulation by Semantic- and Noise-Level Telltales;"C. Kong; B. Chen; H. Li; S. Wang; A. Rocha; S. Kwong";2022;The technological advancements of deep learning have enabled sophisticated face manipulation schemes, raising severe trust issues and security concerns in modern society. Generally speaking, detecting manipulated faces and locating the potentially altered regions are challenging tasks. Herein, we propose a conceptually simple but effective method to efficiently detect forged faces in an image while simultaneously locating the manipulated regions. The proposed scheme relies on a segmentation map that delivers meaningful high-level semantic information clues about the image. Furthermore, a noise map is estimated, playing a complementary role in capturing low-level clues and subsequently empowering decision-making. Finally, the features from these two modules are combined to distinguish fake faces. Extensive experiments show that the proposed model achieves state-of-the-art detection accuracy and remarkable localization performance.;"Face forensics;face forgery detection;face manipulation localization";IEEE
862;AUNet: Learning Relations Between Action Units for Face Forgery Detection;"W. Bai; Y. Liu; Z. Zhang; B. Li; W. Hu";2023;Face forgery detection becomes increasingly crucial due to the serious security issues caused by face manipulation techniques. Recent studies in deepfake detection have yielded promising results when the training and testing face forgeries are from the same domain. However, the problem remains challenging when one tries to generalize the detector to forgeries created by unseen methods during training. Observing that face manipulation may alter the relation between different facial action units (AU), we propose the Action-Units Relation Learning framework to improve the generality of forgery detection. In specific, it consists of the Action Units Relation Transformer (ART) and the Tampered AU Prediction (TAP). The ART constructs the relation between different AUs with AU-agnostic Branch and AU-specific Branch, which complement each other and work together to exploit forgery clues. In the Tampered AU Prediction, we tamper AU-related regions at the image level and develop challenging pseudo samples at the feature level. The model is then trained to predict the tampered AU regions with the generated location-specific supervision. Experimental results demonstrate that our method can achieve state-of-the-art performance in both the in-dataset and cross-dataset evaluations.;"Humans: Face;body;pose;gesture;movement";IEEE
868;Detection of Diffusion Model-Generated Faces by Assessing Smoothness and Noise Tolerance;"B. Liu; B. Liu; M. Ding; T. Zhu";2024;The fast growth of artificial intelligence (AI) raises much concern about the misinformation brought by AI-generated content (AIGC), especially Deepfake techniques that generate fake human faces. The recent development of Diffusion Models (DMs) moves another critical step forward to generate high-resolution and realistic human faces, which has become a challenge for existing Deepfake detectors. In this paper, we propose a DM-generated image detector by looking into the generation pipeline of DMs and the details of DM-generated images. The detector is based on the observation that DM-generated human faces show over-smooth textures and do not contain details as real human faces. Through a comprehensive analysis of DM-generated faces in spatial and frequency domains, we noticed that the over-smoothness improves the tolerance of Gaussian noise since excessive smoothness mitigates some of the impact of noise. Inspired by the observations, we propose a Deepfake detector capable of recognizing challenging DM-generated faces. We mainly propose the Noise Residual Unit (NRD) in our framework to collect the frequency response of images to Gaussian noise as distinctive features for classification. In detail, for an input face image, we add Gaussian noise to it and get the noise-degraded image. Then, the NRU generates the Noise Residual Image (NRI) by calculating the residual of the high-pass-filtered original image and the high-pass-filtered degraded image. The NRI indicates the high-frequency impact brought by the Gaussian noise and, therefore, suggests the tolerance of the original image to noise degradation. The original image and NRI are encoded and fused to obtain the joint representation, which is then fed to a classifier to predict the binary label. We conducted comprehensive experiments to evaluate the effectiveness of the proposed detector. The results indicate that our proposed detector achieves state-of-the-art detection performance on DM-generated faces and generalizes well to unseen DM-generated and GAN-generated face datasets.;"Deepfake detection;diffusion models;frequency analysis";IEEE
873;A Multi-Layer Capsule-based Forensics Model for Fake Detection of Digital Visual Media;"S. S. Khalil; S. M. Youssef; S. N. Saleh";2021;The dangers generated from synthesized multimedia are increasing every day. The creation of the so-called Deepfakes multimedia is vastly evolving, making the detection task harder every day. Researchers and corporations are interested in exploring the technology limits and are coming up with new tools every year to create more robust fake media. In this paper, a new enhanced fake video detection model is introduced addressing many of the face-swapping threats and the low generalization problem. A preprocessing stage is proposed to minimize the noise in the data to enhance their quality. The proposed architecture uses a modified application of capsule neural networks (CapsNet) with an enhanced routing technique. It does not require a lot of training data and generates a small number of training parameters making it fast to build. The model was trained and tested using the DFDC-P dataset and the results have proven that it outperformed other detectors in terms of detection recall, weighted precision, and F1 score.;"deepfake detection;capsule network;capsnet";IEEE
878;A Dataless FaceSwap Detection Approach Using Synthetic Images;"A. Jain; N. Memon; J. Togelius";2022;Face swapping technology used to create �Deepfakes� has advanced significantly over the past few years and now enables us to create realistic facial manipulations. Current deep learning algorithms to detect deepfakes have shown promising results, however, they require large amounts of training data, and as we show they are biased towards a particular ethnicity. We propose a deepfake detection methodology that eliminates the need for any real data by making use of synthetically generated data using Style-GAN3. This not only performs at par with the traditional training methodology of using real data but it shows better generalization capabilities when finetuned with a small amount of real data. Furthermore, this also reduces biases created by facial image datasets that might have sparse data from particular ethnicities. To promote reproducibility the code base has been made publicly available 11https://github.com/anubhav1997/youneednodataset;;IEEE
880;DFP-Net: An explainable and trustworthy framework for detecting deepfakes using interpretable prototypes;"F. Khalid; A. Javed; K. M. Malik; A. Irtaza";2023;The rise of deepfake videos poses a serious threat to the authenticity of visual media, as they have a potential to manipulate public opinion, mislead individuals or groups, harm reputation, etc. Traditional methods for detecting deepfakes rely on deep learning models, which lack transparency and interpretability. To gain the confidence of forensic experts in AI-based deepfakes detector, we present a novel DFP-Net for detecting deepfakes using interpretable and explainable prototypes. Our method makes use of the power of prototype-based learning to generate a set of representative images that capture the essential features of genuine and deepfake images. These prototypes are then used to explain our model�s decision-making process and to provide insights into the features most relevant for deepfake detection. We then use these prototypes to train a classification model that can detect deepfakes accurately and with high interpretability. To further improve the interpretability of our method, we also utilize the Grad-CAM technique to generate heatmaps that highlight the regions of the image that contribute the most towards the decision of the model. These heatmaps can be used to explain the reasoning behind the model�s decision and provide insights into the visual cues that distinguish deepfakes from real images. Experimental results on a large-scale FaceForensics++, Celeb-DF and DFDC-P datasets demonstrate that our method achieves state-of-the-art performance in deepfakes detection. Moreover, the interpretability and explainability of our method make it more trustworthy to forensic experts by allowing them to understand how the model works and makes predictions.;"Deepfakes detection;DFP-Net;Interpretable prototypes;Explainable AI;FaceForensics++";IEEE
885;Contrastive Pseudo Learning for Open-World DeepFake Attribution;"Z. Sun; S. Chen; T. Yao; B. Yin; R. Yi; S. Ding; L. Ma";2023;The challenge in sourcing attribution for forgery faces has gained widespread attention due to the rapid development of generative techniques. While many recent works have taken essential steps on GAN-generated faces, more threatening attacks related to identity swapping or expression transferring are still overlooked. And the forgery traces hidden in unknown attacks from the open-world unlabeled faces still remain under-explored. To push the related frontier research, we introduce a new benchmark called Open-World DeepFake Attribution (OW-DFA), which aims to evaluate attribution performance against various types of fake faces under open-world scenarios. Meanwhile, we propose a novel framework named Contrastive Pseudo Learning (CPL) for the OW-DFA task through 1) introducing a Global-Local Voting module to guide the feature alignment of forged faces with different manipulated regions, 2) designing a Confidence-based Soft Pseudo-label strategy to mitigate the pseudo-noise caused by similar methods in unlabeled set. In addition, we extend the CPL framework with a multi-stage paradigm that leverages pre-train technique and iterative learning to further enhance traceability performance. Extensive experiments verify the superiority of our proposed method on the OW-DFA and also demonstrate the interpretability of deepfake attribution task and its impact on improving the security of deepfake detection area.;;IEEE
888;Extracting Deep Local Features to Detect Manipulated Images of Human Faces;"M. Tarasiou; S. Zafeiriou";2020;Recent developments in computer vision and machine learning have made it possible to create realistic manipulated videos of human faces, raising the issue of ensuring adequate protection against the malevolent effects unlocked by such capabilities. In this paper we propose local image features which are shared across manipulated regions as a key element for the automatic detection of manipulated face images. We also design a lightweight architecture with the correct structural biases for extracting such features and derive a multitask training scheme that consistently outperforms image class supervision alone. The trained networks achieve state-of-the-art results in the FaceForensics++ dataset using significantly reduced number of parameters and are shown to work well in detecting fully generated face images.;;IEEE
891;FakeLocator: Robust Localization of GAN-Based Face Manipulations;"Y. Huang; F. Juefei-Xu; Q. Guo; Y. Liu; G. Pu";2022;Full face synthesis and partial face manipulation by virtue of the generative adversarial networks (GANs) and its variants have raised wide public concerns. In the multi-media forensics area, detecting and ultimately locating the image forgery has become an imperative task. In this work, we investigate the architecture of existing GAN-based face manipulation methods and observe that the imperfection of upsampling methods therewithin could be served as an important asset for GAN-synthesized fake image detection and forgery localization. Based on this basic observation, we have proposed a novel approach, termed FakeLocator, to obtain high localization accuracy, at full resolution, on manipulated facial images. To the best of our knowledge, this is the very first attempt to solve the GAN-based fake localization problem with a gray-scale fakeness map that preserves more information of fake regions. To improve the universality of FakeLocator across multifarious facial attributes, we introduce an attention mechanism to guide the training of the model. To improve the universality of FakeLocator across different DeepFake methods, we propose partial data augmentation and single sample clustering on the training images. Experimental results on popular FaceForensics++, DFFD datasets and seven different state-of-the-art GAN-based face generation methods have shown the effectiveness of our method. Compared with the baselines, our method performs better on various metrics. Moreover, the proposed method is robust against various real-world facial image degradations such as JPEG compression, low-resolution, noise, and blur.;"DeepFake;face manipulation;DeepFake detection and localization";IEEE
892;Exposing DeepFakes Using Convolutional Neural Networks and Transfer Learning Approaches;"S. Suratkar; F. Kazi; M. Sakhalkar; N. Abhyankar; M. Kshirsagar";2020;Advancements in Artificial Intelligence - oriented computing power and the ever-growing reach of social media have proven to be catalysts in emergence and spread of a new vein of AI generated fake videos known as 'DeepFake' videos. Such videos are synthesized using generative machine learning models like Generative Adversarial Networks or Variational AutoEncoders and they can achieve high degrees of realism. Spread of sensitive political or obscene content in form of such videos may lead to social distress to the target entity(s). This paper presents a study pertinent to the detection of DeepFake videos using Convolutional Neural Networks (CNNs) with transfer learning. A comparative study of the performance of various models in the detection of tampered videos has been presented. These models are trained (fine-tuned) and tested on a custom dataset encompassing randomly selected labelled frames from videos in the DeepFake Detection Dataset by Google AI and FaceForensics++ dataset.;"Convolutional Neural Networks;Generative Adversarial Networks;Transfer Learning;Visual Geometry Group;DenseNet;Xception;Inception V3";IEEE
893;Deepfake Algorithm Using Multiple Noise Modalities with Two-Branch Prediction Network;"H. -W. Hsu; J. -J. Ding";2021;In this paper, we propose a facial manipulation detection method based on multiple image noise analysis modalities and a two-branch prediction network to separation different types of forgery artifacts. The proposed architecture reveals whether the input image can be decomposed into a blending of two images from different sources, and checks whether some patches of the input image are generated from a deep learning networks at the same time. We observe that most of the existing forgery detection work] only focuses on finding one of the blending or manipulation artifacts in the input image. As a result, this method provides an effective way for forgery detection by simultaneously checking the manipulation and blending artifacts. In addition, for use with different types of image noise analysis modalities, our method can find more robust detection features in the high-frequency domain compared with traditionally detection in the RGB domain, thereby obtaining better performance. Extensive experiments show that our method outperforms other existing forgery detection methods on detecting synthesized face image, no matter on detecting training dataset or on detecting unseen face manipulation techniques.;;IEEE
898;FakeTransformer: Exposing Face Forgery From Spatial-Temporal Representation Modeled By Facial Pixel Variations;"Y. Sun; Z. Zhang; C. Qiu; L. Wang; L. Sun; Z. Wang";2022;With the rapid development of generation model, AI-based face manipulation technology, which called DeepFakes, has become more and more realistic. This means of face forgery can attack any target, which poses a new threat to personal privacy and property security. Moreover, the misuse of synthetic video shows potential dangers in many areas, such as identity harassment, pornography and news rumors. Inspired by the fact that the spatial coherence and temporal consistency of physiological signal are destroyed in the generated content, we attempt to find inconsistent patterns that can distinguish between real videos and synthetic videos from the variations of facial pixels, which are highly related to physiological information. Our approach first applies Eulerian Video Magnification (EVM) at multiple Gaussian scales to the original video to enlarge the physiological variations caused by the change of facial blood volume, and then transform the original video and magnified videos into a Multi-Scale Eulerian Magnified Spatial-Temporal map (MEMSTmap), which can represent time-varying physiological enhancement sequences on different octaves. Then, these maps are reshaped into frame patches in column units and sent to the vision Transformer to learn the spatio-time descriptors of frame levels. Finally, we sort out the feature embedding and output the probability of judging whether the video is real or fake. We validate our method on the FaceForensics++ and DeepFake Detection datasets. The results show that our model achieves excellent performance in forgery detection, and also show outstanding generalization capability in cross-data domain.;"Digital Face Manipulation;DeepFakes;Face Swap;Image Forensics";IEEE
900;Art of Detection: Custom CNN and VGG19 for Accurate Real Vs Fake Image Identification;"H. V; K. P; M. A";2023;In the current digital age, the ability to distinguish between real and manipulated images has become crucial due to the proliferation of doctored images. This research aims to address this challenge by employing two distinct neural network architectures: a custom Convolutional Neural Network (CNN) and the pre-trained VGG19 model for the classification of real versus fake images. Experimental results reveal that the custom CNN achieved a noteworthy accuracy of 94.46%, outperforming the VGG19 model, which secured an accuracy of 84.24%. Such findings suggest that while pre-trained models like VGG19 bring significant value to image classification tasks, a tailored CNN can offer superior performance for specialized tasks such as detecting image authenticity. This study provides a foundation for further exploration in image forensics, emphasizing the importance of model selection and optimization in combating digital image manipulations.;"Detecting image authenticity;Convolutional Neural Network (CNN);VGG19 Model;Image Classification";IEEE
905;Lip Sync Matters: A Novel Multimodal Forgery Detector;"S. A. Shahzad; A. Hashmi; S. Khan; Y. -T. Peng; Y. Tsao; H. -M. Wang";2022;Deepfake technology has advanced a lot, but it is a double-sided sword for the community. One can use it for beneficial purposes, such as restoring vintage content in old movies, or for nefarious purposes, such as creating fake footage to manipulate the public and distribute non-consensual pornography. A lot of work has been done to combat its improper use by detecting fake footage with good performance thanks to the availability of numerous public datasets and unimodal deep learning-based models. However, these methods are insufficient to detect multimodal manipulations, such as both visual and acoustic. This work proposes a novel lip-reading-based multi-modal Deepfake detection method called �Lip Sync Matters.� It targets high-level semantic features to exploit the mismatch between the lip sequence extracted from the video and the synthetic lip sequence generated from the audio by the Wav2lip model to detect forged videos. Experimental results show that the proposed method outperforms several existing unimodal, ensemble, and multimodal methods on the publicly available multimodal FakeAVCeleb dataset.;;IEEE
911;Countering Deepfakes using an Improved Advanced CNN and its Ensemble with Pretrained Models;"A. Mathur; M. Tejpal; K. Bhargava; K. Natarajan; M. Singh";2024;The extensive spread of DeepFake images on the internet has emerged as a significant challenge, with applications ranging from harmless entertainment to harmful acts like blackmail, misinformation, and spreading false propaganda. To tackle this issue, this paper introduces a sophisticated DeepFake detection model designed to identify and mitigate the increase of these deceptive images. The model architecture integrates an ensemble approach, combining the strengths of two pre-trained Convolutional Neural Network (CNN) models�MobileNet and Xception�with a novel CNN architecture, the Advanced CNN (ACNN). This rigorous validation process enabled the model to achieve a high accuracy rate of 97.89% in detecting DeepFakes. The successful implementation of this ensemble CNN approach demonstrates its effectiveness in distinguishing between real and fabricated imagery with high precision. This research makes a substantial contribution to the field of digital image forensics, offering a reliable tool for stakeholders across various sectors to identify and counteract the spread of DeepFake images online.;"DeepFake Detection;Convolutional Neural Networks (CNN);MobileNet;Xception;Advanced CNN (ACNN);Ensemble Learning;Generative Adversarial Networks (GANs)";IEEE
912;Robust CLIP-Based Detector for Exposing Diffusion Model-Generated Images;"Santosh; L. Lin; I. Amerini; X. Wang; S. Hu";2024;Diffusion models (DMs) have revolutionized image generation, producing high-quality images with applications spanning various fields. However, their ability to create hyper-realistic images poses significant challenges in distinguishing between real and synthetic content, raising concerns about digital authenticity and potential misuse in creating deepfakes. This work introduces a robust detection framework that integrates image and text features extracted by CLIP model with a Multilayer Perceptron (MLP) classifier. We propose a novel loss that can improve the detector�s robustness and handle imbalanced datasets. Additionally, we flatten the loss landscape during the model training to improve the detector�s generalization capabilities. The effectiveness of our method, which outperforms traditional detection techniques, is demonstrated through extensive experiments, underscoring its potential to set a new state-of-the-art approach in DM-generated image detection. The code is available at https://github.com/Purdue-M2/RobustDM_Generated_Image_Detection.;"Diffusion models;CLIP;Robust;AI images";IEEE
917;FaceForensics++: Learning to Detect Manipulated Facial Images;"A. R�ssler; D. Cozzolino; L. Verdoliva; C. Riess; J. Thies; M. Niessner";2019;The rapid progress in synthetic image generation and manipulation has now come to a point where it raises significant concerns for the implications towards society. At best, this leads to a loss of trust in digital content, but could potentially cause further harm by spreading false information or fake news. This paper examines the realism of state-of-the-art image manipulations, and how difficult it is to detect them, either automatically or by humans. To standardize the evaluation of detection methods, we propose an automated benchmark for facial manipulation detection. In particular, the benchmark is based on Deep-Fakes, Face2Face, FaceSwap and NeuralTextures as prominent representatives for facial manipulations at random compression level and size. The benchmark is publicly available and contains a hidden test set as well as a database of over 1.8 million manipulated images. This dataset is over an order of magnitude larger than comparable, publicly available, forgery datasets. Based on this data, we performed a thorough analysis of data-driven forgery detectors. We show that the use of additional domain-specific knowledge improves forgery detection to unprecedented accuracy, even in the presence of strong compression, and clearly outperforms human observers.;;IEEE
918;Using Grayscale Frequency Statistic to Detect Manipulated Faces in Wavelet-Domain;"G. -J. Wang; W. Li; Q. Jiang; X. Jin; X. -H. Cui";2021;Manipulating facial images results in negative influences on the social association, with deep generative models. Although many detection methods have been proposed, they have either designed sophisticated neural networks that lack enough interpretability, or found defects specific to one manipulation method. To address this issue, we propose a new approach to explore the defects of fake facial images after wavelet transform and call it GFS (Grayscale Frequency Statistics). First, we utilize Haar wavelet transformation to decompose the image into low-frequency approximation, horizontal detail, vertical detail, and diagonal detail. The GFS of real and fake images exhibit different distribution and forms in these four subbands. We qualitatively analyze these differences and quantify them as weights. Then, these four subband images are used to train four CNNs respectively, and the obtained detection results also verify the differences in GFS. After that, we combine the prediction results of the four CNNs and the corresponding weights to further improve the detection performance. We conduct extensive experiments on 11 datasets generated by various facial manipulation methods, and the superior results show the effectiveness of our proposed approach. Our findings indicate that the fake images generated by the current facial manipulation methods cannot simulate real images in wavelet-domain.;;IEEE
925;Detecting Forged Facial Videos Using Convolutional Neural Networks;"N. Sambhu; S. Canavan";2023;In this paper, we propose to detect forged videos, of faces, in online videos. To facilitate this detection, we propose to use smaller (fewer parameters to learn) convolutional neural networks (CNN), for a data-driven approach to forged video detection. To validate our approach, we investigate the Face-Forensics public dataset detailing both frame-based and video-based results. The proposed method is shown to outperform current state of the art. We also perform an ablation study, analyzing the impact of batch size, number of filters, and number of network layers on the accuracy of detecting forged videos.;"deepfake;convolutional neural network;videos;deep learning";IEEE
929;Video Manipulations Beyond Faces: A Dataset with Human-Machine Analysis;"T. Mittal; R. Sinha; V. Swaminathan; J. Collomosse; D. Manocha";2023;As tools for content editing mature, and artificial intelligence (AI) based algorithms for synthesizing media grow, the presence of manipulated content across online media is increasing. This phenomenon causes the spread of misinformation, creating a greater need to distinguish between �real� and �manipulated� content. To this end, we present Videosham, a dataset consisting of 826 videos (413 real and 413 manipulated). Many of the existing deepfake datasets focus exclusively on two types of facial manipulations-swapping with a different subject's face or altering the existing face. Videosham, on the other hand, contains more diverse, context-rich, and human-centric, high-resolution videos manipulated using a combination of 6 different spatial and temporal attacks. Our analysis shows that state-of-the-art manipulation detection algorithms only work for a few specific attacks and do not scale well on Videosham. We performed a user study on Amazon Mechanical Turk with 1200 participants to understand if they can differentiate between the real and manipulated videos in Videosham. Finally, we dig deeper into the strengths and weaknesses of performances by humans and SOTA-algorithms to identify gaps that need to be filled with better AI algorithms. We present the dataset here11VideoSham dataset link..;;IEEE
931;Deep Fakes Image Animation Using Generative Adversarial Networks;"A. K. Manjula; R. Thirukkumaran; K. H. Raj; A. Athappan; R. P. Reddy";2022;The idea of picture activity is for the most part moving the pictures at a specific speed so the unaided eye can't detect the distinction. We intend to do the investigation so that for certain adjustments to the current structure that is the deepfake that does the examination without earlier information on the movement target. To do this, We will be training a dataset on a bunch of pictures and recordings for objects of a similar class (e.g., face, body, road view). As of late, a few uses of neural organizations (CNNs) have been applied to the genuine human head. The informational index can be prepared on many pictures and recordings to make practical talking heads. You can energize the first picture of an individual into an objective individual posture (driving video) while safeguarding the individual's appearance and body. In the mean time, in any case, frameworks are being fostered that can recognize recordings and activities produced by Deep-Fakes. Since this is a significant security issue. We energized pictures to create talking heads and tried different things with picture age Using the Deep-Fakes age's contingent generative threatening organization, the outcomes were reasonable. Likewise executed Deep-Fake Detector XceptionNet (a Deep Learning Algorithm that Detects Face Swaps in Videos) with slight adjustments to arrive at 95� exactness when identifying Deep-Fake. At last, you can without much of a stretch idiot Deepfake identifiers by executing an as of late acquainted method with quit making Deep-Fakes. XceptionNet had the option to accomplish a precision of under 30 in recognizing the Deep-Fake age when maddened.;"DeepFakes;ImageAnimation;GANS;Generative Adversarial Networks;cGanz;Co-lab;video;MonkeyNET";IEEE
939;Watch Those Words: Video Falsification Detection Using Word-Conditioned Facial Motion;"S. Agarwal; L. Hu; E. Ng; T. Darrell; H. Li; A. Rohrbach";2023;In today�s era of digital misinformation, we are increasingly faced with new threats posed by video falsification techniques. Such falsifications range from cheapfakes (e.g., lookalikes or audio dubbing) to deepfakes (e.g., sophisticated AI media synthesis methods), which are becoming perceptually indistinguishable from real videos. To tackle this challenge, we propose a multi-modal semantic forensic approach to discover clues that go beyond detecting discrepancies in visual quality, thereby handling both simpler cheapfakes and visually persuasive deepfakes. In this work, our goal is to verify that the purported person seen in the video is indeed themselves by detecting anomalous facial movements corresponding to the spoken words. We leverage the idea of attribution to learn person-specific biometric patterns that distinguish a given speaker from others. We use interpretable Action Units (AUs) to capture a person�s face and head movement as opposed to deep CNN features, and we are the first to use word-conditioned facial motion analysis. We further demonstrate our method�s effectiveness on a range of fakes not seen in training including those without video manipulation, that were not addressed in prior work.;"Applications: Social good;Biometrics;face;gesture;body pose";IEEE
942;Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked Autoencoders;"S. Das; T. Jain; D. Reilly; P. Balaji; S. Karmakar; S. Marjit; X. Li; A. Das; M. S. Ryoo";2024;Vision Transformers (ViTs) have become ubiquitous in computer vision. Despite their success, ViTs lack inductive biases, which can make it difficult to train them with limited data. To address this challenge, prior studies suggest training ViTs with self-supervised learning (SSL) and fine-tuning sequentially. However, we observe that jointly optimizing ViTs for the primary task and a Self-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when the amount of training data is limited. We explore the appropriate SSL tasks that can be optimized alongside the primary task, the training schemes for these tasks, and the data scale at which they can be most effective. Our findings reveal that SSAT is a powerful technique that enables ViTs to leverage the unique characteristics of both the self-supervised and primary tasks, achieving better performance than typical ViTs pre-training with SSL and fine-tuning sequentially. Our experiments, conducted on 10 datasets, demonstrate that SSAT significantly improves ViT performance while reducing carbon footprint. We also confirm the effectiveness of SSAT in the video domain for deepfake detection, showcasing its generalizability. Our code is available at https://github.com/dominickrei/Limited-data-vits.;"Algorithms;Video recognition and understanding;Algorithms;Machine learning architectures;formulations;and algorithms";IEEE