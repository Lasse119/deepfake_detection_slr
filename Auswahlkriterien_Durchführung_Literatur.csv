ID,Title,Authors,Year,Abstract,Keywords,Datenbank
1,Leveraging Deep Learning Approaches for Deepfake Detection: A Review,"Tiwari, Aniruddha and Dave, Rushit and Vanamala, Mounika",2023,"Abstract� Conspicuous progression in the field of machine learning (ML) and deep learning (DL) have led the jump of highly realistic fake media, these media oftentimes referred as deepfakes. Deepfakes are fabricated media which are generated by sophisticated AI that are at times very difficult to set apart from the real media. So far, this media can be uploaded to the various social media platforms, hence advertising it to the world got easy, calling for an efficacious countermeasure. Thus, one of the optimistic counter steps against deepfake would be deepfake detection. To undertake this threat, researchers in the past have created models to detect deepfakes based on ML/DL techniques like Convolutional Neural Networks (CNN). This paper aims to explore different methodologies with an intention to achieve a cost-effective model with a higher accuracy with different types of the datasets, which is to address the generalizability of the dataset.?","convolutional neural network, Machine Learning, Long Short-Term Memory, Fake Image Detection, Deepfake, Deep Neural Network, Deep Learning",ACM
2,Deepfake Creation and Detection using Ensemble Deep Learning Models,"Rao, Sanjeev and Shelke, Nitin Arvind and Goel, Aditya and Bansal, Harshita",2022,"The use of Artificial Intelligence to create falsified videos using Deep Neural Networks is posing a serious problem in distinguishing the real from the counterfeit. These counterfeit videos are known as �Deepfakes�. Due to their realistic appearance and their subsequent ability to influence perceptions and mass sentiment, deepfakes must be monitored. Malicious deepfakes must be detected, and their circulation is immediately controlled. Many deepfake detection technologies have been developed that use particular features to classify fabricated media. This paper proposes the framework of deepfake detection using deep neural network models. The hybrid combination of deep learning models predicts deepfakes with better accuracy. The proposed model is tested and evaluated on the DFDC and CelebDF dataset that classifies more deepfake videos.","LSTM, GANs, Deepfakes, Deep Learning, Artificial Intelligence",ACM
3,Realistic Facial Deep Fakes Detection Through Self-Supervised Features Generated by a Self-Distilled Vision Transformer,"Gomes, Bruno Rocha and Busson, Antonio J. G. and Boaro, Jos\'{e} and Colcher, S\'{e}rgio",2023,"Several large-scale datasets and models to detect deep fake content and aid in combatting its harms have emerged. The best models usually combine Vision Transformers with CNN-based architectures. However, the recent emergence of the so-called Foundation Models (FMs), in which deep learning models are fed with massive amounts of unlabeled data (usually by applying self-supervised techniques), has established a whole new perspective for many tasks previously addressed with specific-tailored models. This work investigates how good FMs can be in DeepFake detection, especially in the case of realistic facial production or adulteration. With this realm, we investigate a model using DINO, a foundation model based on Vision Transformers (ViT) that produces universal self-supervised features suitable for image-level visual tasks. Our experiments show that this model can improve deep fake facial detection in many scenarios with different baselines. In particular, the results showed that models trained with self-attention activation maps had higher AUC and F1-score than the baseline ones in all CNN architectures we used.","vision transfomers, self-supervised, deep learning, deep fake detection",ACM
4,Head Pose Estimation Patterns as Deepfake Detectors,"Becattini, Federico and Bisogni, Carmen and Loia, Vincenzo and Pero, Chiara and Hao, Fei",2024,"The capacity to create �fake� videos has recently raised concerns about the reliability of multimedia content. Identifying between true and false information is a critical step toward resolving this problem. On this issue, several algorithms utilizing deep learning and facial landmarks have yielded intriguing results. Facial landmarks are traits that are solely tied to the subject�s head posture. Based on this observation, we study how Head Pose Estimation (HPE) patterns may be utilized to detect deepfakes in this work. The HPE patterns studied are based on FSA-Net, SynergyNet, and WSM, which are among the most performant approaches on the state-of-the-art. Finally, using a machine learning technique based on K-Nearest Neighbor and Dynamic Time Warping, their temporal patterns are categorized as authentic or false. We also offer a set of experiments for examining the feasibility of using deep learning techniques on such patterns. The findings reveal that the ability to recognize a deepfake video utilizing an HPE pattern is dependent on the HPE methodology. On the contrary, performance is less dependent on the performance of the utilized HPE technique. Experiments are carried out on the FaceForensics++ dataset that presents both identity swap and expression swap examples. The findings show that FSA-Net is an effective feature extraction method for determining whether a pattern belongs to a deepfake or not. The approach is also robust in comparison to deepfake videos created using various methods or for different goals. In the mean the method obtain 86% of accuracy on the identity swap task and 86.5% of accuracy on the expression swap. These findings offer up various possibilities and future directions for solving the deepfake detection problem using specialized HPE approaches, which are also known to be fast and reliable.","DeepFake, face recognition, Head Pose Estimation, machine learning, deep learning",ACM
5,Cross-Forgery Analysis of Vision Transformers and CNNs for Deepfake Image Detection,"Coccomini, Davide Alessandro and Caldelli, Roberto and Falchi, Fabrizio and Gennaro, Claudio and Amato, Giuseppe",2022,"Deepfake Generation Techniques are evolving at a rapid pace, making it possible to create realistic manipulated images and videos and endangering the serenity of modern society. The continual emergence of new and varied techniques brings with it a further problem to be faced, namely the ability of deepfake detection models to update themselves promptly in order to be able to identify manipulations carried out using even the most recent methods. This is an extremely complex problem to solve, as training a model requires large amounts of data, which are difficult to obtain if the deepfake generation method is too recent. Moreover, continuously retraining a network would be unfeasible. In this paper, we ask ourselves if, among the various deep learning techniques, there is one that is able to generalise the concept of deepfake to such an extent that it does not remain tied to one or more specific deepfake generation methods used in the training set. We compared a Vision Transformer with an EfficientNetV2 on a cross-forgery context based on the ForgeryNet dataset. From our experiments, It emerges that EfficientNetV2 has a greater tendency to specialize often obtaining better results on training methods while Vision Transformers exhibit a superior generalization ability that makes them more competent even on images generated with new methodologies.","transformer networks, deep learning, deep fake detection",ACM
6,Security Implications of Deepfakes in Face Authentication,"Salko, Milan and Firc, Anton and Malinka, Kamil",2024,"Deepfakes are media generated by deep learning and are nearly indistinguishable from real content to humans. Deepfakes have seen a significant surge in popularity in recent years. There have been numerous papers discussing their effectiveness in deceiving people. What's equally, if not more concerning, is the potential vulnerability of facial and voice recognition systems to deepfakes. The misuse of deepfakes to spoof automated facial recognition systems can threaten various aspects of our lives, including financial security and access to secure locations. This issue remains largely unexplored. Thus, this paper investigates the technical feasibility of a spoofing attack on facial recognition. Firstly, we perform a threat analysis to understand what facial recognition use cases allow the execution of deepfake spoofing attacks. Based on this analysis, we define the attacker model for these attacks on facial recognition systems. Then, we demonstrate the ability of deepfakes to spoof two commercial facial recognition systems. Finally, we discuss possible means to prevent such spoofing attacks.","deepfake, facial recognition, biometrics systems, machine learning, computer security",ACM
7,Towards Quantitative Evaluation of Explainable AI Methods for Deepfake Detection,"Tsigos, Konstantinos and Apostolidis, Evlampios and Baxevanakis, Spyridon and Papadopoulos, Symeon and Mezaris, Vasileios",2024,"In this paper we propose a new framework for evaluating the performance of explanation methods on the decisions of a deepfake detector. This framework assesses the ability of an explanation method to spot the regions of a fake image with the biggest influence on the decision of the deepfake detector, by examining the extent to which these regions can be modified through a set of adversarial attacks, in order to flip the detector�s prediction or reduce its initial prediction; we anticipate a larger drop in deepfake detection accuracy and prediction, for methods that spot these regions more accurately. Based on this framework, we conduct a comparative study using a state-of-the-art model for deepfake detection that has been trained on the FaceForensics++ dataset, and five explanation methods from the literature. The findings of our quantitative and qualitative evaluations document the advanced performance of the LIME explanation method against the other compared ones, and indicate this method as the most appropriate for explaining the decisions of the utilized deepfake detector.","Adversarial image generation, Deepfake detection, Evaluation framework, Explainable AI, Visual explanations",ACM
8,Deepfake Detection Analyzing Hybrid Dataset Utilizing CNN and SVM,"Mallet, Jacob and Pryor, Laura and Dave, Rushit and Vanamala, Mounika",2023,"Social media is currently being used by many individuals online as a major source of information. However, not all information shared online is true, even photos and videos can be doctored. Deepfakes have recently risen with the rise of technological advancement and have allowed nefarious online users to replace one's face with a computer-generated face of anyone they would like, including important political and cultural figures. Deepfakes are now a tool to be able to spread mass misinformation. There is now an immense need to create models that are able to detect deepfakes and keep them from being spread as seemingly real images or videos. In this paper, we propose a new deepfake detection schema using two popular machine learning algorithms; support vector machine and convolutional neural network, along with a publicly available dataset?named the 140k Real and Fake Faces to accurately detect deepfakes in images with accuracy rates reaching as high as 88.33%.?&nbsp;","convolutional neural network, Support vector machine, Machine Learning, Fake Image Detection, Deepfake",ACM
9,IoT based application designing of Deep Fake Test for Face animation,"Sridevi, Kotari and Kanaprthi. Suresh Kumar and D. Sameera and Garapati, Yugandhar and D. Krishnamadhuri and Bethu, Srikanth",2022,"Development of Deep Learning models of Internet of Things (IoT) enclosures with limited resources are difficult because Both Quality of Results are difficult to achieve&nbsp;- QoR as follows two models, DNN Model, and Inference Accuracy and Quality of Services such as power consumption, throughput, and latency. Currently, the development of DNN models is often separated from deploying them to IoT devices, which leads to the most effective solution. If there are many records that represent objects of substantially the same class (face, human body, etc.), you can apply frames to each object of this class. To achieve this, use an independent representation to distinguish between appearance and progress data. Deep fake detection is achieved by using a novel, lightweight Deep Learning method on the IoT platform that is memory-efficient and lightweight.&nbsp;It is carried out in two different stages. The first phase of the deep fake test aims to implement a method of extracting images from a video and using them in conjunction with a Deep Neural Network to implement a test for face animation.&nbsp;It has been reported that the impact of the background elimination has been reported before the background subtraction. Here the Trans GAN model is used for the image classification. In the second phase, the work can be recorded and executed by the IOT device that can record live video streams and then detect activity involved in live video. An activity detection prototype based on IoT devices with small processing power is presented. This prototype provides improvements to the system, extending its application in various ways to improve portability, networking, and other equipment capabilities. The proposed architecture will be evaluated against four highly competitive object detection benchmarking tasks CIFAR10, CIFAR100, SVHN, and ImageNet.","Object detection, GAN, Face animation, Deep Fake",ACM
10,Where Do Deep Fakes Look? Synthetic Face Detection via Gaze Tracking,"Demir, Ilke and Ciftci, Umur Aybars",2021,"Following the recent initiatives for the democratization of AI, deep fake generators have become increasingly popular and accessible, causing dystopian scenarios towards social erosion of trust. A particular domain, such as biological signals, attracted attention towards detection methods that are capable of exploiting authenticity signatures in real videos that are not yet faked by generative approaches. In this paper, we first propose several prominent eye and gaze features that deep fakes exhibit differently. Second, we compile those features into signatures and analyze and compare those of real and fake videos, formulating geometric, visual, metric, temporal, and spectral variations. Third, we generalize this formulation to the deep fake detection problem by a deep neural network, to classify any video in the wild as fake or real. We evaluate our approach on several deep fake datasets, achieving 92.48% accuracy on FaceForensics++, 80.0% on Deep Fakes (in the wild), 88.35% on CelebDF, and 99.27% on DeeperForensics datasets. Our approach outperforms most deep and biological fake detectors with complex network architectures without the proposed gaze signatures. We conduct ablation studies involving different features, architectures, sequence durations, and post-processing artifacts.","neural networks, generative models, gaze, fake detection, deep fakes",ACM
11,Enhancing Deepfake Detection: Spatial-Temporal Preprocessing and Self-Attention ResI3D Model,"Son, Sangho and Lee, Jaekyu and Min, Kyungha and Kim, Wooju",2024,"Deepfake technology is the outcome of employing deep learning techniques to overlay the face of one individual onto the video of another. As deep learning technology advances rapidly, the proliferation of high-quality deepfakes for malicious digital activities is notably on the rise. With growing concerns about the misuse of deepfake technology, there is an increasing demand for research into deep learning-based methodologies to detect and counteract it. While Deepfake detection using deep learning has been a subject of prior research, these approaches primarily rely on images hence not utilizing temporal information. Additionally, research combining CNN and RNN has inherent limitations. It operates with compressed data, resulting in the loss of spatial information and the utilization of the inherent temporal characteristics in pixel-to-pixel temporal data. In this study, we propose a detection model that harnesses the inherent attributes of video data through self-attention on both the spatial and temporal axes, using the ResI3D model along with the Non-Local Block. Additionally, we conducted experiments during the preprocessing phase to validate and implement methods that facilitate the model's effective learning of both temporal and spatial information. As a result, our model demonstrated enhanced performance when compared to existing deepfake video detection models.","Anomaly Detection, Computer Vision, Deepfakes, Neural Networks",ACM
12,Can Deepfakes be created on a whim?,"Mehta, Pulak and Jagatap, Gauri and Gallagher, Kevin and Timmerman, Brian and Deb, Progga and Garg, Siddharth and Greenstadt, Rachel and Dolan-Gavitt, Brendan",2023,"Recent advancements in machine learning and computer vision have led to the proliferation of Deepfakes. As technology democratizes over time, there is an increasing fear that novice users can create Deepfakes, to discredit others and undermine public discourse. In this paper, we conduct user studies to understand whether participants with advanced computer skills and varying level of computer science expertise can create Deepfakes of a person saying a target statement using limited media files. We conduct two studies; in the first study (n = 39) participants try creating a target Deepfake in a constrained time frame using any tool they desire. In the second study (n = 29) participants use pre-specified deep learning based tools to create the same Deepfake. We find that for the first study, of the participants successfully created complete Deepfakes with audio and video, whereas for the second user study, of the participants were successful in stitching target speech to the target video. We further use Deepfake detection software tools as well as human examiner-based analysis, to classify the successfully generated Deepfake outputs as fake, suspicious, or real. The software detector classified of the Deepfakes as fake, whereas the human examiners classified of the videos as fake. We conclude that creating Deepfakes is a simple enough task for a novice user given adequate tools and time; however, the resulting Deepfakes are not sufficiently real-looking and are unable to completely fool detection software as well as human examiners.","deepfakes, generative models, video synthesis",ACM
13,Data Augmentation-based Novel Deep Learning Method for Deepfaked Images Detection,"Iqbal, Farkhund and Abbasi, Ahmed and Javed, Abdul Rehman and Almadhor, Ahmad and Jalil, Zunera and Anwar, Sajid and Rida, Imad",2024,"Recent advances in artificial intelligence have led to deepfake images, enabling users to replace a real face with a genuine one. deepfake images have recently been used to malign public figures, politicians, and even average citizens. deepfake but realistic images have been used to stir political dissatisfaction, blackmail, propagate false news, and even carry out bogus terrorist attacks. Thus, identifying real images from fakes has got more challenging. To avoid these issues, this study employs transfer learning and data augmentation technique to classify deepfake images. For experimentation, 190,335 RGB-resolution deepfake and real images and image augmentation methods are used to prepare the dataset. The experiments use the deep learning models: convolutional neural network (CNN), Inception V3, visual geometry group (VGG19), and VGG16 with a transfer learning approach. Essential evaluation metrics (accuracy, precision, recall, F1-score, confusion matrix, and AUC-ROC curve score) are used to test the efficacy of the proposed approach. Results revealed that the proposed approach achieves an accuracy, recall, F1-score and AUC-ROC score of 90% and 91% precision, with our fine-tuned VGG16 model outperforming other DL models in recognizing real and deepfakes.","Deepfake detection, data augmentation, image processing, deep learning, artificial intelligence, transfer learning",ACM
14,Disrupting Deepfakes: A Survey on Adversarial Perturbation Techniques and Prevention Strategies,"Bagaria, Utkarsh and Kumar, Vijit and Rajesh, Tanvi and Deepak, Vibhav and S S, Shylaja",2024,"Ensuring digital integrity is paramount in our digitally connected world, and the escalating threat of deepfakes poses a substantial challenge amidst rapid technological advancements. The proliferation of sophisticated techniques for crafting highly realistic deepfakes has raised concerns about their potential for causing significant personal and industrial harm, including defamation and misinformation. Although strides have been made in developing detection methods, irreparable damage is often inflicted once a deepfake infiltrates the public domain. This paper discusses multiple approaches to mitigate the deepfake predicament at its source, emphasizing the need to prevent their generation. We analyse leveraging adversarial machine learning algorithms to generate perturbations that fortify against deepfake creation. By disrupting the underlying algorithms attempting to produce deceptive content, these approaches seek to thwart the inception of harmful deepfakes. This proactive stance aims to preclude the detrimental consequences associated with the release of such manipulated media. The research delves into the active domain of adversarial perturbation generation, exploring innovative methodologies to safeguard against the ever-evolving landscape of deepfake technology. This paper not only contributes to the ongoing discourse on internet safety but also underscores the wide-reaching implications and promising prospects of adversarial machine learning in combating the deepfake menace.","Adversarial Machine Learning, Deepfake, Discriminator, Generator, Gradient, Perturbation",ACM
15,Recapture Detection to Fight Deep Identity Theft,"Trabelsi, Anis and Pic, Marc and Dugelay, Jean-Luc",2023,"The progress made in deep learning has allowed the deployment of more powerful biometric authentication systems instead of traditional ones based on passwords or PIN codes. Facial recognition is widely used on smartphones to grant user access. However, advances in deep learning also improve methods for doctoring images and videos. A fraudulent user can use these methods to steal the identity of another person. It is very easy for impostors to present to the smartphone an image or video of the victim's face displayed on another screen. In this paper, we describe the security risks when a facial recognition system is attacked by presenting an image, a video or an interactive deepfake displayed on a screen. We also present a deep learning-based method to detect this kind of attack.","recaptured image detection, identity theft, face anti-spoofing, e-KYC, digital image forensics",ACM
16,Robust Deepfake Detection by Addressing Generalization and Trustworthiness Challenges: A Short Survey,"Liu, Ping and Tao, Qiqi and Zhou, Joey",2024,"The rapid advancement of deep learning technologies has led to a proliferation of deepfake content, posing serious threats to security, privacy, and trust in digital information. This paper explores the evolution of robust deepfake detection methods over recent years from two perspectives, specifically, generalized and trustworthy detection. As numerous generative techniques continuously emerge, generalized detection emphasizes the robustness against data distribution shift represented by unseen manipulation at testing time. By systematically reviewing generalized detection methods, we categorize these approaches into input-level, model-level, and learning-level. Trustworthy detection aims to enhance robustness against attacks that maliciously fail the detection system, including adversarial and backdoor attacks. To address these threats, researchers have developed robust defense strategies, including adversarial feature similarity learning and ensemble methods. By providing an overview of robust detection methods, attack techniques, and defense strategies, this paper highlights the challenges and advancements in creating reliable and generalizable deepfake detection systems.","deepfake detection, generalization, robustness, trustworthy",ACM
17,Autoencoder-based Data Augmentation for Deepfake Detection,"Stanciu, Dan-Cristian and Ionescu, Bogdan",2023,"Image generation has seen huge leaps in the last few years. Less than 10 years ago we could not generate accurate images using deep learning at all, and now it is almost impossible for the average person to distinguish a real image from a generated one. In spite of the fact that image generation has some amazing use cases, it can also be used with ill intent. As an example, deepfakes have become more and more indistinguishable from real pictures and that poses a real threat to society. It is important for us to be vigilant and active against deepfakes, to ensure that the false information spread is kept under control. In this context, the need for good deepfake detectors feels more and more urgent. There is a constant battle between deepfake generators and deepfake detection algorithms, each one evolving at a rapid pace. But, there is a big problem with deepfake detectors: they can only be trained on so many data points and images generated by specific architectures. Therefore, while we can detect deepfakes on certain datasets with near 100% accuracy, it is sometimes very hard to generalize and catch all real-world instances. Our proposed solution is a way to augment deepfake detection datasets using deep learning architectures, such as Autoencoders or U-Net. We show that augmenting deepfake detection datasets using deep learning improves generalization to other datasets. We test our algorithm using multiple architectures, with experimental validation being carried out on state-of-the-art datasets like CelebDF and DFDC Preview. The framework we propose can give flexibility to any model, helping to generalize to unseen datasets and manipulations.","autoencoder, data augmentation, deep learning, deepfake, digital video forensics, face manipulation, generalization",ACM
18,DEEPFAKER: A Unified Evaluation Platform for Facial Deepfake and Detection Models,"Wang, Li and Meng, Xiangtao and Li, Dan and Zhang, Xuhong and Ji, Shouling and Guo, Shanqing",2024,"Deepfake data contains realistically manipulated faces�its abuses pose a huge threat to the security and privacy-critical applications. Intensive research from academia and industry has produced many deepfake/detection models, leading to a constant race of attack and defense. However, due to the lack of a unified evaluation platform, many critical questions on this subject remain largely unexplored. How is the anti-detection ability of the existing deepfake models? How generalizable are existing detection models against different deepfake samples? How effective are the detection APIs provided by the cloud-based vendors? How evasive and transferable are adversarial deepfakes in the lab and real-world environment? How do various factors impact the performance of deepfake and detection models?To bridge the gap, we design and implement DEEPFAKER1 a unified and comprehensive deepfake detection evaluation platform. Specifically, DEEPFAKER has integrated 10 state-of-the-art deepfake methods and 9 representative detection methods, while providing a user-friendly interface and modular design that allows for easy integration of new methods. Leveraging DEEPFAKER, we conduct a large-scale empirical study of facial deepfake/detection models and draw a set of key findings: (i)&nbsp;the detection methods have poor generalization on samples generated by different deepfake methods; (ii)&nbsp;there is no significant correlation between anti-detection ability and visual quality of deepfake samples; (iii)&nbsp;the current detection APIs have poor detection performance and adversarial deepfakes can achieve about 70% attack success rate on all cloud-based vendors, calling for an urgent need to deploy effective and robust detection APIs; (iv)&nbsp;the detection methods in the lab are more robust against transfer attacks than the detection APIs in the real-world environment; and (v)&nbsp;deepfake videos may not always be more difficult to detect after video compression. We envision that DEEPFAKER will benefit future research on facial deepfake and detection.","Facial deepfake, deepfake detection, adversarial machine learning, experimental evaluation",ACM
19,PUFshield: A Hardware-Assisted Approach for Deepfake Mitigation Through PUF-Based Facial Feature Attestation,"Bathalapalli, Venkata Karthik Vishnu Vardhan and Yanambaka, Venkata Prasanth and Mohanty, Saraju and Kougianos, Elias",2024,"Deepfake has emerged as a threat to individual�s privacy and identity. It uses advanced deep learning algorithms to synthesize visual, text, and audio from multimedia content in a realistic way. The advancement of Deepfake techniques is posing a question on the integrity of the digital content on social media. This work presents a novel hardware assisted Deepfake mitigation approach through the device and content integrity verification. In this work, the potential of hardware security primitive Physical Unclonable Functions (PUF) for mitigation of visual Deepfakes has been explored. The proposed framework presents a novel PUF-based image attestation technique that uses human facial features to create a unique pseudo-identity. The proposed architecture maps facial key point coordinates of each person in an image to PUF and creates a unique PUF generated key thereby having a unique pseudo identity for each image. Experimental evaluation uses Dlib facial detection model for facial attribute extraction and uses Arbiter PUF for image attestation.","Deepfake, Deepfake Mitigation, Hardware Assisted Security (HAS), Physical Unclonable Functions (PUF), Security-by-Design (SbD)",ACM
20,Deepfake Video Detection via Predictive Representation Learning,"Ge, Shiming and Lin, Fanzhao and Li, Chenyu and Zhang, Daichi and Wang, Weiping and Zeng, Dan",2022,"Increasingly advanced deepfake approaches have made the detection of deepfake videos very challenging. We observe that the general deepfake videos often exhibit appearance-level temporal inconsistencies in some facial components between frames, resulting in discriminative spatiotemporal latent patterns among semantic-level feature maps. Inspired by this finding, we propose a predictive representative learning approach termed Latent Pattern Sensing to capture these semantic change characteristics for deepfake video detection. The approach cascades a Convolution Neural Network-based encoder, a ConvGRU-based aggregator, and a single-layer binary classifier. The encoder and aggregator are pretrained in a self-supervised manner to form the representative spatiotemporal context features. Then, the classifier is trained to classify the context features, distinguishing fake videos from real ones. Finally, we propose a selective self-distillation fine-tuning method to further improve the robustness and performance of the detector. In this manner, the extracted features can simultaneously describe the latent patterns of videos across frames spatially and temporally in a unified way, leading to an effective and robust deepfake video detector. Extensive experiments and comprehensive analysis prove the effectiveness of our approach, e.g., achieving a very highest Area Under Curve (AUC) score of 99.94% on FaceForensics++ benchmark and surpassing 12 states of the art at least 7.90%@AUC and 8.69%@AUC on challenging DFDC and Celeb-DF(v2) benchmarks, respectively.","video understanding, deep learning, representation learning, Deepfake video detection",ACM
21,Human Perception of Audio Deepfakes,"M\""{u}ller, Nicolas M. and Pizzi, Karla and Williams, Jennifer",2022,"The recent emergence of deepfakes has brought manipulated and generated content to the forefront of machine learning research. Automatic detection of deepfakes has seen many new machine learning techniques. Human detection capabilities, however, are far less explored. In this paper, we present results from comparing the abilities of humans and machines for detecting audio deepfakes used to imitate someone's voice. For this, we use a web-based application framework formulated as a game. Participants were asked to distinguish between real and fake audio samples. In our experiment, 410 unique users competed against a state-of-the-art AI deepfake detection algorithm for 13229 total of rounds of the game. We find that humans and deepfake detection algorithms share similar strengths and weaknesses, both struggling to detect certain types of attacks. This is in contrast to the superhuman performance of AI in many application areas such as object detection or face recognition. Concerning human success factors, we find that IT professionals have no advantage over non-professionals but native speakers have an advantage over non-native speakers. Additionally, we find that older participants tend to be more susceptible than younger ones. These insights may be helpful when designing future cybersecurity training for humans as well as developing better detection algorithms.","presentation attack, human perception, games, deepfake, audio spoofing",ACM
22,The MeVer DeepFake Detection Service: Lessons Learnt from Developing and Deploying in the Wild,"Baxevanakis, Spiros and Kordopatis-Zilos, Giorgos and Galopoulos, Panagiotis and Apostolidis, Lazaros and Levacher, Killian and Baris Schlicht, Ipek and Teyssou, Denis and Kompatsiaris, Ioannis and Papadopoulos, Symeon",2022,"Enabled by recent improvements in generation methodologies, DeepFakes have become mainstream due to their increasingly better visual quality, the increase in easy-to-use generation tools and the rapid dissemination through social media. This fact poses a severe threat to our societies with the potential to erode social cohesion and influence our democracies. To mitigate the threat, numerous DeepFake detection schemes have been introduced in the literature but very few provide a web service that can be used in the wild. In this paper, we introduce the MeVer DeepFake detection service, a web service detecting deep learning manipulations in images and video. We present the design and implementation of the proposed processing pipeline that involves a model ensemble scheme, and we endow the service with a model card for transparency. Experimental results show that our service performs robustly on the three benchmark datasets while being vulnerable to Adversarial Attacks. Finally, we outline our experience and lessons learned when deploying a research system into production in the hopes that it will be useful to other academic and industry teams.","web service, trustworthy AI, DeepFake detection",ACM
23,Stance-level Sarcasm Detection with BERT and Stance-centered Graph Attention Networks,"Zhang, Yazhou and Ma, Dan and Tiwari, Prayag and Zhang, Chen and Masud, Mehedi and Shorfuzzaman, Mohammad and Song, Dawei",2023,"Computational Linguistics (CL) associated with the Internet of Multimedia Things (IoMT)-enabled multimedia computing applications brings several research challenges, such as real-time speech understanding, deep fake video detection, emotion recognition, home automation, and so on. Due to the emergence of machine translation, CL solutions have increased tremendously for different natural language processing (NLP) applications. Nowadays, NLP-enabled IoMT is essential for its success. Sarcasm detection, a recently emerging artificial intelligence (AI) and NLP task, aims at discovering sarcastic, ironic, and metaphoric information implied in texts that are generated in the IoMT. It has drawn much attention from the AI and IoMT research community. The advance of sarcasm detection and NLP techniques will provide a cost-effective, intelligent way to work together with machine devices and high-level human-to-device interactions. However, existing sarcasm detection approaches neglect the hidden stance behind texts, thus insufficient to exploit the full potential of the task. Indeed, the stance, i.e., whether the author of a text is in favor of, against, or neutral toward the proposition or target talked in the text, largely determines the text�s actual sarcasm orientation. To fill the gap, in this research, we propose a new task: stance-level sarcasm detection (SLSD), where the goal is to uncover the author�s latent stance and based on it to identify the sarcasm polarity expressed in the text. We then propose an integral framework, which consists of Bidirectional Encoder Representations from Transformers (BERT) and a novel stance-centered graph attention networks (SCGAT). Specifically, BERT is used to capture the sentence representation, and SCGAT is designed to capture the stance information on specific target. Extensive experiments are conducted on a Chinese sarcasm sentiment dataset we created and the SemEval-2018 Task 3 English sarcasm dataset. The experimental results prove the effectiveness of the SCGAT framework over state-of-the-art baselines by a large margin.","artificial intelligence, graph attention networks, stance extraction, Sarcasm detection",ACM
24,EfficientNet-based multi-dimensional network optimization for Deepfake video detection,"Zhang, Yong and Zhang, Xinqi and Li, Bingjie",2024,"The rapid development of deep learning techniques, especially generative adversarial networks, has led to the generation of very realistic forged faces. Deepfake technology has brought convenience to society and also produced a large number of undesirable effects. Many detectors have been developed to defend videos generated by Deepfake manipulation techniques. In this paper, we take low overhead and high performance as the task of Deepfake detection and propose a new EfficientNet-B0 combined with ViT Deepfake detection network, which consists of two key components: (1) ConvFFN block, which brings a larger receptive field to the network; (2) Transformer Encoder with Hilo, which separates the high and low frequencies of the attention layer to focus on the global structure. We conducted extensive experiments on the DFDC dataset and the FF++ dataset to demonstrate the stability and practical applicability of the proposed method.","ConvFFN, Deepfake, HiLo, Transformer Encoder",ACM
25,Uncovering Human Traits in Determining Real and Spoofed Audio: Insights from Blind and Sighted Individuals,"Han, Chaeeun and Mitra, Prasenjit and Billah, Syed Masum",2024,"This paper explores how blind and sighted individuals perceive real and spoofed audio, highlighting differences and similarities between the groups. Through two studies, we find that both groups focus on specific human traits in audio�such as accents, vocal inflections, breathing patterns, and emotions�to assess audio authenticity. We further reveal that humans, irrespective of visual ability, can still outperform current state-of-the-art machine learning models in discerning audio authenticity; however, the task proves psychologically demanding. Moreover, detection accuracy scores between blind and sighted individuals are comparable, but each group exhibits unique strengths: the sighted group excels at detecting deepfake-generated audio, while the blind group excels at detecting text-to-speech (TTS) generated audio. These findings not only deepen our understanding of machine-manipulated and neural-renderer audio but also have implications for developing countermeasures, such as perceptible watermarks and human-AI collaboration strategies for spoofing detection.","Audio perception, and audio watermarking, and human-AI collaboration., audio, blind, bona fide audio, deep fake audio, generative AI, neural speech, replay attack, sighted, speech, spoofed audio, text-to-speech (TTS), vision impairments, voice",ACM
26,WildDeepfake: A Challenging Real-World Dataset for Deepfake Detection,"Zi, Bojia and Chang, Minghao and Chen, Jingjing and Ma, Xingjun and Jiang, Yu-Gang",2020,"In recent years, the abuse of a face swap technique called deepfake has raised enormous public concerns. So far, a large number of deepfake videos (known as ""deepfakes"") have been crafted and uploaded to the internet, calling for effective countermeasures. One promising countermeasure against deepfakes is deepfake detection. Several deepfake datasets have been released to support the training and testing of deepfake detectors, such as DeepfakeDetection [1] and FaceForensics++ [23]. While this has greatly advanced deepfake detection, most of the real videos in these datasets are filmed with a few volunteer actors in limited scenes, and the fake videos are crafted by researchers using a few popular deepfake softwares. Detectors developed on these datasets may become less effective against real-world deepfakes on the internet. To better support detection against real-world deepfakes, in this paper, we introduce a new dataset WildDeepfake, which consists of 7,314 face sequences extracted from 707 deepfake videos collected completely from the internet. WildDeepfake is a small dataset that can be used, in addition to existing datasets, to develop and test the effectiveness of deepfake detectors against real-world deepfakes. We conduct a systematic evaluation of a set of baseline detection networks on both existing and our WildDeepfake datasets, and show that WildDeepfake is indeed a more challenging dataset, where the detection performance can decrease drastically. We also propose two (eg. 2D and 3D) Attention-based Deepfake Detection Networks (ADDNets) to leverage the attention masks on real/fake faces for improved detection. We empirically verify the effectiveness of ADDNets on both existing datasets and WildDeepfake. The dataset is available at: https://github.com/deepfakeinthewild/deepfake-in-the-wild.","deepfake detection, deep learning, datasets",ACM
27,Uncovering the Strength of Capsule Networks in Deepfake Detection,"Stanciu, Dan-Cristian and Ionescu, Bogdan",2022,"Information is everywhere, and sometimes we have no idea if what we read, watch or listen is accurate, real or authentic. This paper focuses on detecting deep learning generated videos, or deepfakes - a phenomenon which is more and more present in today's society. While there are some very good methods of detecting deepfakes, there are two key elements that should always be considered, i.e., no method is perfect and deepfake generation techniques continue to evolve, sometimes even faster than detection methods. In our proposed architectures, we focus on a family of deep learning methods that is new, has several advantages over traditional Convolutional Neural Networks and has been underutilized in the fight against fake information, namely the Capsule Networks. We show that: (i) state-of-the-art Capsule Network architectures can be improved in the context of deepfake detection, (ii) they can be used to obtain accurate results using a very small number of parameters, and (iii) Capsule Networks are a viable option over deep convolutional models. Experimental validation is carried out on two publicly available datasets, namely FaceForensics++ and CelebDF, showing very promising results.","face manipulation, digital video forensics, deepfake, deep learning, capsule networks",ACM
28,Boosting Deepfake Detection Features with Attention Units,"Waseem, Saima and ABU-BAKAR, SYED A.R. and Omar, Zaid and Ashfaq Ahmed, Bilal and Baloch, Saba",2023,"One of the emerging problems of deep learning technology is deepfake videos with easy access to powerful and inexpensive computing power; The internet is littered with fake material like fake photos, videos, and audios. People�s identities, privacy and reputations are at risk due to the widespread proliferation of fake media content. Since videos can have a potentially destructive effect on society, establishing their legitimacy is crucial. Thus, we investigate different attention mechanisms in this paper for deepfake detection. In videos, attention mechanisms are responsible for directing the convolutional Neural Network�s (CNNs) emphasis to the most critical parts of the frame in terms of both content and context. Therefore, we answer the question: How do you apply attention to deepfake detection? And what form of attention is effective for deepfake detection tasks? To address these concerns, we conduct research and experimental testing on videos that have been manipulated using four different methods drawn from the FaceForensics++ dataset. We conduct a cross-data evaluat ion for the network with and without attention to assess the network�s capacity to detect previously unseen manipulated images. The proposed approach outperformed conventional Convolutional Neural Networks for deepfake detection by 8% AUC performance.","Attention, Deepfake, Excitation., Facial manipulation, Squeeze",ACM
29,One Detector to Rule Them All: Towards a General Deepfake Attack Detection Framework,"Tariq, Shahroz and Lee, Sangyup and Woo, Simon",2021,"Deep learning-based video manipulation methods have become widely accessible to the masses. With little to no effort, people can quickly learn how to generate deepfake (DF) videos. While deep learning-based detection methods have been proposed to identify specific types of DFs, their performance suffers for other types of deepfake methods, including real-world deepfakes, on which they are not sufficiently trained. In other words, most of the proposed deep learning-based detection methods lack transferability and generalizability. Beyond detecting a single type of DF from benchmark deepfake datasets, we focus on developing a generalized approach to detect multiple types of DFs, including deepfakes from unknown generation methods such as DeepFake-in-the-Wild (DFW) videos. To better cope with unknown and unseen deepfakes, we introduce a Convolutional LSTM-based Residual Network (CLRNet), which adopts a unique model training strategy and explores spatial as well as the temporal information in a deepfakes. Through extensive experiments, we show that existing defense methods are not ready for real-world deployment. Whereas our defense method (CLRNet) achieves far better generalization when detecting various benchmark deepfake methods (97.57% on average). Furthermore, we evaluate our approach with a high-quality DeepFake-in-the-Wild dataset, collected from the Internet containing numerous videos and having more than 150,000 frames. Our CLRNet model demonstrated that it generalizes well against high-quality DFW videos by achieving 93.86% detection accuracy, outperforming existing state-of-the-art defense methods by a considerable margin.","Video Forensics, Domain Generalization and Adaptation, Deepfake",ACM
30,Deep Convolutional Pooling Transformer for Deepfake Detection,"Wang, Tianyi and Cheng, Harry and Chow, Kam Pui and Nie, Liqiang",2023,"Recently, Deepfake has drawn considerable public attention due to security and privacy concerns in social media digital forensics. As the wildly spreading Deepfake videos on the Internet become more realistic, traditional detection techniques have failed in distinguishing between real and fake. Most existing deep learning methods mainly focus on local features and relations within the face image using convolutional neural networks as a backbone. However, local features and relations are insufficient for model training to learn enough general information for Deepfake detection. Therefore, the existing Deepfake detection methods have reached a bottleneck to further improve the detection performance. To address this issue, we propose a deep convolutional Transformer to incorporate the decisive image features both locally and globally. Specifically, we apply convolutional pooling and re-attention to enrich the extracted features and enhance efficacy. Moreover, we employ the barely discussed image keyframes in model training for performance improvement and visualize the feature quantity gap between the key and normal image frames caused by video compression. We finally illustrate the transferability with extensive experiments on several Deepfake benchmark datasets. The proposed solution consistently outperforms several state-of-the-art baselines on both within- and cross-dataset experiments.","transformer, image keyframes, Deepfake detection",ACM
31,BZNet: Unsupervised Multi-scale Branch Zooming Network for Detecting Low-quality Deepfake Videos,"Lee, Sangyup and An, Jaeju and Woo, Simon S.",2022,"Generating a deep learning-based fake video has become no longer rocket science. The advancement of automated Deepfake (DF) generation tools that mimic certain targets has rendered society vulnerable to fake news or misinformation propagation. In real-world scenarios, DF videos are compressed to low-quality (LQ) videos, taking up less storage space and facilitating dissemination through the web and social media. Such LQ DF videos are much more challenging to detect than high-quality (HQ) DF videos. To address this challenge, we rethink the design of standard deep learning-based DF detectors, specifically exploiting feature extraction to enhance the features of LQ images. We propose a novel LQ DF detection architecture, multi-scale Branch Zooming Network (BZNet), which adopts an unsupervised super-resolution (SR) technique and utilizes multi-scale images for training. We train our BZNet only using highly compressed LQ images and experiment under a realistic setting, where HQ training data are not readily accessible. Extensive experiments on the FaceForensics++ LQ and GAN-generated datasets demonstrate that our BZNet architecture improves the detection accuracy of existing CNN-based classifiers by 4.21% on average. Furthermore, we evaluate our method against a real-world Deepfake-in-the-Wild dataset collected from the internet, which contains 200 videos featuring 50 celebrities worldwide, outperforming the state-of-the-art methods by 4.13%.","Deepfake Detection, Forensics, Low-quality Deepfakes, Multi-scale Learning, Unsupervised Super-Resolution",ACM
32,MMDFD- A Multimodal Custom Dataset for Deepfake Detection,"S, ASHA and P, VINOD and Menon, Varun G",2023,"A multi-modal deepfake dataset is relevant in addressing the growing concern of deepfake misuse, which poses a significant security and privacy threat. Deepfakes are becoming increasingly sophisticated, and their potential to deceive individuals and organizations is a significant issue. The ability to generate synthesized human voices using deep learning models and inserting fake subtitles has added to this problem, making it more challenging to detect deepfakes accurately. A superior quality dataset is essential to developing a competent deepfake detector. However, existing datasets are limited and often biased, making it difficult to detect deepfakes accurately. A multi-modal deepfake dataset, such as the proposed multi-modal Audio-Video-Text Deepfake dataset (MMDFD) addresses this gap by providing a more realistic and unbiased dataset. Such a dataset helps develop more accurate and effective deepfake detection methods, which can detect audio, video, and textual deepfakes simultaneously. The proposed dataset is more reflective of situations in the real world since it contains actual YouTube recordings of celebrities from four different racial origins. This helps to avoid the creation of deepfake detectors that are biased toward certain racial or ethnic groups. Overall, a multi-modal deepfake dataset is essential in addressing the growing concerns of deepfake misuse and developing effective detection methods that can detect deepfakes accurately, regardless of the medium.","Deep neural networks, Deepfake Dataset, Multimodal, Subtitle Deepfakes",ACM
33,Deepfake CAPTCHA: A Method for Preventing Fake Calls,"Yasur, Lior and Frankovits, Guy and Grabovski, Fred M. and Mirsky, Yisroel",2023,"Deep learning technology has made it possible to generate realistic content of specific individuals. These �deepfakes� can now be generated in real-time which enables attackers to impersonate people over audio and video calls. Moreover, some methods only need a few images or seconds of audio to steal an identity. Existing defenses perform passive analysis to detect fake content. However, with the rapid progress of deepfake quality, this may be a losing game. In this paper, we propose D-CAPTCHA: an active defense against real-time deepfakes. The approach is to force the adversary into the spotlight by challenging the deepfake model to generate content which exceeds its capabilities. By doing so, passive detection becomes easier since the content will be distorted. In contrast to existing CAPTCHAs, we challenge the AI�s ability to create content as opposed to its ability to classify content. In this work we focus on real-time audio deepfakes and present preliminary results on video. In our evaluation we found that D-CAPTCHA outperforms state-of-the-art audio deepfake detectors with an accuracy of 91-100% depending on the challenge (compared to 71% without challenges). We also performed a study on 41 volunteers to understand how threatening current real-time deepfake attacks are. We found that the majority of the volunteers could not tell the difference between real and fake audio.","CAPTCHA, Deepfake, deep fake, deep learning, fake calls, impersonation, security, social engineering, voice cloning",ACM
34,TCSD: Triple Complementary Streams Detector for Comprehensive Deepfake Detection,"Liu, Xiaolong and Yu, Yang and Li, Xiaolong and Zhao, Yao and Guo, Guodong",2023,"Advancements in computer vision and deep learning have made it difficult to distinguish deepfake visual media. While existing detection frameworks have achieved significant performance on challenging deepfake datasets, these approaches consider only a single perspective. More importantly, in urban scenes, neither complex scenarios can be covered by a single view nor can the correlation between multiple datasets of information be well utilized. In this article, to mine the new view for deepfake detection and utilize the correlation of multi-view information contained in images, we propose a novel triple complementary streams detector (TCSD). First, a novel depth estimator is designed to extract depth information (DI), which has not been used in previous methods. Then, to supplement depth information for obtaining comprehensive forgery clues, we consider the incoherence between image foreground and background information (FBI) and the inconsistency between local and global information (LGI). In addition, we designed an attention-based multi-scale feature extraction (MsFE) module to extract more complementary features from DI, FBI, and LGI. Finally, two attention-based feature fusion modules are proposed to adaptively fuse information. Extensive experiment results show that the proposed approach achieves state-of-the-art performance on detecting deepfakes.","generalization ability, complementary information mining, depth information, Deepfake",ACM
35,Social Media Authentication and Combating Deepfakes using Semi-fragile Invisible Image Watermarking,"Nadimpalli, Aakash Varma and Rattani, Ajita",2024,"With the significant advances in deep generative models for image and video synthesis, Deepfakes and manipulated media have raised severe societal concerns. Conventional machine learning classifiers for deepfake detection often fail to cope with evolving deepfake generation technology and are susceptible to adversarial attacks. Alternatively, invisible image watermarking is being researched as a proactive defense technique that allows media authentication by verifying an invisible secret message embedded in the image pixels. A handful of invisible image watermarking techniques introduced for media authentication have proven vulnerable to basic image processing operations and watermark removal attacks. In response, we have proposed a semi-fragile image watermarking technique that embeds an invisible secret message into real images for media authentication. Our proposed watermarking framework is designed to be fragile to facial manipulations or tampering while being robust to benign image-processing operations and watermark removal attacks. This is facilitated through a unique architecture of our proposed technique consisting of critic and adversarial networks that enforce high image quality and resiliency to watermark removal efforts, respectively, along with the backbone encoder-decoder and the discriminator networks. This allows images shared over the Internet to retain the verifiable watermark as long as facial manipulations or any other Deepfake modification technique is not applied. Thorough experimental investigations on SOTA facial Deepfake datasets demonstrate that our proposed model can embed a  (64) -bit secret as an imperceptible image watermark that can be recovered with a high-bit recovery accuracy when benign image processing operations are applied while being non-recoverable when unseen Deepfake manipulations are applied. In addition, our proposed watermarking technique demonstrates high resilience to several white-box and black-box watermark removal attacks. Thus, obtaining state-of-the-art performance.","Facial Manipulations, Deepfakes, Media Authentication, Watermarking",ACM
36,Fairness evaluation in deepfake detection models using metamorphic testing,"Pu, Muxin and Kuan, Meng Yi and Lim, Nyee Thoang and Chong, Chun Yong and Lim, Mei Kuan",2023,"Fairness of deepfake detectors in the presence of anomalies are not well investigated, especially if those anomalies are more prominent in either male or female subjects. The primary motivation for this work is to evaluate how deepfake detection model behaves under such anomalies. However, due to the black-box nature of deep learning (DL) and artificial intelligence (AI) systems, it is hard to predict the performance of a model when the input data is modified. Crucially, if this defect is not addressed properly, it will adversely affect the fairness of the model and result in discrimination of certain sub-population unintentionally. Therefore, the objective of this work is to adopt metamorphic testing to examine the reliability of the selected deepfake detection model, and how the transformation of input variation places influence on the output. We have chosen MesoInception-4, a state-of-the-art deepfake detection model, as the target model and makeup as the anomalies. Makeups are applied through utilizing the Dlib library to obtain the 68 facial landmarks prior to filling in the RGB values. Metamorphic relations are derived based on the notion that realistic perturbations of the input images, such as makeup, involving eyeliners, eyeshadows, blushes, and lipsticks (which are common cosmetic appearance) applied to male and female images, should not alter the output of the model by a huge margin. Furthermore, we narrow down the scope to focus on revealing potential gender biases in DL and AI systems. Specifically, we are interested to examine whether MesoInception-4 model produces unfair decisions, which should be considered as a consequence of robustness issues. The findings from our work have the potential to pave the way for new research directions in the quality assurance and fairness in DL and AI systems.","robustness testing, oracle problem, metamorphic testing, fairness testing",ACM
37,A Comparative Study on Physical and Perceptual Features for Deepfake Audio Detection,"Li, Menglu and Ahmadiadli, Yasaman and Zhang, Xiao-Ping",2022,"Audio content synthesis has stepped into a new era and brought a great threat to daily life since the development of deep learning techniques. The ASVSpoof Challenge and the ADD Challenge have been launched to motivate the development of Deepfake audio detection algorithms. Currently, the detection models, which consist of front-end feature extractors and back-end classifiers, utilize the physical features mainly, rather than the perceptual features that relate to natural emotions or breathiness. Therefore, we provide a comprehensive study on 16 physical and perceptual features and evaluate their effectiveness in both Track 1 and Track 2 of the ADD Challenge. Based on results, PLP, as a perceptual feature, outperforms the rest of the features in Track 1, while CQCC has the best performance in Track 2. Our experiments demonstrate the significance of perceptual features in detecting Deepfake audios. We also seek to explore the underlying characteristics of features that can distinguish Deepfake audio from a real one. We perform statistical analysis on each feature to show its distribution differences on real and synthesized audios. This paper will provide a potential direction in selecting appropriate feature extraction methods for the future implementation of detection models.","feature selection, feature extraction, deepfake audio, countermeasures, anti-spoofing, add 2022",ACM
38,A Detection Method for DeepFake Hard Compressed Videos based on Super-resolution Reconstruction Using CNN,"Hongmeng, Zhang and Zhiqiang, Zhu and Lei, Sun and Xiuqing, Mao and Yuehan, Wang",2020,"The DeepFake video detection method based on convolutional neural networks has a poor performance in the dataset of hard compressed DeepFake video. And a large number of false tests will occur to the real data. To solve this problem, a networks model detection method for super-resolution reconstruction of DeepFake video is proposed. First of all, the face area of real data is processed by Gaussian blur, which is converted into negative data, and the real data and processing data are input into neural network for training. Then the residual network is used for super-resolution reconstruction of test data. Finally, the trained model is used to test the video after super-resolution reconstruction. Experiments show that the proposed method can reduce the false detection rate and improve the accuracy in detection of single frames.","Super-resolution reconstruction, Hard compressed video, DeepFake detection, Deep Learning",ACM
39,Face Forgery Detection via Symmetric Transformer,"Song, Luchuan and Li, Xiaodan and Fang, Zheng and Jin, Zhenchao and Chen, YueFeng and Xu, Chenliang",2022,"The deep learning-based face forgery detection is a novel yet challenging task. Despite impressive results have been achieved, there are still some limitations in the existing methods. For example, the previous methods are hard to maintain consistent predictions for consecutive frames, even if all of those frames are actually forged. We propose a symmetric transformer for channel and spatial feature extraction, which is because the channel and spatial features of a robust forgery detector should be consistent in the temporal domain. The symmetric transformer adopt the newly-designed attention-based strategies for channel variance and spatial gradients as the vital features, which greatly improves the robustness of deepfake video detection. Moreover, this symmetric structure acts on temporal and spatial features respectively, which ensures the robustness of detection from two different aspects. Our symmetric transformer is an end-to-end optimized network. Experiments are conducted on various settings, the proposed methods achieve significantly improvement on prediction robustness and perform better than state-of-the-art methods on different datasets.","symmetric transformer, deepfake video detection",ACM
40,Am I a Real or Fake Celebrity? Evaluating Face Recognition and Verification APIs under Deepfake Impersonation Attack,"Tariq, Shahroz and Jeon, Sowon and Woo, Simon S.",2022,"Recent advancements in web-based multimedia technologies, such as face recognition web services powered by deep learning, have been significant. As a result, companies such as Microsoft, Amazon, and Naver provide highly accurate commercial face recognition web services for a variety of multimedia applications. Naturally, such technologies face persistent threats, as virtually anyone with access to deepfakes can quickly launch impersonation attacks. These attacks pose a serious threat to authentication services, which rely heavily on the performance of their underlying face recognition technologies. Despite its gravity, deepfake abuse involving commercial web services and their robustness have not been thoroughly measured and investigated. By conducting a case study on celebrity face recognition, we examine the robustness of black-box commercial face recognition web APIs and open-source tools against Deepfake Impersonation (DI) attacks. While the majority of APIs do not make specific claims of deepfake robustness, we find that authentication mechanisms may get built one top of them, nonetheless. We demonstrate the vulnerability of face recognition technologies to DI attacks, achieving respective success rates of 78.0% for targeted (TA) attacks; we also propose mitigation strategies, lowering respective attack success rates to as low as 1.26% for TA attacks with adversarial training.","Deepfake, Face Recognition, Impersonation Attack, Web Services",ACM
41,A Forensic Method for DeepFake Image based on Face Recognition,"Wu, Jian and Feng, Kai and Chang, Xu and Yang, Tongfeng",2020,"DeepFake digital images have serious negative impacts on news integrity, legal forensics, and social security. In order to detect the DeepFake digital images more accurately, a method based on face recognition is proposed. Face image feature vectors are extracted by Facenet, and the Euclidean distances among the vectors of different face images are calculated as classification principle. Then, the machine learning algorithms is trained to perform binary classification of real and fake face images. The experimental results on the Celeb-DF data set show that the proposed method has better detection effect than the existing detection methods.","Image Forensic, Face Recognition, DeepFake",ACM
42,Joint Engagement Classification using Video Augmentation Techniques for Multi-person HRI in the wild,"Kim, Yubin and Chen, Huili and Algohwinem, Sharifa and Breazeal, Cynthia and Park, Hae Won",2023,"Affect understanding capability is essential for social robots to autonomously interact with a group of users in an intuitive and reciprocal way. However, the challenge of multi-person affect understanding comes from not only the accurate perception of each user's affective state (e.g., engagement) but also the recognition of the affect interplay between the members (e.g., joint engagement) that presents as complex, but subtle, nonverbal exchanges between them. Here we present a novel hybrid framework for identifying a parent-child dyad's joint engagement by combining a deep learning framework with various video augmentation techniques. Using a dataset of parent-child dyads reading storybooks together with a social robot at home, we first train RGB frame- and skeleton-based joint engagement recognition models with four video augmentation techniques (General Aug, DeepFake, CutOut, and Mixed) applied datasets to improve joint engagement classification performance. Second, we demonstrate experimental results on the use of trained models in the robot-parent-child interaction context. Third, we introduce a behavior-based metric for evaluating the learned representation of the models to investigate the model interpretability when recognizing joint engagement. This work serves as the first step toward fully unlocking the potential of end-to-end video understanding models pre-trained on large public datasets and augmented with data augmentation and visualization techniques for affect recognition in the multi-person human-robot interaction in the wild. Our code and detailed experimental results are available at https://github.com/ybkim95/multi_person_joint_engagement.","joint engagement recognition, multi human-robot interaction, multi-person affect understanding, nonverbal communication",ACM
43,SiFDetectCracker: An Adversarial Attack Against Fake Voice Detection Based on Speaker-Irrelative Features,"Hai, Xuan and Liu, Xin and Tan, Yuan and Zhou, Qingguo",2023,"Voice is a vital medium for transmitting information. The advancement of speech synthesis technology has resulted in high-quality synthesized voices indistinguishable from human ears. These fake voices have been widely used in natural Deepfake production and other malicious activities, raising serious concerns regarding security and privacy. To deal with this situation, there have been many studies working on detecting fake voices and reporting excellent performance. However, is the story really over? In this paper, we propose SiFDetectCracker, a black-box adversarial attack framework based on Speaker-Irrelative Features (SiFs) against fake voice detection. We select background noise and mute parts before and after the speaker's voice as the primary attack features. By modifying these features in synthesized speech, the fake speech detector will make a misjudgment. Experiments show that SiFDetectCracker achieved a success rate of more than 80% in bypassing existing state-of-the-art fake voice detection systems. We also conducted several experiments to evaluate our attack approach's transferability and activation factor.","voice detection, deepfake, ai-synthesized speech, adversarial attack",ACM
44,Emotions Don't Lie: An Audio-Visual Deepfake Detection Method using Affective Cues,"Mittal, Trisha and Bhattacharya, Uttaran and Chandra, Rohan and Bera, Aniket and Manocha, Dinesh",2020,"We present a learning-based method for detecting real and fake deepfake multimedia content. To maximize information for learning, we extract and analyze the similarity between the two audio and visual modalities from within the same video. Additionally, we extract and compare affective cues corresponding to perceived emotion from the two modalities within a video to infer whether the input video is ""real"" or ""fake"". We propose a deep learning network, inspired by the Siamese network architecture and the triplet loss. To validate our model, we report the AUC metric on two large-scale deepfake detection datasets, DeepFake-TIMIT Dataset and DFDC. We compare our approach with several SOTA deepfake detection methods and report per-video AUC of 84.4% on the DFDC and 96.6% on the DF-TIMIT datasets, respectively. To the best of our knowledge, ours is the first approach that simultaneously exploits audio and video modalities and also perceived emotions from the two modalities for deepfake detection.","multimedia forensics, emotions, deepfakes, audio-visual, affective computing",ACM
45,Evaluation of an Audio-Video Multimodal Deepfake Dataset using Unimodal and Multimodal Detectors,"Khalid, Hasam and Kim, Minha and Tariq, Shahroz and Woo, Simon S.",2021,"Significant advancements made in the generation of deepfakes have caused security and privacy issues. Attackers can easily impersonate a person's identity in an image by replacing his face with the target person's face. Moreover, a new domain of cloning human voices using deep-learning technologies is also emerging. Now, an attacker can generate realistic cloned voices of humans using only a few seconds of audio of the target person. With the emerging threat of potential harm deepfakes can cause, researchers have proposed deepfake detection methods. However, they only focus on detecting a single modality, i.e., either video or audio. On the other hand, to develop a good deepfake detector that can cope with the recent advancements in deepfake generation, we need to have a detector that can detect deepfakes of multiple modalities, i.e., videos and audios. To build such a detector, we need a dataset that contains video and respective audio deepfakes. We were able to find a most recent deepfake dataset, Audio-Video Multimodal Deepfake Detection Dataset (FakeAVCeleb), that contains not only deepfake videos but synthesized fake audios as well. We used this multimodal deepfake dataset and performed detailed baseline experiments using state-of-the-art unimodal, ensemble-based, and multimodal detection methods to evaluate it. We conclude through detailed experimentation that unimodals, addressing only a single modality, video or audio, do not perform well compared to ensemble-based methods. Whereas purely multimodal-based baselines provide the worst performance.","multimodal, media forensics, measurement, deepfakaes, datasets",ACM
46,FakeTagger: Robust Safeguards against DeepFake Dissemination via Provenance Tracking,"Wang, Run and Juefei-Xu, Felix and Luo, Meng and Liu, Yang and Wang, Lina",2021,"In recent years, DeepFake is becoming a common threat to our society, due to the remarkable progress of generative adversarial networks (GAN) in image synthesis. Unfortunately, existing studies that propose various approaches, in fighting against DeepFake and determining if the facial image is real or fake, is still at an early stage. Obviously, the current DeepFake detection method struggles to catch the rapid progress of GANs, especially in the adversarial scenarios where attackers can evade the detection intentionally, such as adding perturbations to fool the DNN-based detectors. While passive detection simply tells whether the image is fake or real, DeepFake provenance, on the other hand, provides clues for tracking the sources in DeepFake forensics. Thus, the tracked fake images could be blocked immediately by administrators and avoid further spread in social networks.In this paper, we investigate the potentials of image tagging in serving the DeepFake provenance tracking. Specifically, we devise a deep learning-based approach, named FakeTagger, with a simple yet effective encoder and decoder design along with channel coding to embed message to the facial image, which is to recover the embedded message after various drastic GAN-based DeepFake transformation with high confidence. The embedded message could be employed to represent the identity of facial images, which further contributed to DeepFake detection and provenance. Experimental results demonstrate that our proposed approach could recover the embedded message with an average accuracy of more than 95% over the four common types of DeepFakes. Our research finding confirms effective privacy-preserving techniques for protecting personal photos from being DeepFaked.","provenance tracking, image tagging, deepfake forensics",ACM
47,Spatiotemporal Inconsistency Learning for DeepFake Video Detection,"Gu, Zhihao and Chen, Yang and Yao, Taiping and Ding, Shouhong and Li, Jilin and Huang, Feiyue and Ma, Lizhuang",2021,"The rapid development of facial manipulation techniques has aroused public concerns in recent years. Following the success of deep learning, existing methods always formulate DeepFake video detection as a binary classification problem and develop frame-based and video-based solutions. However, little attention has been paid to capturing the spatial-temporal inconsistency in forged videos. To address this issue, we term this task as a Spatial-Temporal Inconsistency Learning (STIL) process and instantiate it into a novel STIL block, which consists of a Spatial Inconsistency Module (SIM), a Temporal Inconsistency Module (TIM), and an Information Supplement Module (ISM). Specifically, we present a novel temporal modeling paradigm in TIM by exploiting the temporal difference over adjacent frames along with both horizontal and vertical directions. And the ISM simultaneously utilizes the spatial information from SIM and temporal information from TIM to establish a more comprehensive spatial-temporal representation. Moreover, our STIL block is flexible and could be plugged into existing 2D CNNs. Extensive experiments and visualizations are presented to demonstrate the effectiveness of our method against the state-of-the-art competitors.","video analysis, spatiotemporal inconsistency modeling, deepfake video detection",ACM
48,Towards Generalizable Deepfake Detection with Locality-aware AutoEncoder,"Du, Mengnan and Pentyala, Shiva and Li, Yuening and Hu, Xia",2020,"With advancements of deep learning techniques, it is now possible to generate super-realistic images and videos, i.e., deepfakes. These deepfakes could reach mass audience and result in adverse impacts on our society. Although lots of efforts have been devoted to detect deepfakes, their performance drops significantly on previously unseen but related manipulations and the detection generalization capability remains a problem. Motivated by the fine-grained nature and spatial locality characteristics of deepfakes, we propose Locality-Aware AutoEncoder (LAE) to bridge the generalization gap. In the training process, we use a pixel-wise mask to regularize local interpretation of LAE to enforce the model to learn intrinsic representation from the forgery region, instead of capturing artifacts in the training set and learning superficial correlations to perform detection. We further propose an active learning framework to select the challenging candidates for labeling, which requires human masks for less than 3% of the training data, dramatically reducing the annotation efforts to regularize interpretations. Experimental results on three deepfake detection tasks indicate that LAE could focus on the forgery regions to make decisions. The analysis further shows that LAE outperforms the state-of-the-arts by 6.52%, 12.03%, and 3.08% respectively on three deepfake detection tasks in terms of generalization accuracy on previously unseen manipulations.","interpretation, generalization, deepfake detection, GAN",ACM
49,CT 2.0,"Tedre, Matti and Denning, Peter and Toivonen, Tapani",2021,"CT has been the central rallying point for K-12 computing education at least since the early 2010s. Many teachers, school administrators, and policymakers have joined the movement. A consensus has emerged over the conceptual landscape of CT. Meanwhile, machine learning (ML) has triggered some major changes in many sectors of computing. Children�s lives today are full of ML-driven services�take TikTok�s spot-on recommendations, social media�s automatic tagging of their friends in photos, and targeted personalized advertisement, just to mention a few. Children cannot learn to think about and design ML technology from learning classical programming. ML is poised to upend the CT consensus. Look at some of the changes ML has already triggered in computing. It has enabled greatly improved speech and image recognition, powerful recommendations on streaming services, autonomous navigation of cars, super-human performance in board and computer games, and even alternative-reality �deepfake� videos. Most advances in topics above are due to hardware evolution to non-traditional, special purpose architectures, new algorithms such as convolutional neural networks (CNN) or generative adversarial networks (GAN), and new objectives and measures of success. We will show that several key CT concepts, including debugging, problem-solving workflow, correctness, and notional machines, are insufficient for ML and need to be extended. Moreover, ML introduces new concepts including neural networks, curating and training data, and reinforcement learning that are not part of CT at all. All these changes challenge the traditional views related to teaching CT in K�12. ML is not the only emerging technology appearing in the computing landscape. Quantum computing and biological computing are not far behind. We need to start rethinking how CT must evolve to anticipate and meet these challenges.","School, Machine learning, K-12, Computational thinking, Artificial intelligence",ACM
50,Mastering Deepfake Detection: A Cutting-edge Approach to Distinguish GAN and Diffusion-model Images,"Guarnera, Luca and Giudice, Oliver and Battiato, Sebastiano",2024,"Detecting and recognizing deepfakes is a pressing issue in the digital age. In this study, we first collected a dataset of pristine images and fake ones properly generated by nine different Generative Adversarial Network (GAN) architectures and four Diffusion Models (DM). The dataset contained a total of 83,000 images, with equal distribution between the real and deepfake data. Then, to address different deepfake detection and recognition tasks, we proposed a hierarchical multi-level approach. At the first level, we classified real images from AI-generated ones. At the second level, we distinguished between images generated by GANs and DMs. At the third level (composed of two additional sub-levels), we recognized the specific GAN and DM architectures used to generate the synthetic data. Experimental results demonstrated that our approach achieved more than 97% classification accuracy, outperforming existing state-of-the-art methods. The models obtained in the different levels turn out to be robust to various attacks such as JPEG compression (with different quality factor values) and resize (and others), demonstrating that the framework can be used and applied in real-world contexts (such as the analysis of multimedia data shared in the various social platforms) for support even in forensic investigations to counter the illicit use of these powerful and modern generative models. We are able to identify the specific GAN and DM architecture used to generate the image, which is critical in tracking down the source of the deepfake. Our hierarchical multi-level approach to deepfake detection and recognition shows promising results in identifying deepfakes allowing focus on underlying task by improving (about 2% on the average) standard multiclass flat detection systems. The proposed method has the potential to enhance the performance of deepfake detection systems, aid in the fight against the spread of fake images, and safeguard the authenticity of digital media.","Deepfake detection, generative adversarial nets, diffusion models, multimedia forensics",ACM
51,Multimodal Neurosymbolic Approach for Explainable Deepfake Detection,"Haq, Ijaz Ul and Malik, Khalid Mahmood and Muhammad, Khan",2024,"Deepfake detection has become increasingly important in recent years owing to the widespread availability of deepfake generation technologies. Existing deepfake detection methods present two primary limitations; i.e., they are trained on a specific type of deepfake dataset, which renders them vulnerable to unseen deepfakes, and they regard deepfakes as a �black box� with limited explainability, making it difficult for non-AI experts to understand and trust the decisions. Hence, this article proposes a novel neurosymbolic deepfake detection framework that exploits the fact that human emotions cannot be imitated easily owing to their complex nature. We argue that deep fakes typically exhibit inter- or intra-modality inconsistencies in the emotional expressions of the person being manipulated. Thus, the proposed framework performs inter- and intra-modality reasoning on emotions extracted from audio and visual modalities using a psychological and arousal-valence model for deepfake detection. In addition to fake detection, the proposed framework provides textual explanations for its decisions. The results obtained using the Presidential Deepfakes Dataset and World Leaders Dataset of real and manipulated videos demonstrate the effectiveness of our approach in detecting deepfakes and highlight the potential of a neurosymbolic approach for expandability.","Deepfake detection, Emotion recognition, Knowledge base, Manipulation detection, Neurosymbolic",ACM
52,Towards Understanding of Deepfake Videos in the Wild,"Cho, Beomsang and Le, Binh M. and Kim, Jiwon and Woo, Simon and Tariq, Shahroz and Abuadbba, Alsharif and Moore, Kristen",2023,"Abstract: Deepfakes have become a growing concern in recent years, prompting researchers to develop benchmark datasets and detection algorithms to tackle the issue. However, existing datasets suffer from significant drawbacks that hamper their effectiveness. Notably, these datasets fail to encompass the latest deepfake videos produced by state-of-the-art methods that are being shared across various platforms. This limitation impedes the ability to keep pace with the rapid evolution of generative AI techniques employed in real-world deepfake production. Our contributions in this IRB-approved study are to bridge this knowledge gap from current real-world deepfakes by providing in-depth analysis. We first present the largest and most diverse and recent deepfake dataset, RWDF-23, collected from the wild to date, consisting of 2,000 deepfake videos collected from 4 platforms targeting 4 different languages span created from 21 countries: Reddit, YouTube, TikTok, and Bilibili. By expanding the dataset's scope beyond the previous research, we capture a broader range of real-world deepfake content, reflecting the ever-evolving landscape of online platforms. Also, we conduct a comprehensive analysis encompassing various aspects of deepfakes, including creators, manipulation strategies, purposes, and real-world content production methods. This allows us to gain valuable insights into the nuances and characteristics of deepfakes in different contexts. Lastly, in addition to the video content, we also collect viewer comments and interactions, enabling us to explore the engagements of internet users with deepfake content. By considering this rich contextual information, we aim to provide a holistic understanding of the evolving deepfake phenomenon and its impact on online platforms.","deepfake videos, deepfake detection, deepfake datasets",ACM
53,AntiFake: Using Adversarial Audio to Prevent Unauthorized Speech Synthesis,"Yu, Zhiyuan and Zhai, Shixuan and Zhang, Ning",2023,"The rapid development of deep neural networks and generative AI has catalyzed growth in realistic speech synthesis. While this technology has great potential to improve lives, it also leads to the emergence of ''DeepFake'' where synthesized speech can be misused to deceive humans and machines for nefarious purposes. In response to this evolving threat, there has been a significant amount of interest in mitigating this threat by DeepFake detection.Complementary to the existing work, we propose to take the preventative approach and introduce AntiFake, a defense mechanism that relies on adversarial examples to prevent unauthorized speech synthesis. To ensure the transferability to attackers' unknown synthesis models, an ensemble learning approach is adopted to improve the generalizability of the optimization process. To validate the efficacy of the proposed system, we evaluated AntiFake against five state-of-the-art synthesizers using real-world DeepFake speech samples. The experiments indicated that AntiFake achieved over 95% protection rate even to unknown black-box models. We have also conducted usability tests involving 24 human participants to ensure the solution is accessible to diverse populations.","adversarial machine learning, deepfake defense, generative ai, speech synthesis",ACM
54,Overview of the Grand Challenge on Detecting Cheapfakes at ACM ICMR 2024,"Dang-Nguyen, Duc-Tien and Khan, Sohail Ahmed and Riegler, Michael and Halvorsen, P\r{a}l and Tran, Anh-Duy and Dao, Minh-Son and Tran, Minh-Triet",2024,"Information disorder is one of the most typical challenges in the current era of science and technology. The amount of information on the internet is increasing, but its correctness and authenticity are not always guaranteed, leading to false information, fake news, etc. The mentioned problem negatively affects users' reception and use of information. Unlike deepfake, cheapfake is created using simple techniques and does not rely on AI to produce fake multimedia. Cheapfake is becoming increasingly popular due to its ease of creation. Thus, there is a growing need to develop techniques that can detect cheapfake content. Following previous events, the Grand Challenge on Detecting Cheapfakes at ACM ICMR 2024 continues to seek contributions from researchers on cheapfake detection with the goal of improving effectiveness and creativity in approach, and understanding the limitations of the current dataset. This challenge has accepted 6 new proposed methods from participants with the highest private test accuracies achieved at 72.2% for Task 1 and 54.84% for Task 2. The highest public test accuracies for the two tasks are 95.6% and 93% respectively. These new methods focus on incorporating new AI models such as Stable Diffusion, LLM. These new findings represent the latest advancements in cheapfake detection research and introduce new potential approaches for future research.","cheapfakes detection, misinformation, news, out-of-context media, re-contextualized media",ACM
55,Exposing Vulnerabilities of Deepfake Detection Systems with Robust Attacks,"Hussain, Shehzeen and Neekhara, Paarth and Dolhansky, Brian and Bitton, Joanna and Ferrer, Cristian Canton and McAuley, Julian and Koushanfar, Farinaz",2022,"Recent advances in video manipulation techniques have made the generation of fake videos more accessible than ever before. Manipulated videos can fuel disinformation and reduce trust in media. Therefore detection of fake videos has garnered immense interest in academia and industry. Recently developed Deepfake detection methods rely on Deep Neural Networks (DNNs) to distinguish AI-generated fake videos from real videos. In this work, we demonstrate that it is possible to bypass such detectors by adversarially modifying fake videos synthesized using existing Deepfake generation methods. We further demonstrate that our adversarial perturbations are robust to image and video compression codecs, making them a real-world threat. We present pipelines in both white-box and black-box attack scenarios that can fool DNN-based Deepfake detectors into classifying fake videos as real. Finally, we study the extent to which adversarial perturbations transfer across different Deepfake detectors and create more accessible attacks using universal adversarial perturbations that pose a very feasible attack scenario since they can be easily shared amongst attackers.1","news verification, fake news detection, fake news, digital threats, adversarial machine learning, neural networks, Misinformation detection",ACM
56,SNIPPET: A Framework for Subjective Evaluation of Visual Explanations Applied to DeepFake Detection,"Yang, Yuqing and Joukovsky, Boris and Oramas Mogrovejo, Jos\'{e} and Tuytelaars, Tinne and Deligiannis, Nikos",2024,"Explainable Artificial Intelligence (XAI) attempts to help humans understand machine learning decisions better and has been identified as a critical component toward increasing the trustworthiness of complex black-box systems, such as deep neural networks. In this article, we propose a generic and comprehensive framework named SNIPPET and create a user interface for the subjective evaluation of visual explanations, focusing on finding human-friendly explanations. SNIPPET considers human-centered evaluation tasks and incorporates the collection of human annotations. These annotations can serve as valuable feedback to validate the qualitative results obtained from the subjective assessment tasks. Moreover, we consider different user background categories during the evaluation process to ensure diverse perspectives and comprehensive evaluation. We demonstrate SNIPPET on a DeepFake face dataset. Distinguishing real from fake faces is a non-trivial task even for humans that depends on rather subtle features, making it a challenging use case. Using SNIPPET, we evaluate four popular XAI methods which provide visual explanations: Gradient-weighted Class Activation Mapping, Layer-wise Relevance Propagation, attention rollout, and Transformer Attribution. Based on our experimental results, we observe preference variations among different user categories. We find that most people are more favorable to the explanations of rollout. Moreover, when it comes to XAI-assisted understanding, those who have no or lack relevant background knowledge often consider that visual explanations are insufficient to help them understand. We open-source our framework for continued data collection and annotation at .","Explainable AI, visual explanations, subjective evaluation framework, DeepFake detection, user background categories",ACM
57,Deepfake Videos in the Wild: Analysis and Detection,"Pu, Jiameng and Mangaokar, Neal and Kelly, Lauren and Bhattacharya, Parantapa and Sundaram, Kavya and Javed, Mobin and Wang, Bolun and Viswanath, Bimal",2021,"AI-manipulated videos, commonly known as deepfakes, are an emerging problem. Recently, researchers in academia and industry have contributed several (self-created) benchmark deepfake datasets, and deepfake detection algorithms. However, little effort has gone towards understanding deepfake videos in the wild, leading to a limited understanding of the real-world applicability of research contributions in this space. Even if detection schemes are shown to perform well on existing datasets, it is unclear how well the methods generalize to real-world deepfakes. To bridge this gap in knowledge, we make the following contributions: First, we collect and present the largest dataset of deepfake videos in the wild, containing 1,869 videos from YouTube and Bilibili, and extract over 4.8M frames of content. Second, we present a comprehensive analysis of the growth patterns, popularity, creators, manipulation strategies, and production methods of deepfake content in the real-world. Third, we systematically evaluate existing defenses using our new dataset, and observe that they are not ready for deployment in the real-world. Fourth, we explore the potential for transfer learning schemes and competition-winning techniques to improve defenses.","Deepfake Videos, Deepfake Detection, Deepfake Datasets.",ACM
58,DeepFake detection method based on multi-scale interactive dual-stream network,Ziyuan Cheng and Yiyang Wang and Yongjing Wan and Cuiling Jiang,2024,"DeepFake face forgery has a serious negative impact on both society and individuals. Therefore, research on DeepFake detection technologies is necessary. At present, DeepFake detection technology based on deep learning has achieved acceptable results on high-quality datasets; however, its detection performance on low-quality datasets and cross-datasets remains poor. To address this problem, this paper presents a multi-scale interactive dual-stream network (MSIDSnet). The network is divided into spatial- and frequency-domain streams and uses a multi-scale fusion module to capture both the facial features of images that have been manipulated in the spatial domain under different circumstances and the fine-grained high-frequency noise information of forged images. The network fully integrates the features of the spatial- and frequency-domain streams through an interactive dual-stream module and uses vision transformer (ViT) to further learn the global information of the forged facial features for classification. Experimental results confirm that the accuracy of this method reached 99.30?% on the high-quality dataset Celeb-DF-v2, and 95.51?% on the low-quality dataset FaceForensics++. Moreover, the results of the cross-dataset experiments were superior to those of the other comparison methods.","DeepFake detection, Multi-scale fusion, Interactive dual-stream, High-frequency noise",ScienceDirect
59,Less is more: A minimalist approach to robust GAN-generated face detection,Tanusree Ghosh and Ruchira Naskar,2024,"Hyper-realistic images that are not differentiable from authentic images to regular viewers have become extremely easy to generate and highly accessible. Furthermore, the increasing pervasiveness of social media networks in our daily lives has facilitated the easy dissemination of fake news accompanied by such synthetic images. Hyper-realistic artificial face images are often illicitly used as profile pictures on social media sites, further using such profiles to spread fabricated information, resulting in social perils. Most available synthetic image detectors are challenging to implement in practical scenarios due to their high complexity and performance degradation for images from Online Social Networks (OSNs). In this work, we develop a deep learning-based lightweight synthetic image detector called Relative Chrominance Distance Network (RCD-Net). In this paper, we introduce the RCD image feature set for the first time, which gives a pair-wise chrominance component-based distance measure. To show its effectiveness, we explore multiple luminance-chrominance spaces. Compared to the state-of-the-art (SOTA), our model hugely reduces the network parameter requirements, making it incredibly lightweight. We also study the robustness of the proposed solution against common post-processing operations in the context of online social media networks. Experimental results prove that the proposed solution achieves SOTA performance at a much lower complexity than available solutions.","Fake image detection, Deepfake detection, GAN forensics, Digital image forensics, Synthetic image detection, GAN-face detection",ScienceDirect
60,Fake news or real? Detecting deepfake videos using geometric facial structure and graph neural network,Shahela Saif and Samabia Tehseen and Syed Sohaib Ali,2024,"Deepfake videos are increasingly used in spreading fake news or propaganda having a serious impact on people and society. Traditional deepfake detectors exploit spatial and/or temporal inconsistencies to differentiate between real and fake videos. Owing to the rapidly advancing deepfake creation algorithms, the latest detectors have made use of physiological and biological facial features to create more generic solutions. Our proposed solution uses facial landmarks as the physiological identifiers of a person�s face and through them develops a relationship between facial areas in normal speech and tampered speech. By creating a graph structure from the resulting sparse data, we were able to use a spatio-temporal graph convolutional network for classification, which has significantly fewer parameters and a shorter training time than traditional CNNs. We conducted a multitude of experiments on 3 datasets, utilizing spatio-temporal features. The results demonstrate that this technique has better generalization, and high performance compared to latest research in deepfake detection without the reliance on large deep learning models which are tuned to learning image discrepancies more than data patterns. Moreover, our use of facial landmark-based features with a graph structure paves the way for the development of an explainable AI model that can be relied on.","Video forgery, Forgery detection, Deepfakes, Deepfake videos, Deepfake detection, Graph convolution network",ScienceDirect
61,Deep learning for deepfakes creation and detection: A survey,Thanh Thi Nguyen and Quoc Viet Hung Nguyen and Dung Tien Nguyen and Duc Thanh Nguyen and Thien Huynh-The and Saeid Nahavandi and Thanh Tam Nguyen and Quoc-Viet Pham and Cuong M. Nguyen,2022,"Deep learning has been successfully applied to solve various complex problems ranging from big data analytics to computer vision and human-level control. Deep learning advances however have also been employed to create software that can cause threats to privacy, democracy and national security. One of those deep learning-powered applications recently emerged is deepfake. Deepfake algorithms can create fake images and videos that humans cannot distinguish them from authentic ones. The proposal of technologies that can automatically detect and assess the integrity of digital visual media is therefore indispensable. This paper presents a survey of algorithms used to create deepfakes and, more importantly, methods proposed to detect deepfakes in the literature to date. We present extensive discussions on challenges, research trends and directions related to deepfake technologies. By reviewing the background of deepfakes and state-of-the-art deepfake detection methods, this study provides a comprehensive overview of deepfake techniques and facilitates the development of new and more robust methods to deal with the increasingly challenging deepfakes.","Deepfakes, Face manipulation, Artificial intelligence, Deep learning, Autoencoders, GAN, Forensics, Survey",ScienceDirect
62,A new deepfake detection model for responding to perception attacks in embodied artificial intelligence,JunShuai Zheng and XiYuan Hu and Chen Chen and YiChao Zhou and DongYang Gao and ZhenMin Tang,2024,"Embodied artificial intelligence (AI) represents a new generation of robotics technology combined with artificial intelligence, and it is at the forefront of current research. To reduce the impact of deepfake technology on embodied perception and enhance the security and reliability of embodied AI, this paper proposes a novel deepfake detection model with a new Balanced Contrastive Learning strategy, named BCL. By integrating unsupervised contrastive learning and supervised contrastive learning with deepfake detection, the model effectively extracts the underlying features of fake images from both individual level and category level, thereby leading to more discriminative features. In addition, a Multi-scale Attention Interaction module (MAI) is proposed to enrich the representative ability of features. By cross-fusing the semantic features of different receptive fields of the encoder, more effective deepfake traces can be mined. Finally, extensive experiments demonstrate that our method has good performance and generalization capabilities across intra-dataset, cross-dataset and cross-manipulation scenarios.","Deepfake detection, Unsupervised contrastive learning, Supervised contrastive learning, Balanced contrastive learning",ScienceDirect
63,Towards DeepFake video forensics based on facial textural disparities in multi-color channels,Zhiming Xia and Tong Qiao and Ming Xu and Ning Zheng and Shichuang Xie,2022,"With the development of deep learning, AI-synthesized techniques, such as DeepFake, are widely spread on the Internet. Although many state-of-the-art detection methods have been able to obtain a good detection performance, most neural network models based on data-driven training lack interpretability during feature extraction and analysis. In this study, we propose an interpretable DeepFake video detection method based on facial textural disparities in multi-color channels. We observe that the face region from the DeepFake video appears to be smoother than that of the real one. First, we analyze the statistical disparities between the real and fake frame in each color channel. Next, it is proposed to use the co-occurrence matrix to construct a low-dimensional set of features to distinguish the real video from the DeepFake video. Meanwhile, we evaluate the video-level and frame-level detection performance on the benchmark, where the method can achieve AUC value of 0.996 on FaceForensics++, and 0.718 on Celeb-DF. Our proposed method performs remarkably better than the traditional machine learning based detectors, and comparably to some current deep learning based detectors. More importantly, our proposed method is robust in the face of compression attacks, and more time-efficient compared to existing methods based on deep learning.","Multimedia forensics, DeepFake detection, Color channels, Facial texture",ScienceDirect
64,STB-VMM: Swin Transformer based Video Motion Magnification,Ricard Lado-Roig� and Marco A. P�rez,2023,"The goal of video motion magnification techniques is to magnify small motions in a video to reveal previously invisible or unseen movement. Its uses extend from bio-medical applications and deepfake detection to structural modal analysis and predictive maintenance. However, discerning small motion from noise is a complex task, especially when attempting to magnify very subtle, often sub-pixel movement. As a result, motion magnification techniques generally suffer from noisy and blurry outputs. This work presents a new state-of-the-art model based on the Swin Transformer, which offers better tolerance to noisy inputs as well as higher-quality outputs that exhibit less noise, blurriness, and artifacts than prior-art. Improvements in output image quality will enable more precise measurements for any application reliant on magnified video sequences, and may enable further development of video motion magnification techniques in new technical fields.","Computer vision, Deep learning, Swin Transformer, Motion magnification, Image quality assessment",ScienceDirect
65,Dual-Stream Fusion Network with Multi-Head Self-Attention for Multi-Modal Fake News Detection,Yimei Yang and Jinping Liu and Yujun Yang and Lihui Cen,2024,"ABSTRACT
With the rapid advancement of social media platforms like Weibo and WeChat, alongside the emergence of deepfake technologies, tackling fake information has become a major challenge for society and government institutions. To address this, developing efficient and intelligent methods for fake news detection is crucial. This paper introduces a dual-stream fusion network model (DSF-MHSA) based on deep learning, designed to detect fake news across web pages, images, and text. The model tackles issues such as cross-lingual discrepancies, data imbalance, and multimodal information fusion by integrating deep learning models like ERNIE-M, AlexNet, and ShuffleNet, along with three multi-head self-attention mechanisms. It processes textual and image data separately to capture long-range dependencies and global information, enhancing understanding and recognition. A unified multi-head self-attention mechanism then merges these insights to strengthen cross-modal correlation detection. The model is tested on datasets from Twitter, Weibo, and IKCEST-2023, which includes real online news from various social media sources. Results show that the DSF-MHSA model achieves over 90% accuracy, surpassing traditional models in news detection tasks. This research offers significant practical value for the identification and understanding of news content.","Fake News Detection, Multi-Head Self-Attention, Deep Learning Method, Dual-Stream Network, Social Network",ScienceDirect
66,Voice spoofing detector: A unified anti-spoofing framework,Ali Javed and Khalid Mahmood Malik and Hafiz Malik and Aun Irtaza,2022,"Voice controlled systems (VCS) in Internet of Things (IoT), speaker verification systems, voice-based biometrics, and other voice-assistant-enabled systems are vulnerable to different spoofing attacks i.e., replay, cloning, cloned-replay, etc. VCS are not only susceptible to these attacks in a non-network environment, but they are also vulnerable to multi-order spoofing attacks in networked IoT. Additionally, deepfakes with artificially generated audio pose a great threat to the all systems having voice-interfaces. Most of the existing countermeasures against these voice spoofing attacks work for only one specific attack (e.g. voice replay) and fail to generalize this for other classes of spoofing attacks. Additionally, generalization is also crucial for cross-corpora evaluation. Thus, there exists a need to develop a unified voice anti-spoofing framework capable of detecting multiple spoofing attacks. This work presents a unified anti-spoofing framework that uses novel (ATCoP-GTCC) features to combat the variety of voice spoofing attacks. The proposed novel acoustic-ternary co-occurrence patterns (ATCoP) encode the co-occurrence of similar patterns between the center and neighboring samples. Our experiments demonstrate that ATCoP can better capture the microphone induced distortions in replays, unnatural prosody and algorithmic artifacts in cloned samples, and both the distortions and artifacts in cloned-replays including compression on multi-hop attacks in the spoofing samples. The performance of ATCoP could be further enhanced by the Gammatone cepstral coefficients. To evaluate the effectiveness of the proposed anti-spoofing system for multi-order replay and cloned-replay attacks detection, we created a diverse voice spoofing detection corpus (VSDC) containing multi-order replay and cloned-replay audios against the bonafide and cloned audio recordings, respectively. Experimental results obtained on VSDC, ASVspoof 2019, Google�s LJ Speech, and YouTube deepfakes datasets illustrate the effectiveness of the proposed system in terms of accurate detection for a variety of voice spoofing attacks.","Acoustic ternary co-occurrence patterns, AI for multimedia security, AI for voice-based biometrics in IoT, Anti-spoofing against multiple attack vectors, Deepfakes, Voice spoofing detection",ScienceDirect
67,The Analysis of Neural Network Models to Distinguish AI generated faces from Real faces,Joshita Malla and Harshini Vemuri and SreeDivya Nagalli and S Abhishek and T Anjali,2024,"The rise of Artificial Intelligence (AI)-generated faces that are identical to actual ones is both a technological innovation and a major concern. While considering the implications, some of the existing security systems are unable to differentiate between a high-quality deep-fake and an actual intruder's face. For instance, the risks are quite high at an airport security checkpoint, where facial recognition is the first line of security against unauthorized entry. The primary concern here is how trustworthy the computer programs and algorithms will be in recognizing counterfeits among a plethora of actual and artificially generated faces. This necessitates the need to introduce machine learning approaches to differentiate between actual and fraudulent faces, particularly when AI-generated faces are involved. Effective artificial intelligence systems must be adaptive and change quickly in the face of more complex threats rather than simply recognizing them. AI-generated faces are becoming more convincing by the day, increasing the risk of their exploitation. This poses the need to ensure that the technology on which people rely should be robust and trustworthy in critical situations, whether it is a security checkpoint or an e-commerce site. In this perspective, this study has attempted to develop and implement Artificial Intelligence-powered solutions to detect the artificial faces while ensuring reliability for critical functions in an age where reality constantly blends with fiction.","Artificial Intelligence, Deep Fake, Deep Learning, Facial Recognition, Privacy, Security",ScienceDirect
68,Digital forensics for the socio-cyber world (DF-SCW): A novel framework for deepfake multimedia investigation on social media platforms,Abdullah {Ayub Khan} and Yen-Lin Chen and Fahima Hajjej and Aftab {Ahmed Shaikh} and Jing Yang and Chin {Soon Ku} and Lip {Yee Por},2024,"Owing to the major development of social media platforms, the usage of technological adaptation increases by means of editing software tools. Posting media in social communication environments has become one of our common daily routines. Before posting, various editing generators are used to manipulate pixel values, such as for enhancing brightness and contrast. Undoubtedly, this software helps bring posting media from ordinary to outstanding. But such a type of editing crosses the line in terms of creating fakes�anything that comes from anywhere and does not retain its originality anyway. It poses a series of issues in the process of multimedia forensics investigation and chain of custody. In order to restrict the attempts at deep faking and make the investigation hierarchy more effective, efficient, and reliable in the socio-cyber space (SCS), this paper presents a novel framework called DF-SCW. A digital forensics-enabled socio-cyber world with artificial intelligence (AI), especially deep neural networks (DNNs), for detecting and analyzing deep fake media investigations on social media platforms. It compares pixels with their neighboring values in the same media (such as images and videos) to identify information about the original one. There is a media flag designed to filter out malicious and dangerous attempts, like a powerful leader declaring war. Putting flags on such fakes helps digital investigators resist sharing the posts. In addition, the other prospect of this research is to make the digital forensics ecosystem more appropriate to take qualitative judgments in real-time while media is uploaded on social media platforms. The simulation of the proposed DF-SCW is tested on three different platforms, such as Instagram, Facebook, and Twitter. Through the experiment, the DF-SCW outperformed in terms of detection, identification, and analysis of deepfake media by an increased rate of 3.77%.","Multimedia forensics, Artificial intelligence, Deepfake investigation, Socio-cyber environment, Social media platforms",ScienceDirect
69,Deep learning applications on cybersecurity: A practical approach,Alberto Miranda-Garc�a and Agust�n Zubillaga Rego and Iker Pastor-L�pez and Borja Sanz and Alberto Tellaeche and Jos� Gaviria and Pablo G. Bringas,2024,"One of the most difficult challenges for computer systems has been security. On the other hand, new developments in machine learning are having an impact on almost every aspect of computer science, including cybersecurity. To analyze this impact, we have created three distinct cybersecurity-related problems to show the advantages of deep learning techniques. We examined their potential applications for SPAM filtering, detecting malicious software, and adult-content detection. We experimented with various techniques, such as Long Short-Term Memory (LSTMs) for spam filtering, Deep Neural Networks (DNNs) for malware detection, Convolutional Neural Networks (CNNs) combined with Transfer Learning for adult content detection and image augmentation methods. We are able to achieve an Area Under ROC Curve greater than 0.94 in every scenario, proving that excellent performance with a good relation between cost and effectiveness may be created without the need of complex designs.","Deep learning, Cybersecurity, Transfer learning, Image classification, NLP",ScienceDirect
70,AVFakeNet: A unified end-to-end Dense Swin Transformer deep learning model for audio�visual? deepfakes detection,Hafsa Ilyas and Ali Javed and Khalid Mahmood Malik,2023,"Recent advances in the field of machine learning and social media platforms facilitate the creation and rapid dissemination of realistic fake content (i.e., images, videos, audios). Initially, the fake content generation involved the manipulation of either audio or video streams but currently, more realistic deepfakes content is being produced via modifying both audio�visual streams. Researchers in the field of deepfakes detection mostly focus on identifying fake videos exploiting solely visual or audio modality. However, there exist a few approaches for audio�visual deepfakes detection but mostly are not evaluated on a multimodal dataset with deepfakes videos having the manipulations in both streams. The unified approaches evaluated on the audio�visual deepfakes dataset have reported low detection accuracies and failed when the faces are side-posed. Therefore, in this paper, we introduced a novel AVFakeNet framework that focuses on both the audio and visual modalities of a video for deepfakes detection. More specifically, our unified AVFakeNet model is a novel Dense Swin Transformer Net (DST-Net) which consists of an input block, feature extraction block, and output block. The input and output block comprises dense layers while the feature extraction block employs a customized swin transformer module. We have performed extensive experimentation on five different datasets (FakeAVCeleb, Celeb-DF, ASVSpoof-2019 LA, World Leaders dataset, Presidential Deepfakes dataset) comprising audio, visual, and audio�visual deepfakes along with a cross-corpora evaluation to signify the effectiveness and generalizability of our unified framework. Experimental results highlight the effectiveness of the proposed framework in terms of accurately detecting deepfakes videos via scrutinizing both the audio and visual streams.","AVFakeNet, Audio�visual deepfake detection, Dense swin transformer, FakeAVCeleb, ASVSpoof-2019",ScienceDirect
71,LandmarkBreaker: A proactive method to obstruct DeepFakes via disrupting facial landmark extraction,Yuezun Li and Pu Sun and Honggang Qi and Siwei Lyu,2024,"The recent development of Deep Neural Networks (DNN) has significantly increased the realism of AI-synthesized faces, with the most notable examples being the DeepFakes. In particular, DeepFake can synthesize the face of the target subject from the face of another subject, while retaining the same face attributes. With the increased number of social media portals, DeepFake videos rapidly spread through the Internet, causing a broad negative impact on society. Recent countermeasures to combat DeepFake focus on detection, a passive defense that is not able to prevent or slow down the generation of DeepFakes. Therefore in this paper, we focus on proactive defense and describe a new method named LandmarkBreaker, which is the first dedicated solution to obstruct the generation of DeepFake videos by disrupting facial landmark extraction, inspired by the observation that facial landmark extraction is an indispensable step for face alignment required in DeepFake synthesis. To disrupt facial landmark extraction, we design adversarial perturbations meticulously by optimizing a loss function in an iterative manner. Furthermore, we develop LandmarkBreaker++, which can further reduce the perceptibility of adversarial perturbations using a gradient clipping and face masking strategy. We validate our method on three state-of-the-art facial landmark extractors and investigate the defense performance on a recent Celeb-DF dataset, which demonstrates the efficacy of our method in obstructing the generation of DeepFake videos.","Deepfake defense, Facial landmark extraction, DeepFake obstruction, DNN security",ScienceDirect
72,Deep Fakes in Healthcare: How Deep Learning Can Help to Detect Forgeries,Alaa Alsaheel and Reem Alhassoun and Reema Alrashed and Noura Almatrafi and Noura Almallouhi and Saleh Albahli,2023,"With the increasing use of deep learning technology, there is a growing concern over creating deep fake images and videos that can potentially be used for fraud. In healthcare, manipulating medical images could lead to misdiagnosis and potentially life-threatening consequences. Therefore, the primary purpose of this study is to explore the use of deep learning algorithms to detect deep fake images by solving the problem of recognizing the handling of samples of cancer and other diseases. Therefore, this research proposes a framework that leverages state-of-the-art deep convolutional neural networks (CNN) and a large dataset of authentic and deep fake medical images to train a model capable of distinguishing between authentic and fake medical images. Specifically, the paper trained six CNN models, namely, ResNet101, ResNet50, DensNet121, DenseNet201, MobileNetV2, and MobileNet. These models had trained using 2000 samples over three classes: Untampered, False-Benign, and False-Malicious, and compared against several state-of-the-art deep fake detection models. The proposed model enhanced ResNet101 by adding more layers, achieving a training accuracy of 99%. The findings of this study show near-perfect accuracy in detecting instances of tumor injections and removals.","Deep learning, image processing, medical imaging, artificial intelligence",ScienceDirect
73,Deep fake news detection system based on concatenated and recurrent modalities,Ahmed Sedik and Amr A. Abohany and Karam M. Sallam and Kumudu Munasinghe and T. Medhat,2022,"With the rise in popularity of social media platforms and online forums, they have become a global source of news. Fake News (FNs) spreading through numerous institutions and sectors jeopardizes their reputations, causing users to abandon these platforms. Therefore, there is a huge pool of research in the area of Artificial Intelligence (AI) techniques that are used to detect FNs. Previously, great focus was given to online review classification and free internet posts based on social networks. This research proposes a Deep Learning-based FNs Detection method. This paper proposes a Deep Learning (DL)-based method for detecting FNs. The proposed system consists of three phases; text encoding, feature extraction, and classification. The text encoding process is carried out on the input news words using GLOVE for word representation. The encoded words are then embedded into a specific word length in order to be enrolled in the proposed DL models. The proposed DL models comprise both automatic feature extraction and classification tasks. Furthermore, this study proposes four different DL models, including Convolutional Neural Networks (CNNs) and Concatenated CNNs (C-CNNs), long short-term memory (LSTM), and Gated Recurrent Units, to find an optimal model prior to the section of FNs that outperforms previous works.The proposed DL models are carried out on FNs and FNC datasets which are provided by kaggle, and the suggested C-CNNs algorithm obtained an accuracy of 99.6% and trained faster than others. Multiple evaluation metrics such as precision, recall, F1, and accuracy have been utilized to evaluate the outcome of the proposed models. The experimental results demonstrated overall improvements in the subject of FND when compared with the current models and validated the potential of the proposed methodology for the detection of FNs on Social Media (SM). This study will help researchers to broaden the knowledge of applications of CNNs based on DL methods for FND.","Fake News Detection, Deep Learning, CNN, Concatenated CNN, LSTM, GRU, CNNs-LSTM",ScienceDirect
74,Qualitative failures of image generation models and their application in detecting deepfakes,Ali Borji,2023,"The remarkable advancement of image and video generation models has led to the creation of exceptionally realistic content, posing challenges in differentiating between genuine and fabricated instances in numerous scenarios. However, despite this progress, a gap remains between the quality of generated images and those found in the real world. To address this, we have reviewed a vast body of literature from both academic publications and social media to identify qualitative shortcomings in image generation models, which we have classified into five categories. By understanding these failures, we can identify areas where these models need improvement, as well as develop strategies for detecting generated images and deepfakes. The prevalence of deepfakes in today�s society is a serious concern, and our findings can help mitigate their negative impact. In order to support research in this field, a collection of instances where models have failed is made available at here.","Generative models, Image and video generation, Qualitative failures, Deepfakes, Image forensics, Object and scene recognition, Neural networks, Deep learning",ScienceDirect
75,ViXNet: Vision Transformer with Xception Network for deepfakes based video and image forgery detection,Shreyan Ganguly and Aditya Ganguly and Sk Mohiuddin and Samir Malakar and Ram Sarkar,2022,"With the advent of image generative technologies, there is a huge growth in the development of facial manipulation techniques that allow people to easily modify media data like videos and images by changing the identity or facial expression of the target person with another person�s face. Colloquially, these manipulated videos and images are termed �deepfakes�. As a result, every piece of content in digital media comes with a question � is this authentic? Hence, there is an unprecedented need for a competent deepfakes detection method. The rapid changes in forging methods make this a very challenging task and thus generalization of the detection methods is also of utmost required. However, the generalization strengths of the prevailing deepfakes detection methods are not satisfactory. In other words, these models perform well when trained and tested on the same dataset but fail to perform satisfactorily when models are trained on one dataset and tested on another. The most modern deep learning aided deepfakes detection techniques looked for a consistent pattern among the leftover artifacts in specific facial regions of the target face rather than the entire face. To this end, we propose a Vision Transformer with Xception Network (ViXNet) to learn the consistency of these almost imperceptible artifacts left by deepfaking methods on the entire facial region. The ViXNet comprises two branches � one tries to learn inconsistencies among local face region specifics by combining patch-wise self-attention module and vision transformer, and the other generates global spatial features using a deep convolutional neural network. To assess the performance of ViXNet, we evaluate it using two different experimental setups � intra-dataset and inter-dataset when using three standard deepfakes video datasets, namely FaceForensics++, and Celeb-DF (V2) and one deepfakes image dataset called Deepfakes. We have attained 98.57% (83.60%), 99.26% (74.78%), and 98.93% (75.13%) AUC scores using intra(inter)-dataset experimental setups on FaceForensics++, Celeb-DF (V2), and Deepfakes datasets respectively. Additionally, we have evaluated ViXNet on the Deepfake Detection Challenge (DFDC) dataset and we have obtained 86.32% AUC score and 79.06% F1-score on the said dataset. Performances of the proposed model are comparable to state-of-the-art methods. Besides, the obtained results ensure the robustness and the generalization ability of the proposed model.","Deepfakes, FaceSwap, Soft attention, Vision transformer, Forgery detection, Xception model",ScienceDirect
76,MeST-Former: Motion-enhanced Spatiotemporal Transformer for generalizable Deepfake detection,Baoping Liu and Bo Liu and Ming Ding and Tianqing Zhu,2024,"The rise of Deepfake technology has sparked significant concerns due to its potential for misuse and malicious manipulation of multimedia content. Various detection approaches aimed at detecting Deepfake videos have been proposed, mostly relying on the identification of spatial and temporal artifacts. However, due to the different contexts of source images and the variety of generation techniques, current Deepfake detection methods usually perform well on training datasets, and yet generalize poorly to those unseen identities in new datasets. This issue is widely known as the generalization challenge of Deepfake detection. To address this challenge, this paper proposes an advanced spatiotemporal Deepfake video detector, named Motion-enhanced Spatiotemporal Transformer (MeST-Former). MeST-Former is based on the spatiotemporal modeling capacity of the video Swin Transformer. The spatial and temporal features are obtained from the RGB and motion images, respectively. To enhance the generalization ability of MeST-Former to unseen identities in unseen datasets, the ID-related components in the spatial and temporal features are detached. Specifically, MeST-Former adopts the newly proposed Identity-Decoupling Attention (IDC-Att) module to disentangle the ID-related and ID-unrelated components. Only the ID-unrelated components are used to construct more generalizable spatiotemporal representations. This process makes the constructed spatiotemporal features identity-agnostic and more generalizable to unseen identities. We conducted extensive experiments to evaluate the performance of the MeST-Former. Our results indicate that MeST-Former achieves accurate and generalizable Deepfake detection performance. Notably, MeST-Former also demonstrates high efficacy in detecting AI-animated talking-head videos.","Deepfake detection, Spatiotemporal, Motion, Identity-agnostic, Transformer",ScienceDirect
77,Image forgery detection by transforming local descriptors into deep-derived features,Muhammad Aqib Anwar and Syed Fahad Tahir and Labiba Gillani Fahad and Kashif Kifayat,2023,"Image forgery is the intentional alteration of digital images, either manually using image editors or through deep fake techniques, for the purpose of disseminating fake information. We propose a forgery detection approach that efficiently detects copy-move and splicing attacks of varying scales in digital images. Our goal is to identify the homogeneous region(s) inconsistent with the rest of the image. This region property has been typically employed in object detection and classification, while we exploit this property to detect forgery in images. Thus, we generate the deep-derived features from the existing hand-crafted features in forgery detection as input to the VGG16, a deep learning method, trained for object classification. We use a binary class SVM trained on the obtained deep-derived features to determine whether an image is real or fake. We perform extensive experiments on three publicly available image manipulation datasets, DVMM, Casia and Korus to validate the effectiveness of the proposed methodology. The results show a better accuracy compared to the state-of-the-art methods.","Forgery detection, Local descriptors, Deep derived features, Support vector machine",ScienceDirect
78,Using deep learning techniques and genetic-based feature extraction for presentation attack mitigation,John Jenkins and Kaushik Roy and Joseph Shelton,2020,"Abstract�
Biometric authentication systems are becoming more prevalent for commercial use with computers and smart devices. Biometric systems also have several vulnerable points that can be exploited by a hacker to gain unauthorized access to a system. Replay attacks focus on capturing feature extractors (FEs) during transmission, decrypting, and replaying for illegal access. The Genetic and Evolutionary Feature Extraction (GEFE) technique, developed at North Carolina A&T State University, recently showed promising results in mitigating replay attacks in combination with a feature selection algorithm. Biometric-based presentation attacks, the focus of this work, is another biometric system vulnerability primarily focused on presenting a biometric sample of quality to illegally gain access to secured data. Recently, deep learning techniques to mitigate presentation attacks have shown promising results. However, the accuracy of deep learning-based biometric presentation attack detection (PAD) methods are limited by the quality of the samples provided. In absence of large sets of original biometric sample data, data augmentation has been shown to be successful in generating synthetic biometric image data and improving the performance of deep learning techniques applied. The novelty of this paper lies in the following two aspects: First, a data augmentation technique with Generative Adversarial Networks (GANs) is used to generate comparative synthetic (spoofing) dataset. With the proliferation of deep fakes in media, this technique should provide insight on the GAN technique often used. Once properly trained, the synthetic images are used to create spoofing datasets. Second, the GEFE technique is used in combination with the GANs to generate improved anti-spoofing feature extractors optimized to mitigate presentation attacks. The combination of GEFE and GANs is used to identify those discriminative biometric features used to mitigate synthetic presentation attacks. The GEFE�?+�?GAN technique outperforms the LBP and GEFE techniques alone in overall identification and verification results on spoofing datasets.",", , ",ScienceDirect
79,Deepfake detection in digital media forensics,Vurimi Veera Venkata Naga Sai Vamsi and Sukanya S. Shet and Sodum Sai Mohan Reddy and Sharon S. Rose and Sona R. Shetty and S. Sathvika and Supriya M.�S. and Sahana P. Shankar,2022,"With the development of technology and ease of creation of fake content, the manipulation of media is carried out on a large scale in recent times. The rise of AI altered videos or Deepfake media has posed a great threat to media integrity and is being produced and spread widely across social media platforms, the detection of which is seen to be a major challenge. In this paper, an approach for Deepfake detection has been provided. ResNext, a Convolutional Neural Network (CNN) algorithm and Long Short-Term Memory (LSTM) is used as an approach to detect the Deepfake videos. The approach and its steps are discussed in this paper. The accuracy obtained for the developed Deep-Learning (DL) model over the Celeb-Df dataset is 91%.","Celeb-Df, CNN, LSTM, Deepfake, Prediction, ResNext, Deep Learning",ScienceDirect
80,DFGNN: An interpretable and generalized graph neural network for deepfakes detection,Fatima Khalid and Ali Javed and Qurat-ul ain and Hafsa Ilyas and Aun Irtaza,2023,"Deepfakes are generated using sophisticated deep-learning models to create fake images or videos. As the techniques for creating deepfakes improve, issues like defamation, impersonation, fraud, and misinformation on social media are becoming more prevalent. Existing deep learning-based deepfakes detection models are not interpretable and don�t generalize well when tested across diverse deepfakes generating techniques and datasets. Therefore, the creation of reliable and effective deepfakes detection algorithms is required which are not only generalizable but also interpretable. This paper introduces a novel graph neural network-based architecture to identify hyper-realist deepfake content. Currently, very limited efforts have been done to address the problem of deepfakes detection using graph neural networks. The proposed model is based on the pyramid structure that takes advantage of multi-scale images property by extracting features with progressively smaller spatial sizes as layer depth increases. The method first sliced the image into patches, which are referred to as nodes, and then constructed a graph by connecting the nearest neighbors. To transform and exchange information between all nodes, the proposed model has two basic modules: GraphNet, which uses graph convolution layers to aggregate and update graph information, and FFN, which has linear layers for the transformation of node features. The effectiveness of the method is assessed using the diverse Deepfake Detection Challenge dataset (DFDC), FaceForensics++ (FF++), World Leaders dataset (WLRD), and the Celeb-DF. To demonstrate the generalizability of the proposed method for accurate deepfakes detection, open/close set, cross-set, and cross-corpora evaluations were also performed. The AUC values of 0.98 on FF++, 0.95 on Celeb-DF, 0.92 on DFDC, and 1.00 on most of the sets of WLRD datasets demonstrate the efficacy of the method for identifying manipulated facial images produced using various deepfakes techniques.","Celeb-DF, Deepfakes, DFDC, FaceForensics++, Graph Neural Network, World Leaders Dataset",ScienceDirect
81,SFormer: An end-to-end spatio-temporal transformer architecture for deepfake detection,Staffy Kingra and Naveen Aggarwal and Nirmal Kaur,2024,"Growing AI advancements are continuously pacing GAN enhancement that eventually facilitates the generation of deepfake media. Manipulated media poses serious risks pertaining court proceedings, journalism, politics, and many more where digital media have a substantial impact on society. State-of-the-art techniques for deepfake detection rely on convolutional networks for spatial analysis, and recurrent networks for temporal analysis. Since transformers are capable of recognizing wide-range dependencies with a global spatial view and along temporal sequence too, a novel approach called �SFormer� is proposed in this paper, utilizing a transformer architecture for both spatial and temporal analysis to detect deepfakes. Further, state-of-the-art techniques suffer from high computational complexity and overfitting which causes loss in generalizability. The proposed model utilized a Swin Transformer for spatial analysis that resulted in low complexity, thereby enhancing its generalization ability and robustness against the different manipulation types. Proposed end-to-end transformer based model, SFormer, is proven to be effective for numerous deepfake datasets, including FF++, DFD, Celeb-DF, DFDC and Deeper-Forensics, and achieved an accuracy of 100%, 97.81%, 99.1%, 93.67% and 100% respectively. Moreover, SFormer has demonstrated superior performance compared to existing spatio-temporal and transformer-based approaches for deepfake detection.","Deepfake detection, Digital forensics, Facial manipulation detection, Spatio-temporal, Transformer",ScienceDirect
82,A 3D-CAE-CNN model for Deep Representation Learning of 3D images,Emmanuel Pintelas and Panagiotis Pintelas,2022,"Deep Representation Learning technologies based on supervised Convolutional Neural Networks (CNNs) have attained significant interest mainly due to their superior performance for learning abstract and robust features used in object detection and image classification tasks. However, to efficiently train such models requires a large number of labeled instances especially when these instances are high dimensional such as for 3-Dimensional (3D) Image inputs. Due to this extra dimension the dimensionality of such instances increases drastically. Therefore, the utilization of Unsupervised CNNs topologies such 3D Convolutional AutoEncoders (3D-CAE) have also been proposed. CAEs can learn features (and later used for classification tasks using common machine learning classifiers), without relying on instance labels and thus they are not prone to label limitation. Nevertheless, it is not clear if the features that CAEs learn, are relevant regarding the classification or object detection task since these features are learned via no target output class. For these reasons, in this work we combine 3D-CAE and 3D-CNN to work synergistically together in order to build a hybrid deep representation learning framework model which exploits the advantages of both unsupervised and supervised representation/feature learning approaches, applied on 3D Image inputs. In order to evaluate our strategy, we performed extensive experimental simulations for the DeepFake and Pneumonia detection problems utilizing Video and 3D Scans datasets respectively. Our proposed framework outperformed all the other utilized frameworks, revealing the efficiency of our applied methodology.","Deep Representation Learning, Convolutional AutoEncoders, Deep convolutional neural networks, 3D image classification, DeepFake video detection, 3D Pneumonia detection",ScienceDirect
83,Rethinking gradient operator for exposing AI-enabled face forgeries,Zhiqing Guo and Gaobo Yang and Dengyong Zhang and Ming Xia,2023,"For image forensics, convolutional neural networks (CNNs) tend to learn image content features rather than subtle manipulation traces, which constrains detection performance. Existing works usually address this issue by following a common pipeline, namely subtracting the original pixel value from the predicted pixel value to enforce CNNs to learn more features from the manipulation traces. However, due to the complicated learning mechanism, they might still have some unnecessary performance losses. In this work, we rethink the advantages of image gradient operator in exposing AI-enabled face forgeries, and design two plug-and-play modules, namely tensor pre-processing (TP) and manipulation trace attention (MTA), by combining the gradient operator with CNNs. Specifically, the TP module refines the feature tensor of each channel in the network by the gradient operator to highlight manipulation traces and improve feature representation. Moreover, the MTA module considers two dimensions, namely channel and manipulation traces, to enforce the network to learn the distribution of the manipulation traces. Both modules can be seamlessly integrated into existing CNNs for end-to-end training. Experiments show that the proposed expert system achieves better results than prior works on five public image datasets. The code is available at: https://github.com/EricGzq/GocNet-pytorch.","Face forgery detection, Deepfake detection, Gradient operator, Tensor pre-processing, Attention mechanism",ScienceDirect
84,An efficient deepfake video detection using robust deep learning,Abdul Qadir and Rabbia Mahum and Mohammed A. El-Meligy and Adham E. Ragab and Abdulmalik AlSalman and Muhammad Awais,2024,"The creation and manipulation of synthetic images have evolved rapidly, causing serious concerns about their effects on society. Although there have been various attempts to identify deep fake videos, these approaches are not universal. Identifying these misleading deepfakes is the first step in preventing them from spreading on social media sites. We introduce a unique deep-learning technique to identify fraudulent clips. Most deepfake identifiers currently focus on identifying face exchange, lip synchronous, expression modification, puppeteers, and other factors. However, exploring a consistent basis for all forms of fake videos and images in real-time forensics is challenging. We propose a hybrid technique that takes input from videos of successive targeted frames, then feeds these frames to the ResNet-Swish-BiLSTM, an optimized convolutional BiLSTM-based residual network for training and classification. This proposed method helps identify artifacts in deepfake images that do not seem real. To assess the robustness of our proposed model, we used the open deepfake detection challenge dataset (DFDC) and Face Forensics deepfake collections (FF++). We achieved 96.23% accuracy when using the FF++ digital record. In contrast, we attained 78.33% accuracy using the aggregated records from FF++ and DFDC. We performed extensive experiments and believe that our proposed method provides more significant results than existing techniques.","Video deepfakes, Multimedia forensics, Swish, Visual manipulation",ScienceDirect
85,Deepfakes and beyond: A Survey of face manipulation and fake detection,Ruben Tolosana and Ruben Vera-Rodriguez and Julian Fierrez and Aythami Morales and Javier Ortega-Garcia,2020,"The free access to large-scale public databases, together with the fast progress of deep learning techniques, in particular Generative Adversarial Networks, have led to the generation of very realistic fake content with its corresponding implications towards society in this era of fake news. This survey provides a thorough review of techniques for manipulating face images including DeepFake methods, and methods to detect such manipulations. In particular, four types of facial manipulation are reviewed: i) entire face synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv) expression swap. For each manipulation group, we provide details regarding manipulation techniques, existing public databases, and key benchmarks for technology evaluation of fake detection methods, including a summary of results from those evaluations. Among all the aspects discussed in the survey, we pay special attention to the latest generation of DeepFakes, highlighting its improvements and challenges for fake detection. In addition to the survey information, we also discuss open issues and future trends that should be considered to advance in the field.","Fake news, Deepfakes, Media forensics, Face manipulation, Face recognition, Benchmark, Databases",ScienceDirect
86,TAENet: Two-branch Autoencoder Network for Interpretable Deepfake Detection,Fuqiang Du and Min Yu and Boquan Li and Kam Pui Chow and Jianguo Jiang and Yixin Zhang and Yachao Liang and Min Li and Weiqing Huang,2024,"Deepfake detection attracts increasingly attention due to serious security issues caused by facial manipulation techniques. Recently, deep learning-based detectors have achieved promising performance. However, these detectors suffer severe untrustworthy due to the lack of interpretability. Thus, it is essential to work on the interpretibility of deepfake detectors to improve the reliability and traceability of digital evidence. In this work, we propose a two-branch autoencoder network named TAENet for interpretable deepfake detection. TAENet is composed of Content Feature Disentanglement (CFD), Content Map Generation (CMG), and Classification. CFD extracts latent features of real and forged content with dual encoder and feature discriminator. CMG employs a Pixel-level Content Map Generation Loss (PCMGL) to guide the dual decoder in visualizing the latent representations of real and forged contents as real-map and fake-map. In classification module, the Auxiliary Classifier (AC) serves as map amplifier to improve the accuracy of real-map image extraction. Finally, the learned model decouples the input image into two maps that have the same size as the input, providing visualized evidence for deepfake detection. Extensive experiments demonstrate that TAENet can offer interpretability in deepfake detection without compromising accuracy.","Deepfake detection, Interpretibility representation, Image forensic, Disentanglement learning",ScienceDirect
87,A study on data augmentation in voice anti-spoofing,Ariel Cohen and Inbal Rimon and Eran Aflalo and Haim H. Permuter,2022,"In this paper we perform an in depth study of how data augmentation techniques improve synthetic or spoofed audio detection. Specifically, we propose methods to deal with channel variability, different audio compressions, different bandwidths and unseen spoofing attacks. These challenges, have all been shown to significantly degrade the performance of audio based systems and anti spoofing systems. Our results are based on the ASVspoof 2021 challenge, in the Logical Access (LA) and Deep Fake (DF) categories. Our study is Data-Centric, meaning that the models are fixed and we significantly improve the results by manipulating the data. We introduce two forms of data augmentation - compression augmentation for the DF part, and compression and channel augmentation for the LA part. In addition, we introduce a double sided log spectrogram feature design that improves the results significantly by centering the sub-bands of interest, where the discriminating spoofing artifacts can be localized. Furthermore, a new type of online data augmentation, SpecAverage, is introduced. This method includes masking the audio features with their average value in order to improve generalization. Our best single system and fusion schemes both achieve state of the art performance in the DF category, with an EER of 15.46% and 14.27%, respectively. Our best system for the LA task reduced the best baseline EER by 50% and the min t-DCF by 16%. Our techniques to deal with spoofed data from a wide variety of distributions can be replicated and can help anti spoofing and speech based systems enhance their results.","ASVspoof 2021, Audio data augmentation, Data-centric AI, SpecAugment, Voice anti spoofing, Voice deep fake",ScienceDirect
88,Deep learning model to detect deceptive generative adversarial network generated images using multimedia forensic,Haewon Byeon and Mohammad Shabaz and Kapil Shrivastava and Anjali Joshi and Ismail Keshta and Rajvardhan Oak and Pavitar Parkash Singh and Mukesh Soni,2024,"Computer-generated imagery has been made more lifelike and misleading by new Generative Adversarial Network (GAN) models, such as StyleGAN, posing severe risks to people's safety, social order, and privacy. Deceptive content creation, including Deepfakes, image tampering, and information hiding, can be facilitated through the misuse of GANs. To tackle these challenges, a detection model is proposed in this research, employing a spatial-frequency joint dual-stream convolutional neural network. Learnable frequency-domain filtering kernels and frequency-domain networks are leveraged to thoroughly learn and extract frequency-domain features, considering the discernible artifacts left by GAN images in the frequency spectrum due to the upsampling process during production. Lastly, the two sets of traits are combined to identify GAN-created faces. The proposed model outperforms state-of-the-art methods, as evidenced by experimental findings on various datasets, both in terms of detection accuracy on high-quality created datasets and generalization across datasets.","Deep learning, GANs, Deepfake, Image tampering, Information hiding, Multimedia forensic, Image detection",ScienceDirect
89,Exposing low-quality deepfake videos of Social Network Service using Spatial Restored Detection Framework,Ying Li and Shan Bian and Chuntao Wang and Kemal Polat and Adi Alhudhaif and Fayadh Alenezi,2023,"The increasing abuse of facial manipulation methods, such as FaceSwap, Deepfakes etc., seriously threatens the authenticity of digital images/videos on the Internet. Therefore, it is of great importance to identify the facial videos to confirm the contents and avoid fake news or rumors. Many researchers have paid great attention to the detection of deepfakes and put forward a number of deep-learning-based detection models. The existing approaches mostly face the performance degradation in detecting low-quality(LQ) videos, i.e. heavily compressed or low-resolution videos through some SNS (Social Network Service), resulting in the limitation in real applications. To address this issue, in this paper, a novel Spatial Restore Detection Framework(SRDF) is proposed for improving the detection performance for LQ videos by restoring spatial features. We designed a feature extraction-enhancement block and a mapping block inspired by super-resolution methods, to restore and enhance texture features. An attention module was introduced to guide the texture features restoration and enhancement stage attending to different local areas and restoring the texture features. Besides, an improved isolated loss was put forward to prevent the expansion of a single area concerned. Moreover, we adopted a regional data augmentation strategy to prompt feature restore and enhancement in the region attended. Extensive experiments conducted on two deepfake datasets have validated the superiority of the proposed method compared to the state-of-the-art, especially in the scenarios of detecting low-quality deepfake videos.","Deepfake detection, Video forensics, Super resolution, Attention mechanism",ScienceDirect
90,Detection of real-time deep fakes and face forgery in video conferencing employing generative adversarial networks,Sunil Kumar Sharma and Abdullah AlEnizi and Manoj Kumar and Osama Alfarraj and Majed Alowaidi,2024,"As facial modification technology advances rapidly, it poses a challenge to methods used to detect fake faces. The advent of deep learning and AI-based technologies has led to the creation of counterfeit photographs that are more difficult to discern apart from real ones. Existing Deep fake detection systems excel at spotting fake content with low visual quality and are easily recognized by visual artifacts. The study employed a unique active forensic strategy Compact Ensemble-based discriminators architecture using Deep Conditional Generative Adversarial Networks (CED-DCGAN), for identifying real-time deep fakes in video conferencing. DCGAN focuses on video-deep fake detection on features since technologies for creating convincing fakes are improving rapidly. As a first step towards recognizing DCGAN-generated images, split real-time video images into frames containing essential elements and then use that bandwidth to train an ensemble-based discriminator as a classifier. Spectra anomalies are produced by up-sampling processes, standard procedures in GAN systems for making large amounts of fake data films. The Compact Ensemble discriminator (CED) concentrates on the most distinguishing feature between the natural and synthetic images, giving the generators a robust training signal. As empirical results on publicly available datasets show, the suggested algorithms outperform state-of-the-art methods and the proposed CED-DCGAN technique successfully detects high-fidelity deep fakes in video conferencing and generalizes well when comparing with other techniques. Python tool is used for implementing this proposed study and the accuracy obtained for proposed work is 98.23�%.","Deep fake detection, Deep conditional generative adversarial networks, Ensemble discriminators",ScienceDirect
91,Revealing and Classification of Deepfakes Video's Images using a Customize Convolution Neural Network Model,Usha Kosarkar and Gopal Sarkarkar and Shilpa Gedam,2023,"Deepfake has been exploited in recent years despite its widespread usage in a variety of areas to create dangerous material such as fake movies, rumors, and false news by changing or substituting the face information of the sources and so poses enormous security concerns to society. Research on active detection & prevention technologies is critical as deepfake continues to evolve. Deepfake has been a blessing, but we've taken advantage of it by utilizing it to swap faces. Deepfake is a new subdomain of Artificial Intelligence (AI) technology in which one person's face is layered over another person's face, which is becoming more and more popular on social networking sites. Deepfake pictures and videos can now be created much more quickly and cheaply due to ML (Machine Learning), which is a primary component of deepfakes. Despite negative connotations attached to the term ""deepfakes,"" technology is increasingly being used in commercial & individual contexts. New technical advancements have made it more difficult to distinguish between deepfakes and images that have been digitally manipulated. The rise of deepfake technologies has sparked a growing sense of unease. The primary goal of this project is to properly distinguish deepfake pictures from real images using deep learning techniques. In this study, we implemented a customized CNN algorithm to identify deepfake pictures from a video dataset and conducted a comparative analysis with two other methods to determine which way was superior. The Kaggle dataset was used to train & test our model. Convolutional neural networks (CNNs) have been used in this research to distinguish authentic & deepfake images by training three distinct CNN models. A customized CNN model, which includes several additional layers such as a dense layer, MaxPooling, as well as a dropout layer, has also been developed and implemented. This method follows the frames extraction, face feature extraction, data preprocessing, and classification phases in determining whether Real or Fake images in the video reflect the objectives. Accuracy, loss, and the area under the receiver operating characteristic (ROC) curve were used to characterize the data. Customized CNN outperformed all other models, achieving 91.4% accuracy, a reduced loss value of 0.342, as well as an AUC of 0.92. Besides, we obtained 85.2% testing accuracy from the CNN and 95.5% testing accuracy from the MLP-CNN model.","Deepfake detection, Deep learning, Customize CNN, Deepfake Detection Challenge Dataset, Classification",ScienceDirect
92,Audio-deepfake detection: Adversarial attacks and countermeasures,Mouna Rabhi and Spiridon Bakiras and Roberto {Di Pietro},2024,"Audio has always been a powerful resource for biometric authentication: thus, numerous AI-based audio authentication systems (classifiers) have been proposed. While these classifiers are effective in identifying legitimate human-generated input their security, to the best of our knowledge, has not been explored thoroughly when confronted with advanced attacks that leverage AI-generated deepfake audio. This issue presents a serious concern regarding the security of these classifiers because, e.g., samples generated using adversarial attacks might fool such classifiers, resulting in incorrect classification. In this study, we prove the point: we demonstrate that state-of-the-art audio deepfake classifiers are vulnerable to adversarial attacks. In particular, we design two adversarial attacks on a state-of-the-art audio-deepfake classifier, i.e., the Deep4SNet classification model, which achieves 98.5% accuracy in detecting fake audio samples. The designed adversarial attacks11The code of the attacks will be released open-source in the camera ready. leverage a generative adversarial network architecture and reduce the detector�s accuracy to nearly 0%. In particular, under graybox attack scenarios, we demonstrate that when starting from random noise, we can reduce the accuracy of the state-of-the-art detector from 98.5% to only 0.08%. To mitigate the effect of adversarial attacks on audio-deepfake detectors, we propose a highly generalizable, lightweight, simple, and effective add-on defense mechanism that can be implemented in any audio-deepfake detector. Finally, we discuss promising research directions.","Authentication, Adversarial attacks, Audio deepfake, Fake voice detection, GAN, Biometrics, Security",ScienceDirect
93,A facial geometry based detection model for face manipulation using CNN-LSTM architecture,Peifeng Liang and Gang Liu and Zenggang Xiong and Honghui Fan and Hongjin Zhu and Xuemin Zhang,2023,"This issue of DeepFake technique that may cause great threat to privacy, democracy, and national security has attracted the attention of deep learning researchers. DeepFake detection, therefore, has been a very hot issue in deep learning research. The face landmark feature maps are often used by many DeepFake approaches in generating fake faces. It also provides key information to help to detect manipulated face images. In this paper, we propose a detection approach for manipulated face images. To make full use of face landmark information, we propose a facial geometry prior module (FGPM) to extract facial geometry feature maps. Then the facial geometry feature maps are embedded into upsampling feature maps generated by the CNN-LSTM network. The proposed FGPM exploits facial maps and frequency domain correlation to analyze the discriminative characteristics between manipulated and non-manipulated regions by incorporating the CNN-LSTM network. Finally, a decoder is used to learn the mapping from low-resolution feature maps to pixel-wise to predict manipulation localization. Or a softmax classifier is used to predict real or fake face images. By experimenting on several popular datasets, the proposed detection model has demonstrated the capability of localizing manipulation at the pixel level and with a high prediction on real or fake face images.","DeepFake detection, CNN-LSTM, Facial geometry prior module, Resampling, Facial analysis",ScienceDirect
94,Golden ratio based deep fake video detection system with fusion of capsule networks,Samet Dincer and Guzin Ulutas and Beste Ustubioglu and Gul Tahaoglu and Nicolas Sklavos,2024,"In recent years, with the massive development of new deep learning tools, the production of fake video content has become widespread. This fake content has the potential to cause serious social problems. Therefore, detecting fake content is of great importance. For this purpose, we present a new method for deepfake video detection. In most of the studies, which image frames of the videos are selected to be used in the detection models is determined randomly. This randomness can cause important image frames to be missed which can improve detection performance. The proposed method differs from other studies in the literature by determining which image frames to select from the videos with the help of the golden ratio information on the face. The method was developed using three different feature extraction methods, VGG19, EfficientNet B0, EfficientNet B4, and two different capsule network models, CapsuleNet and ArCapsNet. Performance evaluations were performed on Celeb-DF and DFDC-P, two of the currently challenging deepfake video datasets. The results were improved by fusing the best performing models. For Celeb-DF dataset, 93.63% ACC, 99.14% AUC and for DFDC-P dataset, 82.84% ACC, 89.08% AUC were obtained.","Data security, Multimedia security, Cryptography, Deepfake, Cyber security",ScienceDirect
95,An adversarial attack approach for eXplainable AI evaluation on deepfake detection models,Balachandar Gowrisankar and Vrizlynn L.L. Thing,2024,"With the rising concern on model interpretability, the application of eXplainable AI (XAI) tools on deepfake detection models has been a topic of interest recently. In image classification tasks, XAI tools highlight pixels influencing the decision given by a model. This helps in troubleshooting the model and determining areas that may require further tuning of parameters. With a wide range of tools available in the market, choosing the right tool for a model becomes necessary as each one may highlight different sets of pixels for a given image. There is a need to evaluate different tools and decide the best performing ones among them. Generic XAI evaluation methods like insertion or removal of salient pixels/segments are applicable for general image classification tasks but may produce less meaningful results when applied on deepfake detection models due to their functionality. In this paper, we perform experiments to show that generic removal/insertion XAI evaluation methods are not suitable for deepfake detection models. We also propose and implement an XAI evaluation approach specifically suited for deepfake detection models.","Deepfake, Explainable AI, Evaluation, Adversarial attack, Image forensics",ScienceDirect
96,A GAN-Based Model of Deepfake Detection in Social Media, Preeti and Manoj Kumar and Hitesh Kumar Sharma,2023,"DeepFake uses Generative?+?Adversarial Network for successfully switching the identities of two people. Large public databases and deep learning methods are now rapidly available because of the proliferation of easily accessible tools online. It has resulted in the emergence of very real appealing fake content that produced a bad impact and challenges for society to deal. Pre-trained generative adversarial networks (GANs) that can flawlessly substitute one person's face in a video or image for that other are proving supportive for implementing deepfake. This paper primarily presented a study of methods used to implement deepfake. Also, discuss the main deepfake's manipulation and detection techniques, and the implementation and detection of deepfake using Deep Convolution-based GAN models. A study of Comparative analyses of proposed GAN with other exiting GAN models using parameters Inception Score �IS� and Fr�chet Inception Distance �FID� is also embedded. Along with the abovementioned, the paper discusses open issues and future trends that should be considered to advance in the field.","Digital Forensics, Image Vision, Deep Learning, Generative adversarial network, Deep Fakes, Media Forensics, Face Manipulation, Face Recognition",ScienceDirect
97,DeepFake Videos Detection Based on Texture Features,Bozhi Xu and Jiarui Liu and Jifan Liang and Wei Lu and Yue Zhang,2021,"In recent years, with the rapid development of deep learning technologies, some neural network models have been applied to generate fake media. DeepFakes, a deep learning based forgery technology, can tamper with the face easily and generate fake videos that are difficult to be distinguished by human eyes. The spread of face manipulation videos is very easy to bring fake information. Therefore, it is important to develop effective detection methods to verify the authenticity of the videos. Due to that it is still challenging for current forgery technologies to generate all facial details and the blending operations are used in the forgery process, the texture details of the fake face are insufficient. Therefore, in this paper, a new method is proposed to detect DeepFake videos. Firstly, the texture features are constructed, which are based on the gradient domain, standard deviation, gray level co-occurrence matrix and wavelet transform of the face region. Then, the features are processed by the feature selection method to form a discriminant feature vector, which is finally employed to SVM for classification at the frame level. The experimental results on the mainstream DeepFake datasets demonstrate that the proposed method can achieve ideal performance, proving the effectiveness of the proposed method for DeepFake videos detection.","DeepFake, video tampering, tampering detection, texture feature",ScienceDirect
98,Triple-modality interaction for deepfake detection on zero-shot identity,JunHo Yoon and Angel Panizo-LLedot and David Camacho and Chang Choi,2024,"Recent advancements in generative AI technology have created more realistic fake data that are utilized in various fields, such as data augmentation. However, the misuse of deepfake technology has led to increased damage. Consequently, ongoing research aims to analyze modality characteristics and detect deepfakes through AI-based methods. Existing AI-based deepfake-detection techniques have limitations in detecting deepfakes in modalities and identities that are not included in the training data. This study proposes a baseline approach based on zero-shot identity and one-shot deepfake detection for detecting deepfakes in environments with limited data. Additionally, we propose a triple-modality interaction based on a multimodal transformer (TMI-Former) to consider the triple-modality aspects of deepfakes. TMI-Former comprises four stages: vision feature extraction, representation, residual connection, and late-level fusion. It operates in a two-stage manner, extracting visual features and reconstructing them using auditory and linguistic features, thereby allowing for triple-modality interactions. In environments with limited data, such as zero-shot identity and one-shot deepfake scenarios, TMI-Former demonstrated effectiveness, with an accuracy ranging from 18.75% to 19.5% and an f1-score ranging from 0.2238 to 0.3561, compared to unimodal AI. Furthermore, TMI-Former shows superior performance compared to the existing multi-modal AI, with an accuracy ranging from 1.44% to 19.75% and an f1-score ranging from 0.0146 to 0.4169.","Multi-modal, One-shot, Deepfake, Disinformation detection",ScienceDirect
99,Detecting fake images by identifying potential texture difference,Jiachen Yang and Shuai Xiao and Aiyun Li and Guipeng Lan and Huihui Wang,2021,"Fake detection has become an urgent task. Generative adversarial networks (GANs) extended to deep learning has shown its extraordinary ability in the fields of image, audio, and speech. But advanced technology benefits us, it also poses a threat to us when used in Cyber Crime. The Deepfake (common name for face manipulation methods) based on GANs can realize the replacement of different faces. Due to the development of GANs, faces generated by Deepfake can already be visually real. Deepfake can purposely replace any face to a different person, so that a fabricated event may be widely spread because of the convenience of the Internet, causing serious impacts such as personal attacks and cyber crime. Based on cutting-edge research , this paper proposes a intelligence forensic method of Deepfake detection. We first discover the subtle texture differences between real and fake image in image saliency, which shows difference in the texture of faces. To amplify this difference, we exploit guided filter with saliency map as guide map to enhance the texture artifacts caused by the post-processing and display the potential features of forgery. Resnet18 classification network efficiently learns the exposed difference and finally realizes the real and fake detection of face images. We evaluate the performance of the method and experiments verify that the proposed method can achieve the state-of-the-art detection accuracy .","Fake detection, Security and privacy, Digital forensic, Image saliency, Texture difference",ScienceDirect
100,DEFAEK: Domain Effective Fast Adaptive Network for Face Anti-Spoofing,Jiun-Da Lin and Yue-Hua Han and Po-Han Huang and Julianne Tan and Jun-Cheng Chen and M. Tanveer and Kai-Lung Hua,2023,"Existing deep learning based face anti-spoofing (FAS) or deepfake detection approaches usually rely on large-scale datasets and powerful networks with significant amount of parameters to achieve satisfactory performance. However, these make them resource-heavy and unsuitable for handheld devices. Moreover, they are limited by the types of spoof in the dataset they train on and require considerable training time. To produce a robust FAS model, they need large datasets covering the widest variety of predefined presentation attacks possible. Testing on new or unseen attacks or environments generally results in poor performance. Ideally, the FAS model should learn discriminative features that can generalize well even on unseen spoof types. In this paper, we propose a fast learning approach called Domain Effective Fast Adaptive nEt-worK (DEFAEK), a face anti-spoofing approach based on the optimization-based meta-learning paradigm that effectively and quickly adapts to new tasks. DEFAEK treats differences in an environment as domains and simulates multiple domain shifts during training. To further improve the effectiveness and efficiency of meta-learning, we adopt the metric learning in the inner loop update with careful sample selection. With extensive experiments on the challenging CelebA-Spoof and FaceForensics++ datasets, the evaluation results show that DEFAEK can learn cues independent of the environment with good generalization capability. In addition, the resulting model is lightweight following the design principle of modern lightweight network architecture and still generalizes well on unseen classes. In addition, we also demonstrate our model�s capabilities by comparing the numbers of parameters, FLOPS, and model performance with other state-of-the-art methods.","Meta-learning, Metric loss, Fast learning, Face anti-spoofing, DeepFake",ScienceDirect
101,"Deepfacelab: Integrated, flexible and extensible face-swapping framework",Kunlin Liu and Ivan Perov and Daiheng Gao and Nikolay Chervoniy and Wenbo Zhou and Weiming Zhang,2023,"Face swapping has drawn a lot of attention for its compelling performance. However, current deepfake methods suffer the effects of obscure workflow and poor performance. To solve these problems, we present DeepFaceLab, the current dominant deepfake framework for practical face-swapping. It provides the necessary tools as well as an easy-to-use way to conduct high-quality face-swapping. It also offers a flexible and loose coupling structure for people who need to strengthen their pipeline with other features without writing complicated boilerplate code. We detail the principles that drive the implementation of DeepFaceLab and introduce its pipeline. DeepFaceLab could achieve cinema-level results with high fidelity as our supplemental video shows. We also demonstrate the advantage of our system by comparing our approach with other face-swapping methods. Deepfake defense not only requires the research of detection but also requires the efforts of generation methods. As for a popular and practical toolkit, we encourage users to promote harmless deepfake-entertainment content on social media, reminding the public of the existence of deepfake when they are looking for entertainment.","Face swapping, Practical machine learning, Open source",ScienceDirect
102,Video Deepfake classification using particle swarm optimization-based evolving ensemble models,Li Zhang and Dezong Zhao and Chee Peng Lim and Houshyar Asadi and Haoqian Huang and Yonghong Yu and Rong Gao,2024,"The recent breakthrough of deep learning based generative models has led to the escalated generation of photo-realistic synthetic videos with significant visual quality. Automated reliable detection of such forged videos requires the extraction of fine-grained discriminative spatial-temporal cues. To tackle such challenges, we propose weighted and evolving ensemble models comprising 3D Convolutional Neural Networks (CNNs) and CNN-Recurrent Neural Networks (RNNs) with Particle Swarm Optimization (PSO) based network topology and hyper-parameter optimization for video authenticity classification. A new PSO algorithm is proposed, which embeds Muller's method and fixed-point iteration based leader enhancement, reinforcement learning-based optimal search action selection, a petal spiral simulated search mechanism, and cross-breed elite signal generation based on adaptive geometric surfaces. The PSO variant optimizes the RNN topologies in CNN-RNN, as well as key learning configurations of 3D CNNs, with the attempt to extract effective discriminative spatial-temporal cues. Both weighted and evolving ensemble strategies are used for ensemble formulation with aforementioned optimized networks as base classifiers. In particular, the proposed PSO algorithm is used to identify optimal subsets of optimized base networks for dynamic ensemble generation to balance between ensemble complexity and performance. Evaluated using several well-known synthetic video datasets, our approach outperforms existing studies and various ensemble models devised by other search methods with statistical significance for video authenticity classification. The proposed PSO model also illustrates statistical superiority over a number of search methods for solving optimization problems pertaining to a variety of artificial landscapes with diverse geometrical layouts.","Video deepfake classification, Hybrid deep neural network, 3d convolutional neural network, Evolutionary algorithm, Evolving ensemble classifier",ScienceDirect
103,Deepfake noise investigation and detection,Tianyi Wang and Ming Liu and Wei Cao and Kam Pui Chow,2022,"The fast development of Deepfake has brought huge current and potential future negative impacts to our daily lives. As the circulating popular Deepfake videos have become difficult to be distinguished by human eyes, various Deepfake detection approaches have been attempted using deep learning models. However, even though some existing detection methods have achieved reasonable detection performance with respect to the statistical evaluation metrics, the actual underlying Deepfake forensic traces have been barely discussed. In this study, we investigate the special forensic noise traces within Deepfake image frames and propose a noise-based Deepfake detection model approach using a deep neural network. We train a Siamese noise extractor using a novel face-background strategy to investigate different forensic noise traces of a synthesized face area and an unmodified background area. A similarity matrix module is proposed to analyze the forensic noise trace difference between a cropped face square and a cropped background square from a candidate image frame for the Deepfake detection task. As a result, our proposed model trained on the high-quality Celeb-DF dataset has achieved state-of-the-art performance with 99.15% accuracy and 99.92% AUC score on the in-dataset testing set and 88.95% AUC score on the highly difficult unknown-attack Deepfake video dataset. Furthermore, the visualization of the Deepfake forensic noise traces has shown the explicit distinction between synthesized faces and any unmodified area. We believe that the visualized evidence could provide better proof of Deepfake detection results rather than simply the statistical evaluation numbers.","Deepfake detection, Digital image forensics, Noise trace extraction and investigation, Siamese network",ScienceDirect
104,Feature fusion Vision Transformers using MLP-Mixer for enhanced deepfake detection,Ehab Essa,2024,"Deepfake technology, utilizing deep learning and computer vision, presents significant security threats by generating highly realistic synthetic media, such as images and videos. In this paper, we propose a feature fusion-based method for deepfake detection, harnessing the capabilities of three Vision Transformer (ViT) architectures: Dual Attention Vision Transformers (DaViT), Inception Transformer (iFormer), and Group Propagation Vision Transformer (GPViT). The proposed feature fusion method integrates the local�global contextual understanding of DaViT, the frequency spectrum broadening of iFormer, and the high-resolution feature retention of GPViT to provide a comprehensive analysis of visual data, crucial for detecting subtle manipulations typical in deepfakes. An MLP-Mixer (Multi-Layer Perceptron-Mixer) model is proposed for the feature fusion process for effective feature integration, enhancing the detection capabilities while preserving the individual strengths of each ViT model. The performance of the proposed method is evaluated using standard datasets, namely FaceForensics++ and Celeb-DF, demonstrating its robustness and generalizability across various scenarios. For the four manipulation techniques in the FaceForensics++ dataset, namely DeepFakes (DF), Face2Face (F2F), FaceSwap (FS), and NeuralTextures (NT), the proposed method achieves area under the curve (AUC) of 99.75%, 97.04%, 98.78%, and 87.49% respectively, Moreover, it demonstrates an AUC of 99.84% on the Celeb-DF dataset. The performance of the proposed model has been evaluated against many state-of-the-art methods to ensure its robustness and generalization capabilities.","Deepfake detection, Vision Transformer, Feature fusion, MLP-Mixer",ScienceDirect
105,Machine learning based medical image deepfake detection: A comparative study,Siddharth Solaiyappan and Yuxin Wen,2022,"Deep generative networks in recent years have reinforced the need for caution while consuming various modalities of digital information. One avenue of deepfake creation is aligned with injection and removal of tumors from medical scans. Failure to detect medical deepfakes can lead to large setbacks on hospital resources or even loss of life. This paper attempts to address the detection of such attacks with a structured case study. Specifically, we evaluate eight different machine learning algorithms, which include three conventional machine learning methods (Support Vector Machine, Random Forest, Decision Tree) and five deep learning models (DenseNet121, DenseNet201, ResNet50, ResNet101, VGG19) in distinguishing between tampered and untampered images. For deep learning models, the five models are used for feature extraction, then each pre-trained model is fine-tuned. The findings of this work show near perfect accuracy in detecting instances of tumor injections and removals.","Computed tomography, Generative adversarial networks, Deepfake detection, DICOM, Tampered images, Machine learning",ScienceDirect
106,LBPNet: Exploiting texture descriptor for deepfake detection,Staffy Kingra and Naveen Aggarwal and Nirmal Kaur,2022,"Recent AI advancements made it significantly easier to generate high-quality synthesized faces, referred as deepfakes. It can make people saying and doing things that never happened actually. Owing to the vast usage of social media, manipulated content is susceptible to spread unrest in the society. With the continuous evolvement of AI-enabled deepfake generators, the research on deepake detection has started progressing in the last few years. From analyzing eye-blinking in the previous generation deepfakes to deep learning based models for advanced deepfakes, the existing deepfake detectors have analyzed numerous artefacts. This paper proposes a novel detection approach, LBPNet, to distinguish deepfaked faces from genuine ones by means of exploiting inconsistencies in texture information. In particular, Local Binary Pattern (LBP) of deepfaked and pristine faces have been investigated through a CNN based model. Moreover, the proposed LBPNet technique is evaluated on more advanced and diverse deepfaked datasets such as Celeb-DF, DFDC, and DeeperForensics, which provided a detection accuracy of 92.38%, 80% and 86% respectively. Comprehensive analysis on different benchmark datasets and comparison with state-of-art endorse the superior performance of the proposed method. Thorough experimentations also reveal the robustness of LBPNet against different compression levels and tampering types.","Local Binary Pattern, Deepfake, LBP, Face swap, Texture, Deep network",ScienceDirect
107,Deepfake forensics analysis: An explainable hierarchical ensemble of weakly supervised models,Samuel Henrique Silva and Mazal Bethany and Alexis Megan Votto and Ian Henry Scarff and Nicole Beebe and Peyman Najafirad,2022,"Deepfakes have become exponentially more common and sophisticated in recent years, so much so that forensic specialists, policy makers, and the public alike are anxious about their role in spreading disinformation. Recently, the detection and creation of such forgery became a popular research topic, leading to significant growth in publications related to the creation of deepfakes, detection methods, and datasets containing the latest deepfake creation methods. The most successful approaches in identifying and preventing deepfakes are deep learning methods that rely on convolutional neural networks as the backbone for a binary classification task. A convolutional neural network extracts the underlying patterns from the input frames. It feeds these to a binary classification fully connected network, which classifies these patterns as trustworthy or untrustworthy. We claim that this method is not ideal in a scenario in which the generation algorithms constantly evolve since the detection algorithm is not robust enough to detect comparably minor artifacts introduced by the generation algorithms. This work proposes a hierarchical explainable forensics algorithm that incorporates humans in the detection loop. We curate the data through a deep learning detection algorithm and share an explainable decision to humans alongside a set of forensic analyses on the decision region. On the detection side, we propose an attention-based explainable deepfake detection algorithm. We address this generalization issue by implementing an ensemble of standard and attention-based data-augmented detection networks. We use the attention blocks to evaluate the face regions where the model focuses its decision. We simultaneously drop and enlarge the region to push the model to base its decision on more regions of the face, while maintaining a specific focal point for its decision. In this case, we use an ensemble of models to improve the generalization. We also evaluate the models� decision using Grad-CAM explanation to focus on the attention maps. The region uncovered by the explanation layer is cropped and undergoes a series of frequency and statistical analyses that help humans decide if the frame is real or fake. We evaluate our model in one of the most challenging datasets, the DFDC, and achieve an accuracy of 92.4%. We successfully maintain this accuracy in datasets not used in the training process.","Deepfake, Forensics, Deep learning, Facial recognition",ScienceDirect
108,"A Secure Deepfake Mitigation Framework: Architecture, Issues, Challenges, and Societal Impact",Mohammad Wazid and Amit Kumar Mishra and Noor Mohd and Ashok Kumar Das,2024,"Deepfake refers to synthetic media generated through artificial intelligence (AI) techniques. It involves creating or altering video, audio, or images to make them appear as though they depict something or someone else. Deepfake technology advances just like the mechanisms that are used to detect them. There�s an ongoing cat-and-mouse game between creators of deepfakes and those developing detection methods. As the technology that underpins deepfakes continues to improve, we are obligated to confront the repercussions that it will have on society. The introduction of educational initiatives, regulatory frameworks, technical solutions, and ethical concerns are all potential avenues via which this matter can be addressed. Multiple approaches need to be combined to identify deepfakes effectively. Detecting deepfakes can be challenging due to their increasingly sophisticated nature, but several methods and techniques are being developed to identify them. Mitigating the negative impact of deepfakes involves a combination of technological advancements, awareness, and policy measures. In this paper, we propose a secure deepfake mitigation framework. We have also provided a security analysis of the proposed framework via the Scyhter tool-based formal security verification. It proves that the proposed framework is secure against various cyber attacks. We also discuss the societal impact of deepfake events along with its detection process. Then some AI models, which are used for creating and detecting the deepfake events, are highlighted. Ultimately, we provide the practical implementation of the proposed framework to observe its functioning in a real-world scenario.","Deepfake, Artificial Intelligence (AI), Machine learning, Cyber security, Authentication",ScienceDirect
109,Artificial rabbits optimization with transfer learning based deepfake detection model for biometric applications,Sana Alazwari and Marwa Obayya {Jamal Alsamri} and Mohammad Alamgeer and Rana Alabdan and Ibrahim Alzahrani and Mohammed Rizwanullah and Azza {Elneil Osman},2024,"Deepfake detection is a significant area of research in biometric applications, as it is essential to ensure the integrity and authenticity of biometric information. Biometric data, including fingerprint recognition, facial recognition, and voice recognition, are used extensively for identification and authentication, which makes it crucial to prevent and detect deepfake attacks. Deepfake is a manipulated digital media, for example, a video or image of a person can be replaced with a similarity of another person. A crucial way to deepfake detection in biometric applications is to use a machine learning (ML) algorithm, particularly deep learning (DL), that could learn to distinguish between fake and real biometric information. Hence, the study proposes an Artificial Rabbits Optimization with Transfer Learning Deepfake Detection for Biometric Applications (AROTL-DFDBA) technique. The AROTL-DFDBA technique intends to detect fake and original biometric data using the DL model. In the presented AROTL-DFDBA technique, modified DarkNet-53 model for the feature extraction process. Besides, the ARO method was applied for the optimum hyperparameter selection of the modified DarkNet-53 model. For deepfake detection, the Weighted Regularized Extreme Learning Machine (WR-ELM) technique is applied. The simulation outcomes of the AROTL-DFDBA method can be validated on the DeepFake dataset. The extensive simulation results signify better detection outcomes of the AROTL-DFDBA technique over other existing techniques with a maximum accuracy of 96.48%.","Biometric applications, Computer vision, Deep fake detection, Deep learning, Artificial rabbits optimizer",ScienceDirect
110,Magnifying multimodal forgery clues for Deepfake detection,Xiaolong Liu and Yang Yu and Xiaolong Li and Yao Zhao,2023,"Advancements in computer vision and deep learning have led to difficulty in distinguishing the generated Deepfake media. In addition, recent forgery techniques also modify the audio information based on the forged video, which brings new challenges. However, due to the cross-modal bias, recent multimodal detection methods do not well explore the intra-modal and cross-modal forgery clues, which leads to limited detection performance. In this paper, we propose a novel audio-visual aware multimodal Deepfake detection framework to magnify intra-modal and cross-modal forgery clues. Firstly, to capture temporal intra-modal defects, Forgery Clues Magnification Transformer (FCMT) module is proposed to magnify forgery clues based on sequence-level relationships. Then, the Distribution Difference based Inconsistency Computing (DDIC) module based on Jensen�Shannon divergence is designed to adaptively align multimodal information for further magnifying the cross-modal inconsistency. Next, we further explore spatial artifacts by connecting multi-scale feature representation to provide comprehensive information. Finally, a feature fusion module is designed to adaptively fuse features to generate a more discriminative feature. Experiments demonstrate that the proposed framework outperforms independently trained models, and at the same time, yields superior generalization capability on unseen types of Deepfake.","Deepfake forgery detection, Multimodal clues magnification, Cross-modal inconsistency, Multi-scale representation",ScienceDirect
111,Dynamic face authentication systems: Deep learning verification for camera close-Up and head rotation paradigms,Alejandra Castelblanco and Esteban Rivera and Jes�s Solano and Lizzy Tengana and Christian L�pez and Mart�n Ochoa,2022,"The popularity of face-authentication systems has also generated interest in the study of malicious authentication attempts, such as face spoofing attacks. In this study we investigate two dynamic face-authentication challenges: the camera close-up, and head-rotation paradigms. For each paradigm we developed an ML-based face-authentication system that performs the tasks of liveness detection and face verification. In order to generate structured data-representations from the videos collected in the wild, we designed feature representations that extract three-dimensional and spatial characteristics of a face, while also capturing the particular liveness cues of the requested challenge-based movements. Furthermore, a set of Neural-Network models that employ Convolutional Neural Networks and Siamese Neural Network architectures were proposed. To train and test our models we collected a dataset of 177 live videos recorded by 41 different subjects and a set of 243 attack attempts in uncontrolled scenarios. The resulting NN models yield good performance against multiple types of media-based attacks (printed-attacks, screen-attacks, 2D-masks, videos acquired from public social media, deep fakes). The camera close-up system presented an overall liveness detection accuracy of 97.7% and a face verification accuracy of 97.6%. On the other hand, the evaluation of the head-rotation system resulted in a liveness detection accuracy of 92.4% and face verification accuracy of 98.1%. Face authentication methods based on dynamic user-challenges constitute a scalable approach that does not require specialized hardware to increase the security of face authentication systems in realistic usage scenarios. The proposed methods not only make it harder for attackers to generate spoofing attacks, but they also constitute a practical complement to static biometric authentication systems.","Liveness detection, Face verification, Face authentication, Face spoofing detection, Neural networks",ScienceDirect
112,Preserving manipulated and synthetic Deepfake detection through face texture naturalness,Chit-Jie Chew and Yu-Cheng Lin and Ying-Chin Chen and Yun-Yi Fan and Jung-San Lee,2024,"With the rapid development of deep learning and face recognition technology, AI(Artificial Intelligence) experts have rated Deepfake cheating as the top AI threat. It is difficult for the human eye to distinguish the fake face images generated by Deepfake. Therefore, it has become a popular tool for criminals to seek benefits. Deepfake can be mainly divided into two types, a manipulated Deepfake that falsifies images of others by targeting real faces, and a synthetic Deepfake using GAN to generate a new fake image. So far, seldom cybersecurity system is able to detect these two types simultaneously. In this article, we aim to propose a hybrid Deepfake detection mechanism (HDDM) based on face texture and naturalness degree. HDDM constructs a unique texture from a facial image based on CNN(Convolutional Neural Network) and builds a naturalness degree recognition model via DNN(Deep Neural Network) to help cheating detection. Experimental results have proved that HDDM possesses a sound effect and stability for synthetic and manipulated Deepfake attacks. In particular, the WildDeepfake simulation has demonstrated the possibility of applying HDDM to the real world.","Facial texture, Naturalness, Deepfake, DNN",ScienceDirect
113,Governing ghostbots,Edina Harbinja and Lilian Edwards and Marisa McVey,2023,"This article discusses the legal implications of a novel phenomenon, namely, digital reincarnations of deceased persons, sometimes known as post-mortem avatars, deepfakes, replicas, holographs, or chatbots. To elide these multiple names, we use the term 'ghostbots'. The piece is an early attempt to discuss the potential social and individual harms, roughly grouped around notions of privacy (including post-mortem privacy), property, personal data and reputation, arising from ghostbots, how they are regulated and whether they need to be adequately regulated further. For reasons of space and focus, the article does not deal with copyright implications, fraud, consumer protection, tort, product liability, and pornography laws, including the non-consensual use of intimate images (�revenge porn�). This paper focuses on law, although we fully acknowledge and refer to the role of philosophy and ethics in this domain. We canvas two interesting legal developments with implications for ghostbots, namely, the proposed EU Artificial Intelligence (AI) Act and the 2021 New York law amending publicity rights to protect the rights of celebrities whose personality is used in post-mortem �replicas�. The latter especially evidences a remarkable shift from the norm we have chronicled in previous articles of no respect for post-mortem privacy to a growing recognition that personality rights do need protection post-mortem in a world where pop stars and actors are routinely re-created using AI. While the legislative motivation here may still be primarily to protect economic interests, we argue it also shows a concern for dignitary and privacy interests. Given the apparent concern for the appropriation of personality post-mortem, possibly in defiance or ignorance of what the deceased would have wished, we propose an early solution to regulate the rise of ghostbots, namely an enforceable �do not bot me� clause in analogue or digital wills.","Ghostbots, Deepfakes, Post-mortem privacy, Digital legacy, Digital remains",ScienceDirect
114,A deep learning model for FaceSwap and face-reenactment deepfakes detection,Marriam Nawaz and Ali Javed and Aun Irtaza,2024,"Recently, the higher availability of multimedia content on social websites, together with lightweight deep learning (DL) empowered tools like Generative Adversarial Networks (GANs) has caused the generation of realistic deepfakes. Such fabricated data has the potential to spread disinformation, revenge porn, initiate monetary scams, and can result in adverse immoral and illegal societal issues, etc. Hence, the accurate identification of deepfakes is mandatory to discriminate between real and manipulated content. In this work, we have presented a DL-based approach namely a unified network for FaceSwap (FS) and Face-Reenactment (FR) Deepfakes Detection (AUFF-Net). More clearly, both the spatial and temporal information from the video samples are used to detect two types of visual manipulations i.e., FS and FR. For this reason, a novel DL framework namely the Inception-Swish-ResNet-v2 model is introduced as a feature extractor for computing the information at the spatial level. While the Bi-LSTM model is utilized to measure the temporal information. Additionally, 3 dense layers are included at the last of the model structure to suggest a discriminative group of the feature vector We performed extensive experimentation on a challenging dataset namely the FaceForensic++, and attainede average accuracy values of 99.21?%, and 98.32?% for FS, or FR, respectively. Furthermore, we introduced an explainability module to show the reliable keypoints selection capability of our technique. Moreover, we have performed a cross-dataset evaluation to show the generalization power of our approach. Both the qualitative and quantitative results have confirmed the effectiveness of the suggested approach for visual manipulation categorization under the occurrence of various adversarial attacks.","Deep learning, Deepfakes, FaceSwap, Face-reenactment, Inception-swish-Resnet-v2, Bi-LSTM",ScienceDirect
115,A multi-label classification method based on transformer for deepfake detection,Liwei Deng and Yunlong Zhu and Dexu Zhao and Fei Chen,2024,"With the continuous development of hardware and deep learning technologies, existing forgery techniques are capable of more refined facial manipulations, making detection tasks increasingly challenging. Therefore, forgery detection cannot be viewed merely as a traditional binary classification task. To achieve finer forgery detection, we propose a method based on multi-label detection classification capable of identifying the presence of forgery in multiple facial components. Initially, the dataset undergoes preprocessing to meet the requirements of this task. Subsequently, we introduce a Detail-Enhancing Attention Module into the network to amplify subtle forgery traces in shallow feature maps and enhance the network's feature extraction capabilities. Additionally, we employ a Global�Local Transformer Decoder to improve the network's ability to focus on local information. Finally, extensive experiments demonstrate that our approach achieves 92.45% mAP and 90.23% mAUC, enabling precise detection of facial components in images, thus validating the effectiveness of our proposed method.","Deepfake detection, Multi-label classification, Transformer",ScienceDirect
116,Compressed Deepfake Detection using Spatio-Temporal Approach with Model Pruning,Vidya K and Praveen Ramesh and Hrithik Viknesh and Sanjay Devanand,2023,"Deepfake is a deep learning�technology that replaces source person face photos with the�target person face photos in a movie to create a video of the target by�executing the�actions performed by source person. Due to the�limited storage capacity and network bandwidth constraints, compressed media is now commonly employed in social networks. The goal of this research study�is to determine whether or not a given compressed video is a deepfake. To do this, both the spatial and temporal components of the video should be considered, and the findings will be integrated by�using an appropriate fusion approach. Hence, the deep learning model used in the spatial approach is pruned using the Network Pruning technique to achieve a better performance. The combined prediction of the spatial and temporal approaches indicates whether the given video is deepfake or not.","Compressed, Fusion, Pruning, Spatio-Temporal features",ScienceDirect
117,Texture and artifact decomposition for improving generalization in deep-learning-based deepfake detection,Jie Gao and Marco Micheletto and Giulia Orr� and Sara Concas and Xiaoyi Feng and Gian Luca Marcialis and Fabio Roli,2024,"The harmful utilization of DeepFake technology poses a significant threat to public welfare, precipitating a crisis in public opinion. Existing detection methodologies, predominantly relying on convolutional neural networks and deep learning paradigms, focus on achieving high in-domain recognition accuracy amidst many forgery techniques. However, overseeing the intricate interplay between textures and artifacts results in compromised performance across diverse forgery scenarios. This paper introduces a groundbreaking framework, denoted as Texture and Artifact Detector (TAD), to mitigate the challenge posed by the limited generalization ability stemming from the mutual neglect of textures and artifacts. Specifically, our approach delves into the similarities among disparate forged datasets, discerning synthetic content based on the consistency of textures and the presence of artifacts. Furthermore, we use a model ensemble learning strategy to judiciously aggregate texture disparities and artifact patterns inherent in various forgery types, thereby enabling the model�s generalization ability. Our comprehensive experimental analysis, encompassing extensive intra-dataset and cross-dataset validations along with evaluations on both video sequences and individual frames, confirms the effectiveness of TAD. The results from four benchmark datasets highlight the significant impact of the synergistic consideration of texture and artifact information, leading to a marked improvement in detection capabilities.","DeepFake detection, Generalization, Texture, Artifact, Ensemble learning strategy",ScienceDirect
118,Customized Convolutional Neural Network for Accurate Detection of Deep Fake Images in Video Collections,Dmitry Gura and Bo Dong and Duaa Mehiar and Nidal Al Said,2024,"The motivation for this study is that the quality of deep fakes is constantly improving, which leads to the need to develop new methods for their detection. The proposed Customized Convolutional Neural Network method involves extracting structured data from video frames using facial landmark detection, which is then used as input to the CNN. The customized Convolutional Neural Network method is the date augmented-based CNN model to generate �fake data� or �fake images�. This study was carried out using Python and its libraries. We used 242 films from the dataset gathered by the Deep Fake Detection Challenge, of which 199 were made up and the remaining 53 were real. Ten seconds were allotted for each video. There were 318 videos used in all, 199 of which were fake and 119 of which were real. Our proposed method achieved a testing accuracy of 91.47%, loss of 0.342, and AUC score of 0.92, outperforming two alternative approaches, CNN and MLP-CNN. Furthermore, our method succeeded in greater accuracy than contemporary models such as XceptionNet, Meso-4, EfficientNet-BO, MesoInception-4, VGG-16, and DST-Net. The novelty of this investigation is the development of a new Convolutional Neural Network (CNN) learning model that can accurately detect deep fake face photos.","Deep fake detection video analysis, convolutional neural network, machine learning, video dataset collection, facial landmark prediction, accuracy, models",ScienceDirect
119,A dual descriptor combined with frequency domain reconstruction learning for face forgery detection in deepfake videos,Xin Jin and Nan Wu and Qian Jiang and Yuru Kou and Hanxian Duan and Puming Wang and Shaowen Yao,2024,"Conventional face forgery detectors have primarily relied on image artifacts produced by deepfake video generation models. These methods have performed well when the training and test sets were derived from the same deepfake algorithm, but accuracy and generalizability remain a challenge for diverse datasets. In this study, both supervised and unsupervised approaches are proposed for more accurate detection in in-domain and cross-domain experiments. Specifically, two descriptors are introduced to extract rich information in the spatial domain to achieve higher accuracy. A frequency domain reconstruction module is then included to expand the representation space for facial features. A reconstruction method based on an auto-encoder was also applied to obtain a frequency domain coding vector. In this process, reconstruction learning was sufficient for extracting unknown information, while a combination with classification learning provided essential high-frequency pixel differences between real and fake samples, thus facilitating forgery identification. A series of validation experiments with large-scale benchmark datasets demonstrated that the proposed technique was superior to existing methods.","Deepfake detection, Digital forensics, Frequency domain analysis, Deep learning, Auto encoder, Video forgery",ScienceDirect
120,JRC: Deepfake detection via joint reconstruction and classification,Bosheng Yan and Chang-Tsun Li and Xuequan Lu,2024,"Deep learning has enabled realistic face manipulation for malicious purposes (e.g., deepfakes), which poses significant concerns over the integrity of the media in circulation. Most existing deep learning techniques for deepfake detection can achieve promising performance in the intra-dataset evaluation setting, but are unable to perform satisfactorily in the inter-dataset evaluation setting. Most previous methods use a backbone network to extract global features for making predictions and only employ binary supervision to train the network. Classification merely based on the learning of global features often leads to weak generalizability to deepfakes of unseen manipulation methods. In this paper, we design a two-branch Convolutional AutoEncoder (CAE), which considers the reconstruction and classification tasks simultaneously for deepfake detection. This Joint Reconstruction and Classification (JRC) method shares the information learned by one task with the other, each focusing on different aspects, and hence boosts the overall performance. JRC is end-to-end, and experiments demonstrate that it achieves state-of-the-art performance on three commonly-used datasets, particularly in the cross-dataset evaluation setting.","Deepfake detection, Unsupervised reconstruction, Joint supervision",ScienceDirect
121,Complementary regional energy features for spoofed speech detection,G�kay Di?ken,2024,"Automatic speaker verification systems are found to be vulnerable to spoof attacks such as voice conversion, text-to-speech, and replayed speech. As the security of biometric systems is vital, many countermeasures have been developed for spoofed speech detection. To satisfy the recent developments on speech synthesis, publicly available datasets became more and more challenging (e.g., ASVspoof 2019 and 2021 datasets). A variety of replay attack configurations were also considered in those datasets, as they do not require expertise, hence easily performed. This work utilizes regional energy features, which are experimentally proven to be more effective than the traditional frame-based energy features. The proposed energy features are independent from the utterance length and are extracted over nonoverlapping time-frequency regions of the magnitude spectrum. Different configurations are considered in the experiments to verify the regional energy features� contribution to the performance. First, light convolutional neural network � long short-term memory (LCNN � LSTM) model with linear frequency cepstral coefficients is used to determine the optimal number of regional energy features. Then, SE-Res2Net model with log power spectrogram features is used, which achieved comparable results to the state-of-the-art for ASVspoof 2019 logical access condition. Physical access condition from ASVspoof 2019 dataset, logical access and deep fake conditions from ASVspoof 2021 dataset are also used in the experiments. The regional energy features achieved improvements for all conditions with almost no additional computational or memory loads (less than 1% increase in the model size for SE-Res2Net). The main advantages of the regional energy features can be summarized as i) capturing nonspeech segments, ii) extracting band-limited information. Both aspects are found to be discriminative for spoofed speech detection.","Energy features, Feature extraction, Replay speech detection, Synthetic speech detection, Deep learning",ScienceDirect
122,Deepfake detection using deep feature stacking and meta-learning,Gourab Naskar and Sk Mohiuddin and Samir Malakar and Erik Cuevas and Ram Sarkar,2024,"Deepfake is a type of face manipulation technique using deep learning that allows for the replacement of faces in videos in a very realistic way. While this technology has many practical uses, if used maliciously, it can have a significant number of bad impacts on society, such as spreading fake news or cyberbullying. Therefore, the ability to detect deepfake has become a pressing need. This paper aims to address the problem of deepfake detection by identifying deepfake forgeries in video sequences. In this paper, a solution to the said problem is presented, which at first uses a stacking based ensemble approach, where features obtained from two popular deep learning models, namely Xception and EfficientNet-B7, are combined. Then by selecting a near-optimal subset of features using a ranking based approach, the final classification is performed to classify real and fake videos using a meta-learner, called multi-layer perceptron. In our experimentation, we have achieved an accuracy of 96.33% on Celeb-DF (V2) dataset and 98.00% on the FaceForensics++ dataset using the meta-learning model both of which are higher than the individual base models. Various types of experiments have been conducted to validate the robustness of the current method.","Deepfake, Stacking based ensemble, Deep learning, Feature selection, Meta-learning",ScienceDirect
123,Counter-act against GAN-based attacks: A collaborative learning approach for anti-forensic detection,Kutub Uddin and Tae Hyun Jeong and Byung Tae Oh,2024,"The massive success of deep learning allows us to forge images in more perfect manners for ethical and even unethical purposes. Several forensic methods have been proposed to expose artifacts in fake images. However, the practice of anti-forensics (AF), particularly deep learning-based AF on digital images, has made such forgeries difficult to detect. Therefore, a counter-AF (CAF) algorithm is necessary to reveal AF traces and ensure the authenticity of image content. In this study, we propose a novel data-driven approach to counteract generative adversarial network (GAN)-based AF attacks. We consider different forgery techniques, such as noise addition, filtering, and deepfake generation to generate fake images. Subsequently, GAN-based AF attacks were applied to conceal the forgery fingerprints such that they can deceive forensic methods. We built a new CAF method that allows collaborative learning to detect GAN-based AF attacks. We designed a novel CAF-GAN model by considering the commonly used GAN architectures. The proposed CAF-GAN model generates a new image from the input image, which helps collaborative learning to detect AF images. GAN-based AF attacks can effectively hide forgery fingerprints and significantly reduce the performance of forensic methods. However, the proposed CAF method can effectively detect AF images in match and mismatch scenarios of AF and CAF-GAN models.","Image forensic, Anti-forensic, GAN-based attacks, Counter-anti-forensic, Deep learning, And metric learning",ScienceDirect
124,DF-UDetector: An effective method towards robust deepfake detection via feature restoration,Jianpeng Ke and Lina Wang,2023,"The abuse of deepfakes, a rising face swap technique, causes severe concerns about the authenticity of visual content and the dissemination of misinformation. To alleviate the threats imposed by deepfakes, a vast body of data-centric detectors has been deployed. However, the performance of these methods can be easily defected by degradations on deepfakes. To improve the performance of degradation deepfake detection, we creatively explore the recovery method in the feature space to preserve the artifacts for detection instead of directly in the image domain. In this paper, we propose a method, namely DF-UDetector, against degradation deepfakes by modeling the degraded images and transforming the extracted features to a high-quality level. To be specific, the whole model consists of three key components: an image feature extractor to capture image features, a feature transforming module to map the degradation features into a higher quality, and a discriminator to determine whether the feature map is of high quality enough. Extensive experiments on multiple video datasets show that our proposed model performs comparably or even better than state-of-the-art counterparts. Moreover, DF-UDetector outperforms by a small margin when detecting deepfakes in the wild.","Degradation deepfake detection, Feature space manipulation, Deep neural networks, Face manipulation, Deep learning, Deepfakes",ScienceDirect
125,Acoustic features analysis for explainable machine learning-based audio spoofing detection,Carmen Bisogni and Vincenzo Loia and Michele Nappi and Chiara Pero,2024,"The rapid evolution of synthetic voice generation and audio manipulation technologies poses significant challenges, raising societal and security concerns due to the risks of impersonation and the proliferation of audio deepfakes. This study introduces a lightweight machine learning (ML)-based framework designed to effectively distinguish between genuine and spoofed audio recordings. Departing from conventional deep learning (DL) approaches, which mainly rely on image-based spectrogram features or learning-based audio features, the proposed method utilizes a diverse set of hand-crafted audio features � such as spectral, temporal, chroma, and frequency-domain features � to enhance the accuracy of deepfake audio content detection. Through extensive evaluation and experiments on three well-known datasets, ASVSpoof2019, FakeAVCelebV2, and an In-The-Wild database, the proposed solution demonstrates robust performance and a high degree of generalization compared to state-of-the-art methods. In particular, our method achieved 89% accuracy on ASVSpoof2019, 94.5% on FakeAVCelebV2, and 94.67% on the In-The-Wild database. Additionally, the experiments performed on explainability techniques clarify the decision-making processes within ML models, enhancing transparency and identifying crucial features essential for audio deepfake detection.","Deepfake audio, Deepfake detection, Audio spoofing, Explainable AI, Acoustic features",ScienceDirect
126,Deepfake forensics: Cross-manipulation robustness of feedforward- and recurrent convolutional forgery detection methods,Frederic Chamot and Zeno Geradts and Evert Haasdijk,2022,"Recently, deep-learning based video-manipulation techniques, so-called deepfakes, have gained a lot of traction in popular media. Deepfakes are predominantly used to photo-realistically alter the identity of actors recorded on video, and misuse of this new technology has the potential to harm individuals, companies, or to inflict damage in a societal context. The accelerated pace, at which deepfake technology is improved, challenges contemporary research to provide the urgently required detection methods. A major obstacle to reliable deepfake detection in the field is the impaired generalizability across specific instances of deepfake models, i.e. detection performance of previously not encountered manipulation models. The present work aims to establish a better understanding of the critical factors that guide cross-manipulation detection performance. Recent studies have indicated that the properties of video-based modeling may be leveraged to enhance the detection of unknown deepfake manipulations. Therefore, we compare multiple image- and video-based detection models and evaluate their performance on instances both generated by known, and unknown manipulation models. Furthermore we attempt to replicate research that successfully improved cross-manipulation detection by using image-perturbation methods to degrade training data. Using multiple data-sources to emulate in- and out-sample detection performance, we demonstrate that none of the two model types show universally superior performance. Also, our results confirm that cross-manipulation evaluation results in problematic detection accuracy for all models, regardless of whether we apply image-perturbation techniques during training. Additionally, the detection performance on a set of manually selected, high-quality deepfake videos indicates that the current state-of-the-art detection models are not yet fully equipped for real-world applications.","Deepfake detection, Computer vision, Image perturbations, Recurrent convolutional networks",ScienceDirect
127,Learning Spatio-temporal features to detect manipulated facial videos created by the Deepfake techniques,Xuan Hau Nguyen and Thai Son Tran and Van Thinh Le and Kim Duy Nguyen and Dinh-Tu Truong,2021,"In the last years, the face synthetic video generation has been rapid, and hyper-realistic forged videos are based on Deepfake techniques. It leads to a loss of trust in videos' content and makes it malicious by spreading forged videos on the internet. Until now, there are a few algorithms that have been suggested for detecting forged videos created by Deepfake techniques, but most of them based on analyzing or learning features on frames separately in a video. Those algorithms often pay less attention to Spatio-temporal features, so these algorithms' accuracy is usually not good. This paper proposes a 3-dimensional (3-D) convolutional neural network model that can learn Spatio-temporal features from an adjacent frame sequence in a video. Our proposed network's binary detection accuracy reached over 99% on the two largest benchmark datasets as Deepfake of FaceForensics++ and VidTIMIT datasets. The experimental results of the proposed method outperform state-of-the-art methods.","Video forensic, Deepfake video detection, Autoencoder-decoder, Generative adversarial networks, Deep learning, 3-D convolutional neural network",ScienceDirect
128,GAN-CNN Ensemble: A Robust Deepfake Detection Model of Social Media Images Using Minimized Catastrophic Forgetting and Generative Replay Technique,Preeti Sharma and Manoj Kumar and Hitesh Kumar Sharma,2024,"Deep-fake photographs are difficult to discern from real ones, especially when utilized in social media platforms. Anyone can willfully create disinformation about public personalities, politicians, and celebrities using these deep fake photographs. So, it is an important need of society to work for an effective model for its detection. The models for deep fake detection commonly use CNN-based detectors. These detectors experience a drop in performance when used for transfer learning or continual learning techniques. A significant limitation in this process is CNN's catastrophe forgetting defect. For the solution of this problem, a Generative replay technique in the form of a GAN-CNN model is implemented that works to minimize this catastrophe forgetting issue that further helps for better detection. It involves generating and storing samples from previous tasks and then replaying them during the training of new tasks which makes CNN more robust to identify deep fakes. The GAN model used in this work is traditional DCGAN improved with necessary adjustments to achieve training stability. It is observed that the model attained a good accuracy of 98.67%(training),70.08% (testing) and minimum loss with a value of 0. 0337 for 100 epochs. Also, it acquired good precision values of 68% and 72%, Recall values are 74% and 66%, and F1 scores of 71% and 69% for classes 0 and 1 respectively. The model outcome is found stable and reliable in deep fake detection under dynamic training conditions. Optimum values of evaluation parameters ensure the model's capacity to learn new tasks preserving the existing task-learning knowledge.","Deep Learning, CNN;GAN;Catastrophe forgetting;CNN continual learning;Lifelong learning, GAN-CNN deep fake detector",ScienceDirect
129,AI-assisted deepfake detection using adaptive blind image watermarking,Ling-Yuan Hsu,2024,"This paper proposes a new adaptive blind watermarking technology for deepfake detection, which can embed deepfake detection information into the image and verify the image's authenticity without requiring additional information. The proposed scheme utilizes mixed modulation combined with partly sign-altered mean value to embed a set of coefficients that enhance robustness against attacks while maintaining high image quality. Additionally, blind adaptive deepfake detection technology with the tamper detection mean value is employed to detect relative positions adaptively, even when face images are slightly modified or deepfaked. To further improve the performance of the proposed scheme, a gray wolf optimizer is introduced to optimize parameters, and a denoising autoencoder is employed to facilitate the identification of extracted watermarks. This technology will adaptively embed watermark information while preserving the original face image, thereby maintaining the authenticity of the face in the image and verifying the owner of the image. The code is available at https://github.com/lyhsu01/AwDD.","Deepfake detection, Blind image watermarking, Partly sign-altered, Mixed modulation",ScienceDirect
130,Watching the BiG artifacts: Exposing DeepFake videos via Bi-granularity artifacts,Han Chen and Yuezun Li and Dongdong Lin and Bin Li and Junqiang Wu,2023,"Recent years have witnessed significant advances in AI-based face manipulation techniques, known as DeepFakes, which has brought severe threats to society. Hence, an emerging and increasingly important research topic is how to detect DeepFake videos. In this paper, we propose a new DeepFake detection method based on Bi-granularity artifacts (BiG-Arts). We observe that the most of DeepFake video generation can commonly introduce bi-granularity artifacts: the intrinsic-granularity artifacts and extrinsic-granularity artifacts. Specifically, the intrinsic-granularity artifacts are caused by a common series of operations in model generation such as up-convolution or up-sampling, while the extrinsic-granularity artifacts are introduced by a common step in post-processing that blends the synthesized face to original video. To this end, we formulate DeepFake detection as multi-task learning problem, to simultaneously predict the intrinsic and extrinsic artifacts. Benefiting from the guidance of detecting Bi-granularity artifacts, our method is notably boosted in both within-datasets and cross-datasets scenarios. Extensive experiments are conducted on several DeepFake datasets, which corroborates the superiority of our method. Our method has been contributed as a part of the solution to achieve the Top-1 rank in DFGC competition (https://competitions.codalab.org/competitions/29583).","Multimedia forensics, Deepfake detection, Granularity artifacts, Multi-task learning",ScienceDirect
131,Europol: the AI hacker threat to biometrics,Tim Ring,2021,"BTT's Tim Ring reports on a deep-dive study into how cybercriminals are using deepfakes and other AI technology to defeat the face and voice recognition security used by banks, businesses and governments.", ,ScienceDirect
132,�There Is something Rotten in Denmark�: Investigating the Deepfake persona perceptions and their Implications for human-centered AI,Ilkka Kaate and Joni Salminen and Jo�o M. Santos and Soon-Gyo Jung and Hind Almerekhi and Bernard J. Jansen,2024,"Although they often have a negative connotation due to their social risks, deepfakes have the potential to improve HCI, human-centered AI, and user experience (UX). To investigate the impact of deepfakes on persona UX, we conducted an experimental study with 46 users who used a deepfake persona and a human persona to carry out a design task. We collected think-aloud, observant notes, and survey data. The results of our mixed-method analysis indicate that if users observe glitches in the deepfake personas, these glitches have a detrimental effect on the persona UX and task performance; however, not all users identify glitches. Our quantitative analysis of survey data shows that there are differences in how (a) users perceive deepfakes, (b) users detect deepfake glitches, (c) deepfake glitches affect information comprehension, and (d) deepfake glitches affect task completion. Glitches have the most significant impact on authenticity, persona perception, and task perception variables but less impact on behavioral variables. The results imply that organizations implementing deepfake personas need to address perceptual challenges before the full potential of deepfake technology can be realized for persona creation.","Deepfakes, User perceptions, Human-centered AI, User study",ScienceDirect
133,The Effect of Deep Learning Methods on Deepfake Audio Detection for Digital Investigation,Mvelo Mcuba and Avinash Singh and Richard Adeyemi Ikuesan and Hein Venter,2023,"Voice cloning methods have been used in a range of ways, from customized speech interfaces for marketing to video games. Current voice cloning systems are smart enough to learn speech characteristics from a few samples and produce perceptually unrecognizable speech. These systems pose new protection and privacy risks to voice-driven interfaces. Fake audio has been used for malicious purposes and is difficult to classify what is real and fake during a digital forensic investigation. This paper reviews the issue of deep-fake audio classification and evaluates the current methods of deep-fake audio detection for forensic investigation. Audio file features were extracted and visually presented using MFCC, Mel-spectrum, Chromagram, and spectrogram representations to further study the differences. Harnessing the different deep learning techniques from existing literature were compared using five iterative tests to determine the mean accuracy and the effects thereof. The results showed a Custom Architecture gave better results for the Chromagram, Spectrogram, and Me-Spectrum images and the VGG-16 architecture gave the best results for the MFCC image feature. This paper contributes to further assisting forensic investigators in differentiating between synthetic and real voices.","Deepfake audio, digital investigation, CNN, voice cloning",ScienceDirect
134,Deepfake detection: Enhancing performance with spatiotemporal texture and deep learning feature fusion,Abdelwahab Almestekawy and Hala H. Zayed and Ahmed Taha,2024,"Deepfakes bring critical ethical issues about consent, authenticity, and the manipulation of digital content. Identifying Deepfake videos is one step towards fighting their malicious uses. While the previous works introduced accurate methods for Deepfake detection, the stability of the proposed methods is rarely discussed. The problem statement of this paper is to build a stable model for Deepfake detection. The results of the model should be reproducible. In other words, if other researchers repeat the same experiments, the results should not differ. The proposed technique combines multiple spatiotemporal textures and deep learning-based features. An enhanced 3D Convolutional Neural Network, which contains a spatiotemporal attention layer, is utilized in a Siamese architecture. Various analyses are carried out on the control parameters, feature importance, and reproducibility of results. Our technique is tested on four datasets: Celeb-DF, FaceForensics++, DeepfakeTIMIT, and FaceShifter. The results demonstrate that a Siamese architecture can improve the accuracy of 3D Convolutional Neural Networks by 7.9�% and reduce the standard deviation of accuracy to 0.016, which indicates reproducible results. Furthermore, adding texture features enhances accuracy by up to 91.96�%. The final model can achieve an Area Under Curve (AUC) up to 97.51�% and 95.44�% in same-dataset and cross-dataset scenarios, respectively. The main contributions of this work are the enhancement of model stability and the assurance of result repeatability, ensuring consistent results with high accuracy.","Deepfake detection, Deep learning, 3D CNN, Siamese architecture",ScienceDirect
135,Reducing Dataset Specificity for Deepfakes Using Ensemble Learning,Qaiser Abbas and Turki Alghamdi and Yazed Alsaawy and Tahir Alyas and Ali Alzahrani and Khawar Iqbal Malik and Saira Bibi,2022,"The emergence of deep fake videos in recent years has made image falsification a real danger. A person�s face and emotions are deep-faked in a video or speech and are substituted with a different face or voice employing deep learning to analyze speech or emotional content. Because of how clever these videos are frequently, Manipulation is challenging to spot. Social media are the most frequent and dangerous targets since they are weak outlets that are open to extortion or slander a human. In earlier times, it was not so easy to alter the videos, which required expertise in the domain and time. Nowadays, the generation of fake videos has become easier and with a high level of realism in the video. Deepfakes are forgeries and altered visual data that appear in still photos or video footage. Numerous automatic identification systems have been developed to solve this issue, however they are constrained to certain datasets and perform poorly when applied to different datasets. This study aims to develop an ensemble learning model utilizing a convolutional neural network (CNN) to handle deepfakes or Face2Face. We employed ensemble learning, a technique combining many classifiers to achieve higher prediction performance than a single classifier, boosting the model�s accuracy. The performance of the generated model is evaluated on Face Forensics. This work is about building a new powerful model for automatically identifying deep fake videos with the DeepFake-Detection-Challenges (DFDC) dataset. We test our model using the DFDC, one of the most difficult datasets and get an accuracy of 96%.","Deep machine learning, deep fake, CNN, DFDC, ensemble learning",ScienceDirect
136,"Fake news research trends, linkages to generative artificial intelligence and sustainable development goals",Raghu Raman and Vinith {Kumar Nair} and Prema Nedungadi and Aditya {Kumar Sahu} and Robin Kowalski and Sasangan Ramanathan and Krishnashree Achuthan,2024,"In the digital age, where information is a cornerstone for decision-making, social media's not-so-regulated environment has intensified the prevalence of fake news, with significant implications for both individuals and societies. This study employs a bibliometric analysis of a large corpus of 9678 publications spanning 2013�2022 to scrutinize the evolution of fake news research, identifying leading authors, institutions, and nations. Three thematic clusters emerge: Disinformation in social media, COVID-19-induced infodemics, and techno-scientific advancements in auto-detection. This work introduces three novel contributions: 1) a pioneering mapping of fake news research to Sustainable Development Goals (SDGs), indicating its influence on areas like health (SDG 3), peace (SDG 16), and industry (SDG 9); 2) the utilization of Prominence percentile metrics to discern critical and economically prioritized research areas, such as misinformation and object detection in deep learning; and 3) an evaluation of generative AI's role in the propagation and realism of fake news, raising pressing ethical concerns. These contributions collectively provide a comprehensive overview of the current state and future trajectories of fake news research, offering valuable insights for academia, policymakers, and industry.","Deep fake, Ethics, Fake news, Generative AI, Prominence percentile, Sustainable development goal",ScienceDirect
137,Deepfake Detection Using Machine Learning Algorithms,M. S. Rana; B. Murali; A. H. Sung,2021,"Deepfake, a new video manipulation technique, has drawn much attention recently. Among the unlawful or nefarious applications, Deepfake has been used for spreading misinformation, fomenting political discord, smearing opponents, or even blackmailing. As the technology becomes more sophisticated and the apps for creating them ever more available, detecting Deepfake has become a challenging task, and accordingly researchers have proposed various deep learning (DL) methods for detection. Though the DL-based approach can achieve good solutions, this paper presents the results of our study indicating that traditional machine learning (ML) techniques alone can obtain superior performance in detecting Deepfake. The ML-based approach is based on the standard methods of feature development and feature selection, followed by training, tuning, and testing an ML classifier. The advantage of the ML approach is that it allows better understandability and interpretability of the model with reduced computational cost. We present results on several Deepfake datasets that are obtained relatively fast with comparable or superior performance to the state-of-the-art DL-based methods: 99.84% accuracy on FaceForecics++, 99.38% accuracy on DFDC, 99.66% accuracy on VDFD, and 99.43% on Celeb-DF datasets. Our results suggest that an effective system for detecting Deepfakes can be built using traditional ML methods.",Deepfake;Deep Learning;Machine Learning;Face Manipulation,IEE
138,A Novel Approach for Detecting Deepfake Face Using Machine Learning Algorithms,M. Kumar; P. K. Rai; P. Kumar,2024,"In today's digital age, the ability to identify, differentiate, and authenticate manipulated online content is essential. Being ability to discriminate between the real and the fake is crucial. Recent advances in technologies such as artificial intelligence, machine learning, and deep learning are playing a major role in the generation of deepfake media (images and videos). Very realistic deep fake images and videos can be produced by utilizing sophisticated deep learning models such as generative adversarial neural networks (GAN s) and autoencoders, in conjunction with a sizable image collection pertaining to the subject matter. Deepfakes (DF) refer to artificially synthesized images or videos created using features such as face swapping and facial expression recombination. These face manipulation techniques have become extremely sophisticated. Deepfakes can be used to create child pornography, pornographic images of celebrities, revenge porn, fake news and harassment, spreading disinformation on social media platforms, financial fraud, election manipulation, and more. Therefore, there is a need to design and develop a robust framework to identify these deepfake images and videos. The purpose of this paper is to identify deepfakes from visual deepfake datasets and perform a comparative analysis of deep fake detection through machine learning algorithms.",Deepfake;Artificial Intelligence (AI);Machine Learning (ML);Deep Learning;Generative Adversarial Neural Networks (GANs);Face Swapping,IEE
139,Deep Learning Technique for Recognition of Deep Fake Videos,F. Mira,2023,"New computing methods and digital content have been created thanks to recent advancements in digital media technology. They have also contributed to advancing recent AI-based innovations and provide straightforward instruments for producing real video changes. These ""Deep Fakes"" or fraudulent films might seriously jeopardise the public�s perceptions of a case or society. These films� consequences on spreading fake news, particularly, are significant when they act as accurate depictions. These false films may, however, be created by manipulating software. Data protection, identifying deep fakes, and preventing media manipulation are just a few ways deep fake detection contributes to cybersecurity. In light of this, it is essential and mandatory to be able to spot this sort of misleading data. This paper examines the most promising new approaches to deep fake video detection by analysing the latest findings from the research community. It analysed the results from two research and proposed using convolutional neural networks and long short-term memory to distinguish fake from real video frames. The report suggested using these and other detection methods and the unique method for identifying deep fakes that used the YOLO face detector to distinguish facial video frames (YOLO-CNN-XGBoost) and suggested investigating other novel detection methods.",Deep Learning;Deep Fake;Deep Fake Video;Video Recognition;Yolo;Fake Detection,IEE
140,Unmasking the Truth: A Deep Learning Approach to Detecting Deepfake Audio Through MFCC Features,I. Altalahin; S. AlZu'bi; A. Alqudah; A. Mughaid,2023,"Deepfake content is artificially created or altered using artificial intelligence (AI) methods to appear real. Synthesis can include audio, video, images, and text. Deepfakes may now produce content that looks normal, making it more difficult to identify. Significant progress has been made in identifying video deep fakes in recent years; However, most of the investigations into voice deep fake detection have used the ASVSpoof-2019 dataset and several machine learning and deep learning algorithms. This research uses machine-based and deep-learning approaches to identify fake audio. Melted frequency cepstral coefficients (MFCCs) are used to extract the most useful information from the sound. We choose the 2019 ASVSpoof dataset, which is the latest reference dataset. Experimental results show that Convolutional Neural Networks (CNN): (CNN-LSTM) outperformed other machine learning (ML) models in terms of accuracy, achieving an accuracy of up to 88%.",Deepfake Audio;CNN-LSTM;Melted frequency cepstral coefficients,IEE
141,A Comparative Study: Deepfake Detection Using Deep-learning,N. Khatri; V. Borar; R. Garg,2023,"In recent decades, we have seen significant advancement in fields like Artificial Intelligence, Machine Learning, and Deep Learning, resulting in the developing of new technologies such as deepfake. Deepfakes are a form of digital media that replaces one identity�s likeness with another or creates a synthetic personality: in the form of high-quality realistic fake video, image, or audio. Deepfakes can be helpful in education, art, activism, and self-expression; however, some subjects can use deepfakes to harm the portrayal of people, create pornographic content, and spread misleading information. High-quality deepfakes are easy to build but incredibly difficult to detect, creating a need to explore technologies which can be helpful in deepfake detection. Therefore, we present a comparative study of deep-learning models that can benefit deepfake detection. We have explored four deep-learning models, namely, VGG16, MobileNetV2, XceptionNet, and InceptionV3 and trained these models on the FaceForensics++ dataset. Finally, we evaluate the performance of these models for deepfake detection and conclude the study with our observations and future scope for improvement in this field.",deepfake detection;computer vision;deep learning;image classification;convolutional neural networks,IEE
142,DeepFake Detection Using Error Level Analysis and Deep Learning,R. Rafique; M. Nawaz; H. Kibriya; M. Masood,2021,"The image recognition software is used in numerous distinctive industries that include entertainment and media. The deep learning (DL) algorithms have been of great help in the development of several techniques used for creating, altering, and locating any data. The deepfake method is a photo-faking technique that includes replacing two people's faces to an extent that it becomes very difficult to identify it with a naked eye. The convolution neural network (CNN) models including Alex Net and Shuffle Net are used to recognize genuine and counterfeit face images in this article. The technique analyzes the performance and working of all distinctive algorithms using the real/fake face recognition collection from Yonsei University's Computational Intelligence Photography Lab. The first step in the process starts by the normalizing of pictures then the Error Level Analysis is carried out before it is put into several difference CNN models. Then the in-depth features are extracted from the CNN models utilizing the Support Vector Machine and the K-nearest neighbor methods. The most perfect accuracy of 88.2% of Shuffle Net via KNN was analyzed while Alex Net's vector had the accuracy of 86.8%.",Deep Learning;Machine Learning;CNN;Deepfake Detection;SVM;KNN,IEE
143,Deep Learning-Powered Face Detection and Recognition for Challenging Environments,T. J. Reddy; M. S. Ganesh; M. H. Kumar Reddy; C. Bhandhavya; R. Jansi,2024,"The increasing prevalence of surveillance systems in both public and private domains underscores the growing need for robust human face detection and recognition capabilities. This research introduces an innovative real-time framework that leverages deep learning techniques, particularly Convolutional Neural Networks (CNNs), to accurately detect human faces in complex images. Through a combination of image preprocessing, training using diverse dataset and classification using trained model, this system excels at identifying faces even in challenging scenarios marked by low lighting and diverse angles. This capability enables the precise identification of individuals of interest. Rigorous testing on publicly available dataset showcases the system's outstanding performance in terms of face detection and recognition accuracy. To validate the outstanding performance of CNN is face detection, comparison was done using other machine learning algorithms like k-NN, random forest and logistic regression. This research contributes to the advancement of facial recognition technology, offering a reliable solution for video surveillance applications. It holds the potential to enhance security, surveillance, and forensic practices, benefiting stakeholders ranging from law enforcement agencies to public safety organizations and private security firms.",CNN;Facial Recognition;Machine learning;Deep learning;Accuracy,IEE
144,Comparative Analysis on Different DeepFake Detection Methods and Semi Supervised GAN Architecture for DeepFake Detection,J. John; B. V. Sherif,2022,"The use of deep learning results in solving a wide range of real-world problems and applications, but there are some drawbacks along with this positive side. One of the most recent and advanced problems among them is the wide use of deepfakes. Deepfakes are digital tampered images or videos created using different deep learning methods. In a deepfake, the face of a targeted person is superimposed on a source image so that this digital tampered data can be used for digital frauds, blackmailing, pornography etc. With the developments in the deep learning field, it is becoming challenging to distinguish between real and fake manually. So it is essential to do research and development in the area of deepfake detection. In this paper, an extensive discussion and timely overview on different deepfake detection methods are done under the classification of feature-based, temporal-based, and deep feature-based deepfake detection. The comparison study is mainly done based on the key features used, face detection architecture, deep learning architecture, video-based or image-based, the dataset used, frames size, and dataset size used. Along with the comparison, a semisupervised GAN architecture is also proposed and developed to detect the deepfake images.",DeepFake;SGAN;DeepFake Detection,IEE
145,Advanced Deepfake Detection using Machine Learning Algorithms: A Statistical Analysis and Performance Comparison,M. S. Rana; A. H. Sung,2024,"As techniques and tools for synthetic media and Deepfakes continue to advance, it is increasingly clear that video, audio and images can no longer be relied upon as truthful recordings of reality. Every digital communication channel is now vulnerable to manipulation, and there is widespread use of Deepfakes to propagate misinformation and disinformation, inflame political discord, defame opposition, commit cyber frauds or blackmail individuals. While deep learning (DL) methods have been widely used to identify Deepfakes, this paper demonstrates that classical machine learning (ML) methods can achieve superior performance--comparable with or exceeding state-of-the-art DL methods in detecting Deepfakes. Using the traditional procedures of feature development and selection, training, and testing of ML classifiers for the task actually provides better understandability and interpretability while consuming much less computing resource. In addition, an omnibus test, the Analysis of Variance (ANOVA), is conducted to compare the performance of multiple ML models. We present experiments that achieve 99.84% accuracy on the FaceForecics++ dataset, 99.38% accuracy on the DFDC dataset, 99.66% accuracy on the VDFD dataset, and 99.43% accuracy on the Celeb-DF dataset. Our study thus challenges the notion that DL approaches are the only effective way to detect Deepfakes and demonstrates that judicious use of ML approaches can be highly efficacious and cost-effective.",Deepfakes;Deepfake Detection;Face Manipulation;Machine Learning;Analysis of Variance;Omnibus Test,IEE
146,Facial Action Unit-Based Deepfake Video Detection Using Deep Learning,Q. Jaleel; I. Hadi,2022,"Deepfake videos are becoming more realistic, making them a menace. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Widespread use of falsified videos and images on social media requires accurate detection. An identity switch (DeepFake) and an expression swap create facial modifications. This paper can detect deepfakes that are perfectly created. Traditional detection approaches that observe artifacts and pixel irregularities cannot keep up with modern technology. The paper is divided into two stages. In the first stage, the paper extracts facial action units from a person and creates a profile for him. This profile represents the behavior of his facial expressions, which differ from one person to another. This was done by building a deep learning network and training it based on a dataset. The second stage is testing, which involves taking videos, extracting facial action units, and testing them on the network to classify them as fake or real. The network has proven its ability to classify with high accuracy of %95.75 compared to traditional methods.",GAN;facial action unit;Facial expression recognition;Media Forensics;DeepFake Detection;face detection,IEE
147,Synthetic Content Detection in Deepfake Video using Deep Learning,K. Jalui; A. Jagtap; S. Sharma; G. Mary; R. Fernandes; M. Kolhekar,2022,"In recent years, significant improvements in the field of deep learning have promoted the development of highly realistic AI-based video manipulation and forgery technologies commonly known as �DeepFake� using Autoencoders and Generative Adversarial Networks (GANs). Although this technology has its own set of beneficial applications, it decreases the integrity of digital visual media and can have serious sociopolitical implications. With new improving video manipulation tools, the detection of deepfake is a major challenge. According to the recent surveys that are reported, the deepfake systems are able to give a decision about whether a given video contains fake content or not. The objective of our project is to identify the presence of deepfake content in the digital video and report the same. Our system uses ResNext Convolution Neural Network for extracting the features of the video at frame level and Long Short-Term Memory (LSTM) for training a model to classify if a video is deepfake or pristine. We have trained the network using Deepfake Detection Challenge dataset. The result along with the confidence score of the model is shown to the user using a simple graphical user interface.",Deep Fake Detection;Deep Learning;Auto Encoders;Generative Adversarial Networks;Convolution Neural Network (CNN);Long Short-Term Memory (LSTM),IEE
148,AI Based Deepfake Detection,A. Garde; S. Suratkar; F. Kazi,2022,"Advances in machine learning, especially following the 2014 release of Generative Adversarial Networks, have allowed techniques and methods to be used for nefarious ends. Generative Adversarial Networks can even create fake images and videos which appears to be real to human eyes. Generative Adversarial Networks can swap the faces of two different people. For film producers or graphic designers, this tool is quite useful. Face swapping has been done in movies to replace the real person's face with that of the actor. A computer-generated versions of actors Carrie Fisher and Peter Cushing have been featured in a movie named �Star Wars: The Rise of Skywalker� from the �Star wars� film series just like they appeared in the 1977 original, while other Marvel films have �de-aged� actors such as Michael Douglas and Robert Downey Jr. However, this has the potential to be misused. By producing ultra-realistic Deep Fake videos using various trailblazing machine learning techniques, felon are trying to harass, blackmail the innocents. It can also be used to induce political instability by disseminating erroneous information, which can cause communal, diplomatic, and violent outbreak with disastrous consequences. This gives rise to a significant menaces to security of the person as well as national defence, necessitating the development of automated methods for detecting deep fake videos. The eye blinking pattern in deepfaked videos is not formed as naturally as it should be due to the incapability of Generative Adversarial Networks. This will come in handy when constructing a deepfake detecting algorithm. The project uses an object's eye blinking pattern to determine whether or not a video is deepfaked.",Deep-Fake;GANs;Deep Learning;Eye blinking;Convolutional Neural Networks;SVM,IEE
149,Security Strengthen and Detection of Deepfake Videos and Images Using Deep Learning Techniques,S. Talreja; A. Bindle; V. Kumar; I. Budhiraja; P. Bhattacharya,2024,"The identification of fraudulent movies or images created using deep learning algorithms is the subject of this research and attempts an in-depth investigation of Deepfake Detection. Deepfakes are created by manipulating or replacing certain parts of an original video or image using machine learning algorithms, usually concentrating on face features. Deepfake detection's main goal is to precisely recognize and distinguish these altered media from real movies and photos. This study looks at a number of deepfake detection techniques, including forensic methods, machine learning algorithms, and picture analysis. These approaches' efficiency and performance are assessed based on their capacity to accurately identify and categories deep-fakes. The paper also examines the difficulties and restrictions of deepfake detection, such as the development of more complex and convincing deepfakes. Further, prospective uses and future possibilities for deepfake detection research are examined, with an emphasis on improving detection skills and creating effective countermeasures. Overall, this research offers insightful information about cutting-edge methods and developments in Deepfake Detection, giving a greater comprehension of its importance in resolving the issues brought on by manipulated media in the current digital era.",DeepFake Detection;Deep Learning;Machine Learning,IEE
150,Audio Deepfake Detection by using Machine and Deep Learning,H. H. Kilinc; F. Kaledibi,2023,"Fake voices are one of the hottest topics in cyber security, forensics, and social media. There are a variety of usage scenarios, from speech disorders to fake news to telephone and financial fraud. With products using artificial intelligence technology such as Google Audio LM, it is possible to produce realistic, well-structured, and consistent sound sequences. These products, although synthetic, can accurately replicate intonation, accents, and other unique features by mimicking the human voice. A solution using machine and deep learning methods to recognize fake voices is proposed. In the feature extraction stage, Mel-frequency cepstral coefficients (MFCCs) are used. Then these features are classified using machine and deep learning-based models. According to the results obtained, the sound is judged to be real or fake.",Audio Deepfake;MFCC;Feature Extraction;Fake Audio Detection,IEE
151,A Comprehensive Analysis on Web-Based Deep Fake Detection Techniques,S. R; A. K. T A; A. Jayaraj; A. Snil; C. M. Varghese; H. Lakshman,2024,"Deepfake technology has emerged as a critical challenge to the authenticity of digital media, necessitating effective detection techniques. This review explores various advancements in deepfake detection tools, with a particular focus on web-based solutions designed to enhance user capabilities in detecting manipulated images. This study evaluates the effectiveness of these tools, which utilize advanced machine learning algorithms to analyze visual cues and identify inconsistencies that indicate deepfake manipulation. This review highlights the integration of user-friendly interfaces and robust detection mechanisms that address the spread of misinformation. Additionally, this study examines the role of diverse training datasets in improving the detection accuracy and the tool's importance on transparency and user education to enable digital literacy. This review aims to provide an overview of the current approaches and methodologies in deepfake detection, contributing to the effort of preserving digital content integrity and trustworthiness.",Deepfake detection;authentication;deep learning;machine learning,IEE
152,Detection of Deep-Morphed Deepfake Images to Make Robust Automatic Facial Recognition Systems,A. Mitra; S. P. Mohanty; P. Corcoran; E. Kougianos,2021,"Face Morphing has emerged as a pervasive attack of Facial Recognition Systems. The rapid growth of Generative Adversarial Networks takes it to a complete new level. Deepfake or deep neural network based face morphing, a.k.a deep-morph attack, presents a significant threat to Facial Recognition System. In this paper, we propose a novel Convolutional Neural Network based detection method of deep morphed deepfake images which is suitable for IoT environments in smart cities. A high accuracy of 94.83% has been achieved for the DeepfakeTIMIT HQ dataset. This lightweight and fast network is a natural choice for IoT environments.",Smart City;Facial recognition System;Deep-fake;Deep-Morph;Deep Learning;Convolutional Neural Network,IEE
153,Unmasking Deepfake Faces from Videos Using An Explainable Cost-Sensitive Deep Learning Approach,F. Mahmud; Y. Abdullah; M. Islam; T. Aziz,2023,"Deepfake technology is widely used, which has led to serious worries about the authenticity of digital media, making the need for trustworthy deepfake face recognition techniques more urgent than ever. This study employs a resource-effective and transparent cost-sensitive deep learning method to effectively detect deepfake faces in videos. To create a reliable deepfake detection system, four pre-trained Convolutional Neural Network (CNN) models: XceptionNet, InceptionResNetV2, EfficientNetV2S, and EfficientNetV2M were used. FaceForensics++ and CelebDf-V2 as benchmark datasets were used to assess the performance of our method. To efficiently process video data, key frame extraction was used as a feature extraction technique. Our main contribution is to show the model�s adaptability and effectiveness in correctly identifying deepfake faces in videos. Furthermore, a cost-sensitive neural network method was applied to solve the dataset imbalance issue that arises frequently in deepfake detection. The XceptionNet model on the CelebDf-V2 dataset gave the proposed methodology a 98% accuracy, which was the highest possible whereas, the InceptionResNetV2 model, achieves an accuracy of 94% on the FaceForensics++ dataset. Source Code: https://github.com/Faysal-MD/Unmasking-Deepfake-Faces-from-Videos-An-Explainable-Cost-Sensitive-Deep-Learning-Approach-IEEE2023",Deepfake video;Keyframe;Explainable AI (XAI);Cost-sensitive;Face Detection;CelebDf;FaceForensics++;CNN,IEE
154,A Comparative Study on Deepfake Detection Algorithms,A. Kaushal; S. Singh; S. Negi; S. Chhaukar,2022,"In recent years, the number of images and videos shared online increased and people have easy ways to access such content. �DeepFake� refers to any multimedia content created using deep learning technology in order to make it appear realistic. The creation of deepfake videos and images using deep learning techniques leads to very realistic �DeepFake� videos and images by changing the digital content of images and videos. Deepfake is widely recognized as one of artificial intelligence�s most dangerous uses. Deepfake makes it possible to place a person in a totally imaginary situation since it is used to imitate an activity that the person did not perform. Deepfakes have been becoming increasingly dangerous to democracy, society�s security and people�s privacy. The distribution of such deepfake content on various platforms urged the international community to revaluate the threat to social security posed by such content. It encouraged the researchers around the world to develop effective deepfake detection methods. In this paper we have discussed such approaches of deepfake detection in videos and images that are available in recent studies and have provided comparative review of research on deepfake detection algorithms. It also compares the different detection techniques and examines their limitations and advantages.",Deepfake;Deep Learning;Deepfake Detection;Detection Accuracy;Artificial Intelligence;Generative Adversarial Networks,IEE
155,Enhanced Preprocessing Stage For Feature Extraction of Deepfake Detection Based on Deep Learning Methods,M. A. Abdulhamid; A. N. Hashim,2023,"Biometric identities are at risk of deepfake facial manipulation. Over the past few years, deepfake detection has been the subject of extensive research, most which centered on the application of machine learning strategies. However, the recognition of deepfake is still one of the most challenging problems in computer vision today. Deep learning has recently gained popularity due to its potential to solve a wide range of real-world problems, including detecting deepfakes. Our research focused on improving feature extraction methods by using deep learning and comparing preprocessing methods to show how they affect detection performance. A preprocessing approach was proposed to improve the regions of interest (ROIs) used to feed Moodle feature extraction. The proposed algorithmic approach involves finding one key frame extracted from a video by using the oriented fast and rotated brief algorithm, detecting the face oval region using the DLIB library as an ROI and performing quality improvement via contrast-limited adaptive histogram equalization (CLAHE)/adaptive histogram equalization (AHE) and comparing them. On the FaceForensics ++ dataset, CLAHE demonstrated superior performance compared with AHE with InceptionV3 as a feature extractor. The final classification result had an accuracy ratio of 89%, and the area under the curve was measured to be 77%.",Preprocessing;Deepfake;Histogram equalization;Machine learning,IEE
156,DFFMD: A Deepfake Face Mask Dataset for Infectious Disease Era With Deepfake Detection Algorithms,N. M. Alnaim; Z. M. Almutairi; M. S. Alsuwat; H. H. Alalawi; A. Alshobaili; F. S. Alenezi,2023,"Deepfake is a technology that creates fake images and videos with replaced or synthesized faces. Deepfakes are becoming a concerning social phenomenon, as they can be maliciously used to generate false political news, disseminate dangerous information, falsify electronic evidence, and commit digital harassment and fraud. The ease and accuracy of creating Deepfakes have been bolstered by the popularity of wearing face masks since the beginning of the infectious disease outbreak (2020). Because these masks obstruct defining facial features, fake videos are now even more challenging to identify, increasing the necessity for advanced Deepfake detection technology. The research also creates a real/fake video dataset with face masks because the field lacks the dataset required for detection-model training. The proposed research proposes a Deepfake Face Mask Dataset (DFFMD) based on a novel Inception-ResNet-v2 with preprocessing stages, feature-based, residual connection, and batch normalization. The combination of preprocessing stages, feature-based, residual connection, and batch normalization increases the detection accuracy of deepfake videos in the presence of facemasks, unlike the traditional methods. The study�s results compared with existing state-of-the-art methods detect face-mask-Deepfakes with 99.81% accuracy compared to the traditional InceptionResNetV2 and VGG19, whose accuracy is 77.48%, and 99.25%, respectively. Future work should evaluate the accuracy of developing a subsequent experimental work for increased detection of deepfake with facemasks.",Deepfake;deep learning;CNN;generation;detection;fake videos;neural network;mask;face mask,IEE
157,Combining Deep Learning and Super-Resolution Algorithms for Deep Fake Detection,N. S. Ivanov; A. V. Arzhskov; V. G. Ivanenko,2020,"Deep Fake is a technique for human image synthesis based on artificial intelligence. In this article is explored the problem of Deep Fake Video content and its detection. Has been gathered information about previous attempts, analyzed methods used by different researches and considered their actuality right now. Basing on results of the discovery was designed strategy to expose Deep Fake videos that combines previous detection methods with super-resolution algorithms. Results of the research were compared with expected, so recommendations and possible way of continuing developments were given.",deep fake detection;deep learning;neural networks;super-resolution algorithms,IEE
158,Deep Fake Detection using Adversarial Ensemble Techniques,B. V. Chowdary; M. Prabhakar; M. Akhil; K. Pavan; B. P. T. Reddy,2024,"The rise of deepfake technology has resulted in unprecedented challenges in the field of digital media verification, posing significant threats to personal security, misinformation, and trust in digital content. In response to this pressing issue, this study presents an advanced deepfake detection system using deep learning approach. Specifically, the proposed system integrates ResNeXt and Long Short-Term Memory (LSTM) architectures to accurately identify the manipulated content. By leveraging the spatial-temporal features captured by these combined architectures, the proposed system aims to enhance the detection rate of deepfakes across various media formats. The proposed approach offers a robust solution to counteract the evolving sophistication of deepfake technology, thereby enhancing the integrity and authenticity of digital media content.",Deepfake Detection;Deep Learning;ResNeXt;LSTM;Digital Media Verification,IEE
159,Deepfake video detection using InceptionResnetV2,S. Guefrechi; M. B. Jabra; H. Hamam,2022,"Recently, deepfake face-swapping technology has become popular, making it easy to create ultra-realistic fake videos. Detecting the authenticity of videos is becoming increasingly important due to the potential negative impact videos can have on the world. This research is a method for developing a deep learning model, which can make a distinction between real and fake videos. Research papers on the subject of transfer learning in the domain of computer vision to take advantage of the earlier created neural network functions for image classification and to create new models based on them. Deep learning continues to evolve in both generating and detecting deepfakes. Models developed to detect deepfakes are designed using older datasets, may become outdated over time, and require new detection techniques all the time. Research results are promising with over 90% accuracy and areas for development and further development",Deepfake;Video authenticity;Deepfake detection;Fine-tuning;InceptionResnet-V2,IEE
160,Comparative Analysis of Deep Fake Detection Techniques,F. Alanazi,2022,"Deep learning and artificial intelligence are important knowledge areas that have provided solutions allowing the successful resolution of complex problems. Some of these problems include, but are not limited to, human-level control, data analytics and other digitisation challenges. One of the offshoots of deep learning is a concept termed �deepfake�, which can be described as the imposition of video of a face image from a source to video of the face image of a target individual in order to make the targeted person appear to express the content of the source video [2]. It is important to establish the fact that deepfakes have been used for malicious purposes, becoming a threat to national security, privacy, democracy, and society at large. It is, therefore, fundamental to review the science behind the method, and the available detection techniques to curtail this digital innovation, so as to reduce its level of threat; that is the focus of this paper.",deepfakes;artificial intelligence;deep learning;autoencoders;forensics;GAN;generative adversarial networks,IEE
161,"Deepfake Generation, Detection and Datasets: a Rapid-review",A. Ko�ak; M. Alkan,2022,"Deepfake is the general expression of fake images or videos. Images and videos created with Deep Neural Networks (DNN) can cause both personal and national problems. Deepfake technology has been making progress day by day. Accordingly, both the detection methods and the diversity of the data sets to be trained are increasing. In this article, datasets created in deepfake technology and applications that use datasets for deepfake detection are evaluated. The data sets used are produced with different models. There exist both traditional and deep learning-based detection methods for deepfake detection. Due to the recent malicious use of deepfake technology, detection methods and methods to be used in applications are of great importance. When the detection methods are compared, the accuracy of the deep learning-based detection method is higher for each data set. The method that provides the highest accuracy among two different data sets is the Xception method.",Deepfake;DNN;traditional detection method;deep learning-based detection method;Xception,IEE
162,Deepfake Detection on Social Media: Leveraging Deep Learning and FastText Embeddings for Identifying Machine-Generated Tweets,S. Sadiq; T. Aljrees; S. Ullah,2023,"Recent advancements in natural language production provide an additional tool to manipulate public opinion on social media. Furthermore, advancements in language modelling have significantly strengthened the generative capabilities of deep neural models, empowering them with enhanced skills for content generation. Consequently, text-generative models have become increasingly powerful allowing the adversaries to use these remarkable abilities to boost social bots, allowing them to generate realistic deepfake posts and influence the discourse among the general public. To address this problem, the development of reliable and accurate deepfake social media message-detecting methods is important. Under this consideration, current research addresses the identification of machine-generated text on social networks like Twitter. In this study, a simple deep learning model in combination with word embeddings is employed for the classification of tweets as human-generated or bot-generated using a publicly available Tweepfake dataset. A conventional Convolutional Neural Network (CNN) architecture is devised, leveraging FastText word embeddings, to undertake the task of identifying deepfake tweets. To showcase the superior performance of the proposed method, this study employed several machine learning models as baseline methods for comparison. These baseline methods utilized various features, including Term Frequency, Term Frequency-Inverse Document Frequency, FastText, and FastText subword embeddings. Moreover, the performance of the proposed method is also compared against other deep learning models such as Long short-term memory (LSTM) and CNN-LSTM displaying the effectiveness and highlighting its advantages in accurately addressing the task at hand. Experimental results indicate that the design of the CNN architecture coupled with the utilization of FastText embeddings is suitable for efficient and effective classification of the tweet data with a superior 93% accuracy.",Text classification;machine learning;deep learning;deepfake;machine generated text,IEE
163,Guardian AI: Synthetic Media Forensics through Multimodal Fusion and Advanced Machine Learning,K. K; S. R; D. S; D. S,2024,"The burgeoning spread of synthetic media disrupts content verification and threatens online trust. This research proposes Guardian AI, a robust deepfake detection system achieving 93% accuracy by harnessing the synergistic power of facial recognition, image forensics, and machine learning. Guardian AI extracts diverse features from videos: facial recognition models analyze landmarks, expressions, and lip-syncing for inconsistencies; image forensics algorithms detect manipulated pixels, lighting patterns, and compression artifacts; and temporal analysis captures unnatural head movements and frame-to-frame motion discrepancies. These multifaceted features are then fused and fed into a rigorously trained deep learning model on multi-modal datasets of real and deepfake videos. Guardian AI classifies video inputs as real or fake, providing a confidence score for its prediction. By leveraging facial recognition's subtle inconsistency detection, image forensics' manipulation artifact identification, and machine learning's robust multi-cue integration, Guardian AI achieves exceptional accuracy and generalizability, adapting to evolving deepfake creation techniques with its diverse training data. This study signifies a significant contribution to content verification by delivering a high accuracy deepfake detection system, paving the way for a more reliable and trustworthy online environment.",Deepfake Detection;Facial Recognition;Image Forensics;Machine Learning;Multimodal Fusion;Content Verification,IEE
164,Hybrid Recurrent Deep Learning Model for DeepFake Video Detection,G. Jaiswal,2021,"Nowadays deepfake videos are concern with social ethics, privacy and security. Deepfake videos are synthetically generated videos that are generated by modifying the facial features and audio features to impose one person�s facial data and audio to other videos. These videos can be used for defaming and fraud. So, counter these types of manipulations and threats, detection of deepfake video is needed. This paper proposes multilayer hybrid recurrent deep learning models for deepfake video detection. Proposed models exploit the noise-based temporal facial convolutional features and temporal learning of hybrid recurrent deep learning models. Experiment results of these models demonstrate its performance over stacked recurrent deep learning models.",Deepfake detection;Hybrid Recurrent model;Deep learning;Deepfake video;video temporal feature,IEE
165,A Detect method for deepfake video based on full face recognition,K. Feng; J. Wu; M. Tian,2020,"In recent years, with the continuous upgrading of computer hardware and the continuous development of deep learning technology, new multimedia tampering tools can make it easier for people to tamper with faces in videos. Tampered videos produced by these new tools may hardly be detected by human, so we need effective method to detect these face-tampered videos. Current popular video face tampering technologies mainly include Deepfake technology based on self-encoder and Face2face technology based on computer graphics. In this paper, we propose a new method for tamper video detection based on the full faces. Facenet algorithm is used here to compare the similarity between real and fake video faces. Finally, in the experimental part, the results showed a significant effect.",deepfake;facenet;convolution network;machine learning,IEE
166,Development of Deepfake Detection Techniques for Protecting Multimedia Information using Deep Learning,N. Siva Rama Lingham; J. J. M. A. Devakanth; G. Raj; K. Gayathri; R. Janani; R. Dhanapal,2024,The development of proposed deepfake detection techniques plays a prominent role in the safeguarding the multimedia information. The various challenges are addressed using the aid of deep learning techniques. This involves hybrid optimization techniques such as particle swarm optimization and genetic algorithms. This helps to improve the accuracy and efficiency in the detection of deepfake. PSO helps in optimizing the weights and parameters of the neural network to obtain faster convergence. GA helps in obtaining potential solutions to obtain the robust deepfake detection model. The integration of deep learning with hybrid optimization involves the collection and preprocessing of the multimedia information and proceeds to an optimization algorithm. The manipulated content in the online platform are detected during the training process. The hybrid optimization tcehniques helps in obtaining model generability and achieving resilience in various attacks occurring in the deepfake generation. The integration of PSO and GA helps in the accurate detection of deepfake content through continuous training and evaluation. Thus the proposed system forms a safeguarding tool for multimedia content and helps to eliminate various risks.,Deepfake;Deep learning techniques;Optimization algorithm;Genetic algorithm;Particle swarm optimization;Multimedia content,IEE
167,Deep fake Video Detection Using Unsupervised Learning Models: Review,B. N. Jyothi; M. A. Jabbar,2023,"The recent decade has been the most emerging for technical advancements in computer and communication fields. These advancements have made the task of automation much cheaper and available to every other individual at minimum or free of cost. Deep Fakes are one such advancement in the field of image processing. Deep fakes are images or videos developed using deep learning models to create fake images or videos. Although there are advantages of these deep fakes like visual training, powerful simulation, etc... There are also demerits or disadvantages highly possible with these technological advancements such as creating content that never existed, making a person speak something which one has not spoken at all. These mentioned possibilities lead to person identification theft, spreading of false or misinformation, etc... This paper is an attempt to investigate the proposed detection techniques for deep fakes. It focuses on unsupervised deep fake detection techniques and the role of ensemble models for detection.",Deep Learning;Deep fakes;deep fake detection;unsupervised learning;an ensemble of model,IEE
168,A Measurement Study on Gray Channel-based Deepfake Detection,S. B. Son; S. H. Park; Y. K. Lee,2021,"Deepfake detection techniques have been widely studied to resolve security issues. However, existing techniques mainly focused on RGB channel-based analysis, which still shows incomplete detection accuracy. In this paper, we validate the performance of Gray channel-based deepfake detection. To compare RGB channel-based analysis and Gray channel-based analysis in deepfake detection, we quantitatively measured the performance by using popular CNN models, deepfake datasets, and evaluation indicators. Our experimental results confirm that Gray channel-based deepfake detection outperforms RGB channel-based deepfake detection in terms of accuracy and analysis time.",deepfake detection;gray-channel analysis;deep learning;deepfake,IEE
169,Deepfake Image Detection Using Vision Transformer Models,B. Ghita; I. Kuzminykh; A. Usama; T. Bakhshi; J. Marchang,2024,"[none]hyphenat Deepfake images are causing an increasing negative impact on the day to day life and pose significant challenges for the society. There are various categories of deepfake images as the technology evolves and becomes more accessible. In parallel, deepfake detection methods are also improving, from basic features analysis to pairwise analysis and deep learning; nevertheless, to date, there is no consistent method able to fully detect such images. This study aims to provide an overview of existing methods of deepfake detection in the literature and investigate the accuracy of models based on Vision Transformer (VIT) when analysing and detecting deepfake images. We implement a VIT model-based deepfake detection technique, which is trained and tasted on a mixed real and deepfake images dataset from Kaggle, containing 40000 images. The results show that The VIT model scores relatively high, 89.9125 %, which demonstrates its potential but also highlights there is significant room for improvement. Preliminary tests also highlight the importance of a large dataset for training and the fast convergence of the model. When compared with other deepfake machine learning and deep learning detection methods, the performance of the ViT model is in line with prior research and warrants further investigation in order to evaluate its full potential.",deepfake images;deepfake detection;Vision Transformer model,IEE
170,Deepfake Generation and Detection - An Exploratory Study,D. Garg; R. Gill,2023,"Deepfakes generated through algorithms based on deep learning have obtained a lot of interest recently. Deepfakes are utilized to manipulate content (audio, video and image) with high realism. Deepfakes have been influenced using artificial intelligence to make it look like someone is saying or doing something that they never actually said or did. Deepfakes can be used for malicious purposes, such as to tarnish someone's reputation or to influence public opinion. Researchers are developing new methods to detect deepfakes, as it is a challenging to distinguish between real and fake content. Deep learning is a powerful tool that is usable to develop both deepfake generation and detection methods. This article provides an extensive review of the existing state of research in creation and detection of deepfakes. It covers the diverse techniques for creation and detection, and existing benchmark datasets.",Deepfakes;Deep Learning;Forgery;Audio Deepfake;Video Deepfake;Image Deepfake;Face swap,IEE
171,An Improved DeepFake Detection Approach with NASNetLarge CNN,?. ?lhan; E. Bal?; M. Karak�se,2022,"Deep fake images are a new technology that has emerged with the development of computer vision and deep learning technologies in recent years. The development of these deep fake technologies has led to the production of many fake or manipulated products. Thus, the problem of detecting the deep fake has emerged and many methods have been developed to solve this problem. In this study, feature extraction and classification method on the dataset with NASNetLarge CNN deep learning model is proposed and a successful result is produced. In the proposed method, training and test datasets were created by removing facial regions from the video frames in the Celeb-DFv2 dataset. The architecture of the NASNetLarge model is explained and the success of the model is tested. According to the test results, an ACC value of 96.7% was obtained and compared with other methods. As a result, the study offers an easier model training with a smaller dataset than other methods and produces a competitive and successful result.",deepfake;manipulation;detection;NASNetLarge;image classification;video detection,IEE
172,Deepfake Video Detection Based on Convolutional Neural Networks,S. R. Adnan; H. A. Abdulbaqi,2022,"The increasing use of mobile camera technology and the growth of social media using and sharing have made the generation and publishing of digital videos more suitable than ever before. However, the manipulation and fabrication of videos have decreased in recent years, because of machine learning and computer vision techniques. This study uses the detection method that applies by comparing the areas of the generated face and their surrounding areas with the Convolutional Neural Network (CNN) Model. The model was applied to the DFDC dataset with different 60 clips for real and fake. The methodology of this work passes through three stages, the first stage pass through preprocessing to convert each video into frames and detect the face in each frame and then be cropped by Haar Cascade function; in the feature's extraction stage the ResNet-50 is applied as the feature extraction model. In the last stage, the CNN classifier for detecting whether the image is fake or real. From the experiment, The Deepfake detection method detects the fake face in the video, where the detection accuracy was achieved at 98%.",CNN;Deepfake video;DFDC;ResNet-50;Deep learning,IEE
173,Improving Deepfake Detection by Mixing Top Solutions of the DFDC,A. Trabelsi; M. M. Pic; J. -L. Dugelay,2022,"The falsification of faces in videos is a growing phenomenon over the years. One of the most popular ways to tamper a face in a video is known as �deepfake�, Today, many tools exist to allow anyone to create a deepfake to discredit an individual or usurp an identity. Fortunately, the detection of deepfakes is an increasing topic of interest for the scientific community. As a result, many efforts have been made to develop mechanisms to automatically identify deepfake videos. In addition, several public deepfakes datasets have been built to help researchers to develop more effective detection methods. The most recent and also the most complete of these datasets is the one built by Facebook as part of the international DeepFake Detection Challenge (DFDC). Thousands of different frameworks, mainly based on deep learning, have been proposed during this challenge. The best solution that has been proposed obtains the accuracy of 82% on the DFDC dataset. However, the accuracy of this method is only 65% on unseen videos from the Internet. In this paper we analyse the five best methods of the DFDC and their complementarity. In addition, we experimented different assembly strategies (boosting, bagging and stacking) among these solutions. We show that we can achieve a large improvement $(+ 41\%$ on log loss and $+2.26\%$ on accuracy) when we carefully choose the models to be assembled with the most appropriate right merging method to use.",deepfake detection;deepfake detection challenge;ensembling,IEE
174,A Heterogeneous Feature Ensemble Learning based Deepfake Detection Method,J. Zhang; K. Cheng; G. Sovernigo; X. Lin,2022,"The Deepfake technique can swap the face of a person with the face of another person in an image or a video which may cause a public security problem. Recently, researchers have focused on detecting deepfake images by deep learning. However some recent works have observed that detectors trained on images produced by one deepfake model perform poorly when tested on others. In this paper we propose to detect deepfake images through heterogeneous feature ensemble learning. We first extract gray gradient features, spectrum features and texture features from real and fake face images, then integrate them into an ensemble feature vector through a flatten process, and finally adopt a back-propagation neural network to train a deepfake detector with the feature vector. Experimental results show that our approach achieves better detection accuracy compared with several state-of-the-art deepfake detectors.",Deepfake detection;Ensemble Learning;Heterogeneous Feature;Neural Network,IEE
175,Review: DeepFake Detection Techniques using Deep Neural Networks (DNN),H. Chotaliya; M. A. Khatri; S. Kanojiya; M. Bivalkar,2023,"In the age of advanced digital manipulation, deepfake videos pose a significant threat to society by allowing the creation of highly convincing counterfeit footage. The application of deep learning has proven instrumental in tackling an extensive array of practical issues and real-world applications. However, alongside its substantial benefits, there exist certain disadvantages. Deepfake videos involve the substitution of one person's characteristics with those of another, achieved through the application of advanced Deep Learning techniques. This technology can be exploited with harmful intentions, leading to the dissemination of misinformation, manipulation, and persuasive content. This paper explores multiple deep learning techniques designed for detecting deep fake images and videos. It conducts a comparative analysis of these techniques, including CNN models like ResNet, VGG16, and Efficient Net, along with RNN models like LSTM, to assess their effectiveness in deepfake video detection.",DeepFake detection;CNN;GAN;RNN;LSTM,IEE
176,Short And Low Resolution Deepfake Video Detection Using CNN,A. Rahman; N. Siddique; M. J. Moon; T. Tasnim; M. Islam; M. Shahiduzzaman; S. Ahmed,2022,"Recently, convincing deepfake videos are growing very fast that can delude even the trained experts. These deepfake videos have huge impacts all over the world covering the political, social, and personal lives. The state-of-the-art machine learning studies are demonstrating noticeable success to detect fake videos in high resolution and long-time video data while the same performance is not observed in low resolution and short-time clips. In this work, we have trained a convolutional neural network (CNN) that demonstrates mentionable accuracy in detecting fake videos in low-resolution and short-time video data. We have exploited Kaggle Deepfake Detection Challenge (DFDC) and the Face Forensics++ datasets in our experiment. Our model shows 94.93% accuracy in detecting fake videos for the DFDC dataset while the same is 93.2% for FaceForensics++ Dataset. We evaluated our models by different performance metrics and compared the performance with state-of-the-art methods. Our model demonstrates comparable performance.",Deepfake Video;Machine-Learning;dlib;Convolutional Neural Network(CNN);Deepfake-Detection-Challenge(DFDC);FaceForensics++,IEE
177,Deepfake Detection System Using Deep Neural Networks,M. L. Saini; A. Patnaik; Mahadev; D. C. Sati; R. Kumar,2024,"The rapid progress in technology and automation has enabled sophisticated manipulation of multimedia content, blurring the line between real and fabricated media. Deepfake technology, driven by deep learning and Generative Adversarial Networks (GANs), creates hyper-realistic fake content, with applications spanning video games, films, and advertising. However, this technology also carries substantial societal risks, fostering misinformation and explicit content. To mitigate these concerns, this paper presents a Deepfake detection system that utilizes deep neural networks to discern genuine from forged images. Frames are extracted from videos and face detection and face cropped are performed. LSTM and ResNext CNN are utilized to generate a feature vector. The proposed system uses the Anvil platform to design the front end and Visual Studio and Jupyter Notebook for the back end. A publicly available dataset was used to train and test the model. The proposed model achieved an impressive 86% accuracy on video dataset.",Deepfake;Fake contents;Deep Neural Networks;Generative Adversarial Networks (GANs);Anvil Platform,IEE
178,A Survey on Deepfake Video Detection Techniques Using Deep Learning,A. Das; K. S. A. Viji; L. Sebastian,2022,"Deep learning is an effective technology that has been widely used in different ways. �DeepFake� videos are generated using deep learning technology called generative adversarial network where the videos are created with swaped faces in a video, altered facial expressions, change of gender, creation of fake video content and altered facial features. Fake videos are used in the situations like extortion of money, terrorism events or create political agitation. The deepfake technologies are used for positive purposes, such as film-making and virtual reality. The good quality results from deepfakes are very hard to recognised with people eyes. Many deep learning techniques are built to detect deepfake content in images and videos. A comparative study of the performance of various deepfake videos detection models in the deep learning is preseted in this paper. Convolutional Neural Network (CNN) models include ResNet, VGG16, Efficientnet etc.. Recurrent Neural Network (RNN) model includes Long Short-Term Memory LSTM.",Deepfake video detection;Convolutional neural network (CNN);Recurrent neural network (RNN);Support vector machine (SVM),IEE
179,Methods of Deepfake Detection Based on Machine Learning,A. A. Maksutov; V. O. Morozov; A. A. Lavrenov; A. S. Smirnov,2020,"Nowadays, people faced an emerging problem of AI-synthesized face swapping videos, widely known as the DeepFakes. This kind of videos can be created to cause threats to privacy, fraudulence and so on. Sometimes good quality DeepFake videos recognition could be hard to distinguish with people eyes. That's why researchers need to develop algorithms to detect them. In this work, we present overview of indicators that can tell us about the fact that face swapping algorithms were used on photos. Main purpose of this paper is to find algorithm or technology that can decide whether photo was changed with DeepFake technology or not with good accuracy.",deep learning;DeepFake detection;neural networks;face swapping indicators,IEE
180,Explaining Deep Learning Models for Spoofing and Deepfake Detection with Shapley Additive Explanations,W. Ge; J. Patino; M. Todisco; N. Evans,2022,"Substantial progress in spoofing and deepfake detection has been made in recent years. Nonetheless, the community has yet to make notable inroads in providing an explanation for how a classifier produces its output. The dominance of black box spoofing detection solutions is at further odds with the drive toward trustworthy, explainable artificial intelligence. This paper describes our use of SHapley Additive exPlanations (SHAP) to gain new insights in spoofing detection. We demonstrate use of the tool in revealing unexpected classifier behaviour, the artefacts that contribute most to classifier outputs and differences in the behaviour of competing spoofing detection models. The tool is both efficient and flexible, being readily applicable to a host of different architecture models in addition to related, different applications. All results reported in the paper are reproducible using open-source software.",spoofing;presentation attack detection;explainability;Shapley additive explanations;ASVspoof,IEE
181,Employing Super Resolution to Improve Low-Quality Deepfake Detection,A. S. Perera; A. S. Atukorale; P. Kumarasinghe,2022,"The rapid progress in deepfake content generation has now come to a point where it raises significant concerns about the implications for society. Therefore, a new challenge of detecting deepfakes arises to protect individuals from potential misuse. Even though introduced detection algorithms perform well on high-quality deepfakes, detecting low-quality deepfakes has been challenging. As a remedy, researchers try to feed more training data to increase detection ability. HoWever, providing more data and processing them is not always feasible in a practical scenario. Thus, for the first time in this domain, we propose to employ super-resolution (SR) as a preprocessing step instead of feeding more data to improve low-quality deepfake detection. Extensive experiments were conducted on the FaceForensics++ deepfake dataset. Initially, three baseline models, Meso-4, MesoInception-4, and XceptionNet, were trained and tested on the dataset without any preprocessing mechanism. XceptionNet outperformed with 90.54% accuracy revealing deeper networks detect low-quality depfakes adequately. Then those baseline models were trained with SR preprocessing. To do that, we employed two SR networks, called VDSR and RSRGAN. RESRGAN+XceptionNet outperformed the previous baseline models by obtaining 96.05% accuracy, showing SR preprocessing usefulness in low-quality deepfake detection. Further experiments utilizing performance metrics, statistical tests, and visualization of activation maps showed that SR preprocessing is promising when applied to deepfake detection networks and detection algorithms experience a significant performance.",Deepfake;deep learning (DL);detection;low-quality;super-resolution (SR),IEE
182,Explainable Deep-Fake Detection Using Visual Interpretability Methods,B. Malolan; A. Parekh; F. Kazi,2020,"Deep-Fakes have sparked concerns throughout the world because of their potentially explosive consequences. A dystopian future where all forms of digital media are potentially compromised and public trust in Government is scarce doesn't seem far off. If not dealt with the requisite seriousness, the situation could easily spiral out of control. Current methods of Deep-Fake detection aim to accurately solve the issue at hand but may fail to convince a lay-person of its reliability and thus, lack the trust of the general public. Since the fundamental issue revolves around earning the trust of human agents, the construction of interpretable and also easily explainable models is imperative. We propose a framework to detect these Deep-Fake videos using a Deep Learning Approach: we have trained a Convolutional Neural Network architecture on a database of extracted faces from FaceForensics' DeepFakeDetection Dataset. Furthermore, we have tested the model on various Explainable AI techniques such as LRP and LIME to provide crisp visualizations of the salient regions of the image focused on by the model. The prospective and elusive goal is to localize the facial manipulations caused by Faceswaps. We hope to use this approach to build trust between AI and Human agents and to demonstrate the applicability of XAI in various real-life scenarios.",deep-fakes;deep-fake detection;faceswap;interpretability;explainable AI (XAI);LRP;LIME,IEE
183,Deep Fake Face Detection using Convolutional Neural Networks,M. Alben Richards; E. Kaaviya Varshini; N. Diviya; P. Prakash; P. Kasthuri; A. Sasithradevi,2023,"More fake face image generators have emerged worldwide owing to the growth of Face Image Modification (FIM) tools like Face2Face and Deepfake, which pose a severe threat to public trust. Although there have been significant advancements in the identification of certain FIM, a reliable false face detector is still lacking. Convolutional Neural Network (CNN) tends to learn picture content representations because of the structure's relative stability. A deep fake face detection model is developed by analyzing the visual features in a face. By the use of deep learning techniques, a CNN model is developed to identify deep fakes.",Deep fake;Convolutional Neural Network;Fake Face Detection,IEE
184,Detecting Deepfake Videos using Face Recognition and Neural Networks,M. A. Murugan; T. Mathu; S. J. Priya,2024,"Deepfake videos created using advanced artificial intelligence techniques, pose a significant threat to digital media credibility. This project introduces a holistic strategy for identifying these videos, incorporating face recognition, feature extraction, and an innovative deep-learning model. The methodology involves pre-processing video data, extracting facial features using the face recognition library, and training a neural network model on processed face-only videos. The project filters videos based on frame count, extracts face, and creates a curated dataset for the detection model. Face-only videos are loaded and pre-processed to train a custom neural network model, which combines a pre-trained ResNext CNN with an LSTM layer for temporal feature extraction. The model is trained using Adam optimization with a cross-entropy loss function, and after completion, it has an accuracy of 95% and is capable of differentiate between fake and real videos using a confidence score.",Deepfake video detection;celeb-df;face-recognition;LSTM;ResneXt,IEE
185,A Study on Deep Fake Face Detection Techniques,M. Arya; Priyanshu; Upwan; Akash; U. Goyal; S. Chawla,2024,"Advanced technology and the widespread use of deep fake technology has rendered the digital landscape vulnerable to deceptive manipulations, particularly through the creation of synthetic face images. This comprehensive review precisely traces the historical trajectory of deep fake faces, encompassing their evolution and its impact on various domains. It also investigates into the growing concerns regarding misinformation and privacy breaches. The literature review analyzes important works, pivotal milestones, and notable case studies, providing a complete understanding of the dynamic landscape of deep fake faces. This study analyzes existing detection techniques, ranging from neural networks to machine learning approaches, offering insights into the complexities of current methodologies. It sheds light on both the strengths and limitations of these techniques, emphasizing the need for robust solutions to counter adversarial attacks and address data scarcity. Building on this analysis, this study explores breakthroughs within the field of deep fake detection, highlighting instances where identification has been successful. It also underscores the ethical considerations that come with the evolution of these technologies. In proposing innovative solutions and discussing potential optimizations for existing techniques, the review explores interdisciplinary approaches and emerging technologies like blockchain and explainable AI. The findings provide a summary of key insights collected from the literature, identify research gaps, and project the future of deep fake face detection. This study concludes by emphasizing the ongoing societal impact of these developments in the digital era.",Deep Fake Technology;Synthetic images;Interdisciplinary Approaches;Deep Fake Detection;Synthetic Faces;Societal Impact;Detection Techniques,IEE
186,BTS-E: Audio Deepfake Detection Using Breathing-Talking-Silence Encoder,T. -P. Doan; L. Nguyen-Vu; S. Jung; K. Hong,2023,"Voice phishing (vishing) is increasingly popular due to the development of speech synthesis technology. In particular, the use of deep learning to generate an arbitrary-content audio clip simulating the victim�s voice makes it difficult not only for humans but also for automatic speaker verification (ASV) systems to distinguish. Countermeasure (CM) systems have been developed recently to help ASV combat synthetic speech. In this work, we propose BTS-E, a framework to evaluate the correlation between Breathing, Talking (speech), and Silence sounds in an audio clip, then use this information for deepfake detection tasks. We argue that natural human sounds, such as breathing, are hard to synthesize by Text-to-speech (TTS) system. We conducted a large-scale evaluation using ASVspoof 2019 and 2021 evaluation set to validate our hypothesis. The experiment results show the applicability of the breathing sound feature in detecting deepfake voices. In general, the proposed system significantly increases the performance of the classifier by up to 46%.",breathing sound;deepfake speech detection;sound segmentation,IEE
187,A Comparative Study of Deepfake Video Detection Method,K. N. Ramadhani; R. Munir,2020,"Deepfake technology allows humans to manipulate images and videos using deep learning technology. The results from deepfakes are very difficult to distinguish using ordinary vision. Many algorithms are built to detect deepfake content in images and videos. There are several approaches in deepfake detection, including a visual feature-based approach, a local feature-based approach, a deep feature-based approach and a temporal feature-based approach. The main challenge in developing deepfake detection algorithms is the variety of existing deepfake models in both images and videos. Another challenge is that deepfake technology is still evolving, making deepfake images and videos look more realistic and harder to detect.",deepfake;Generative Adversarial Networks;autoencoder;deep learning,IEE
188,Deepfake Detection in Videos and Picture: Analysis of Deep Learning Models and Dataset,S. S. Chauhan; N. Jain; S. C. Pandey; A. Chabaque,2022,"Deepfake detection is the concept of distinguishing a computer manipulated graphic from a real recorded graphic. The technology used for this purpose is deep learning. It is a sub branch of artificial intelligence. With technology becoming more readily available, deepfakes are also increasing in use in recent years. It becomes evident that a system is needed that detects deepfakes and prevents its use in suspicious activities. Development of a deepfake detection technology becomes evident to avoid the use of deepfakes in such activities. For this purpose, many tech giants have assimilated huge datasets which consist of videos that were made using deepfakes already available. To detect a deepfake, one requires an equally capable or even better algorithm and detection technique. Generative Adversarial Nets, GANs, is one such technique that might be able to rival other deepfake techniques. This paper will discuss various methods to apply to detect deep fakes along with the process, libraries used, dataset liabilities and limitations, analysis and efficiency. Since Deep Learning technology is evolving each day with new innovations, this paper provides a comparative study about methods that have already been tested and their limitations with respective models and how to possibly make them more efficient.",Generative Adversarial Nets;Deepfakes;Deep Learning.,IEE
189,Deepfake Creation Using Gans and Autoencoder and Deepfake detection,M. K. Das; M. Kumar; I. K. Kapil; R. K. Yadav,2023,"Deep learning techniques is useful in a myriad of applications such as computer vision processing, natural language processing, as well as deepfake detection. The development of deep learning algorithms for imaging detection has resulted in the development of deepfakes. These fakes employ advanced algorithms for deep learning to generate fake images that are extremely difficult to differentiate from authentic images. In a fake video, the face, expression or speech is replaced with an image of another's face, with a distinct speech or emotion with the help of the technology of deep learning. These videos are typically so sophisticated that the traces of manipulation are hard to spot. Social media are among the most frequently targeted and most serious because they are vulnerable platforms that are susceptible to blackmailing or making a person look bad. There are several existing efforts to detect fake images, but there have been very few efforts developed for video content on social media.",deep-fake;deep learning;GANS;autoencoder,IEE
190,Deepfake Detection Method Based on Face Edge Bands,Z. Deng; B. Zhang; S. He; Y. Wang,2022,"The rapid development of face forgery technology and the generation of realistic fake videos have caused serious harm to individuals, society and even the country, so it is important to detect deepfake videos. There are many detection methods available for forged videos, but the overall performance is yet to be improved and does not cope well with high quality forged images or videos. Observing that existing forgery algorithms leave synthetic forgery traces at the edges of faces when creating videos, this paper proposes a new method for detecting forged videos. It first finds the face edges from the video frames, then extracts the face edge bands as deep learning inputs and trains them based on EfficientNet-B3 to achieve effective detection of deepfake videos. Experiments show that the method in this paper can achieve more than 99.8% AUC values on all four forgery methods of the Face-Forensics++ dataset.",deepfake;detection;face edge;Efficient-Net,IEE
191,Detection of Deepfake Video using Deep Learning and MesoNet,L. Rebello; L. Tuscano; Y. Shah; A. Solomon; V. Shrivastava,2023,"Fraudsters are increasingly using evidence tampering to evade criminal charges and the acquisition of personal data for identity-related offenses. Deepfake is one of the most common strategies used today for identity theft and reputation defamation. To prevent the spread of these crimes, we need a system that can tell the difference between real and deep fake videos. Deep Neural Networks will be used in our system to identify and mark films as legitimate or manipulated, as well as the altered sections, by running the video through our trained Sequence Model, which can detect any discrepancies or alterations as a sequence of frames. LSTM will be used for temporal sequence analysis, and CNN will be employed for frame feature extraction. MesoNet is a neural network built primarily to identify deep fakes, but it would also be used for other purposes. MesoNet manages the noise produced by low-quality video processing, which impedes analysis. DeepFakes jeopardizes facial recognition and internet content. This deception is risky and can be exploited to impersonate a legitimate user. Our approach will propose a temporal-aware method for automatically detecting deepfake videos.",DeepFake Detection;Deep Learning;Neural Networks;Convolution Neural Network;Recurrent Neural Network;Long Short-Term Memory;MesoNet,IEE
192,An Efficient Deepfake Video Detection Approach with Combination of EfficientNet and Xception Models Using Deep Learning,S. Ata?; ?. ?lhan; M. Karak�se,2022,"Artificial intelligence is used in many areas and is constantly being developed. In recent years, videos made with deep fakes, which are often heard, have also developed. The use of videos made with deep fakes as blackmail in people's lives, manipulating the videos of important people to cause anxiety on people and etc. due to the fact that it poses a threat in many areas presents a big problem today. Efforts are being made to prevent this threat by detecting deep fake videos. Deep fake detection is still not fully resolved. For this reason, prominent technology companies provide support to researchers in this field and develop deep fraud detection by suggesting methods and organizing contests on most platforms such as Kaggle. In this article, a detection method is proposed to minimize the current concern of deep forgery. In the proposed method, the Xception model with high performance and speed and the EfficientNetB4 model with high accuracy were used. The proposed method aims to achieve better results and improvements in detecting fake videos.",,IEE
193,Deepfake Detection Using Deep Learning,P. R. S; P. D; S. G; S. R. K; G. B,2024,"In recent decades, rapid advancements in AI, machine learning, and deep learning have yielded new methods and tools for manipulating multimedia. While this technology has primarily found applications in legitimate fields such as entertainment and education, there have been instances of malicious users exploiting it for unlawful or nefarious purposes. For instance, individuals have used these techniques to create highly realistic fake videos, images, or audio recordings, with the intention of spreading misinformation, propaganda, inciting political discord, promoting hate, or even engaging in harassment and blackmail. These manipulated and hyper-realistic media have gained notoriety as �Deepfakes� in recent times. The literature has documented various approaches to address the challenges posed by Deepfakes.",Deepfake detection;video or image manipulation;digital media forensics,IEE
194,Comparison of Different Machine Learning Algorithms for Deep Fake Detection,Raveena; P. Punyani; R. Chhikara,2023,"Deepfake is a newly developed area of artificial intelligence technology that is widely used on social media and involves superimposing the facial features of one person over that of another. Machine learning is the primary component of deepfake creation, and it has made it possible for deepfake videos and pictures to be produced much more quickly and cheaply. Although the term ""deepfakes"" has a bad reputation, the technology is increasingly being used both professionally and personally. Although while it is still pretty new, recent technical developments make it harder and harder to distinguish between deep fakes and synthetic pictures. This study presents a comparative analysis of different algorithms, such as KNN, Support Vector Machine, Random Forest tree, Decision or Classification tree, and Na�ve Bayes algorithm. To evaluate the effectiveness of these algorithms, the dataset undergoes preprocessing before being used as input for each algorithm. Subsequently, their performance is measured by calculating and comparing metrics like F1-score, recall, precision, and accuracy.",Machine learning algorithms;classification problem;Random Forest;Na�ve Bayes;Support Vector Machine;Decision tree;KNN,IEE
195,Usage of Convolutional Neural Network for Deepfake Video Detection with Face-Swapping Technique,D. Stephen; T. Mantoro,2022,"Deepfakes have started to become a tool that brings a negative impact on society. There are various approaches that have been implemented in Deepfake Video detection, such as human-centered approach via dynamic prototypes, dynamic face augmentation, and usage of Neural Networks. However, some of the approaches that have been proposed only used several features, such as frame-by-frame detection. This paper will demonstrate the usage of Convolutional Neural Network (CNN) in detecting deepfake videos that are made with the face-swapping method. The aim of the study is to assess the feasibility of multiple combination between CNN architectures and their training dataset to detect deepfake videos made with face-swapping method that is taken from the Celeb-DF dataset. The assessment results in EfficientNetB4, combined with FaceForensics++, become the best model according to its detectability and false positive rate, when compared with other CNN architectures, while Xception trained with DFDC has the most minimum false positive rate, but the least detectability. Several improvements can be made to the research, such as the usage of GAN-based dataset for testing, usage of self-trained model with training dataset, usage of Siamese CNN architecture and comparison between Siamese and non-Siamese CNN architecture.",deepfake;video detection;CNN;deep learning;EfficientNet;Xception,IEE
196,Deep Fake Detection: Unmasking the Illusion using CNN and LSTM,V. Niranjani; S. Aishwarya; T. Devamitra; B. Jagapreetha,2023,"Concerns regarding the veracity of digital media have arisen due to the development of deepfake technology. In order to effectively combat this new threat, this study offers a novel deepfake detection strategy that combines a number of techniques, including Photoplethysmography (PPG). For the detection and classification of deepfakes, our solution combines PPG with sophisticated deep learning techniques. PPG records physiological signals, enhancing analysis of images and sounds. Convolutional neural networks (CNNs), long short-term memory (LSTM) networks, and audio fingerprinting are used to extract features from a large dataset that was used to train the system. A thorough study showing our multi-algorithm fusion approach�s improved performance in deepfake detection over single-algorithm approaches, including measures like accuracy and precision. This study also explores its resilience against adversarial attacks and consider ethical implications. This research work represents a significant advancement in deepfake detection, emphasizing the integration of various algorithms, including PPG, for improved accuracy and resilience. It has applications in media forensics, content verification, and online security, offering a comprehensive solution to the deepfake detection challenge while promoting responsible digital content authentication.",Deepfake;Machine Learning;Social Media;Digital harassing;Image and video analysis;Photoplethysmography (PPG);Convolutional Neural Networks (CNNs);Long Short-Term Memory (LSTM) networks,IEE
197,A Novel Machine Learning based Method for Deepfake Video Detection in Social Media,A. Mitra; S. P. Mohanty; P. Corcoran; E. Kougianos,2020,"With the advent of deepfake videos, video forgery has become a serious threat. Videos in social media are the most common and serious targets. There are some existing works for detecting deepfake videos but very few attempts have been made for videos in social media. This paper presents a neural network based method to detect fake videos. A model, consisting of a convolutional neural network (CNN) and a classifier network is proposed. Three different structures, XceptionNet, InceptionV3 and Resnet50 have been considered as the CNN modules and a comparative study has been made. Xception Net has been chosen in the proposed model and paired with the proposed classifier for classification. We used the FaceForensics++ dataset to reach the best model. Our model integrated in the algorithm detects compressed videos in social media.",Deepfake;Deep Learning;Depthwise Separable Convolution;Convolutional Neural Network (CNN);Transfer Learning;Social Media;Compressed Video.,IEE
198,Fakequipo: Deep Fake Detection,P. Bide; Varun; G. Patil; S. Shah; S. Patil,2022,"Deep learning have a variety of applications in different fields such as computer vision, automated self-driving cars, natural language processing tasks and many more. One of such deep learning adversarial architecture changed the fundamentals of the data manipulation. The inception of Generative Adversarial Network (GAN) in the computer vision domain drastically changed the way how we saw and manipulated the data. But this manipulation of data using GAN has found its application in various type of malicious activities like creating fake images, swapped videos, forged documents etc. But now, these generative models have become so efficient at manipulating the data, especially image data, such that it is creating real life problems for the people. The manipulation of images and videos done by the GAN architectures is done in such a way that humans cannot differentiate between real and fake images/videos. Numerous researches have been conducted in the field of deep fake detection. In this paper, we present a structured survey paper explaining the advantages, gaps of the existing work in the domain of deep fake detection.",GAN;Visual Transformer;Deep Fake Detection,IEE
199,Detecting Deepfake Human Face Images Using Transfer Learning: A Comparative Study,H. Vajpayee; N. Yadav; A. Raj; S. Jhingran,2023,"Deepfake technology has made it easy to create realistic, manipulated videos and images, raising concerns about the potential for them to be used to spread misinformation or harm individuals. Deepfake technology has advanced significantly in recent years, making it increasingly difficult to distinguish between real and fake images. This has raised concerns about the potential for deepfake images to be used maliciously, for example, in political propaganda or cyber fraud. As a result, there is a growing need for effective methods of detecting deepfake images. So, it became important to propose an effective classification on deepfake. In this paper the authors have proposed an effective classification on deepfake images using Transfer Learning. This approach will help in classification of Real and fake through Human face images. The authors have utilized Real vs Fake Face classification dataset to apply the proposed approach. The Loss, Accuracy, Precision, Recall, AUC, and F1 Score parameters have been used to analyze the performance of proposed approaches. The outcome of this work shows the EfficientNetV2L Model with the accuracy of 99% as compared among EfficientNetV2B0-B3 and S, M, L models.",Deep Learning (DL);EfficientNetV2L;Deepfake;Classification;Transfer learning,IEE
200,Implementation of a Deepfake Detection System using Convolutional Neural Networks and Adversarial Training,S. Bommareddy; T. Samyal; S. Dahiya,2023,"Due to the threat of spreading erroneous information, the employment of deep convolutional neural network (CNN) techniques has resulted in an increase in the number of altered images. A trustworthy and effective mechanism for identifying false photographs is required to solve this problem. In this study, we used the V4D architecture to analyze manipulated videos and concentrated on identifying DeepFake videos in three different contexts: I identifying all types of manipulations, (ii) identifying single manipulations, and (iii) identifying cross manipulation detection, which was used to assess the videos' authenticity. To do this, we used a variety of manipulation techniques and created algorithms to classify undiscovered manipulation methods.",Deepfakes;Deepfake Detection;Media forensics;Facial Manipulation Detection;Convolutional Neural Networks;Manipulation techniques;Generative Adversarial Networks,IEE
201,AI-Generated Video Forgery Detection and Authentication,A. K. Tiwari; A. Sharma; P. Rayakar; M. K. Bhavriya; Nisha,2024,"Deep learning has a variety of uses and issues it can solve in the real world, but it also has some limitations. The growing use of AI-Morped Videos is one of the most recent and complicated issues. ""AI Morphed Videos,"" which are digitally manipulated still or moving visuals, are made using deep learning techniques. In an AI Morphed Video, the target�s face is superimposed over the original image so that the altered digital data can be used for online frauds, extortion, pornography, etc. It is getting harder and harder to manually discern between true and false as deep learning develops. Therefore, research and development in the field of AI Morphed Video detection are crucial. An overview of the several AI Morphed Video detection strategies is completed in time for the classification of feature-based, temporal-based, and deep feature-based AI Morphed Video detection. The comparison research is based mostly on the key features used, including the face detection architecture, the deep learning architecture, whether it is video-based or image-based, the dataset used, the frames size, and the dataset size used. Along with the comparison, a semi-supervised GAN architecture is also proposed and built to recognize the AI Morphed Video.",AI Morphed Video Detection;AI;DL;auto encoders;generative adversarial network;Video forgery,IEE
202,Detection of Deep Fake Images Using Convolutional Neural Networks,G. Aggarwal; A. K. Srivastava; K. Jhajharia; N. V. Sharma; G. Singh,2023,"Images are frequently manipulated for various purposes, often serving the interests of specific parties. Given that images are commonly regarded as evidence of reality, their manipulation can significantly contribute to the spread of fake news or misleading information. Detecting such image falsifications necessitates access to extensive image data and the development of models capable of scrutinizing each pixel within an image. Furthermore, ensuring efficiency and flexibility in data training is vital to support practical applications. Big data and deep learning concepts, particularly the Convolutional Neural Network (CNN) architecture utilizing Error Level Analysis (ELA), have proven highly effective, achieving a forgery detection rate of 91.83% with convergence in just 9 epochs.",Deep fake detection;Convolutional Neural Networks (CNNs);Image forensics;image recognition;image analysis,IEE
203,Deepfake Detection: A Systematic Literature Review,M. S. Rana; M. N. Nobi; B. Murali; A. H. Sung,2022,"Over the last few decades, rapid progress in AI, machine learning, and deep learning has resulted in new techniques and various tools for manipulating multimedia. Though the technology has been mostly used in legitimate applications such as for entertainment and education, etc., malicious users have also exploited them for unlawful or nefarious purposes. For example, high-quality and realistic fake videos, images, or audios have been created to spread misinformation and propaganda, foment political discord and hate, or even harass and blackmail people. The manipulated, high-quality and realistic videos have become known recently as Deepfake. Various approaches have since been described in the literature to deal with the problems raised by Deepfake. To provide an updated overview of the research works in Deepfake detection, we conduct a systematic literature review (SLR) in this paper, summarizing 112 relevant articles from 2018 to 2020 that presented a variety of methodologies. We analyze them by grouping them into four different categories: deep learning-based techniques, classical machine learning-based methods, statistical techniques, and blockchain-based techniques. We also evaluate the performance of the detection capability of the various methods with respect to different datasets and conclude that the deep learning-based methods outperform other methods in Deepfake detection.",Deepfake detection;video or image manipulation;digital media forensics;systematic literature review,IEE
204,Exploring Green AI for Audio Deepfake Detection,S. Saha; M. Sahidullah; S. Das,2024,"The state-of-the-art audio deepfake detectors leveraging deep neural networks exhibit impressive recognition performance. Nonetheless, this advantage is accompanied by a significant carbon footprint. This is mainly due to the use of high-performance computing with accelerators and high training time. Studies show that average deep NLP model produces around 626k lbs of CO2 which is equivalent to five times of average US car emission at its lifetime. This is certainly a massive threat to the environment. To tackle this challenge, this study presents a novel framework for audio deepfake detection that can be seamlessly trained using standard CPU resources. Our proposed framework utilizes off-the-shelve self-supervised learning (SSL) based models which are pre-trained and available in public repositories. In contrast to existing methods that fine-tune SSL models and employ additional deep neural networks for downstream tasks, we exploit classical machine learning algorithms such as logistic regression and shallow neural networks using the SSL embeddings extracted using the pre-trained model. Our approach shows competitive results compared to the commonly used high-carbon footprint approaches. In experiments with the ASVspoof 2019 LA dataset, we achieve a 0.90% equal error rate (EER) with less than 1k trained model parameters. To encourage further research in this direction and support reproducible results, the Python code will be made publicly accessible following acceptance 1.",ASVspoof;Anti-spoofing;Audio deepfake detection;Green AI;Low-carbon footprint;Self-supervised learning,IEE
205,Audio Deepfake Detection Using Data Augmented Graph Frequency Cepstral Coefficients,M. Dua; S. Meena; Neelam; Amisha; N. Chakravarty,2023,"Automatic speaker verification (ASV) systems serve an important role in identifying speakers in a variety of domains by enabling authentication, convenience, fraud detection, personalization, and forensic applications. The demand for ASV systems originates from how simple and effective speech biometrics may be. The growing popularity of such applications raises concerns about the growing possibility of speech attack. The purpose of this research is to identify audio spoofing attacks in an ASV system. The suggested model has a front -end and a back -end. The front -end has two features: Gammatone Cepstral Coefficients (GTCC) and Graph Frequency Cepstral Coefficients (GFCC) based on Spectrograms. Four machine learning models are utilised in the backend: Logistic Regression (LR), Decision Tree (DT), Support Vector Machine (SVM), and K-nearest Neighbour (KNN), as well as one deep learning model named Long Short -Term Memory (LSTM) and a transfer learning based pertained ResNet 50 model. The Logical Access (LA) partition of ASVspoof 2021 is used for training, whereas the Deepfakes (DF) portion of ASVspoof 2021 is used for testing. To address the issue of dataset imbalance, methods such as SpecAugment and Speed perturbation are used to extracted features, particularly GTCC features. For deep fake detection, the suggested model, which combines GFCC with pretrained ResNet50, obtains an outstanding Equal Error Rate (EER) of 1.78% and a tandem-Detection Cost Function (t-DCF) of 0.0458min.",ASV;GTCC;EER;LA;GSP;ResNet50;LSTM,IEE
206,"Enhancing Deepfake Detection for Public Awareness, Law Enforcement and Legal Verification",J. Y. Ng; S. C. Chong; K. K. Wee,2024,"In recent years, as you can see the emergence of deepfake technology had raised worrying concerns in various sectors, including politics, the media industry and most importantly cybersecurity. As deep fakes they can manipulate audio and video content created using deep learning techniques. This research aims to investigate and discover the best methods to detect and uncover deep fake content which also addresses the needs for a reliable deepfake method. The study�s approach, which integrates multimodal data fusion and leverages NAS, achieved outstanding results, reaching 99.37% accuracy after 15 epochs. This performance surpasses benchmarks set by traditional CNNs and earlier GAN-based methods. Experiments were conducted using two datasets, FaceForensics++ and Celeb-DF (v2), further validating the robustness of the method. These findings underscore the effectiveness of automated deep learning in combating digital misinformation",Deepfake;Neural Architecture Search;Machine Learning;Deep Learning;Cybersecurity,IEE
207,Hybrid Deepfake Detection Utilizing MLP and LSTM,J. Mallet; N. Krueger; R. Dave; M. Vanamala,2023,"The growing reliance of society on social media for authentic information has done nothing but increase over the past years. This has only raised the potential consequences of the spread of misinformation. One of the growing methods in popularity is to deceive users through the use of a deepfake. A deepfake is a new invention that has come with the latest technological advancements, which enables nefarious online users to replace one's face with a computer-generated, synthetic face of numerous powerful members of society. Deepfake images and videos now provide the means to mimic important political and cultural figures to spread massive amounts of false information. Models that are able to detect these deepfakes to prevent the spread of misinformation are now of tremendous necessity. In this paper, we propose a new deepfake detection schema utilizing two deep learning algorithms: long short-term memory and multilayer perceptron. We evaluate our model using a publicly available dataset named 140k Real and Fake Faces to detect images altered by a deepfake with accuracies achieved as high as 74.7%.",Deepfake;Machine Learning;Fake Image Detection;Long Short-Term Memory;Multilayer Perceptron,IEE
208,Enhancing Global Security: A Robust CNN Model for Deepfake Video Detection,M. Solaiman; M. S. Rana,2024,"In recent years, the rapid advancements in machine learning (ML), artificial intelligence (AI), and deep learning (DL) have ushered in a new era of sophistication in image and video manipulation techniques. Notably, the emergence of Deepfake technology, driven by AI, has garnered substantial attention. Deepfakes involve training DL models on extensive datasets of similar faces and subsequently mapping one person's expressions onto another's face, resulting in deceptively realistic fake videos that can be virtually indistinguishable from authentic ones. The proliferation of Deepfakes poses various threats, including the potential to incite political turmoil, coerce individuals, or fabricate false terrorist incidents. This trend undermines privacy, consent, and the trustworthiness of digital media. Consequently, there is a pressing need to continually advance Deepfake detection and prevention methodologies to safeguard against their malevolent use and uphold the integrity of digital content. This paper introduces a Convolutional Neural Network (CNN) based DL model specifically developed for the classification of Deepfake video frames. Our model exhibits impressive performance, as validated by a thorough analysis on the VDFD dataset, where it achieves an outstanding average precision, recall, and F1-score of 95%, 94%, and 94%, respectively. Moreover, our model showcases its efficacy across various widely recognized Deepfake datasets, including FF++, Celeb-DF, and DFDC, with frame detection average rates for precision, recall, and F1-score ranging from 80% to 85%. These compelling results signify that our proposed CNN-based frame detection technique is a powerful tool for Deepfake detection, emphasizing the critical significance of automated Deepfake detection with an exceptionally high detection rate. This technology represents a pivotal step toward protecting against the potential misuse of Deepfakes, reinforcing the security and integrity of digital content in our modern world.",Global Security;Deepfakes;Deepfake detection;CNN;Versatile Deepfake Dataset;Video manipulation detection,IEE
209,Intelligent Deep Detection Method for Malicious Tampering of Cancer Imagery,K. M. A. Alheeti; A. Alzahrani; N. Khoshnaw; D. Al-Dosary,2022,"In recent years, deep generative networks have reinforced the need for caution while consuming different formats of digital information. One method of deepfake generation involves the insertion and removal of tumors from medical scans. Significant drains on hospital resources or even loss of life are the consequences of failure to detect medical deepfakes. This research attempts to evaluate machine learning algorithms and pre-trained deep neural networks' (DNN) ability to distinguish tampered data and authentic data. Moreover, this research aims to classify cancer scans based on DNN. The experimental results show that the proposed method based on using DNN can enhance performance detection. Furthermore, the proposed system increased the detection accuracy rate and reduced the number of false alarms.",deepfake;medical image tampering;machine learning;DNN;detection accuracy;false alarms,IEE
210,Synthetic Voice Detection and Audio Splicing Detection using SE-Res2Net-Conformer Architecture,L. Wang; B. Yeoh; J. W. Ng,2022,"Synthetic voice and splicing audio clips have been generated to spoof Intemet users and artificial intelligence (AI) technologies such as voice authentication. Existing research work treats spoofing countermeasures as a binary classification problem: bonafide vs. spoof. This paper extends the existing Res2Net by involving the recent Conformer block to further exploit the local patterns on acoustic features. Experimental results on ASVspoof 2019 database show that the proposed SE-Res2Net-Conformer architecture is able to improve the spoofing countermeasures performance for the logical access scenario. In addition, this paper also proposes to re-formulate the existing audio splicing detection problem. Instead of identifying the complete splicing segments, it is more useful to detect the boundaries of the spliced segments. Moreover, a deep learning approach can be used to solve the problem, which is different from the previous signal processing techniques.",spoofing countermeasures;audio splicing detection;Res2Net;synthetic voice detection;deepfake,IEE
211,Analysis of Deepfake Detection Techniques,B. Puri; J. Kumar; S. Mukherjee; B. S. V,2023,"The proliferation of deepfakes, utilizing sophisticated machine learning algorithms to create falsified media content, is a growing concern for society. This study aims to delve deeper into the different methods used for detecting deepfakes, and assess their effectiveness in identifying manipulated content. Specifically, we are interested in exploring the factors that impact the accuracy of these detection methods, including the quality of source material and the complexity of the deepfake algorithm. By analyzing existing research and experimentation, this paper offers insights into the challenges and limitations of deepfake detection and highlights the need for continued innovation in this field. Ultimately, our research paper aims to contribute to ongoing efforts to combat the spread of deepfakes and promote the creation of trustworthy media content that accurately represents reality.",,IEE
212,Deepfake Detection Using CNN and DCGANS to Drop-Out Fake Multimedia Content: A Hybrid Approach,K. Bansal; S. Agarwal; N. Vyas,2023,"The creation of Deep Fakes, which are altered videos, audio, and photographs capable of disseminating false information and fake news and modifying sensitive records, is the result of the rapid advancements in artificial intelligence and machine learning. DeepFakes may also be used for interactive learning and visual effects in entertainment and education. As a result, numerous deep learning models, such as Convolutional Neural Networks (CNN) and Generative Adversarial Networks (GAN), are being used for detection. DeepFakes detection and removal have become essential challenges. Facebook AI's Deepfake Detection Challenge (DFDC) dataset is invaluable for developing and evaluating detection techniques. While it represents serious risks, creating trustworthy detection techniques might lessen their impact and enable investigation of their possible beneficial applications. To ensure the authenticity and dependability of multimedia information in the face of the ongoing DeepFake threat, this paper emphasizes the importance of transfer learning, deep learning, and optimization techniques in building effective detection models. By doing this, we can stop the spread of fake news and information, protect the public's trust, and promote the moral and beneficial application of DeepFake technology across various fields.",Transfer Learning;Deep Learning;Convolutional Neural Networks (CNN);Image Classification;ImageNet;Optimization Techniques,IEE
213,Two-Branch Deepfake Detection Network Based on Improved Xception,R. Zhang; Z. Jiang; C. Sun,2023,"With the continuous development of computer technology, the level of AI technology has also been greatly improved. But it comes with growing security and ethical challenges, including deep fake faces. While current detection methods work well in high definition video, they often do not perform as well when detecting relatively low definition video. For example, the clarity of the forged video is often too low, the quality compression of the video on the social platform and the level of the user's own equipment lead to the clarity is not too high, which makes the detection accuracy need to be improved. At the same time, the quality of detection across data sets also needs to be improved. To solve these problems, this paper proposes a two-branch detection network based on improved Xception. The network consists of a whole branch that detects the whole detected video and a local branch that detects each frame of the video. The whole branch uses the improved Xception network and Gated Recurrent Unit (GRU) to detect the whole video to be detected. The local branch uses the improved Xception network and a series of data enhancement measures, including Face-Cutout, to detect every frame of the detected video. To verify the effectiveness of the algorithm, tests were performed on the FF+ dataset and the Celeb-DF dataset. The experimental results show that the detection level of the proposed method is better than other detection networks, and it has better detection performance in cross-dataset and cross-definition scenarios, which proves the effectiveness of the proposed method.",deepfake;deep learning;attention;Xception;forgery detection,IEE
214,"Detection of Deepfake Images and Videos Using SVM, CNN, and Hybrid Approaches",I. S. Stankov; E. E. Dulgerov,2024,"The proliferation of deepfake technology, driven by advancements in artificial intelligence, particularly generative adversarial networks (GANs), has introduced new challenges in verifying the authenticity of multimedia content. Deepfakes can create highly realistic fake images and videos that are difficult to distinguish from real ones, posing significant threats to privacy, security, and information integrity. This study investigates the effectiveness of three machine learning models�Support Vector Machine (SVM), Convolutional Neural Network (CNN), and a combined CNN-SVM approach�in identifying deepfake images and videos. By leveraging a dataset containing both real and computer-generated content, we trained and evaluated each model on their ability to accurately classify these media types.",Deepfake;SVM;CNN;Combined Approach;Image Analysis;Video Analysis;Machine Learning,IEE
215,A Lightweight CNN for Efficient Deepfake Detection of Low-resolution Images in Frequency Domain,S. D; R. S; S. Ravi; V. M; P. M. P. U,2024,"Deepfake detection in frequency domain is extensively explored for two reasons �artifacts generated by the up-sampling layer of Generative Adversarial Networks are more prominent in the frequency domain and some image processing tasks are simpler and efficient in this domain. Traditional convolutional neural networks outperform the machine learning models for their ability to detect deepfakes of low-resolution images also. But these networks involve numerous trainable parameters resulting in huge computation cost, time and high memory requirements. This paper presents a lightweight Convolutional Neural Network (CNN) architecture that is optimized for efficient deepfake detection of low-resolution images in the frequency domain. The proposed model achieves almost the same accuracy as that of the traditional network but with the parameter requirement reduced by 92%. This renders the model suitable for use in memory-constrained and power-constrained environments such as mobile devices and other embedded systems.",Deepfake detection;frequency domain;pixel domain;lightweight CNN;depthwise separable convolution,IEE
216,Frequency Masking for Universal Deepfake Detection,C. T. Doloriel; N. -M. Cheung,2024,"We study universal deepfake detection. Our goal is to detect synthetic images from a range of generative AI approaches, particularly from emerging ones which are unseen during training of the deepfake detector. Universal deepfake detection requires outstanding generalization capability. Motivated by recently proposed masked image modeling which has demonstrated excellent generalization in self-supervised pre-training, we make the first attempt to explore masked image modeling for universal deepfake detection. We study spatial and frequency domain masking in training deepfake detectors. Based on empirical analysis, we propose a novel deepfake detector via frequency masking. Our focus on frequency domain is different from the majority, which primarily target spatial domain detection. Our comparative analyses reveal substantial performance gains over existing methods. Code and models are publicly available1.",deepfake;masked image modeling;generative AI;GAN;diffusion models,IEE
217,Deep learning based DeepFake video detection,S. Guefrachi; M. Ben Jabra; N. A. Alsharabi; M. T. Ben Othman; Y. O. Alharabi; A. Alkholidi; H. Hammam,2023,"Recent advances in DeepFake face-swapping technology have made it simple to create fake videos that appear remarkably real. Since it has been employed in numerous instances for deceit, extortion, and the falsification of facts, its widespread use has generated a huge social, security, and political risk. Its use on websites and social media has become more widespread. Detecting this crime is becoming more and more important due to the potential harm false videos may inflict on a global scale. This research offers a method for building a deep learning model that really can tell the difference between authentic and false videos. The article describes how to create new models based on the VGG16 neural network, a previously created neural network that does image categorization, using transfer learning in the computer vision field. Deep learning is still becoming better at both producing and spotting DeepFakes. DeepFake detection algorithms are developed using dated public datasets, and as a result, they may become obsolete with time. and require continual updating. The research findings are encouraging, and our results reached an accuracy rate of over 90%.",Deep-fake detection;Video authenticity;Fine-tuning;VGG16,IEE
218,Deepfake Audio Detection via MFCC Features Using Machine Learning,A. Hamza; A. R. R. Javed; F. Iqbal; N. Kryvinska; A. S. Almadhor; Z. Jalil; R. Borghol,2022,"Deepfake content is created or altered synthetically using artificial intelligence (AI) approaches to appear real. It can include synthesizing audio, video, images, and text. Deepfakes may now produce natural-looking content, making them harder to identify. Much progress has been achieved in identifying video deepfakes in recent years; nevertheless, most investigations in detecting audio deepfakes have employed the ASVSpoof or AVSpoof dataset and various machine learning, deep learning, and deep learning algorithms. This research uses machine and deep learning-based approaches to identify deepfake audio. Mel-frequency cepstral coefficients (MFCCs) technique is used to acquire the most useful information from the audio. We choose the Fake-or-Real dataset, which is the most recent benchmark dataset. The dataset was created with a text-to-speech model and is divided into four sub-datasets: for-rece, for-2-sec, for-norm and for-original. These datasets are classified into sub-datasets mentioned above according to audio length and bit rate. The experimental results show that the support vector machine (SVM) outperformed the other machine learning (ML) models in terms of accuracy on for-rece and for-2-sec datasets, while the gradient boosting model performed very well using for-norm dataset. The VGG-16 model produced highly encouraging results when applied to the for-original dataset. The VGG-16 model outperforms other state-of-the-art approaches.",Deepfakes;deepfake audio;synthetic audio;machine learning;acoustic data,IEE
219,Improving the Generalization Ability of Deepfake Detection via Disentangled Representation Learning,J. Hu; S. Wang; X. Li,2021,"Deepfake refers to a deep learning based technology which can synthesize visually realistic face images/videos. The misuse of this technology poses a great threat to the society. Although numerous approaches have been proposed to detect Deepfake forgeries, their generalization ability on unseen datasets is limited. In this paper, we propose a new approach that detects human face forgeries by automatically locating the forgery-related region to make the final decision. The proposed network contains two modules, including: the disentanglement module to extract forgery relevant information and the classification module to detect the manipulation artifacts from various regions at different scales. The experiment results on three widely used Deepfake datasets show that the proposed approach can achieve high detection accuracies and outperforms several state-of-the-arts methods especially when evaluated on the unseen datasets.",Disentangle representation learning;Deep-fake detection;deep neural network,IEE
220,A Review on the Detection of Deep Fake and Propaganda Videos and Images-based Voice and Facial Manipulation using AI Techniques,M. Thanga Raj; M. Arunachalam; R. Ramalakshmi; K. Ramaraj; M. Arunachalam; P. Kaleeswari,2023,"The videos or images based on deep fake video is the creation of artificial intelligence models namely deep and machine learning techniques to superimpose, replace, combine and merge images as well as clips of videos thereby generating a video as fake, which seems trustworthy. Without involving this consent, the explicit content is generated is Deep-fake videos. Recently, Artificial Intelligence (AI) model is widely addressing the exciting task of autonomous control, object detection, image processing and enlarge data analysis. During the past years, the videos, images and audio are the form of deep fakes. A deepfake determination desires an evolution of technology. A person�s face or voice is swapped with another one during deepfakes thereby providing higher accurate videos. A deepfake determination desires an evolution of technology. To detect face or voice manipulation, novel AI models namely ML and DL to solve the deepfake detection challenges. The main objective of this research is to provide existing studies related to the detection of deepfake video or images based on different techniques, benchmark dataset, and discussion and future directions.",Deepfake videos or images;Image processing models;Authentication;Machine learning;Deep learning,IEE
221,Deep Fake Detection using Advance ConvNets2D,K. S; V. K. A; S. P. P; P. M,2023,"Even a few decades ago, it would have been impossible to foresee the widespread use of deep learning to tackle such complex issues. It has many positive applications but it can also be misused to cause harm to the society. One such challenge is deep fakes, and now more than ever, when anyone with a smartphone app can create a fake image or video, it is crucial to take measures to authenticate the content online. Visual and auditory �deepfakes� may be generated with the aid of neural networks. Deepfake mimics machine learning models with the help of Generative Adversarial Networks. Many well-known people have been affected by the rapid spread of false news stories on social media platforms like Facebook, YouTube, Twitter, etc. Artificial Neural Network (ANN) based deep fakes may appear identical to authentic images or videos before being moderated but they always have spatial and temporal signatures. A neural network has been trained to specialize in Deep fake detection can quickly identify these signs. To determine whether or not a video is deep fake, Residual Network and InceptionResNetV2 models are employed in this research.",Neural networks;GAN;Residual Networks;Image;Video;InceptionResNet.,IEE
222,Deepfake Video Detection System Using Deep Neural Networks,S. R. B. R; P. Kumar Pareek; B. S; G. G,2023,"A deepfake is a type of synthetic media that uses artificial intelligence and machine learning techniques to manipulate or superimpose images, videos, or audio onto existing footage in a way that appears authentic and realistic, often with the intent to deceive or mislead viewers. There are several approaches to using neural networks for deep fake detection. One approach is to use a convolutional neural network (CNN) [1] to analyze the visual artifacts in the image or video. The CNN can detect inconsistencies or anomalies in the image or video that are indicative of manipulation, such as differences in lighting or blurring at the edges of the image. ResN et-50 has been used in deepfake detection by training the network on a large dataset of real and fake videos In this paper, Resnet50 and LSTM [13] are combined to make a hybrid architecture are used in deep fake video detection as a web framework using python. Combining ResNet50 and LSTM can help to leverage the strengths of both architectures and improve the accuracy of deep fake video detection, especially for videos that involve both image-based and sequential data. A comparative analysis of different models were assessed using various datasets such as Celeb-DF, Face Forensic++ datasets.",Convolutional Neural Network;ResNet50;LSTM;Deep Fake;GAN,IEE
223,Comparative analysis of deepfake detection methods using machine learning and deep learning,P. Agrawal; S. Pathak; S. Potey; V. Dhengre; N. Rakesh; R. Parvathi,2024,"The paper examines the growing issue of deepfake technology, which uses cutting-edge machine learning to spoof face features in videos. This technology has the potential to be abused in a number of situations, including blackmail, political manipulation, and the staging of terrorist acts. The study�s main goal is to present a thorough summary of current studies that use cutting-edge deep learning techniques to identify fake information. The Deepfakes Detection Challenge (DFDC) dataset is introduced, neural network applications are covered, and the effectiveness of current deepfake detection models is assessed. Because deepfake applications potentially pose a hazard, the research emphasizes the need for tools that can automatically detect and evaluate the integrity of digital visual data. Additionally, it discusses numerous algorithms and approaches that have been put out in the literature for producing and identifying deepfakes, with a focus on deep learning-based methods.",Convolutional Neural Network;Video Forensic;Recurrent Neural Network;Xception;Machine learning;DeepLearning;Detection.,IEE
224,Enhancing Face Forgery Detection in a Decentralized Landscape: A Federated Learning Approach with ResNet,V. Gautam; H. Maheshwari; R. G. Tiwari; A. K. Agarwal; N. K. Trivedi,2023,"Recent advancements in technologies could be the reason for fake image and video generation over the internet. This may be the cause of fake identity creation over the internet for forgery. These types of acts may be the reason for security issues in society. The legacy fake forgery method is not that capable of recognizing such forgery as the methods are trained with publicly available centralized datasets and never focus on privacy and security issues and adversely influence the forgery detection. Hence, the objective of this research is to provide decentralized ways to handle these issues effectively. The issue is taken care of with an effective federated learning-based deep learning technique. In the proposal, several deep learning models were used to generate a residual feature map from the available image dataset and later federated learning was used to generate a decentralized infrastructure for collaborative client machines. The complete experiment setup is established with a publicly available dataset and various variable parameters are used such as the number of clients and round of communication. Afterward, deep learning models� performance is compared for forgery detection under federated learning environments, and it has been observed that ResNet deep learning outperforms with an accuracy rate of 87.83% in FaceForensic dataset.",Facial Forgery Detection;Deep Learning;Feature Learning;Federated Learning;Privacy-Preserving,IEE
225,Forensics and Analysis of Deepfake Videos,M. T. Jafar; M. Ababneh; M. Al-Zoube; A. Elhassan,2020,"The spread of smartphones with high quality digital cameras in combination with easy access to a myriad of software apps for recording, editing and sharing videos and digital images in combination with deep learning AI platforms has spawned a new phenomenon of faking videos known as Deepfake. We design and implement a deep-fake detection model with mouth features (DFT-MF), using deep learning approach to detect Deepfake videos by isolating, analyzing and verifying lip/mouth movement. Experiments conducted against datasets that contain both fake and real videos showed favorable classification performance for DFT-MF model especially when compared with other work in this area.",Deep Learning;Python;Deepfake;Videos;Digital Forensics;Manipulation;Detection;Classification;Segmentation,IEE
226,Preserving Visual Authenticity: Block chain-Augmented AI Frameworks for Advanced Digital Deception Recognition and Mitigation,M. Priya; J. Murugesan; P. Bhuvaneswari; M. Rubigha; S. Lalithambikai; B. Mohanraj,2024,"The rapid advancements in deep learning have given rise to sophisticated DeepFake technologies, posing significant threats to visual integrity and authenticity in digital media. This paper presents an innovative approach to DeepFake detection and mitigation by integrating blockchain technology with artificial intelligence frameworks. The proposed Blockchain-Augmented AI (BAAI) framework utilizes the immutability and decentralized nature of block chain to enhance the security and reliability of the detection process. Our method involves the development of advanced AI models for detecting DeepFakes, which are then integrated with a blockchain-based ledger to ensure the verifiability and traceability of detection results. In this proposed work, a novel integration of blockchain technology and AI designed to enhance DeepFake detection capabilities. The framework achieves a $97 \%$ accuracy rate, ensuring reliable identification of manipulated media, while maintaining a low false positive rate of 3%. These results highlight the BAAI framework�s effectiveness in minimizing erroneous detections and its robustness in safeguarding digital visual content. In the face of increasingly sophisticated DeepFake technologies, this framework offers a crucial advancement in combating digital deception.",DeepFake Detection;Visual Integrity;Blockchain-Augmented AI (BAAI);Detection Accuracy;False Positives;Detection Precision;Media Authenticity,IEE
227,An Enhanced Deepfake Video Detection Technique,M. Alkaabi; M. Albloushi; A. Alkaabi; A. Alhammadi; F. Alketbi; M. M. Masud,2023,"A deepfake is a piece of digital material that has been altered, such as a picture or a video in which the subject�s likeness has been substituted. Deepfake is a real danger to society since it distorts the opinions and perceptions of those around us. Deep learning, which is referred to as �a subset of AI,� is used to create deepfake. Deep learning is a combination of algorithms with the ability to learn and make sensible decisions on their own. People may be led astray by deepfake into believing something to be genuine when it is not. In the hands of internet scammers and cybercriminals, such cutting-edge technologies as deepfake can become dangerous tools. Deepfakes can be hard to spot, making it tough to stop the dissemination of fake content. Additionally, anyone with little programming knowledge can make deepfakes because they can be made with relatively simple tools. Understanding the dangers of deepfake, we are motivated to understand the technology behind deepfake generation, search for technologies to counter this threat, and develop effective detection techniques to accurately identify deepfake videos with high efficiency. In order to achieve this, we have conducted an extensive literature search on various algorithms for creating and detecting deepfake videos. We have identified their relative strengths and limitations, and areas for potential improvements. We have developed to enhance the current detection techniques by designing and developing a new technique that can effectively identify fake videos with multiple faces.",deepfake;deep learning;generative adversarial network;deepfake video detection,IEE
228,Detecting Fake Audio of Arabic Speakers Using Self-Supervised Deep Learning,Z. M. Almutairi; H. Elgibreen,2023,"One of the most significant discussions in forensics is Audio Deepfake, where AI-generated tools are used to clone audio content of people�s voices. Although it was intended to improve people�s lives, attackers utilized it maliciously, compromising the public�s safety. Thus, Machine Learning (ML) and Deep Learning (DL) methods have been developed to detect imitated or synthetically faked voices. However, the developed methods suffered from massive training data or excessive pre-processing. To the author�s best knowledge, Arabic speech has not yet been explored with synthetic fake audio, and it is very limited to the challenged fakeness, which is imitation. This paper proposed a new Audio Deepfake detection method called Arabic-AD based on self-supervised learning techniques to detect both synthetic and imitated voices. Additionally, it contributed to the literature by creating the first synthetic dataset of a single speaker who perfectly speaks Modern Standard Arabic (MSA). Besides, the accent was also considered by collecting Arabic recordings from non-Arabic speakers to evaluate the robustness of Arabic-AD. Three extensive experiments were conducted to measure the proposed method and compare it to well-known benchmarks in the literature. As a result, Arabic-AD outperformed other state-of-the-art methods with the lowest EER rate (0.027%), and high detection accuracy (97%) while avoiding the need for excessive training.",Audio deepfake;imitation fakeness;Arabic-AD method;modern standard Arabic (MSA);machine learning (ML);deep learning (DL),IEE
229,"Language-focused Deepfake Detection Using Phonemes, Mouth Movements, and Video Features",J. Krause; A. De Souza Inacio; H. S. Lopes,2023,"The potential implications of Artificial Intelligence (AI) and Deep Learning (DL) algorithms in generating highly realistic deepfake videos have raised concerns regarding the reliability of our human senses. In response to this challenge, we propose a deepfake detection system based on phonemes, the transcribed text, associated mouth movements, and video-extracted features. As a proof-of-concept, we develop a deepfake detection system specifically designed for the Portuguese language, employing three presidential candidates from the 2022 Brazilian elections. Additionally, we introduce a unique dataset comprising real and fake videos involving these three individuals and deliberately blending their identities. The extracted features consolidate relevant attributes, which we utilized to train multiple classification algorithms. Notably, our computational models demonstrate satisfactory performance when authenticating or detecting fake videos containing at least one of the trained phonemes from the Portuguese language. Hence, we conclude that deepfake detection is feasible, primarily due to the absence of natural expressions, particularly in non-English language deepfake videos. Furthermore, developing individual-guided deepfake detection systems may facilitate the authentication of videos featuring celebrities or politicians during future online events.",Deepfake;Language-focused;Phoneme-based.,IEE
230,Deepfake Video Detection with Facial Features and Long-Short Term Memory Deep Networks,D. -C. Stanciu; B. Ionescu,2021,"Generative models have evolved immensely in the last few years. GAN-based video and image generation has become very accessible due to open source software available to anyone, and that may pose a threat to society. Deepfakes can be used to intimidate, blackmail certain public figures or to mislead the public. At the same time, with the rising popularity of deepfakes, detection algorithms have also evolved significantly. The majority of those algorithms focus on images rather than to explore the temporal evolution in the video. In this paper, we explore whether the temporal information of the video can be used to increase the performance of state-of-the-art deepfake detection algorithms. We also investigate whether certain facial regions contain more information about the authenticity of the video by using the entire aligned face as input for our model and by only selecting certain facial regions. We use late fusion to combine those results for increased performance. To validate our solution, we experiment on 2 state-of-the-art datasets, namely FaceForensics++ [1] and CelebDF [2]. The results show that using the temporal dimension can greatly enhance the performance of a deep learning model.",deepfake;deep learning;digital video forensics;face manipulation;facial regions;LSTM,IEE
231,Deepfake Detection using a Two-Stream Capsule Network,Z. Joseph; C. Nyirenda,2021,"This paper aims to address the problem of Deepfake Detection using a Two-Stream Capsule Network. First we review methods used to create Deepfake content, as well as methods proposed in the literature to detect such Deepfake content. We then propose a novel architecture to detect Deepfakes, which consists of a two-stream Capsule network running in parallel that takes in both RGB images/frames as well as Error Level Analysis images. Results show that the proposed approach exhibits the detection accuracy of 73.39 % and 57.45 % for the Deepfake Detection Challenge (DFDC) and the Celeb-DF datasets respectively. These results are, however, from a preliminary implementation of the proposed approach. As part of future work, population-based optimization techniques such as Particle Swarm Optimization (PSO) will be used to tune the hyper parameters for better performance.",Deepfake;Deepfake detection;face tampering;deep learning;convolutional neural networks;Capsule networks;Error Level Analysis,IEE
232,Analysis Survey on Deepfake detection and Recognition with Convolutional Neural Networks,S. R. Ahmed; E. Sonu�; M. R. Ahmed; A. D. Duru,2022,"Deep Learning (DL) is the most efficient technique to handle a wide range of challenging problems such as data analytics, diagnosing diseases, detecting anomalies, etc. The development of DL has raised some privacy, justice, and national security issues. Deepfake is a DL-based application that has been very popular in recent years and is one of the reasons for these problems. Deepfake technology can create fake images and videos that are difficult for humans to recognize as real or not. Therefore, it needs to be proposed some automated methods for devices to detect and evaluate threats. In another word, digital and visual media must maintain their integrity. A set of rules used for Deepfake and some methods to detect the content created by Deepfake have been proposed in the literature. This paper summarizes what we have in the critical discussion about the problems, opportunities, and prospects of Deepfake technology. We aim for this work to be an alternative guide to getting knowledge of Deepfake detection methods. First, we cover Deepfake history and Deepfake techniques. Then, we present how a better and more robust Deepfake detection method can be designed to deal with fake content.",Deep-fakes;face exploitation;AI;DL;auto-encoders;generative adversarial network;forensics;review,IEE
233,Deepfake Video Detection Based on Image Source Anomaly,Y. Wang; G. Liao,2024,"In order to detect the deepfake videos, most of the effective detection approaches need huge number of samples for training, including the real and fake samples. However, the fake samples are not easy to obtain. To find the solution, this paper proposes a deepfake video detection method based on image source anomaly, which only needs the real samples for training. The proposed method uses a neural network to extract features from the face region and its eight neighbor regions, and then uses another neural network to compare the similarity between the features from face region and each one of its neighbor regions. Finally, the average similarity score is utilized as the measure to detect deepfake video. The experimental results show that the proposed method has good detection performance, which achieved the HTER of 2.75% in the DFD dataset and 2.25% in the FF++ dataset, while it needs less samples for training. Moreover, the proposed method also has good cross-datasets performance. It had the HTER of 1.22% when training in FF++ dataset and testing in DFD dataset, which indicates that it can be used in many practical scenarios.",deepfake;image source;anormaly detection;multimedia forensics;deep learning,IEE
234,Xception Net & Vision Transformer: A comparative study for Deepfake Detection,D. Shah; D. Shah; D. Jodhawat; J. Parekh; K. Srivastava,2022,"Deepfakes are artificial media in which an existing image consisting of a person is replaced with someone else. The creation of fake content is not new, but deepfakes are more credible because it involves the use of advanced deep learning techniques to manipulate or generate audio and visual content. In the 21st century, there have been astonishing advancements in Generative Adversarial Networks (GANs) and the use of encoder and decoder architecture [1] which have resulted in various effective methods of deepfake creation such as face-swap, lip-syncing, puppet-master and many more [2]. These methods are not only easily accessible but also get more accurate with time. Earlier deepfakes were detected with deep convolutional neural networks such as EfficientNet B7 and Xception Net, but with further advancements in deepfake generation there comes a need for better deepfake detection methods. This paper analyses the performance of Xception Net which has historically performed well with deepfake detection [3]�[5], Vision transformer [6] which is a fairly new technology and a combination of the two models. The paper proposes a combination of Xception and Vision transformer such that Xception Net is used for feature extraction from the patches and the output is then fed as a sequence to a transformer. This work is expected to assist readers to understand when to use Xception Net, Vision transformer and a combination of the two.",DFDC (DeepFake Detection Challenge);Deepfake;Xception;Vision Transformer;Deep Learning;Deepfake Detection,IEE
235,Financial Cybercrime: A Comprehensive Survey of Deep Learning Approaches to Tackle the Evolving Financial Crime Landscape,J. Nicholls; A. Kuppa; N. -A. Le-Khac,2021,"Machine Learning and Deep Learning methods are widely adopted across financial domains to support trading activities, mobile banking, payments, and making customer credit decisions. These methods also play a vital role in combating financial crime, fraud, and cyberattacks. Financial crime is increasingly being committed over cyberspace, and cybercriminals are using a combination of hacking and social engineering techniques which are bypassing current financial and corporate institution security. With this comes a new umbrella term to capture the evolving landscape which is financial cybercrime. It is a combination of financial crime, hacking, and social engineering committed over cyberspace for the sole purpose of illegal economic gain. Identifying financial cybercrime-related activities is a hard problem, for example, a highly restrictive algorithm may block all suspicious activity obstructing genuine customer business. Navigating and identifying legitimate illicit transactions is not the only issue faced by financial institutions, there is a growing demand of transparency, fairness, and privacy from customers and regulators, which imposes unique constraints on the application of artificial intelligence methods to detect fraud-related activities. Traditionally, rule based systems and shallow anomaly detection methods have been applied to detect financial crime and fraud, but recent developments have seen graph based techniques and neural network models being used to tackle financial cybercrime. There is still a lack of a holistic understanding of the financial cybercrime ecosystem, relevant methods, and their drawbacks and new emerging open problems in this domain in spite of their popularity. In this survey, we aim to bridge the gap by studying the financial cybercrime ecosystem based on four axes: (a) different fraud methods adopted by criminals; (b) relevant systems, algorithms, drawbacks, constraints, and metrics used to combat each fraud type; (c) the relevant personas and stakeholders involved; (d) open and emerging problems in the financial cybercrime domain.",Anomaly detection;artificial intelligence;cybersecurity;cryptocurrency analysis;SIM-swap analysis;deep learning;financial crime;hacking;social engineering,IEE
236,A New Approach to in Ensemble Method for Deepfake Detection,S. Atas; M. Karakose,2023,"With the great development of technology and deep learning gaining competence in many areas, recently forgery of images has started to pose great threats and become the main topic of most technology companies. But here, with the ongoing race between good and evil, new approaches have emerged in fraud detection. Since this technological development is bilateral, fraud detection is constantly trying to be developed and trying to catch fraud. In this regard, various approaches have emerged by many different companies and people to contribute to society. In the method we have proposed to contribute to these detection processes and to detect forgery, feature extraction is provided on images using the D-CNN model, and with these features, SVM, Estimation is done on features with Random Forest and Logistic Regression. Finally, using the Ensemble method, an estimation process is performed by taking all the estimates together with the sampling on the images. Thanks to this proposed method, the determinations made are supported in a layered way and precision is ensured at the accuracy rate.",Deepfake Detection;Ensemble Method;D-CNN,IEE
237,Generation And Detection of Deepfakes using Generative Adversarial Networks (GANs) and Affine Transformation,J. Vijaya; A. A. Kazi; K. G. Mishra; A. Praveen,2023,"Deepfake technology has gained significant attention and notoriety in recent years for its ability to manipulate visual and audio content, leading to widespread concerns about its potential for abuse. Deepfake videos can be created by using deep learning algorithms that enable the synthesis of facial and vocal features of a target individual onto another person, leading to convincing and often misleading videos. While the technology behind deep fakes is constantly evolving, there has been increasing interest in understanding and mitigating their potential negative impacts. Researchers and experts are exploring ways to detect and prevent the creation of malicious deep fakes while also developing ethical guidelines to regulate their use. This paper presents a deep fake project that utilizes Generative Adversarial Networks (GANs) and affine transformations to generate deep fake videos. The proposed approach takes a target image and a driving video as inputs and generates a realistic-looking deep fake video that mimics the facial expressions and movements of the driving video and combines it with the target image and also incorporates a classification model to detect whether the generated deep fake video is real or fake. The classification model will also be based on the same architecture as used in generating the fake videos and will be used to evaluate the realism and quality of the generated deep fake videos. It generates a novel approach for generating and detecting deep fake videos that can be applied to various applications, such as entertainment, education, and security. However, creating deep fakes also offers potential benefits, such as improving the entertainment industry and enhancing the quality of content creation. As technology advances, it is crucial to balance its potential benefits with its potential risks and take appropriate measures to ensure that deep fakes are used ethically and responsibly. The proposed method aims to identify the real identity of a person appearing in a video and use this information to detect whether the video is genuine or not. This identity-aware approach leverages a deep neural network architecture that combines facial recognition and face forgery detection techniques. The proposed solution has the potential to enhance the security of digital media and protect individuals from various forms of identity theft and cyber-crime.",Deepfake;facial/vocal features;GANs;affine,IEE
238,DeepFake Detection Based VGG-16 Model,W. A. Jbara; J. H. Soud,2024,"This DeepFake technology allows for the creation of convincing fake images and videos that are indistinguishable from real ones, which is causing widespread concern. This work introduces the state-of-the-art technology for detecting DeepFake videos, while based on the VGG-16 Convolutional Neural Network, ensuring accurate and reliable results. Data augmentation is used for performance improving and reduce the computational resources, also using Multi-task Cascaded Convolutional Networks technique for face detection. With this innovative solution, you can easily identify and detect DeepFake videos that have the potential to mislead, deceive, or manipulate viewers. The experimental results using Celeb-DF and DeepFake Face Mask datasets have greatly improved this model for fake video detectors. These datasets pass through several steps that end with the classification stage for fake face detection, the classification report including several metrics: 94.28% for accuracy, 0.1503 for loss, 0.9428 for Precision, 0.9428 for Recall, 0.9859 for AUC and 0.9428 for F1_score in evaluation model performance. The data augmentation process that used to improve the model performance and reduce computational resources. According to the initial results, VGG19 outperforms other analyzed models with a highest accuracy of 94.28%.",Deep learning;DeepFake;MTCN;Celeb-DF-v2;DFFM;VGG-16,IEE
239,An Experimental Evaluation on Deepfake Detection using Deep Face Recognition,S. Ramachandran; A. V. Nadimpalli; A. Rattani,2021,"Significant advances in deep learning have obtained hallmark accuracy rates for various computer vision applications. However, advances in deep generative models have also led to the generation of very realistic fake content, also known as deepfakes, causing a threat to privacy, democracy, and national security. Most of the current deepfake detection methods are deemed as a binary classification problem in distinguishing authentic images or videos from fake ones using two-class convolutional neural networks (CNNs). These methods are based on detecting visual artifacts, temporal or color inconsistencies produced by deep generative models. However, these methods require a large amount of real and fake data for model training and their performance drops significantly in cross dataset evaluation with samples generated using advanced deepfake generation techniques. In this paper, we thoroughly evaluate the efficacy of deep face recognition in identifying deepfakes, using different loss functions and deepfake generation techniques. Experimental investigations on challenging Celeb-DF and FaceForensics++ deepfake datasets suggest the efficacy of deep face recognition in identifying deepfakes over two-class CNNs and the ocular modality. Reported results suggest a maximum Area Under Curve (AUC) of 0.98 and Equal Error Rate (EER) of 7.1% in detecting deepfakes using face recognition on the Celeb-DF dataset. This EER is lower by 16.6% compared to the EER obtained for the two-class CNN and the ocular modality on the Celeb-DF dataset. Further on the FaceForensics++ dataset, an AUC of 0.99 and EER of 2.04% were obtained. The use of biometric facial recognition technology has the advantage of bypassing the need for a large amount of fake data for model training and obtaining better generalizability to evolving deepfake creation techniques.",Deepfakes;Deep Learning;Biometrics;Face Recognition,IEE
240,Deepfake Detection Using Graph Representation with Multi-dimensional Features,J. Chen; W. Lin; J. Xu,2023,"The proliferation of fake video poses a significant threat to the authority and authenticity of news across multiple domains. The most existing methods of deepfake detection primarily focus on identifying the face as a whole in a video, ignoring the correlation between the facial components. However, our investigation indicates that constituent potions of a face have different effects in deepfake detection. To address this issue, we divided the face in a video frame into several regions and explored the relationship between these regions. Our approach involves constructing a feature graph of this correlation, aiming to make use of the relationship and temporal characteristics between regions of a face in a deepfake video. To begin with, the features of each facial region are extracted through CNN. Subsequently, the feature graph of the entire video is constructed with these features being the vertices and the correlation being the edge. A graph neural network is finally utilized to determine whether the video has been tampered with. Our experiments on several publicly accessible datasets demonstrate that the proposed approach outperforms other state-of-the-art deepfake detection techniques in most scenarios.",graph representation;deepfake detection;temporal characteristics,IEE
241,CNN based Deep Learning model for Deepfake Detection,V. Jolly; M. Telrandhe; A. Kasat; A. Shitole; K. Gawande,2022,"In the recent period there has been massive progress in synthetic image generation and manipulation which significantly raises concerns for its ill applications towards society. This would result in spreading false information, leading to loss of trust in digital content. This paper introduces an automated and effective approach to get facial expressions in videos, and especially focused on the latest method used to produce hyper realistic fake videos: Deepfake. Using faceforenc++ dataset for training our model, we achieved more that 99% successful detection rate in Deepfake, Face2Face, faceSwap and neural texture. Regular image forensics techniques are usually not very useful, because of the strong deterioration of data due to the compression. Thus, this paper follows a layered approach with first detecting the subject with the help of existing facial recognition networks followed by extracting facial features using CNN, then passing through the LSTM layer, where we make use of our temporal sequence for face manipulation between frames. Finally use of the Recycle-GAN which internally makes use of generative adversarial networks to merge spatial and temporal data.",Face Detection;FaceForensics++;DeepFake;Face2Face;FaceSwap;Neural Texture;Convolutional Neural Network (CNN);Long Short-Term Memory (LSTM),IEE
242,Deepfake Detection Using Custom Densenet,V. R. Pasupuleti; P. Reddy Tathireddy; G. Dontagani; S. A. Rahim,2023,"Deepfake detection has grown to be an increasingly important research area due to the potential harm that deepfakes can cause to individuals and society. In recent years, deep learning techniques have shown promising results for detecting deepfake images and videos. In this research, we provide a deep learning-based strategy using Custom DenseNet for deepfake image detection. This model used a big dataset of actual and deepfake photos to train a convolutional neural network (CNN) using the Custom DenseNet architecture. The Custom DenseNet architecture is a deep residual network that has shown excellent performance in various computer vision tasks. To categorize images as real or fake, the CNN is trained using a binary cross-entropy loss function. To evaluate the approach, we used several performance indicators including F1-score, recall, accuracy, and precision. We also contrasted our strategy with other cutting-edge deepfake detection techniques. Our test results demonstrate that our solution employing Custom DenseNet surpasses existing deepfake detection techniques in terms of accuracy, precision, recall, and F1-score. We achieved an accuracy of 97%, a precision of 95%, and an F1- score of 75%. These results demonstrate the effectiveness of our approach in detecting deepfake images. Overall, our study shows that deep learning techniques, specifically the Custom DenseNet architecture, can be highly effective in detecting deepfake images.",deep fakes;metrics scores;CNN;DenseNet;binary cross- entropy,IEE
243,Facial Behavior Analysis-Based Deepfake Video Detection using GAN Discriminator,Q. Jaleel; I. H. Ali,2022,"Deepfake is an artificial intelligence-based method for making fake images of people. It works by putting the existing (source) images or videos on the final (destination) images or videos. But recent improvements in deep learning have made it much easier to make fake videos that look real and are convincing with a relatively small amount of data and computing power. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Many researchers are based on discovering deep fakes that were created by traditional methods. Traditional methods of detection that look for artifacts and pixels that don't match up can't keep up. This paper can detect deepfakes that are perfectly created. It is detected by modifying the GAN algorithm and inverting its function. The discriminator model of a GAN network is used to analyze behavior, facial gestures, and the appearance of an object. The paper is divided into two stages. The first stage is to use a GAN discriminator that has been modified. It is then trained using a deepfake dataset. The second stage is to test the videos by extracting the faces. Next, run it through the GAN discriminator to see if it's a forgery. In comparison to other networks, the GAN discriminator has demonstrated its ability and accuracy in detecting fake videos. The network's accuracy in detecting and distinguishing between real and fake videos is %94.65.",GAN;GAN discriminator;Media Forensics;DeepFake Detection;Face Detection,IEE
244,Deepfake Detection using EfficientNet: Working Towards Dense Sampling and Frames Selection,T. -A. To; H. -C. Luong; N. -T. Nguyen; T. -T. Nguyen; M. -T. Tran; T. -L. Do,2022,"Deepfake is a controversial technology that allows the automatic generation of video content through generative adversarial networks. The emergence of Deepfake technology is problematic and sophisticated, making it more difficult to detect. In our paper, we contribute a deep-learning method to resolve that problem. We use the MTCNN face detector to extract facial images and apply data augmentation and EfficientNet for real-fake classification. We apply frame selection with the raw label prediction to tackle the fault cases and receive the final label. With the approach above applied, we utilize training and evaluation datasets from FaceForensics++ and achieve an accuracy of 62.5%.",Deepfake Detection;Efficient Net;Dense Sampling;Frame Selection,IEE
245,Detecting Deepfake Videos Dilemma Revisited: Finding Gaps and Shortcomings,F. Kharbat; L. Badawi,2023,"The rapid proliferation of deepfake videos across the internet in recent years has prompted concern amongst policymakers, tech companies, and the public at large. These concerns stem from the often malicious intent behind the use of these generated videos. Despite the substantial efforts invested in developing detection algorithms for deepfake videos, there persist noteworthy gaps in this evolving landscape. In this paper, we offer a brief comparison between the methods implemented in detecting deepfake videos and images and a description of the process of deepfake video detection. Additionally, we analyze the future works section of the most recent and relevant literature and pinpoint the gaps that have not been resolved. Further, we classify the concentration of these gaps into three main themes, offering a structured perspective on the unresolved challenges.",Deepfake;Generative Networks;Detection;Spatiotemporal,IEE
246,A High-Fidelity Partial Face Manipulation Dataset for Enhanced Deepfake Detection,K. Tong; J. Zhang; Y. Wang; H. Tohidypour; P. Nasiopoulos,2024,"Deepfake technology has already impacted the integrity of news and may grow to hugely destructive political and social force. The realistic and convincing nature of deepfakes poses a threat to the authenticity of information, alarming individuals and organizations. While many studies have explored the issue of deepfakes, the majority of them have focused on swapping entire faces rather than partially manipulating them, which can be more difficult to detect. In this paper, we introduce a high-fidelity partially manipulated face dataset, aiming to fill the gap in the existing deepfake research by providing a comprehensive benchmark for partially manipulated face detection. Our dataset includes a diverse set of partially manipulated faces which is generated from high-quality facial images. Our proposed alignment pipeline ensures that the partially manipulated faces may be realistically integrated into the original images, providing a more challenging evaluation environment for deepfake detection models. Both objective and subjective evaluations of our proposed dataset have shown promising results, indicating its potential to become a significant benchmark for partially manipulated face detection.",Deep learning;Deepfake;Local facial feature editing;Generative adversarial network,IEE
247,Improving DeepFake Video Detection Performance with a Noval Deep Learning Approach,M. A. Fouda; W. El-Shafai; E. -S. M. El-Rabaie,2023,"With the rise in both the quantity and sophistication of deepfake videos, the need for robust detection systems to identify potentially misleading content on social media and the internet has become paramount. However, current automated face forgery detection systems still face limitations, often demonstrating bias towards the training dataset. This research paper addresses this issue by proposing a novel approach for detecting deepfake media. We introduce a custom Visual Geometry Group (VGG16) deepfake detection method that leverages convolutional neural network architectures. To evaluate the effectiveness of our approach, we utilize the deepfake detection challenge (DFDC) dataset on Kaggle to build network models and compare the performance of our custom VGG16 method against the standard VGG16. Additionally, we investigate the impact of data augmentation techniques on the performance of Convolutional Neural Network (CNN)-based deepfake detectors, examining their effect on both VGG16 and our custom VGG16 approach using the DFDC dataset. Our results demonstrate a high level of accuracy, with precision, recall, and f1-score values of 0.983, 0.975, and 0.979, respectively, and an overall accuracy of 0.986 for deepfake detection. This study presents a promising approach to enhance the accuracy of deepfake video detection, representing a crucial step towards mitigating the potential negative impacts of deepfake technology.",Deepfake;Deep learning;CNN;Data Augmentation;Deepfake Detection;and VGG16,IEE
248,DeepFake Detection System using Deep Learning,O. Ahmed; S. Fekry; A. Metwally; A. Abdelwahid; D. Khattab; A. Abdulelmagid; R. Hossieny,2023,"Due to the growing usage of DeepFake technology to produce fake photos and videos, the problem of DeepFake identification has become a serious concern in recent years. With the use of this technology, fake material that is difficult to tell apart from real content may be produced. Therefore, the development of accurate DeepFake detection algorithms is essential to identify and prevent the spread of manipulated content. However, current publicly available DeepFake detection datasets suffer from a lack of diversity, with only a few actors appearing in multiple videos. This results in an oversampled training dataset, leading to model overfitting and inadequate performance when tested on new data. The overfitting problem can cause deep neural networks to focus more on facial features than on specific traits of DeepFake content, thereby reducing the model's ability to generalize. To address this issue and broaden the training dataset's variety, we suggest applying data augmentation methods like Face Cutout and Random Erase. The Face Cutout technique randomly removes a rectangular area of an image containing the face, while the Random Erase technique randomly removes a rectangular area of the image. These techniques introduce variations in the images, making it more challenging for the model to overfit and focus on specific traits of DeepFake content. We evaluated our approach using several models and achieved significant accuracy improvements using the EfficientnetV2B0 model and Random Erase augmentation.",DeepFake;Random Erase;Face Cutout,IEE
249,Transformer-Based Feature Compensation and Aggregation for DeepFake Detection,Z. Tan; Z. Yang; C. Miao; G. Guo,2022,"Deepfake detection has attracted increasing attention in recent years. In this paper, we propose a transformer-based framework with feature compensation and aggregation (Trans-FCA) to extract rich forgery cues for deepfake detection. To compensate local features for transformers, we propose a Locality Compensation Block (LCB) containing a Global-Local Cross-Attention (GLCA) to attentively fuse global transformer features and local convolutional features. To aggregate features of all layers for capturing comprehensive and various fake flaws, we propose Multi-head Clustering Projection (MCP) and Frequency-guided Fusion Module (FFM), where the MCP attentively reduces redundant features into a few concentrated clusters, and the FFM interacts all clustered features under the guidance of frequency cues. In Trans-FCA, besides global cues captured by transformer architecture, local details and rich forgery defects are also captured using the proposed fetaure compensation and aggregation. Extensive experiments show our method outperforms the state-of-the-art methods on both intra-dataset and cross-dataset testings (with AUCs of 99.85% on FaceForensics++ and 78.57% on Celeb-DF), which clearly demonstrates the superiority of our Trans-FCA for deepfake detection.",Face forgery detection;transformer;deep learning,IEE
250,AVA: A Photorealistic AI Bot for Human-like Interaction and Extended Reality,V. Narkhede; O. Surushe; S. Kulkarni; H. Solanki; T. Ekbote; D. Joshi,2023,"In the era of rapid technological advancement, artificial intelligence (AI) and machine learning (ML) are transforming the way we work and interact with the world around us. The hiring process is a crucial aspect of any organization, as it determines the quality of the workforce and the success of the business. However, traditional hiring methods can be time-consuming and prone to bias. In this paper, we propose a better approach to hiring that leverages the power of Artificial Intelligence (AI) and machine learning (ML) to automate and improve the efficiency of the process. Our proposed system allows managers to specify their requirements and receive a shortlist of candidates based on their skills, experience, and performance in a one-on-one interview with a photorealistic artificial intelligence bot. The bot also assesses candidates� confidence and body language to rank them accordingly. By using AI and machine learning in the hiring process, we can save time and reduce bias, leading to better-quality hires and a more productive workforce.",Artificial Intelligence;Efficiency;Interview;Workforce,IEE
251,Image Forgery Detection Using Convolutional Neural Networks,A. Meepaganithage; S. Rath; M. Nicolescu; M. Nicolescu; S. Sengupta,2024,"With the advancement of technology, the ability to forge realistic images has become increasingly accessible, and this has led to a significant challenge in the digital forensics field. A lot of research has been conducted in this area to address this challenge. Traditional image forgery detection methods are time-consuming and slow. Therefore, deep learning methods have played a vital role in image forgery detection. In this research, we investigate the use of convolutional neural network models for image forgery detection and evaluate their performance. From the experimental results, it can be seen that ResNet models have demonstrated high performance in detecting forged images accurately. Out of all the convolutional models we evaluated, the ResNet-101 model obtained the best results, with 93.46% accuracy, 95.08% precision, 92.10% recall, 94.91% specificity, and 93.57% F1-score. ResNet-101 model correctly identified 621 out of 650 authentic images and 584 out of 650 forged images.",image forgery detection;digital forensics;machine learning;deep learning;convolutional neural networks,IEE
252,Comparison of Deepfakes Detection Techniques,S. Salman; J. A. Shamsi,2023,"Detection of fake audio and video is a challenging problem. Deepfake is popularly used for creating fake audio and video content using deep learning. Deepfakes, artificially created audiovisual interpretations can be used to degrade the reputation of a renowned person, hate-speech, or affect public belief. The development of novel methods for identifying various deep fake video types has received a significant amount of research throughout the years. In this research, we present a thorough comparative analysis of current state-of-the-art deepfake detection methods. The primary goal of our research is to identify the factors that contribute to the performance degradation of deepfake detection models currently being used when tested against a comprehensive dataset.",deepfake detection;deep learning;comparative revicew,IEE
253,Deep-Fake Finder: Uncovering Forgery Image Through Neural Network Analysis,D. Bhargava; S. Rani; M. Singh; N. Tripathi; A. Bhargava; G. Panwar,2024,"Digital images are a common form of media shared on social media, and their circulation can undermine news credibility and public trust. This research proposes a method for extracting image content, classifying it, verifying its authenticity, and identifying manipulations. With the exponential increase in social networking services, there has been a huge growth in the generation of image data, leading to the creation of fabricated images. These images are a major source of fake news, negatively impacting society. To verify the authenticity of these images, a method using a CNN deep learning model can be used. Pixel-based fake image detection can find tempering of an image up to a certain level. The raw image can be mangled in sections or as a whole, and it is necessary to recognize the type of image tampering and localize the tampered region. The image is converted into pixel format, and the RGB values are fed into the network's input layer. The output layer has two neurons for phony and genuine images, allowing us to infer if the image is phony and how likely it is to be tampered.",Machine Learning (ML);Deep Learning (DL);Neural Networks;Forged Images;R-RANSAC;SPRT,IEE
254,DeepFake Detection Through Key Video Frame Extraction using GAN,L. S; K. Sooda,2022,"The emergence of deepfake videos in recent years has made image falsification a real threat. A deepfake video uses deep learning technology to substitute a person's face, emotion, or speech with the face, emotion, or speech of another person. Finding such deceptive deepfake videos on social media is the first step in preventing them. A robust neural network-based technique to identify false videos is presented in this paper. An important video frame extraction approach is used to speed up the process of finding deep fake videos. A model made up of a convolutional neural network (CNN) and a classifier network consisting of GAN technology is provided. Resnet, Resnext50 and LSTM were passed over in favor of the Confusion Matrix when deciding which structure to pair with the classifier while detecting the fake video. The model is a method for detecting visual artefacts. The subsequent classifier network uses the feature vectors from the CNN module as this is the input to categorize the video whether it is fake or real one. The dataset is considered from DeepFake Detection Challenge to get the best model. The key goal is to get high accuracy without using a lot of data to train the model. In comparison to earlier efforts, the key video frame extraction method dramatically decreases computations by achieving 97.2% accuracy using the Deepfake Detection Challenge dataset.",Convolutional Neural Network;Deepfake;LSTM;Resnet;Resnext50,IEE
255,Developing Self-evolving Deepfake Detectors Against AI Attacks,I. Miller; D. Lin,2022,"As deep-learning based image and video manipulation technology advances, the future of truth and information looks bleak. In particular, Deepfakes, wherein a person�s face can be transferred onto the face of someone else, pose a serious threat for potential spread of convincing misinformation that is drastic and ubiquitous enough to have catastrophic real-world consequences. To prevent this, an effective detection tool for manipulated media is needed. However, the detector cannot just be good, it has to evolve with the technology to keep pace with or even outpace the enemy. At the same time, it must defend against different attack types to which deep learning systems are vulnerable. To that end, in this paper, we review various methods of both attack and defense on AI systems, as well as modes of evolution for such a system. Then, we put forward a potential system that combines the latest technologies in multiple areas as well as several novel ideas to create a detection algorithm that is robust against many attacks and can learn over time with unprecedented effectiveness and efficiency.",deepfake;AI attack,IEE
256,Open-Set Deepfake Detection To Fight The Unknown,M. M. Diniz; A. Rocha,2024,"In this paper, we design a new open-set method to detect deepfakes that does not assume information about the techniques behind the deepfakes generation. Contrary to existing methods, which build upon known telltales left by the deepfake creation process, we assume no prior knowledge about the sample generation, thus presenting a method for blind deepfake detection, a necessary step toward true generalization. Our methodology relies upon unsupervised learning, open-set formulations for each discovered group and, finally, relevance tests through extreme-value theory and isolation forest formulations. The results indicate that the proposed open-set technique is competitive with state-of-the-art closed-set deepfake detection methods. As a notable outcome, we achieved an AUC = 0.807, which is 5.57% higher than the baseline architecture trained using a closed-set approach. Finally, we believe our efforts herein are just a first attempt tackling this difficult problem and discuss some additional improvements for practical deployment of such systems.",Deepfake Detection;Open-set Methods;Triplet loss,IEE
257,Multimodal Approach for DeepFake Detection,M. Lomnitz; Z. Hampel-Arias; V. Sandesara; S. Hu,2020,"Generative Adversarial Networks (GANs) have become increasingly popular in machine learning because of their ability to mimic any distribution of data. Though GANs can be leveraged for legitimate purposes, they have increasingly been used to create manipulative and misleading synthetic media, known as deepfakes, intended for nefarious purposes. In this submission we discuss a multimodal deepfake detection solution submitted against the Facebook DeepFake Detection Challenge, a state of the art benchmark dataset and competition released at the end of 2019. Our solution incorporates information from single images and series of images, and also incorporates temporal information from audio and video data, and was ultimately ranked among the top 25% of teams.",deep learning;deep fakes;generative adversarial networks,IEE
258,A Hybrid Xception-LSTM Model with Channel and Spatial Attention Mechanism for Deepfake Video Detection,D. Dagar; D. K. Vishwakarma,2023,"The great strides taken in recent times in image and video manipulation have raised serious concerns. Deepfake technology uses deep learning approaches to create highly realistic, astonishing content. Detecting such videos is the only promising defense against such fraudulent data. To counter the malicious intent of the user, a deepfake detection model is proposed that employs channel and spatial attention mechanisms(CBAM) along with Xception and LSTM pretrained models. Xception uses depthwise separable convolution to capture the latent spatial artifacts. LSTM captures the discrepancies among the manipulated sequences; hence, this hybrid ensembling of models allows the learning of powerful features. The evaluation is performed on the recently proposed Div-DF dataset consisting of varied video manipulation like face swap, facial reenactment, and lip-sync. It shows that the model works well (Accuracy~ 93 % & AUC ~ 0.98) on the diversified dataset and easily beats the score of various state-of-the-art deepfake detection and image classification models.",deepfake detection;deepfake dataset;video manipulation detection;channel attention;spatial attention,IEE
259,Beyond Deepfake Images: Detecting AI-Generated Videos,D. S. Vahdati; T. D. Nguyen; A. Azizpour; M. C. Stamm,2024,"Recent advances in generative AI have led to the development of techniques to generate visually realistic synthetic video. While a number of techniques have been developed to detect AI-generated synthetic images, in this paper we show that synthetic image detectors are unable to detect synthetic videos. We demonstrate that this is because synthetic video generators introduce substantially different traces than those left by image generators. Despite this, we show that synthetic video traces can be learned, and used to perform reliable synthetic video detection or generator source attribution even after H.264 re-compression. Furthermore, we demonstrate that while detecting videos from new generators through zero-shot transferability is challenging, accurate detection of videos from a new generator can be achieved through few-shot learning.",Generative AI;Synthetic images;Synthetic Videos;Media Forensics;Deep Neural Networks;Deep Learning;synthetic image detection;synthetic video detection;video forensics;image forensics;Deepfake,IEE
260,DeepSight: Enhancing Deepfake Image Detection and Classification through Ensemble and Deep Learning Techniques,T. Manju; S. Kalarani,2024,"in today�s digital age, deepfake images poses a significant threat to multimedia content authenticity and integrity. Detecting and classifying deepfake images with high accuracy is crucial to addressing this growing challenge. Deepfake images, generated using advanced machine learning techniques, have become a significant concern due to their potential to deceive individuals and manipulate information. This paper presents DeepSight, an innovative approach that combines ensemble learning techniques with deep learning models to enhance deepfake image detection and classification. DeepSight leverages the diversity of multiple classifiers trained on distinct feature representations extracted from the input image data. The framework begins with an initial assessment to determine whether the image has been manipulated. Subsequently, the image goes through deep feature extraction using Convolutional Neural Networks (CNNs). The resulting feature vectors are then classified using Random Forest, KNearest Neighbors, and XGBoost, with hyper-parameter optimization. Experimental evaluations on benchmark datasets demonstrate DeepSight�s superior performance compared to state-of-the-art methods, achieving higher accuracy and robustness across various deepfake generation techniques and quality levels. Notably, DeepSight achieves the highest accuracy of 97.5% when utilizing DenseNet and XGBoost. Overall, DeepSight represents a significant advancement in deepfake image detection and classification. It provides a reliable solution to address deceptive visual content in digital environments.",Deepfake image;Ensemble learning;Machine learning;Deep learning,IEE
261,A Comprehensive Study on Mitigating Synthetic Identity Threats Using Deepfake Detection Mechanisms,S. Uppal; V. Banga; S. Neeraj; A. Singhal,2024,"Synthetic Identity Threats (SIT) present one of the greatest risks that could undermine the integrity and security of digital systems. These threats adapt Deepfake Technology through generation of new faces, modification of facial attributes or reenactment of fake emotions on human faces. This study is a full documentation of how Deepfake Detection mechanisms can be modelled to neutralize these SIT's using various Deep Learning architectures. We also explored applications of Deepfake beyond malicious intent into forms that are less nefarious like entertainment purposes. We utilized Generative Adversarial Networks to create Deepfakes and experimented with conducting face swaps between two distinct photos as well to assess the quality of Deepfake Technology. For detection of Deepfakes, Convolution Neural Network has shown the highest accuracy of 89.36%, Inception ResNet attained an accuracy of 82.978% while Visual Geometry Group and EfficientNet were at a score of 82.8% and 83% respectively. It is evident that although the current detecting methods are competent in their abilities, the SIT environment continues to develop. Through analyzing the nuances of producing Deepfakes and comparing current quality detection methods, we hope to offer useful information on how scholars and administrators can better protect the internet from deceitful attacks of Deepfakes.",Synthetic Identity Threats (SIT);Deepfake Detection Challenge Dataset (DFDC);Convolution Neural Network (CNN);Inception ResNet;Visual Geometry Group (VGG);EfficientNet;Generative Adversarial Networks (GAN);Deepfake Generation;Face Swapping,IEE
262,A Comprehensive Review of Media Forensics and Deepfake Detection Technique,M. Kandari; V. Tripathi; B. Pant,2023,"In recent years, as the use of the internet and social media has advanced, so the number of fake media content also grows rapidly. Media forensic techniques are becoming essential to analyze and extract information from various types of media, such as images, videos, and audio recordings, to be used as evidence in legal proceedings. As of recent trends, social media is being flooded with sophisticated deepfakes. So evolving deepfake detection technique is required to curb the flow of misinformation via deepfake videos. This paper intends to present a review of evolving media forensics and deepfake detection techniques.",Deepfake;Deep learning;internet;Media forensic;Misinformation;social media,IEE
263,A New Approach for Effective Medical Deepfake Detection in Medical Images,M. Karak�se; H. Yet??; M. �e�en,2024,"In today�s world, deepfake technology is being used to generate fake images, sounds, and videos from real images and sounds using deep learning and artificial intelligence techniques. It is possible to manipulate medical images with this technology. The manipulation of medical images can lead to incorrect diagnoses by medical professionals, disrupting the functioning of hospitals. As a result of these disruptions, hospitals may experience significant financial and life-threatening problems. In this study, it is aimed to obtain an effective deep learning-based method to detect manipulated medical images. Initially, two distinct datasets are created which contain Knee Osteoarthritis X-ray and lung CT scans. Data pre-processing and augmentation methods are applied for data standardization and variation. The instances in datasets are labeled as real or fake. The medical deepfake distinguish ability of YoloV3, YoloV5nu, YoloV5su, YoloV8n, YoloV8s, YoloV8m, YoloV8l, YoloV8x models tested on these datasets. In the analysis performed, all YOLO models showed almost full success in distinguishing Knee Osteoarthritis X-ray images. In lung CT scan images, although YoloV8 models generally achieved good performance, the YoloV5 models gave the best and worst results. While the best result was obtained from YoloV5su with a recall value of 0.997, the worst result was obtained from the YoloV5nu model with a recall value of 0.91. Furthermore, the best model (YoloV5su) works 60% faster than YoloV8x model, which has the second highest performance. The findings show that YoloV5su can be used for fast and accurate medical deepfake detection.",Medical deepfake image detection;deep learning;YOLO;convolutional neural networks,IEE
264,Dodging DeepFake Detection via Implicit Spatial-Domain Notch Filtering,Y. Huang; F. Juefei-Xu; Q. Guo; Y. Liu; G. Pu,2024,"The current high-fidelity generation and high-precision detection of DeepFake images are at an arms race. We believe that producing DeepFakes that are highly realistic and �detection evasive� can serve the ultimate goal of improving future generation DeepFake detection capabilities. In this paper, we propose a simple yet powerful pipeline to reduce the artifact patterns of fake images without hurting image quality by performing implicit spatial-domain notch filtering. We first demonstrate that frequency-domain notch filtering, although famously shown to be effective in removing periodic noise in the spatial domain, is infeasible for our task at hand due to the manual designs required for the notch filters. We, therefore, resort to a learning-based approach to reproduce the notch filtering effects, but solely in the spatial domain. We adopt a combination of adding overwhelming spatial noise for breaking the periodic noise pattern and deep image filtering to reconstruct the noise-free fake images, and we name our method DeepNotch. Deep image filtering provides a specialized filter for each pixel in the noisy image, producing filtered images with high fidelity compared to their DeepFake counterparts. Moreover, we also use the semantic information of the image to generate an adversarial guidance map to add noise intelligently. Our large-scale evaluation on 3 representative DeepFake detection methods (tested on 16 types of DeepFakes) has demonstrated that our technique significantly reduces the accuracy of these 3 fake image detection methods, 36.79% on average and up to 97.02% in the best case.",DeepFake;DeepFake evasion;DeepFake detection,IEE
265,Performance Analysis of Deepfake Text Detection Techniques on Social-media,A. Gaur; S. K. Singh; P. Saxena,2024,"In the last few years, there has been remarkable progress in the domain of natural language generation & understanding. This has led to the development of enhanced text generation capability of machines that can generate spurious text or deepfake text. The technology may be exploited to change and shape public sentiment on social media. Therefore, mechanisms to detect deepfake text is a crucial task. The study emphasizes on detection of deepfake text on social media platform X (formerly Twitter). It presents the performance of machine learning classifiers Logistic regression (LR), XGB classifier, and AdaBoost classifier, utilizing feature engineering methods Term Frequency (TF) and Term Frequency-Inverse Document Frequency (TF-IDF). Deep learning methods such as Dense Neural Networks (DNN), Bi-directional Long Short-Term Memory (Bi-LSTM), and Convolutional Neural Networks (CNN)in addition to state-of-the-art models and variants such as Bi-Directional Encoder Representations from Transformers (BERT), DistilBERT & RoBERTa are also a part of study, leading to 89.17% accuracy in deepfake text detection.",Deepfake;Text Classification;Deep learning;Tweets;convolution neural networks,IEE
266,Optimization of DeepFake Video Detection Using Image Preprocessing,A. Berjawi; K. Samrouth; O. Deforges,2023,"Deep learning has been evolving recently which allowed it to handle complex problems like big data, computer vision, and human-level control. One of the deep learning-powered applications recently emerged is called �deepfake�. Deepfake algorithms have recently been a controversial development in Artificial Intelligence, because they use deep learning to generate fake yet realistic content based on an input dataset. As a result, many are concerned with the potential risks in terms of cyber-security as it causes threats to privacy, democracy, and national security. Multiple techniques were proposed to detect deepfake videos, however most cannot cope with the variety of the deepfake generation techniques. Therefore, in this study, we optimize one of the best existing deepfake detection methods based on Xception model. In particular, our proposed optimization scheme consists of a pre-processing phase performing advanced image enhancement on the videos in hand for highlighting the face features for better feature extraction as well fake content detection, which is preceded by a close-up dataset cleansing. Our experiments show that the proposed pre-processing optimization scheme had improvemes the performance of the Xception Binary Classifier- Inference model from 94% to 96%.",Deep Learning;Image Processing;Deepfake;Pre-processing;Xception Binary Classifier-Inference model,IEE
267,An effective approach for detecting deepfake videos using Long Short-Term Memory and ResNet,S. Keerthana; N. Deepika; E. Pooja; I. Nandhini; M. Shanthalakshmi; G. R. Khanaghavalle,2024,"Deep learning algorithms are becoming more potent and producing human-synthesized, undifferentiated footage is a simple process thanks to advances in computing power. A method of synthesizing human images called deep fakes is built on neural network techniques like GAN. These technologies use deep learning algorithms to overlay target pictures onto the source films, producing realistic-looking deep-fake photos and videos. In this work, we provide a novel deep-learning approach that can reliably discriminate between actual and AI-generated fake videos. In this work, we test our method on a large number of balanced and mixed datasets created by mixing various publicly available datasets, such as Face-Forensic++, Deepfake detection, Celeb DF, and other publicly available datasets as images and videos, to emulate real-time scenarios and improve model performance with real-time data by using LSTM and ResNet.",Deep Learning;Computer Vision;Deepfake;GAN;LSTM;ResNet,IEE
268,Deepfake Audio Detection Using Spectrogram-based Feature and Ensemble of Deep Learning Models,L. Pham; P. Lam; T. Nguyen; H. Nguyen; A. Schindler,2024,"In this paper, we propose a deep-learning-based system for the task of deepfake audio detection. This work is a part of the proposed toolchain for speech analysis in EUCINF (EUropean Cyber and INFormation) project, which is an European project with multiple partners in Europe. In particular, the raw input audio is first transformed into various spectrograms using three transformation methods of Short-time Fourier Transform (STFT), Constant-Q Transform (CQT), Wavelet Transform (WT) combined with different auditory- based filters of Mel, Gammatone, linear filters (LF), and discrete cosine transform (DCT). Given the spectrograms, we evaluate a wide range of classification models based on three deep learning approaches. The first approach is to train the spectrograms using our proposed baseline models of CNN-based model (CNN- baseline), RNN-based model (RNN-baseline), C-RNN model (C-RNN baseline). Meanwhile, the second approach is to apply the transfer learning from computer vision models such as ResNet- 18, MobileNet-V3, EfficientNet-BO, DenseNet-121, SuffleNet- V2, Swint, Convnext- Tiny, GoogLeNet, MNASsnet, and Reg- Net. In the third approach, we leverage the state-of-the-art audio pre-trained models of Whisper, Seamless, Speechbrain, and Pyannote to extract audio embed dings from the input spectrograms. Then, the audio embed dings are explored by a Multilayer perceptron (MLP) model to detect fake or real audio samples. Finally, high-performance deep learning models from these approaches are fused to achieve the best performance. We evaluated our proposed models on ASVspoof 2019 benchmark dataset. Our best ensemble model achieved an Equal Error Rate (EER) of 0.03, which is highly competitive to top-performing systems in the ASVspoofing 2019 challenge. Experimental results also highlight the potential of selective spectrograms and deep learning approaches to enhance model performance on the task of audio deepfake detection.",Items- deepfake audio;spectrogram;feature extraction;classification model,IEE
269,Comparative Analysis of Deepfake Detection Models,O. Jannu; V. Sekar; T. Padhy; P. Padalkar,2024,"Deepfakes, which leverage advanced machine learning techniques such as generative adversarial networks (GANs), pose a significant threat to the integrity of visual content and raise concerns about misinformation and identity theft. This research provides a comparative analysis of various deepfake detection models, aiming to dissect their strengths and weaknesses. Notable architectures like Xception and ResNet50 exhibit high accuracy, precision, and recall with minimal gender bias. However, the Swin Transformer, while excelling in fake image detection, faces challenges with real images, suggesting potential bias. The CNN model demonstrates subpar performance, emphasizing limitations in classifying both fake and real images effectively. MobileNet shows moderate overall performance but maintains balanced precision and recall. The study recommends an ensemble approach to combine model strengths and address individual weaknesses. Future work should focus on refining model architectures, exploring ensemble strategies, and mitigating biases in real image detection.",Deepfakes;Deepfake Detection;Comparative Analysis;Neural Networks;Machine Learning;Ensemble Approach;Biases;Model Evaluation,IEE
270,Fake Information Detection Using Deep Learning Methods: A Survey,P. Dhiman; A. Kaur; A. Bonkra,2023,"Fake content has always existed, even before the internet was founded. Because social media is free to use and accessible, a great deal of information is shared on these sites. These platforms play a significant role in the dissemination of information, whether accurate or false. The unregulated proliferation of fake information creation and dissemination that we've seen in recent years poses a constant threat to democracy. Fake content articles have the power to persuade individuals, leaving them perplexed. Deep learning techniques are extremely useful for detecting fake information. This paper analyses multiple DL techniques and datasets used by different researchers for analysis that aids in the detection of bogus information.",Deep learning techniques;disinformation;fake information detection;misinformation,IEE
271,Deepfake Detection Based on Multi-scale RGB-Frequency Feature Fusion,Y. Meng; X. Wang; X. Wang; Z. Liu; H. Zhou,2024,"Withthe rapid advancement of Deepfake technology, Deepfake content is becoming increasingly realistic and is being widely utilized in political forgery, financial fraud, and the dissemination of false news. In order to more accurately detect Deepfake images and adapt the detection model to various compression scenarios, we propose a forgery detection model based on multi-scale Rgb-Frequency domain feature extraction. This model employs different scale size feature extraction in CNN and extracts multi-scale features in the RGB domain. Subsequently, different feature sequences are input into the Transformer decoder to establish connections between modules and perform classification. The results demonstrate that MRFD exhibits strong robustness and generalization ability when adapting to changes in compression rates. On the LQ dataset of FF++, the ACC and AUC are 90.87% and 93.87%, respectively. The ACC on HQ dataset reaches 97.54% with an AUC of 99.27%.",Deepfake detection;CNN combined with ViT;Rgb-Frequency domain feature fusion;multi-scale feature extraction,IEE
272,Employing Deep Learning Approaches to Detect Deepfake Attributes in Videos,G. Malleswari; A. S. Reddy; R. Raja,2024,"The combination of �fake� and deep learning techniques is known as deepfake technology. Deepfakes are created and detected using deep learning, a form of artificial intelligence. Generative adversarial networks, which are made up of two machine learning models cooperating, are used to create these deepfakes. People may grow less and less inclined to believe content that is genuine as long as deepfake photos and videos keep appearing on social media. Deepfake detection techniques are designed to discriminate between real and fake photos and videos on social media. These techniques rely on training the detection models using datasets that contain both genuine and fraudulent images or videos, highlighting the need for high-quality and diverse data for effective detection. In this research, we initially delve into the realm of deepfake technology and the associated challenges. Subsequently, we identify accessible video datasets. Following that, we employ long short-term memory for learning sequences and utilize convolutional neural networks for classifying eye states. Additionally, we leverage the eye aspect ratio to identify blinking intervals and compute the dimensions of closed and open eyes.",Deepfake images;Generative adversarial networks;deep learning;machine learning;convolutional neural networks,IEE
273,Deep fake Image Detection based on Modified minimized Xception Net and DenseNet,I. Sahib; T. A. A. AlAsady,2022,"This paper deals with the problem of image forgery detection because of the problems it causes. Where The Fake im-ages can lead to social problems, for example, misleading the public opinion on political or religious personages, de-faming celebrities and people, and Presenting them in a law court as evidence, may Doing mislead the court. This work proposes a deep learning approach based on Deep CNN (Convolutional Neural Network) Architecture, to detect fake images. The network is based on a modified structure of Xception net, CNN based on depthwise separable convolution layers. After extracting the feature maps, pooling layers are used with dense connection with Xception output, to in-crease feature maps. Inspired by the idea of a densenet network. On the other hand, the work uses the YCbCr color system for images, which gave better Accuracy of %99.93, more than RGB, HSV, and Lab or other color systems.",convolutional neural network (CNN);Xception net;Densenet;depthwise separable convolution;Deep fake,IEE
274,Unmasking the Illusion: Deepfake Detection through MesoNet,A. Gupta; D. Pandey,2024,"In today�s era of vast digital manipulation, the rise of deepfake technology poses a significant challenge to genuineness of multimedia content and introduces a profound risk to privacy, cybersecurity, and information integrity. Our research contributes to the ongoing discussion on deepfake detection, with a particular focus on assessing effectiveness of MesoNet model. It focuses on analysis of face micro-expressions and makes use of the Face2Face deepfake dataset, known for its adeptness in facial reenactment. Objectives of the research include evaluating MesoNet's efficacy by scrutinizing its performance across various parameters, fine-tuning the model for improved results, and gaining nuanced insights into its capabilities. Results reveal a notable advancement, with MesoNet achieving an accuracy of 90.4%, surpassing the previous 89.1%. Improved results after careful adjustment of activation functions and regularization parameters underscores the significance of hyperparameter optimization in deep learning models.",CNN;deepfake;MesoNet;face swap;expression swap;Face2Face,IEE
275,DeepFakes Detection in Videos using Feature Engineering Techniques in Deep Learning Convolution Neural Network Frameworks,S. J. Burroughs; B. Gokaraju; K. Roy; L. Khoa,2020,"In this paper, we discuss the intermediate results of our on-going study of DeepFakes detection in videos. Our core focus is in exploitation of feature engineering as a precursor filtering technique, to the deep learning-based convolution neural network (CNN) classification frameworks. In previous research, we focused on the standard deviation of the points of interest from SIFT or Scale-Invariant Feature Transform, to detect whether visual media has been compromised with misinformation. Hence, in this new approach we rely on classical frequency analysis of images that reveals different behaviors at higher frequencies. We noticed in literature review that there lies a distinct contrast of range of frequency component that emphasize important information in images [11]. We plan to use Discrete Wavelet Transform, abbreviated as DWT, and anticipate improvement of detection accuracy when used on complex and poor-quality images of FaceForensics++. The DWT features will be input to the CNN binary classification to further analyze the performance essentially when detecting this fraudulent information and to compare the detection performance against previous research which used Scale-Invariant Feature Transform.",DeepFake;deep learning;discrete wavelet transform;frequency;cyber identity;security,IEE
276,Deepfake Detection: A Multi-Algorithmic and Multi-Modal Approach for Robust Detection and Analysis,S. Nailwal; S. Singhal; N. T. Singh; A. Raza,2023,"In a time when deepfakes are eroding the reliability of digital media, our innovative research introduces a multi-faceted framework that achieves unprecedented levels of detection accuracy. Boasting a 97% success rate in verifying visual content and an almost unblemished 98.5% in audio analysis, our system serves as a formidable barrier against the malicious alteration of digital assets. Central to our model's stellar performance is the seamless integration of convolutional neural networks (CNNs) with ReLU activation mechanisms, all fine-tuned via stochastic gradient descent (SGD). This expertly engineered architecture is highly proficient at analyzing the nuanced spatial features of visual media, and it works in synergy with cutting-edge machine learning algorithms. For the audio detection aspect, we employ random forest algorithms, celebrated for their robustness and versatility. This ensemble learning approach adds an extra layer of complexity to the model, effectively identifying the intricate spectral and temporal characteristics of audio streams, thereby boosting the overall efficacy of our detection system. Our methodology is further fortified by meticulous data preprocessing methods, such as normalization and data augmentation, which ensure the model's robustness against a myriad of deepfake techniques. This groundbreaking research not only establishes a new benchmark in the arena of deepfake detection but also has significant ramifications for the wider field of cybersecurity and the preservation of digital authenticity. With its unmatched performance metrics, our research represents a pivotal advancement in combating the growing menace of deepfakes in today's digital society.",deepfake detection;SGD;CNN;deep learning;random forest;ReLu;GAN,IEE
277,Deep Fake in picture using Convolutional Neural Network,J. N. Singh; A. Gautam; H. Tomar,2023,"Deepfake is a system that combines fake pictures and videos with deep learning. Deep learning is the source of Deepfake. The unethical practice of creating falsified photographs and movies is now possible because of neoteric advances in the fields of Artificial Intelligence and Machine Learning. Today, it is very easy to create photo simulative images using generative adversarial networks. These fake images and videos are widely available on the internet and social media. It is difficult to tell which of them is real or not. These images are typically taken with the goal of stirring up social disturbance, political turmoil, or distributing false information among the general public. Viewers will easily comprehend these images because they will look to be real. Deepfake is rapidly harming individuals, communities, companies, security, religion, and democracy, according to recent studies. These videos and photographs are of astounding quality, and they have a huge social media reach. It has far-reaching effects that are destructive beyond comprehension. An extensive overview of the different deep-fake methods is provided in this publication. So, the objective of this paper is to identify these fake images using a conventional neural network. In order to address this issue, we train a model for particular datasets, produce deep fakes, and then use that model to try to identify the deep fake. An authentic and false image is required for the training process in order to train the model.",CNN;Image Detection;RNN,IEE
278,Robust and Generalized DeepFake Detection,S. Yadav; S. Bommareddy; D. K. Vishwakarma,2022,"Images that are manipulated are prevalent and are on the spike because of the advancement in deep convolutional neural networks (CNNs) techniques. There have been several concerns regarding the advent spread of false information. There exists a need for a reliable and robust method to detect such fake images. In this paper, analysis was done using the architecture SlowFast in detecting manipulated videos. This paper focuses on detecting DeepFake videos under three distinct scenarios, which are (i) all manipulation detection, (ii) single manipulation detection, and then (iii) cross manipulation detection used to test the veracity of the videos. The manipulation methods and designing algorithms to categorize such unknown manipulation techniques were used.",Deepfakes;Deepfake Detection;Media forensics;Computer Vision;SOTA(State-Of-The-Art);Facial Manipulation Detection,IEE
279,Deepfake Detection using GAN Discriminators,S. A. Aduwala; M. Arigala; S. Desai; H. J. Quan; M. Eirinaki,2021,"Deepfake videos are videos where the features of a person are replaced with the features of another person. Videos can be manipulated using powerful Deep Learning techniques. This technology may be used maliciously as a means of misinformation, manipulation, and persuasion. There are currently not many solutions to identify products of Deepfake technology, although there is significant research being conducted to tackle this problem. One often researched deep learning technology is the Generative Adversarial Network (GAN). These networks are commonly used to generate Deepfake videos but not used for their detection. In this work, we explore solutions based on GAN discriminators as a means to detect Deepfake videos. Using MesoNet as a baseline, we train a GAN and extract the discriminator as a dedicated module to detect Deepfakes. We test several discriminator architectures using multiple datasets to explore how the efficacy of the discriminator varies with different setups and training methods. Finally, we propose a model to boost the efficacy of a group of GAN discriminators using ensemble methods. Our results show that GAN discriminators, even augmented by ensemble methods, do not perform well on videos from unknown sources.",Deepfake Detection;Generative Adversarial Networks;GAN;Discriminator;Deepfake Videos;Deep Learning;Image Processing;Feature Recognition,IEE
280,Transfer-Learning and YOLO V7 Hybridised for Human Cropping for Deepfake Detection Algorithms,N. Waqas; S. I. Safie; K. A. Kadir; S. Khan; A. A. Khan,2023,"The advent of deep learning technology has created images and videos convincingly fake to appeal viewers enough in appearing close to real. Such image and video modalities, known as Deepfakes, can cause harm to individuals, communities, and countries. Detecting Deepfakes is essential to prevent their negative impacts, and several detection techniques that utilize deep learning algorithms have been developed over the recent past years. The algorithms reduce the target modality to dimensional latent space to include features important for subsequent reconstruction of the same modality from the developed latent distribution data. However, manual data preprocessing such as splitting frames and cropping regions from Deepfake videos for the facial features can be tedious and time-consuming. This article proposes YOLO V7 hybridised with transfer-learning to automate the cropping process in Deepfake videos and frames splitting, making it easier to extract facial features from videos. Various popular datasets have been used for Deepfake detection, and this article explores the benefits of the proposed approach. The results present a comparison of the proposed approach with state-of-the-art models from the levels of Precision, Recall, and mAP@.5 to demonstrate the robustness of the proposed technique. Notably, it is evident that our approach outperforms other models, boasting a precision value of 0.9009, a recall value of 0.8979, and an mAP@.5 value of 0.8745.",Deepfake;YOLO;Deep learning;Transfer Learning,IEE
281,Quick Classification of Xception And Resnet-50 Models on Deepfake Video Using Local Binary Pattern,A. Arini; R. Broer Bahaweres; J. Al Haq,2022,"The ease of deepfake videos are created indicates that there is an increasing need for authentication methods to classify deepfake videos. This issue is very sensitive, deepfakes make it possible to make someone say or do something they never said or did in a video, this puts a person�s dignity at risk. Another problem arises with the large size of the deepfake video dataset, because large datasets require longer training times and high computational specifications. This paper describes an approach to deepfake video classification using a small dataset and image processing. We propose a method that applies MTCNN (Multi-task Cascaded Convolutional Networks) to capture face data on video frames, image processing in the form of Gaussian filters and Local Binary Pattern (LBP) with Xception model for deepfake video classification and ResNet-50 as comparison. We use a dataset totaling 2000 frames from the entire Celeb-DF(V2) dataset. The results show that the proposed method, the Xception model, has better performance with an AUC value of 0.87 and an accuracy value of 0.79 compared to the ResNet-50 model.",Video Classification;Deepfake;Xception;ResNet-50;MTCNN;Gaussian Filter;Local Binary Pattern;Small Dataset;Celeb-DF(V2),IEE
282,Integrating Audio-Visual Features For Multimodal Deepfake Detection,S. Muppalla; S. Jia; S. Lyu,2023,"Deepfakes are AI-generated media in which an image or video has been digitally modified. The advancements made in deepfake technology have led to privacy and security issues. Most deepfake detection techniques rely on the detection of a single modality. Existing methods for audio-visual detection do not always surpass that of the analysis based on single modalities. Therefore, this paper proposes an audio visual based method for deepfake detection, which integrates fine-grained deepfake identification with binary classification. We categorize the samples into four types by combining labels specific to each single modality. This method enhances the detection under intra-domain and cross-domain testing.",Deepfake detection;Multi-modality deepfakes;Audio-visual feature learning,IEE
283,Deepfakes Detection Methods: A Literature Survey,M. Weerawardana; T. Fernando,2021,"Recently, a great amount of concern has been attracted to the phenomena of DeepFake, which has been created for capturing and reenacting faces in a video and swap a face with someone else�s face using neural networks. In Deepfake technology, a computer-generated fake video shows fictional contents as real things. Many unbelievable applications in this technology are starting to be explored. Currently, malicious usages of fake videos are gaining in the computerized world like fake news, celebrity pornographic videos, revenge porn, and financial frauds. So, celebrities, politicians and famous people are facing mostly to Deepfake detection problem. Human�s naked eyes are weak to directly identify the difference between real videos and Deepfake videos because they are quite realistic. So, bothered people require an automated computerized Deepfake detection tool. This paper reviews existing Deepfake detection methods using traditional methods and deep learning technologies. Further this paper discussing the limitations of current methods and availability of datasets in the society. According to the literature, there is not a highly accurate and automated detection method to identify Deepfakes. The unavailability of efficient Deepfake detection method is a big challenge to the world due to the ease of generating Deepfake videos and their rapid spread. However, there are many efforts to solve this phenomenon and deep learning related methods show remarkable performance than other methods.",Deepfake technology;dataset;fake detection;machine learning;deep learning,IEE
284,4DPM: Deepfake Detection With a Denoising Diffusion Probabilistic Mask,R. Yang; Z. Deng; Y. Zhang; X. Luo; R. Lan,2024,"In the face of increasingly realistic fake human faces, research on enhancing the differences between real and fake images is valuable for improving the generalization capabilities of fake face detection models. In this letter, we propose a method called DPMask (Diffusion Probabilistic Mask) to amplify the distinctions between authentic and counterfeit human facial images. Specifically, we use a dataset consisting of real human facial images and Simplex noise to train a denoising diffusion probabilistic model for the proposed DPMask. Subsequently, we separately apply the DPMask and U-Net to real and fake human facial images to create noticeably distinct genuine and counterfeit human facial images. A lightweight classification network blue is further designed based on RepVGG to classify the newly generated real and fake human faces. Experimental results demonstrate that our model achieves high accuracy on a manually created fake face dataset (RFFD), a GAN-generated fake face dataset (Seq-DeepFake), and a DDPM-generated face dataset (HiFi-IFDL). Furthermore, the addition of DPMask significantly improves the performance of some public fake face detection models.",DDPM;deepfake detection;DPMask;lightweight model,IEE
285,DeepFake Detection Based on Discrepancies Between Faces and Their Context,Y. Nirkin; L. Wolf; Y. Keller; T. Hassner,2022,"We propose a method for detecting face swapping and other identity manipulations in single images. Face swapping methods, such as DeepFake, manipulate the face region, aiming to adjust the face to the appearance of its context, while leaving the context unchanged. We show that this modus operandi produces discrepancies between the two regions (e.g., Fig. 1). These discrepancies offer exploitable telltale signs of manipulation. Our approach involves two networks: (i) a face identification network that considers the face region bounded by a tight semantic segmentation, and (ii) a context recognition network that considers the face context (e.g., hair, ears, neck). We describe a method which uses the recognition signals from our two networks to detect such discrepancies, providing a complementary detection signal that improves conventional real versus fake classifiers commonly used for detecting fake images. Our method achieves state of the art results on the FaceForensics++ and Celeb-DF-v2 benchmarks for face manipulation detection, and even generalizes to detect fakes produced by unseen methods.",Image forensics;deep learning;deep fake;face swapping;fake image detection,IEE
286,Unmasking Deep Fakes: Detecting Low-Quality Forgeries through Unseen Artifacts,M. Venkateshwarlu; M. Yashaswi; D. Shah; R. A. Reddy,2024,"The spread of deepfakee-technology is a danger to the veracity of multimedia material, since it may be used to manipulate people's identities or spread false information. Low-quality forgeries continue to be difficult to detect because of their subtle artifacts, which elude traditional detection approaches. This is true even while deep fake detection algorithms have made significant progress in identifying high-quality forgeries. This research work presents a unique method for identifying hidden elements in low-quality forgeries, which may be used to uncover deep fakes. The proposed approach, which makes use of sophisticated machine learning algorithms and computer vision techniques, is centred on locating and taking advantage of distinctive artifacts that are introduced throughout the deep fake production process. This study provides a thorough analysis of these artefacts and show how well they can distinguish between real multimedia material and poor-quality deep fakes. The proposed technique is effective in properly detecting low-quality forgeries of photos, videos, and audio recordings. These findings are based on experiments conducted on a variety of datasets. Additionally, the proposed method's resilience is assessed against the cutting-edge deep fake creation techniques and emphasize its practical benefits in preventing the distribution of false information.",Deepfakes;generative adversarial networks;convolution neural networks;visibility matrix;cross-entropy,IEE
287,DeepFake Videos Detection and Classification Using Resnext and LSTM Neural Network,S. Patel; S. K. Chandra; A. Jain,2023,"Deepfake videos, which are artificial intelligence-altered videos that have acquired extensive awareness recently. Deep learning algorithms are utilized to create these deepfake films, which are meant to disseminate false information about anyone, including politicians and celebrities. These movies have been purposefully made viral in order to propagate propaganda and false information, to frighten people, and to destabilize society. It is exceedingly challenging for a casual viewer to recognize a deep fake video with the naked eye. Finding these manipulated films has been extremely difficult and requires careful attention. In order to recognize a deepfake movie, this paper, a novel methodology that combines ResNext, a Convolutional Neural Network (CNN) algorithm, with Long Short-Term Memory (LSTM), a Recurrent Neural Network (RNN) has been developed. It is found that as the number of epochs increased, the model's accuracy increased and its training loss reduced.",Artificial Intelligence;Deepfake;Deep learning algorithm;Convolutional Neural Network (CNN);ResNext;LSTM;Recurrent Neural network (RNN),IEE
288,A Comparative Analysis of Deep Fake Techniques,S. Chaudhary; R. Saifi; N. Chauhan; R. Agarwal,2021,"Recent developments and evolutions in machine learning algorithms have directed to the emergence of first-class altered pictures that create video frames and have a striking similarity to real-world pictures that create video frames. This can have a disastrous effect on how people perceive digitally available knowledge or facts. Recent developments in machine learning and camera function have allowed pictures that compose video frames and sounds to be convincingly altered. These deep-fake films differ from actual videos by replacing the soundtrack, the lip movement, or the location where the video was captured (background). Many relevant tools and automated systems for detecting such deep fake films have been developed. Researchers employ techniques such as pose estimation, facial artefacts, temporal pattern analysis, background comparison, eye blinking, and mesoscopic analysis. In a unique statistical research, we want to present a descriptive review of these traditional deep Fake detection approaches.",DeepFakes;Algorithms;Analysis;Creation-Detection,IEE
289,A Study On Deep Fakes Detection Using Blinks and Tracker,V. C; K. S; R. V R; S. S; T. R,2022,"Deep learning, a type of artificial intelligence (AI), replicates how the human brain processes data when processing data for tasks including speech recognition, object detection, visual object recognition, language translation, and decision-making. Generative Adversarial Network (GAN) is an outstanding generative version which can be extensively utilized in diverse applications. Recent research has indicated that it's far feasible to achieve faux face photographs with an excessive visible excellence primarily based totally in this novel version. For instance, the example may be impacted by a person's orientation, age, the hour of the day, or level of personal wellbeing. The misuse of the fake faces in photo manipulation could lead to certain ethical, moral, and legal issues. Therefore, in this work we first recommend a Convolution Neural Network (CNN) based entirely technique to find fake face photos produced by the modern-day pleasant technique, and we provide practical evidences to indicate that the proposed technique can create high-satisfactory results with a median accuracy over 87.5% which was accomplished in previous papers and projects. In order to further support the logic of our method, we also provide comparison results assessed on a few variations of the suggested CNN architecture, including the excessive by skip filter, the variety of the layer agencies, and the activation function.",Deep Learning;Deep fake;GAN's;Cyber Security;CNN,IEE
290,A Comparative Analysis of Deepfake Detection Techniques: A Review,M. Quadir; P. Agrawal; C. Gupta,2023,"Every person in this new generation has access to all of humanity's wisdom. Many technological possibilities are available. Nonetheless, we misuse this benefit by using deepfake for face swap. The deep fake method of machine learning, which is popular on social media, superimposes one person's face over another person's face. Deep learning, which has allowed researchers to produce deepfake images and videos considerably more rapidly and affordably, is the main ingredient in deepfakes. Even though the word �deepfakes� has a terrible image, more people are using the technology privately and practically. Although it is still fairly new, recent technological advancements have made it more difficult to tell the difference between deep fakes and synthetic images. Deepfake technology is evolving, and there is rising unease. The analysis of deep fakes has already been done by a number of researchers utilizing techniques like GAN, Convolution Neural Network with or without LSTM, Support Vector Machine, and Machine Learning. This paper analyzes the many techniques that have been used by researchers to identify Deepfake videos and rates the performance of multiple Deepfake video detection systems. According to our analysis, integrating CNN and the LSTM together produces superior outcomes and accuracy, which could also be improved by applying the concept of image enhancement.",Artificial Intelligence;Deepfake;Generative Adversarial Networks;LSTM;Security,IEE
291,DeepFake-o-meter: An Open Platform for DeepFake Detection,Y. Li; C. Zhang; P. Sun; L. Ke; Y. Ju; H. Qi; S. Lyu,2021,"In recent years, the advent of deep learning-based techniques and the significant reduction in the cost of computation resulted in the feasibility of creating realistic videos of human faces, commonly known as DeepFakes. The availability of open-source tools to create DeepFakes poses as a threat to the trustworthiness of the online media. In this work, we develop an open-source online platform, known as DeepFake-o-meter, that integrates state-of-the-art DeepFake detection methods and provide a convenient interface for the users. We describe the design and function of DeepFake-o-meter in this work.",Multimedia Forensics;DeepFake Detection;Software Engineering,IEE
292,An Efficient Deep Video Model For Deepfake Detection,R. Sun; Z. Zhao; L. Shen; Z. Zeng; Y. Li; B. Veeravalli; Y. Xulei,2023,"The use of deep learning technology to manipulate images and videos of people in ways that are difficult to distinguish from the real ones, known as deepfake, has become a matter of national security concern in recent years. As a result, many studies have been carried out to detect deepfake and manipulated media. Among these studies, deep video models based on convolutional neural networks have been the preferred method for detecting deepfake in videos. This study presents a novel deep video model called Sequential-Parallel Networks (SPNet) that provides efficient deepfake detection. The SPNet model consists of a simple yet innovative sequential-parallel block that first extracts spatial and temporal features sequentially, then concatenates them together in parallel. As a result, the presented SPNet possesses comparable spatiotemporal modeling abilities as most state-of-the-art deep video methods but with lower computation complexity and fewer parameters. The efficiency of the presented SPNet is demonstrated on a large-scale deepfake benchmark in terms of high recognition accuracy and low computational cost.",Deepfake;Deep Video Model;Sequential-Parallel Networks;Spatio-temporal Modelling,IEE
293,Voice Analysis for Detecting Artificial Speech and Predicting Gender and Age: A Literature Survey,R. Bharadwaj; R. Dugad; A. Gile; G. Patil; S. Hatyalikar,2023,This article surveys the literature on voice analysis. The present invention relates to a method and system for analyzing voice data to detect artificial speech then demodulate it to original speech and predict the gender and age of the speaker if the input speech is not fake. The system includes a voice analysis module that processes the voice data and extracts features from the voice signals. The extracted features are then compared with pre-stored reference features to determine the authenticity of the voice signal and the gender and age of the speaker.,Voice Detection;Audio Processing;deep learning;gender voice prediction;neural networks,IEE
294,Comparative Analysis and Evaluation of CNN Models for Deepfake Detection,P. Ritter; D. Lucian; Anderies; A. Chowanda,2023,"Deepfake technology has become a significant concern due to its ability to create highly realistic fake videos and images, leading to the potential deception of individuals. Detecting deepfakes has become a critical research area in computer vision and multimedia forensics. This paper presents a comparative analysis of deepfake detection models, focusing on evaluating their accuracy and robustness. Four CNN models, namely ResNet-152, MobilenetV3, Convnext Large, and EffecientNetB7, were implemented and trained using a custom dataset obtained from FaceForensics++. The models were evaluated based on training accuracy, average loss, and testing accuracy. An LSTM layer was also incorporated into each model's architecture to leverage sequential information. The results demonstrate varying performance among the models, with EfficientNet B7 achieving the highest testing accuracy of 75%. The findings of this study provide insights for future research in this critical area.",deepfake detection;CNN models;comparative analysis;accuracy;LSTM layer,IEE
295,A Threat of Deepfakes as a Weapon on Digital Platform and their Detection Methods,M. Khichi; R. Kumar Yadav,2021,"Advances in machine learning, deep learning, and Artificial Intelligence(AI) allows people to exchange other people's faces and voices in videos to make it look like what they did or say whatever you want to say. These videos and photos are called �deepfake� and are getting more complicated every day and this has lawmakers worried. This technology uses machine learning technology to provide computers with real data about images, so that we can make forgeries. The creators of Deepfake use artificial intelligence and machine learning algorithms to mimic the work and characteristics of real humans. It differs from counterfeit traditional media because it is difficult to identify. As In the 2020 elections loomed, AI-generated deepfakes were hit the news cycle. DeepFakes threatens facial recognition and online content. This deception can be dangerous, because if used incorrectly, this technique can be abused. Fake video, voice, and audio clips can do enormous damage. This paper examines the algorithms used to generate deepfakes as well as the methods proposed to detect them. We go through the threats, research patterns, and future directions for deepfake technologies in detail. This research provides a detailed description of deep imitation technology and encourages the creation of new and more powerful methods to deal with increasingly severe deep imitation by studying the history of deep imitation.",Deepfake;Convolutional Neural Networks(CNNs);Deep Neural Networks(DNNs);Recurrent Neural Networks(RNNs);Generative Adversarial Networks(GANs);Deepfake Detection Challenge(DFDC),IEE
296,Exploiting Correlation Between Facial Action Units for Detecting Deepfake Videos,Q. H. Vu; P. Singh,2024,"The potential misuse of deepfakes has led to an increase in research into deepfake detection methods. These methods employ machine learning, deep learning, and other intricate techniques to spot subtle inconsistencies in deepfake videos. However, as deepfake technology advances, the current research exposes gaps, such as inadequate performance on real-world data and susceptibility to adversarial attacks. Among various detection methodologies, the use of identity-based features like facial action units shows potential in identifying synthetic content. Given that correlations between facial features may be distinctive, they could play a crucial role in differentiating real and artificial imagery. In this study, we propose a method of high accuracy to distinguish genuine videos from deepfakes by exploiting the correlation of facial action units. Our main contributions are twofold: (1) merging identity-based techniques with traditional machine learning for deepfake detection, and (2) evaluating this approach's robustness against compression.",Deepfake detection;action units;facial features,IEE
297,ShuffleSR: Image Deepfake Detection Using Shuffle Transformer,C. Yang; C. Zhu; C. Deng; Z. Xiao,2023,"We proposed an improved method based on the Shuffle Transformer for facial forgery detection. The method incorporated SE (Squeeze-and-Excitation) and ROI (Region of Interest) modules. By introducing the SE module, the network's channel attention capability was enhanced and enabled the model to focus more on important feature channels. Meanwhile, the ROI module was employed to extract the region of interest corresponding to the face, enabling the network to concentrate on processing facial regions. The performance of facial forgery detection was improved as a result. Evaluations were conducted on the DFDC dataset and a custom dataset containing various forgery algorithms. The results demonstrated that the enhanced Shuffle Transformer achieved significant performance improvements in facial forgery detection and exhibited better robustness and generalization capabilities while excelling across different forgery algorithms.",deep learning;Shuffle Transformer;facial forgery detection;region of interest,IEE
298,Cross-Modality and Within-Modality Regularization for Audio-Visual Deepfake Detection,H. Zou; M. Shen; Y. Hu; C. Chen; E. S. Chng; D. Rajan,2024,"Audio-visual deepfake detection scrutinizes manipulations in public video using complementary multimodal cues. Current methods, which train on fused multimodal data for multimodal targets face challenges due to uncertainties and inconsistencies in learned representations caused by independent modality manipulations in deepfake videos. To address this, we propose cross-modality and within-modality regularization to preserve modality distinctions during multimodal representation learning. Our approach includes an audio-visual transformer module for modality correspondence and a cross-modality regularization module to align paired audio-visual signals, preserving modality distinctions. Simultaneously, a within-modality regularization module refines unimodal representations with modality-specific targets to retain modal-specific details. Experimental results on the public audio-visual dataset, FakeAVCeleb, demonstrate the effectiveness and competitiveness of our approach.",Audio-visual fusion;deepfake detection;contrastive learning;representation regularization,IEE
299,Deepfake Detection Using XceptionNet,A. V; P. T. Joy,2023,"This paper presents a precise and highly efficient method for detecting deepfakes, which have become increasingly accessible via mobile applications, posing significant threats to society. Leveraging the Xception network, a state-of-the-art convolutional neural network (CNN), we address the challenge of identifying and categorizing deepfakes in both images and videos. With deepfakes achieving unprece-dented levels of visual fidelity, traditional detection methods are inadequate. The Xception network excels in capturing intricate visual patterns and anomalies indicative of deepfake manipulation. Trained on extensive datasets encompassing both real and deepfake content, it offers exceptional generalization capabilities, enabling accurate classification of previously unseen instances. This research emphasizes the critical need for robust deep fake detection mechanisms to protect against malicious use, ensuring compliance with official rules and ethical standards, and preserving public trust. The proposed Xception- based approach holds promise in addressing this pressing challenge, providing a reliable means to distinguish deepfakes from authentic content, ultimately safeguarding the integrity of digital media and information dissemination.",Deepfake;XceptionNet;Deep learning,IEE
300,DeepFake Detection for Human Face Images and Videos: A Survey,A. Malik; M. Kuribayashi; S. M. Abdullahi; A. N. Khan,2022,"Techniques for creating and manipulating multimedia information have progressed to the point where they can now ensure a high degree of realism. DeepFake is a generative deep learning algorithm that creates or modifies face features in a superrealistic form, in which it is difficult to distinguish between real and fake features. This technology has greatly advanced and promotes a wide range of applications in TV channels, video game industries, and cinema, such as improving visual effects in movies, as well as a variety of criminal activities, such as misinformation generation by mimicking famous people. To identify and classify DeepFakes, research in DeepFake detection using deep neural networks (DNNs) has attracted increased interest. Basically, DeepFake is the regenerated media that is obtained by injecting or replacing some information within the DNN model. In this survey, we will summarize the DeepFake detection methods in face images and videos on the basis of their results, performance, methodology used and detection type. We will review the existing types of DeepFake creation techniques and sort them into five major categories. Generally, DeepFake models are trained on DeepFake datasets and tested with experiments. Moreover, we will summarize the available DeepFake dataset trends, focusing on their improvements. Additionally, the issue of how DeepFake detection aims to generate a generalized DeepFake detection model will be analyzed. Finally, the challenges related to DeepFake creation and detection will be discussed. We hope that the knowledge encompassed in this survey will accelerate the use of deep learning in face image and video DeepFake detection methods.",Deep learning;DeepFake;CNNs;GANs,IEE
301,"The Art of Deepfake Text Obfuscation: Lessons Learned From a Manual, First-Person Perspective",J. Jang; T. Le,2024,"The rapid emergence of generative AI, particularly large-language-model-based conversational chatbots like Chat-GPT, has brought about significant advancements. However, they are also accompanied by pressing concerns about potential harmful uses, such as the generation of large-scale misinformation and political propaganda online. To tackle these, there have been several developments in AI -generated text detection tools that can effectively detect whether a text is generated by machines or written by humans. This paper analyzes the behaviors of these detectors from the adversarial perspective via the emerging text obfuscation task from the natural language processing literature. Particularly, this paper focuses on assessing the accuracy and limitations of machine-generated text detectors by employing a manual, first-person perspective of text obfuscation. Text obfuscation can be simply described as manipulating certain elements of an AI -generated text to deceive a detector model. Our findings reveal the ease with which these detectors can be deceived through intuitive text obfuscation, exposing potential weaknesses. The results of our study shed light on the human perception of text obfuscation, contrasting it with that of machines and advocating for continued development in AI-generated text detection.",Generative AI;Text obfuscation;AI detection,IEE
302,Forgery-Domain-Supervised Deepfake Detection With Non-Negative Constraint,Y. Yuan; X. Fu; G. Wang; Q. Li; X. Li,2022,"Fake faces produced by deepfake techniques have attracted public concerns in recent years. Deepfake detection is a binary classification task that distinguishes fake faces from real ones. As the training data for deepfake detection is usually generated from real faces via various face forgery methods, it is difficult for a single binary decision boundary to distinguish fake faces. Besides that, the learned features often involve irrelevant information for identifying fake faces that are generated from diverse forgery methods. To deal with such challenges, unlike existing approaches that regard fake detection as a binary classification, we re-model the task as a multiclass forgery-domain classification task, where each forgery method is treated as a distinct class. This simplifies the complex decision boundary brought by the diversity of forgery patterns and provides more forgery-relevant information for the learning process. In addition, we introduce a non-negative constrained learning framework composed of non-negative features and a non-negative constrained classifier (NCC) to block irrelevant features with zero weights and enhance forgery-relevant features with positive weights, leading to a sparse structure of the classifier. Furthermore, to capture subtle and discriminative forgery-relevant features, we propose an integration module over augmented faces based on cross-attention. We demonstrate that our approach achieves competitive performance and generalization ability on widely-used benchmarks through extensive experiments.",Classifier regularization;deepfake detection;face classification;face forensics;feature integration,IEE
303,Deepfake Video Authentication Based on Blockchain,U. Patil; P. M. Chouragade,2021,"Nowadays, it is difficult to predict the information such as news and videos on the internet is real or not and people are increasingly sharing it on social media without thinking of fake. As soon as they verify the authenticity of a video, they start expressing their concerns and sharing the opinions of others. Therefore, such videos spread rapidly and help in sharing fake videos or unverified information. The need today is to focus on building a strong fake video detection system as soon as possible to avoid the consequences of such unverified information. This paper analyzes the recent research articles to detect the deep fake videos on social media.",Blockchain;Deepfake Video;Fake Video;Fake Video Detection System;Video Authentication;Video Integrity;Video Tampering,IEE
304,Deepfake Detection using Inception-ResNet-V2 Network,R. R. Rajalaxmi; S. P. P; R. A. M; P. S; D. P; G. E,2023,"Deepfakes entails obscene videos in which a face can be changed with someone else's utilizing neural networks. Deepfakes are a public problem, thus developing methods to detect them is critical. With deepfake and human-level control, deep learning has already utilized to address complicated issues. Deepfake is a new branch of AI technology, which in that one's face is superimposed on another's face, which is popular on social media. Deep learning techniques were also employed in the development of software that affects national security, democracy and privacy. One of the most current applications that use deep learning is deepfakes. Algorithms for deepfake may generate fake photos and movies which are indistinguishable from real ones. As a result, the development of technology capable of automatically detecting and assessing the reliability of digital video is critical. This research describes algorithms for detecting deepfakes. By reviewing the influence of deepfakes and deepfake recognition systems, this work enables the creation of new and so many effective methodologies to cope with increasingly complex deepfakes. InceptionResNetV2 architecture in Convolutional Neural Networks (CNN) is utilized in this comparative study to distinguish real and deepfake images.",Deep Learning;Deepfake;CNN;Inception ResNet-V2,IEE
305,Application of spatial and Wavelet transforms for improved Deep Fake Detection,F. Aymen; W. Hussein,2024,"Deepfake technology has been controversial for the past recent years. It has been considered a double-edged sword for what it has the capability of doing. As much as deep fake technology can be beneficial in many situations, it has caused a global concern over the safety of individuals. It can be used to create inappropriate content to blackmail someone, or it can be used to fabricate fake news and cause chaos in society. Therefore, developing algorithms to detect whether any content is authentic or tampered with is crucial to protect people. With the evolution of Generative Adversarial Networks (GANs), many deepfake tools have evolved to create non-distinguishable content. This new evolution has raised the flag of the necessity to get matters into control. In this research, various new methods to detect deep fakes are proposed using the frequency analysis (Fourier transform and wavelet transform) of the frames of the videos to discriminate the footage achieving an accuracy of 92.24% using a novel CNN-LSTM model trained on Wavelet transform data. This research argues that the wavelet transform can hold information and features that can outperform training on spatial images on a custom dataset that combines many various datasets.",Deepfake;spatial domain;frequency domain;Fourier transform;wavelet Transform;3DCNN;CNN-LSTM;Multimodal Model;Spatial-temporal Transformer,IEE
306,Artifact Based Deepfake Detection Methods,Preeti; S. Bansal,2023,"One of the biggest innovations of Artificial Intelligence (AI) is the ability to generate manipulated or synthesized media (images, videos). When these generated media is created in to look like real and original people then it is called a Deepfake. Deepfakes have gained attention due to their potential to create convincing and misleading content that can be difficult to distinguish from authentic media. While they have garnered positive value in entertainment sector but have seen as a biggest threat regarding its ethical and societal implications particularly in the context of misinformation, identity theft, privacy invasion, and defamation. Rigorous research has been done since its beginning to prevent and detect media forgery and many detection techniques have been developed and discussed in literature. There is no clear winner in identification of DeepFakes however the artefact-based approaches seem to be much superior in the literature. In order to find the lean and identify best detection technique, an evaluation of existing techniques is needed which is the main purpose of our paper. This compares the video forgery detection techniques in terms of convergence, accuracy and equal error rate (EER).",Artificial Intelligence;Machine Learning;Generative AI;DeepFakes;Artifacts,IEE
307,Deepfake Video Detection Methods using Deep Neural Networks,M. Kshirsagar; S. Suratkar; F. Kazi,2022,"Nowadays, humans are dealing with incipient trouble known as deepfake videos, advanced with the usage of deep learning. Due to freely accessible deep fake technology equipment and inexpensive computational power, internet is flooded with fake media like fake images, videos, audios etc. Fake images and videos are causing threats to privacy, reputation and the very identity of common people. Researchers are taking efforts to develop tools using various Convolutional Neural Networks (CNNs) to automatically detect this fake media however the existing tools are not able to cope with the evolution of deep fakes. In this paper, 26 unique deep convolutional models are utilised for the task of deepfake video detection. The models can natively classify objects like table, face, humans, cars etc. However, the paper highlights the use of these models in detection of deepfake/manipulated images and videos by changing the top layer of the model with sigmoid layer hence, detecting artifacts in an image produced by Generative Adversarial Networks (GANs)[11]. Once the models are trained, the paper demonstrates the usefulness of model ensemble to improve the accuracy of proposed system and thereby making the system more reliable.",Deep learning;deepfake detection;ensemble learning;autoencoders,IEE
308,Deepfake Detection through Deep Learning,D. Pan; L. Sun; R. Wang; X. Zhang; R. O. Sinnott,2020,"Deepfakes allow for the automatic generation and creation of (fake) video content, e.g. through generative adversarial networks. Deepfake technology is a controversial technology with many wide reaching issues impacting society, e.g. election biasing. Much research has been devoted to developing detection methods to reduce the potential negative impact of deepfakes. Application of neural networks and deep learning is one approach. In this paper, we consider the deepfake detection technologies Xception and MobileNet as two approaches for classification tasks to automatically detect deepfake videos. We utilise training and evaluation datasets from FaceForensics++ comprising four datasets generated using four different and popular deepfake technologies. The results show high accuracy over all datasets with an accuracy varying between 91�98% depending on the deepfake technologies applied. We also developed a voting mechanism that can detect fake videos using the aggregation of all four methods instead of only one.",DeepFake Detection;Xception;MobileNet;FaceForenscis++;Keras;TensorFlow,IEE
309,eKYC-DF: A Large-Scale Deepfake Dataset for Developing and Evaluating eKYC Systems,H. Felouat; H. H. Nguyen; T. -N. Le; J. Yamagishi; I. Echizen,2024,"The reliability of remote identity-proofing systems (i.e., electronic Know Your Customer, or eKYC, systems) is challenged by the development of deepfake generation tools, which can be used to create fake videos that are difficult to detect using existing deepfake detection models and are indistinguishable by facial recognition systems. This poses a serious threat to eKYC systems and a danger to individuals� personal information and property. Existing deepfake datasets are not particularly appropriate for developing and evaluating eKYC systems, which require specific motions, such as head movement, for liveness detection. Furthermore, they do not contain ID information or protocols for facial verification evaluation, which is vital for eKYC. We found that eKYC systems without the ability to detect deepfakes can be easily compromised. We have thus created a large-scale collection of high-quality fake videos (more than 228,000 videos) that are diverse in terms of age, gender, and ethnicity, plus a corresponding facial image subset. The videos include a variety of head movements and facial expressions. This large collection of high-quality diverse videos is well-suited for developing and evaluating various tasks related to eKYC systems. Furthermore, we provide protocols for traditional deepfake detection and facial verification, which are widely used in eKYC systems. It is worth mentioning that systematic evaluation of facial recognition systems on deepfake detection has not been reported. The entire eKYC-DF dataset, evaluation toolkit, and trained models are open access to researchers on GitHub: https://github.com/hichemfelouat/eKYC-DF.",Deepfake detection;electronic Know Your Customer;eKYC;facial verification;face swapping;face recognition,IEE
310,Deepfake Detection System Using a Hybrid Model,S. S; P. Kokil; S. D; P. A. Swamy,2023,"There has been a rapid advancement in deep fake technology in recent years, which makes it increasingly difficult to detect fake images, especially those involving human faces, which have become difficult to detect. The traditional methods of detecting deep fake images are usually based on a human-crafted feature or a rule-based system, which can be easily beaten with simple cheating techniques. Intending to detect deepfake face images, we present a novel method that uses CapsNet and EfficientNet as feature extractors to detect deepfake face images. They are well suited to detect deepfake images that have undergone geometric transformations or variations as they can learn the spatial relationship between those features. Using EfficientNet, a powerful and efficient deep learning architecture, as a feature extractor, we extract high-level characteristics from an input image to create a more accurate image analysis.Based on our experiments,it was found that this method demonstrated the capability to detect various types of deep fake images with an accuracy rate of 99.64%, including those fabricated through face swapping and re-enacting. This method could be applied to a wide range of real-world applications, including in media forensics, law enforcement, and online media verification, so that it could be applied in many different contexts.",EfficientNet;Capsule;Networks;Routing layer;Transfer learning;Deep fake,IEE
311,A Novel Framework based on a Hybrid Vision Transformer and Deep Neural Network for Deepfake Detection,M. Shahin; M. Deriche,2024,"Generative Adversarial Networks (GANs) have enabled the creation of photo-realistic images from random noise. GAN based technologies however, led to the dissemination of synthetic images, often containing inappropriate and miss leading content, on social media. Detecting such manipulated images is crucial, yet challenging. The issue is compounded by the fact that GAN-generated images can be indistinguishable from authentic ones, rendering traditional forgery detection techniques ineffective. Deepfake images further exacerbate this problem, posing threats to news integrity, legal proceedings, and societal security. To address these challenges, we harness the potential of Vision Transformer (ViT) in conjunction with Convolutional Autoencoders (CAE) to craft innovative Framework for image analysis and deepfake detection. We introduce two distinct models, each offering unique insights into image processing. The proposed models yield excellent accuracy rate of approximately 87%, reaffirming the robustness and consistency of the proposed approach and enhanced performance compared to state of the art.",,IEE
312,Detection of Deepfake Environmental Audio,H. Ouajdi; O. Hadder; M. Tailleur; M. Lagrange; L. M. Heller,2024,"With the ever-rising quality of deep generative models, it is increasingly important to be able to discern whether the audio data at hand have been recorded or synthesized. Although the detection of fake speech signals has been studied extensively, this is not the case for the detection of fake environmental audio. We propose a simple and efficient pipeline for detecting fake environmental sounds based on the CLAP audio embedding. We evaluate this detector using audio data from the 2023 DCASE challenge task on Foley sound synthesis. Our experiments show that fake sounds generated by 44 state-of-the-art synthesizers can be detected on average with 98% accuracy. We show that using an audio embedding trained specifically on environmental audio is beneficial over a standard VGGish one as it provides a 10% increase in detection performance. The sounds misclassified by the detector were tested in an experiment on human listeners who showed modest accuracy with nonfake sounds, suggesting there may be unexploited audible features.",Fake detection;Environmental sound;Deep learning;Classification;Deepfake audio,IEE
313,"Deepfake Video Detection Based on Spatial, Spectral, and Temporal Inconsistencies Using Multimodal Deep Learning",J. K. Lewis; I. E. Toubal; H. Chen; V. Sandesera; M. Lomnitz; Z. Hampel-Arias; C. Prasad; K. Palaniappan,2020,"Authentication of digital media has become an ever-pressing necessity for modern society. Since the introduction of Generative Adversarial Networks (GANs), synthetic media has become increasingly difficult to identify. Synthetic videos that contain altered faces and/or voices of a person are known as deepfakes and threaten trust and privacy in digital media. Deep-fakes can be weaponized for political advantage, slander, and to undermine the reputation of public figures. Despite imperfections of deepfakes, people struggle to distinguish between authentic and manipulated images and videos. Consequently, it is important to have automated systems that accurately and efficiently classify the validity of digital content. Many recent deepfake detection methods use single frames of video and focus on the spatial information in the image to infer the authenticity of the video. Some promising approaches exploit the temporal inconsistencies of manipulated videos; however, research primarily focuses on spatial features. We propose a hybrid deep learning approach that uses spatial, spectral, and temporal content that is coupled in a consistent way to differentiate real and fake videos. We show that the Discrete Cosine transform can improve deepfake detection by capturing spectral features of individual frames. In this work, we build a multimodal network that explores new features to detect deepfake videos, achieving 61.95% accuracy on the Facebook Deepfake Detection Challenge (DFDC) dataset.",deepfake detection;deep learning;multi-modal;computer vision,IEE
314,A New Approach to Detect Deepfake Video using Multi-Input Convolutional Neural Network,M. A. Rahman; M. Ehsan Shahmi Chowdhury,2022,"In this modern age, Deepfake videos are spreading around, having a severe impact on the social and personal lives of the general public. Efficient techniques, operating better than others, is hence in the requirement. In this research, combination of many objects like left eye, right eye and mouth shapes from image frames of videos are taken into consideration, thus achieving better accuracy than other detection techniques. In this proposal, deep learning techniques, specially the multi-input Convolution Neural Network, are executed. The proposal firstly detects the face, followed by specific objects such as left eye, right eye and mouth. Then multi-input CNN is applied that classifies the data based on eyes and mouth. After applying multi-input CNN, the accuracy increases impressively. Novel techniques are used to extract specific features like eyes, mouth. Memory storage was a concern for the proposal. Despite this, comparison with other relevant research works proved better accuracy and data analysis.",Convolutional Neural Network;DeepFake Detection;Deep Learning;Image Frames;Video Detection,IEE
315,Using the CNN Architecture Based on the EfficientNetB4 Model to Efficiently Detect Deepfake Images,A. Zhalgasbayev; T. Aiteni; N. Khaimuldin,2024,"This study evaluates the effectiveness of using the EfficientNetB4 model architecture for deepfake image detection and identifies the main challenges in developing an accurate model for deepfake image detection. Deepfake image detection is a complex task that requires lots of data, advanced models and new approaches for handling features in face images which shows that image is real or fake. This research is based on the Deepfake Detection Challenge (DFDC), which took place in 2019�2020, where world experts showed new approaches to solving this problem. During the research and development of the model, the best practices and experience of experts were used to identify the deepfake images.",Deepfake;Deep Learning;EfficientNet;CNN;TensorFlow,IEE
316,Deepfake Video Detection by Combining Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN),Y. Al-Dhabi; S. Zhang,2021,"Nowadays, people are facing an emerging problem called deepfake videos. These videos were created using deep learning technology. Some are created just for fun, while others are trying to manipulate your opinions, cause threats to your privacy, reputation, and so on. Sometimes, deepfake videos created using the latest algorithms can be hard to distinguish with the naked eye. That's why we need better algorithms to detect deepfake. The system we are going to present is based on a combination of CNN and RNN, as research shows that using CNN and RNN combined achieve better results. We are going to use a pre-trained CNN model called Resnext50. Using this, we save the time of training the model from scratch. The proposed system uses Resnext pretrained model for Feature Extraction and these extracted features are used to train the Long short-term memory (LSTM). Using CNN and RNN combined, we capture the inter frames as well as intra frames features which will be used to detect if the video is real or fake. We evaluated our method using a large collection of deepfake videos gathered from a variety of distribution sources. We demonstrate how our system may obtain competitive results while utilizing a simplistic architecture.",Deep learning;Deepfake Detection;convolutional Neural Network (CNN);Recurrent Neural Network (RNN),IEE
317,Deepfake Detection with Deep Learning: Convolutional Neural Networks versus Transformers,V. L. L. Thing,2023,"- The rapid evolvement of deepfake creation technologies is seriously threating media information trustworthiness. The consequences impacting targeted individuals and institutions can be dire. In this work, we study the evolutions of deep learning architectures, particularly CNNs and Transformers. We identified eight promising deep learning architectures, designed and developed our deepfake detection models and conducted experiments over well-established deepfake datasets. These datasets included the latest second and third generation deepfake datasets. We evaluated the effectiveness of our developed single model detectors in deepfake detection and cross datasets evaluations. We achieved 88.74%, 99.53%, 97.68%, 99.73% and 92.02% accuracy and 99.95%, 100%, 99.88%, 99.99% and 97.61 % AUC, in the detection of FF++ 2020, Google DFD, Celeb-DF, Deeper Forensics and DFDC deepfakes, respectively. We also identified and showed the unique strengths of CNNs and Transformers models and analysed the observed relationships among the different deepfake datasets, to aid future developments in this area.",deepfakes;misinformation;detection;deep learning;convolutional neural networks;transformers;authenticity verification,IEE
318,Deepfake Detection using Inception-ResnetV2,A. Verma; D. Gupta; M. K. Srivastava,2021,"Deep learning has benefited us in resolving many complex problems. Computer vision is a subcategory of it. With the ability to find patterns from unstructured data, Deep learning has immense potential. Big techs are very keen on producing a computer with human brain-like decision-making capabilities. With all these sweeter sides comes the bitter side of it. Deepfake is one such occurrence. It creates a mask which contain properties of a particular person and can be applied to some other person. In this way the target is depicted doing deeds which he never did. With the increased capacity of a specific field i.e. Generative Adversarial Network (GAN); now we can create high-quality deepfakes. Deepfakes nowadays can easily deceive human eyes. The consequences of this can be devastating and unforeseeable. Creating chaos, privacy threats are some of the major reasons why people are questioning deepfakes. Victims� size has started including common public. What could be done is to keep a check over its spreading. This work has taken into consideration the problems that emerged by deepfakes and proposed a method to detect forgery among videos.",Deep Learning;DeepFakes;Artificial Intelligence;Inception-ResnetV2,IEE
319,DeepfakeStack: A Deep Ensemble-based Learning Technique for Deepfake Detection,M. S. Rana; A. H. Sung,2020,"Recent advances in technology have made the deep learning (DL) models available for use in a wide variety of novel applications; for example, generative adversarial network (GAN) models are capable of producing hyper-realistic images, speech, and even videos, such as the so-called �Deepfake� produced by GANs with manipulated audio and/or video clips, which are so realistic as to be indistinguishable from the real ones in human perception. Aside from innovative and legitimate applications, there are numerous nefarious or unlawful ways to use such counterfeit contents in propaganda, political campaigns, cybercrimes, extortion, etc. To meet the challenges posed by Deepfake multimedia, we propose a deep ensemble learning technique called DeepfakeStack for detecting such manipulated videos. The proposed technique combines a series of DL based state-of-art classification models and creates an improved composite classifier. Based on our experiments, it is shown that DeepfakeStack outperforms other classifiers by achieving an accuracy of 99.65% and AUROC of 1.0 score in detecting Deepfake. Therefore, our method provides a solid basis for building a Realtime Deepfake detector.",Deepfake;DeepfakeStack;GANs;Deep Ensemble Learning;Greedy Layer-wise Pretraining,IEE
320,Detecting Deepfakes Using Deep Learning,J. C. Dheeraj; K. Nandakumar; A. V. Aditya; B. S. Chethan; G. C. R. Kartheek,2021,"Images play an important role in defining human perception, and the power to manipulate such images gives immense power to malicious users. The new advancement in Artificial Intelligence, has altogether worked on the quality and productivity in creating counterfeit face pictures; for instance, the face manipulated by GANs is sensible to such an extent that it is hard to recognize the validness, either by the computer or by people. To improve the accuracy of recognizing facial pictures created by AI from genuine facial ones, an enhanced model has been proposed in this paper which is dependent on profound learnings like Deep Learning, Convolutional Neural Network (CNN), and Error Level Analysis (ELA). Our findings push the boundaries of understanding DeepFake detection and our solution to detect these images is based on the concepts of image error level and Deep learning. Our model uses the Convolutional Neural Network (CNN) architecture that utilizes error level analysis (ELA) to pre-process the images. We have utilized a dataset comprising on 24,000 images with equal split of real and deepfake images to traing and test our model. We were able to achieve an accuracy of 99%. The proposed model has a shorter training time and higher efficiency than most other methods for DeepFake detection.",Convolutional Neural Network (CNN);Error Level Analysis (ELA);Deep Learning;DeepFake,IEE
321,Dual-Task Mutual Learning With QPHFM Watermarking for Deepfake Detection,C. Wang; C. Shi; S. Wang; Z. Xia; B. Ma,2024,"Deepfake technology has rapidly evolved and emerged in recent years, posing significant threats to individuals' reputations and security. Although passive detection methods can achieve reasonable accuracy, they still lack proactive defense mechanisms. To address this issue, this letter proposes a proactive detection framework that combines Quaternion Polar Harmonic Fourier Moments (QPHFMs) with Dual-Task Mutual Learning (DTML) framework. Firstly, watermark information is embedded into QPHFMs, ensuring high imperceptibility while enhancing robustness against common attacks. Secondly, DTML is introduced, where the knowledge distilled from watermark detection can facilitate more accurate deepfake detection. Experimental results on benchmark datasets demonstrate that our method surpasses state-of-the-art techniques, delivering exceptional performance in watermark robustness and imperceptibility while simultaneously accomplishing accurate deepfake detection.",Dual-task mutual learning;image watermarking;quaternion polar harmonic Fourier moments;proactive deepfake detection,IEE
322,Deep fake Image Detection Based on Deep Learning Using a Hybrid CNN-LSTM with Machine Learning Architectures as Classifier,O. A. H. H. Al-Dulaimi; S. Kurnaz,2024,"One of the most important and difficult subjects in social communication is detecting deepfake images and videos. Deepfake techniques have developed widely, making this technology quite available and proficient enough so that there is worry about its bad application. Considering this issue, discovering fake faces is very important for ensuring security and preventing sociopolitical issues on a private and general level. Deep learning provides higher performance than typical image processing approaches when it comes to deepfake detection. This work presents construction of an artificial intelligence system, which is capable of detecting deepfake from more than one dataset. This study proposes neural network models based on deep learning using random forest (RF) and support vector machines (SVM) as classifier for deepfake detection. The use of two classifiers (RF) and (SVM) and their combination with a convolutional neural network is the first study of its kind in the field of deepfake detection in images from three open-source datasets (FaceForensics++, FaceAntiSpoofing, and iFakeFaceDB). This proposed method shows an accuracy of 96%, 87% and 52% in iFakeFaceDB, CelebA-Spoof, FaceForensics++ and respectively.",Convolutional neural network;DeepFake detection;Machine learning,IEE
323,Investigation Of Comparison on Modified CNN Techniques to Classify Fake Face in Deepfake Videos,A. G. S; N. Thillaiarasu,2022,"Deepfake is an advanced deep learning technology that will allow us to swap faces. With recent advancements in Neural network algorithms such as Generative Adversarial Neu- ral networks, hyper-realistic images and videos can be generated. It will be difficult to differentiate between fake and real images orvideos for naked eyes. These fake images and videos pose a real threat in various societal platforms. To reduce these issues various deep learning technologies can be used to classify deepfakes. Here we have compared three neural net models such as ResNext., Xception, and Ensemble of both. Our study has shown that the Ensemble method works better compared to others.",GAN;ResNext;Xception;BlazeFace;CNN;En-semble;Deep Learning;Deepfake,IEE
324,A Novel Framework for Detection of Digital Face Video Manipulation using Deep Learning,S. Chandra; S. Saxena; S. Kumar; M. K. Chaube; S. K G; S. H. Alsamhi; E. Curry; A. Saif,2023,"Digital face manipulation and classification have recently attracted the attention of academia and industry worldwide. Researchers have developed deep learning and computer vision techniques for detecting face manipulations, and it has become a challenging task to differentiate between authentic and manipulated face images manually. The challenge results in the decline of authenticity in digital media content. In this paper, we propose a framework for the classification of manipulating face images using the EfficientNet learning model. The proposed framework takes four digital facial forgeries: Face-Swap, Face-2-Face, DeepFakes, and neural textures. Multiple manipulation techniques are used to process manipulated faces, such as the Blaze-face tracking method, to determine the locations of the face images and pixel coordinates. The proposed framework is used first to identify the type of face manipulation and then to perform detection of the tampered regions in the face images. The proposed framework provided an automated benchmark that considers all four modification techniques in a realistic situation. The results show that the proposed framework outperforms existing approaches regarding accuracy and efficiency. Furthermore, the proposed framework is suitable for detecting digital face video manipulation in various applications, including forensics and security.",Machine learning;deep learning;Face-Swap;neural textures;Face-2-Face,IEE
325,Face forgery detection with a fused attention mechanism,J. Wang; Y. Qi; J. Hu; J. Hu,2022,"In recent years, the technology of forged faces has become more and more sophisticated, and the human eye cannot even distinguish these forged products. The fake face images or videos generated by this series of technologies are widely disseminated on the Internet, causing a serious impact on society, thus drawing attention to DeepFake detection, and more research is also inclined to this, but The current research has the problem that the extracted artifact features are relatively single, which leads to the relatively low performance of the artifact detection algorithm. To solve the limitations of the existing methods, the DeepFake detection method fused with attention mechanism is proposed, which extracts the global and local features of the face respectively. Artifact features are found in multiple regions of the face. The method is trained on the FaceForensics++ dataset, and the detection accuracy is improved in different network structures.",DeepFake Detection;attention mechanism;feature fusion,IEE
326,Image Feature Detectors for Deepfake Image Detection Using Transfer Learning,K. M. A. Alheeti; S. S. Al-Rawi; H. A. Khalaf; D. Al Dosary,2021,"Deepfake is heavily based on artificial intelligence and machine learning to generate audio content and visuals with an extremely high potential to deceive. In this paper, a new detection system to identify any deepfake for audio or images. In other words, transfer learning techniques are used to present an intelligent detection system of deepfake videos. In this work, a support vector machine is employed for the detection process. Outstanding results are obtained from the train and test this system with various types of images that are real or fake.",AI;deepfake;detection;machine learning,IEE
327,Audio-Visual Deepfake Detection System Using Multimodal Deep Learning,A. Parikh; K. Pereira; P. Kumar; K. Devadkar,2023,"With the rise of deepfake videos in today�s digital landscape, there is a pressing need to develop advanced detection and mitigation technologies. Deepfake videos, which use machine learning algorithms to manipulate and alter audiovisual content, can spread false information, create confusion, and even cause harm. To address this issue, our work leverages Deep Learning technology to process audio-visual data in real-time through a web interface, specifically a browser plugin. Our approach uses a multimodal neural network that is fed extracted audio and visual features from a video for deepfake prediction. The model achieves a maximum validation accuracy of 90 percent and is used to build an API that is responsive, and low-latency. Our end-to-end solution is implemented as a Chrome extension using JavaScript that communicates with the API. With this solution, we aim to contribute to the development of advanced deepfake detection and mitigation technologies that can help prevent the spread of false information and its potential consequences.",Deepfakes;Computer Vision;Deep Learning;Multimodal Datasets,IEE
328,"Bot or Human? Detection of DeepFake Text with Semantic, Emoji, Sentiment and Linguistic Features",A. T. Y. Chong; H. N. Chua; M. B. Jasser; R. T. K. Wong,2023,"Detecting machine-generated text (MGT), also known as Deepfake text, has become increasingly important in Artificial Intelligence (AI) age and social media platforms. With the proliferation of MGT and the potential consequences of its dissemination, there is a pressing need to develop effective methods for distinguishing between MGT and human-written text (HWT). Our research aim has two-fold: firstly, to examine the inherent differences between MGT and HWT on Twitter, and secondly, to develop a classifier specifically designed for MGT detection on the platform. This classifier utilizes contextualized text embeddings as its foundation while considering additional linguistic features, sentiment features, and emoji embeddings. Our experimental results demonstrate that incorporating additional features enhances the model's ability to detect MGT. Combining fine-tuned BERT embeddings with emoji and linguistic features using a multi-layer perceptron classifier achieves the highest accuracy rate of 88.3%. Our analysis reveals distinct characteristics of MGT compared to HWT, including differences in engagement behavior, linguistic patterns, named entities, sentiment expressions, and text perplexity. Our research contributes to the field of MGT detection by offering a comprehensive approach that combines semantic text embeddings with supplementary features. The proposed model provides a significant step forward in addressing the challenge of Deepfake text detection.",Artificial Intelligence;Machine Learning;Data Mining;Deepfake Detection;Feature Engineering,IEE
329,IsSwap: Deep Fake Detection,A. Aggarwal; S. Wadhwa; P. Gupta; N. Anand; R. Kushwah,2021,"In this era of technology the intake of information through digital media has grown exponentially and it has provided people with personal motives to spread falsified information among the masses to create biased opinions and a sense of unrest. The falsified information is provided to the people especially during elections to create political unrest among the masses or simply to spread a rumour. Since most of the information consumed by people is in the form of videos, it has become a great target spot for people with malicious intent. Deep-Fake is an emerging threat to celebrities, political faces and JSON common people. The paper is aimed at overcoming the given challenge by providing a fast and reliable method to determine the authenticity of a given video. We have proposed a model for detecting deep fake videos via XceptionNet and ResNet50 together with multiple hidden layers of neural networks. The results shows that the proposed method outperformed other state-of-the-art methods in terms of precision and recall rate and performed well in predicting whether the video is fake or real.",Deep Learning;GAN;Neural Network;Deepfake;Video Manipulation,IEE
330,Analyzing Fairness in Deepfake Detection With Massively Annotated Databases,Y. Xu; P. Terh�rst; M. Pedersen; K. Raja,2024,"In recent years, image and video manipulations with Deepfake have become a severe concern for security and society. Many detection models and datasets have been proposed to detect Deepfake data reliably. However, there is an increased concern that these models and training databases might be biased and, thus, cause Deepfake detectors to fail. In this work, we investigate factors causing biased detection in public Deepfake datasets by (a) creating large-scale demographic and non-demographic attribute annotations with 47 different attributes for five popular Deepfake datasets and (b) comprehensively analysing attributes resulting in AI-bias of three state-of-the-art Deepfake detection backbone models on these datasets. The analysis shows how various attributes influence a large variety of distinctive attributes (from over 65M labels) on the detection performance which includes demographic (age, gender, ethnicity) and non-demographic (hair, skin, accessories, etc.) attributes. The results examined datasets show limited diversity and, more importantly, show that the utilised Deepfake detection backbone models are strongly affected by investigated attributes making them not fair across attributes. The Deepfake detection backbone methods trained on such imbalanced/biased datasets result in incorrect detection results leading to generalisability, fairness, and security issues. Our findings and annotated datasets will guide future research to evaluate and mitigate bias in Deepfake detection techniques. The annotated datasets and the corresponding code are publicly available. The code link is: https://github.com/xuyingzhongguo/DeepFakeAnnotations.",Deepfake;deepfake detection;databases;bias;fairness;image manipulation;video manipulation,IEE
331,DeepFake Video Analysis using SIFT Features,M. ?or?evi?; M. Milivojevi?; A. Gavrovska,2019,"Recent advantages in changing faces using DeepFake algorithms, which replace a face of one person with a face of another, truly represent what artificial intelligence and deep learning are capable of. Deepfakes in still images or video clips represent forgeries and tampered visual information. They are becoming increasingly successful and even difficult to notice in some cases. In this paper we analyze deepfakes using SIFT (Scale-Invariant Feature Transform) features. The experimental results show that in deepfake analysis using SIFT keypoints can be considered valuable.",SIFT features;video analysis;forgery;DeepFake;deep learning;computer vision.,IEE
332,Towards Measuring Fairness in AI: The Casual Conversations Dataset,C. Hazirbas; J. Bitton; B. Dolhansky; J. Pan; A. Gordo; C. C. Ferrer,2022,"This paper introduces a novel dataset to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of age, genders, apparent skin tones and ambient lighting conditions. Our dataset is composed of 3,011 subjects and contains over 45,000 videos, with an average of 15 videos per person. The videos were recorded in multiple U.S. states with a diverse set of adults in various age, gender and apparent skin tone groups. A key feature is that each subject agreed to participate for their likenesses to be used. Additionally, our age and gender annotations are provided by the subjects themselves. A group of trained annotators labeled the subjects� apparent skin tone using the Fitzpatrick skin type scale. Moreover, annotations for videos recorded in low ambient lighting are also provided. As an application to measure robustness of predictions across certain attributes, we provide a comprehensive study on the top five winners of the DeepFake Detection Challenge (DFDC). Experimental evaluation shows that the winning models are less performant on some specific groups of people, such as subjects with darker skin tones and thus may not generalize to all people. In addition, we also evaluate the state-of-the-art apparent age and gender classification methods. Our experiments provides a thorough analysis on these models in terms of fair treatment of people from various backgrounds.",AI robustness;algorithmic fairness;deepfakes;dataset;age;gender;skin tone,IEE
333,EfficientNets for DeepFake Detection: Comparison of Pretrained Models,A. A. Pokroy; A. D. Egorov,2021,"Rapid advances in media generation techniques have made the creation of AI-generated fake face videos more accessible than ever before. In order to accelerate the development of new ways to expose forged videos, Facebook created Deep Fake Detection Challenge (DFDC), which demonstrated multiple approaches to solve this problem. Analysis of top-performing solutions revealed that all winners used pre-trained EfficientNet networks, which was finetuned on videos containing face manipulations. Because of this observation, we decide to compare the performance of EfficientNets models within the task of detecting fake videos. For comparison, we use models, based on the highest-performing entrant of DFDC, entered by Selim Seferbekov, and the DFDC dataset as training data. Our experiments show that there is no strong correlation between model performance and its size. The best accuracy was achieved by B4 and B5 models.",deepfake videos;deep learning;digital media forensics;detection techniques,IEE
334,Enhancing Authenticity Verification with Transfer Learning and Ensemble Techniques in Facial Feature-Based Deepfake Detection,N. Qazi; I. Ahmed,2024,"Deepfake technology, facilitated by deep learning algorithms, has emerged as a significant concern due to its potential to deceive humans with fabricated content indistinguishable from reality. The proliferation of deepfake videos presents a formidable challenge, propagating misinformation across various sectors such as social media, politics, and healthcare. Detecting and mitigating these threats is imperative for fortifying defenses and safeguarding information integrity.This paper tackles the complexities associated with deepfake detection, emphasizing the necessity for innovative approaches given the constraints of available data and the evolving nature of forgery techniques. Our proposed solution focuses on leveraging facial features and transfer learning to discern fake videos from genuine ones, aiming to identify subtle manipulations in visual content. We systematically break down videos into frames, employ the Haar cascade algorithm for facial recognition, and utilize transfer learning to extract discriminative features. We evaluate multiple pre-trained models, including VGG16, ConvNeXtTiny, EfficientNetB0, EfficientNetB7, DenseNet201, ResNet152V2, Xception, NASNetMobile, and MobileNetV2, for feature extraction. Subsequently, we feed these features into a Deep Artificial Neural Network (DANN) for deepfake detection and employ ensemble learning to combine the strengths of the best-performing models for enhanced accuracy.We found that the ensemble model comprising ConvNextTiny, EfficientNetB0, and EfficientNetB7 showed enhanced accuracy in detecting deep fakes compared to alternative models achieving up to 98% accuracy through ensemble learning.",Deepfake detection;video classification;Transfer learning;EfficentNetB0;DenseNet;Ensemble learning,IEE
335,Audio Deepfake Detection Using Deep Learning,R. Anagha; A. Arya; V. H. Narayan; S. Abhishek; T. Anjali,2023,"The capacity to identify real audio recordings from their modified counterparts is essential in the age of sophisticated digital manipulation for maintaining security and trust in a vari- ety of applications, from media forensics to voice authentication systems. This research aims to create a deep learning model that can distinguish between authentic and altered audio files, with an emphasis on identifying audio deepfakes. The study uses Mel spectrogram representations and data augmentation techniques to effectively extract features from the ASV spoof 2019 dataset and train models. Convolutional neural networks (CNNs) comprising a number of layers, including convolutional, pooling, batch normalization, ReLU activation, dropout, global average pooling, and a dense classification layer are used as the foundation of the design. The Adam optimizer is used to optimize the model once it has been trained using binary cross-entropy loss, and a variety of metrics, such as accuracy, F1 score, ROC curve, and AUC, are used to track its performance. By making it easier to identify audio deepfakes, this project will ultimately increase the security and integrity of audio data in the digital world.",Audio Deepfake Detection;Deep Learning;Convolutional Neural Network (CNN);Mel Spectrogram;ASVspoof 2019 Dataset;Binary Classification;Feature Extraction;Perfor- mance Metrics,IEE
336,MIS-AVoiDD: Modality Invariant and Specific Representation for Audio-Visual Deepfake Detection,V. S. Katamneni; A. Rattani,2023,"Deepfakes are synthetic media generated using deep generative algorithms and have posed a severe societal and political threat. Apart from facial manipulation and synthetic voice, recently, a novel kind of deepfakes has emerged with either audio or visual modalities manipulated. In this regard, a new generation of multimodal audio-visual deepfake detectors is being investigated to collectively focus on audio and visual data for multimodal manipulation detection. Existing multimodal (audio-visual) deepfake detectors are often based on the fusion of the audio and visual streams from the video. Existing studies suggest that these multimodal detectors often obtain equivalent performances with unimodal audio and visual deepfake detectors. We conjecture that the heterogeneous nature of the audio and visual signals creates distributional modality gaps and poses a sig-nificant challenge to effective fusion and efficient performance. In this paper, we tackle the problem at the representation level to aid the fusion of audio and visual streams for multimodal deepfake detection. Specifically, we propose the joint use of modality (audio and visual) invariant and specific representations. This ensures that the common patterns and patterns specific to each modality representing pristine or fake content are preserved and fused for multimodal deepfake manipulation detection. Our experimental results on FakeAVCeleb and KoDF audio-visual deepfake datasets suggest the enhanced accuracy of our proposed method over SOTA unimodal and multimodal audio-visual deepfake detectors by 17.8% and 18.4%, respectively. Thus, obtaining state-of-the-art performance.",Deepfakes;Audio-visual Deepfake Detection;Modality Invariant;Modality Specific Features,IEE
337,Attention Guided Multi-attribute Architecture For Deepfake Detection,R. Sharma; B. Jawade; A. Agarwal; S. Setlur; N. Ratha,2023,"Deepfake content generated through visual and audio manipulations is speculated to become one of the most threatening artificial intelligence (AI) technologies capable of grave negative impact on society through identity fraud, reputation damage, and undermining of trust in large-scale political campaigns and criminal investigation procedures. A significant measure of the efforts towards solving this problem fails to generalize beyond the training data. We hypothesize that the primary reason behind the drawback is the dearth of efforts toward the exploitation of multiple channels of information from the data. Towards this goal, we investigate a multimodal paradigm exploiting an attention-informed feature generation procedure through a deep network. We further augment the supervisory signal using camera sensor fingerprints which contain additional corroboratory information for the decision-making process. We demonstrate that a non-linear transformation of the decision space augmented through multiple channels allows for a significant boost in the generalization capacity over unseen datasets or attacks. We illustrate the applicability of our framework on the widely known datasets of FaceForensics++ and CelebDF.",Deepfake detection;Multimodal fusion;Multi-scale attention;Camera Fingerprint/Noiseprint,IEE
338,Enhancing Social Media Security: LSTM-Based Deep Fake Video Detection,A. Barbadekar; S. Sole; A. Shekhavat,2024,"The rapid advancement of generative artificial intelligence (AI) techniques has led to the widespread creation and dissemination of deepfake videos, which convincingly manipulated media, containing fabricated content often indistinguishable from reality. Detecting such deepfake videos is a critical challenge in ensuring the originality and credibility of information in the digital age. In this paper, an approach for detecting deepfake videos using generative AI-based methods has been proposed. For this, this paper introduces a deepfake detection method using Long-short term memory (LSTM) based model. Celeb-DF (v2) has been used for this experiment. From the videos in the dataset, faces were extracted, cropped and were saved in a new video having only face images. By using ResNext, a CNN-based approach, feature extraction was performed and classification was done using the LSTM model. Highest accuracy of 95.33% was achieved using this model.",Artificial Intelligence (AI);Generative Adversarial Networks (GAN);Long-short term memory (LSTM),IEE
339,Div-Df: A Diverse Manipulation Deepfake Video Dataset,D. Dagar; D. K. Vishwakarma,2023,"Recent advances in image and video manipulation have given rise to grave concerns. Deepfake technology employs deep learning techniques to produce astoundingly lifelike content. Deepfakes are risky since they have the ability to counterfeit someone�s identity by replacing their face with that of another person or generating random noise in the mouth area. Additionally, with just a few seconds of audio, AI-based deep learning models can replicate any person�s voice. Detecting such videos is the only promising defense against such fraudulent data. Several deepfake datasets have been made available to help in deepfake detector training and testing, including DF-TIMIT [1], FaceForensics++ [2], Celeb-DF [3], DFDC [4], Deeperforensics1.0 [5], etc. Even though this has significantly improved deepfake detection methods, they are still unable to capture real-world scenarios entirely, as most of the dataset is face-swap manipulation. To bridge this gap, we have proposed a Div-DF dataset containing various types of video manipulation like face swap, facial reenactment, and lip-sync. This dataset is composed of 150 real videos of different celebrities of different professions and 250 deepfake videos (100 face-swap videos, 100 facial reenactment videos, and 50 lip-sync videos). Deepfake videos are synthesized using state-of-the-art Face-Swap GAN(FSGAN) and the Wav2Lip method. The dataset contains high-quality samples of face-swapped and lip-sync videos, while the samples of face-re-enactment are of average quality. We have tested state-of-the-art detection and image classification models to standardize our dataset�s baseline evaluation of various detection methods. We have done a comprehensive assessment along different metrics and found that our dataset is challenging and represents real-world samples.",deepfake dataset;face-swap;facial reenactment;lip-sync;deepfake,IEE
340,Deepfake Fingerprint Detection Model Intellectual Property Protection via Ridge Texture Enhancement,C. Yuan; Q. Guo; Z. Zhou; Z. Fu; Z. Xia,2023,"In addition to relying on super computing power and professional domain knowledge, training a high-precision deepfake fingerprint detection model (DFDM) to authenticate the fingerprints also requires the support of massive private fingerprint data. To sum up, the DFDM should be deemed as intellectual property (IP) of the trainers, so it is crucial to protect IP. Currently, most watermarking-based IP protection schemes are implemented by introducing additional tasks, such as constructing trigger sets, fine-tuning model weights, etc., which severely impair the performance of the original task and increase the training cost. Inspired by the feature knowledge learned by the model, this letter proposes an IP protection (IPP) scheme for DFDM by verifying whether the suspect model contains the fingerprint ridge features learned by the victim model from another perspective based on the verifier. Firstly, the local binary pattern (LBP) is used to enhance the ridge texture on the fingerprint samples, so that DFDM can better learn the ridge features. Then, a DFDM lacking texture augmentation is employed as the adversarial model for training the meta-verifier without any alteration to the model parameters. Finally, the trained meta-verifier is used to determine whether the suspected model contains the ridge features in the victim model. The public fingerprint dataset (LivDet2017) was leveraged in the DFDM training process to validate our approach. Experimental results show that the proposed scheme can verify the IP of DFDM and is robust to some common attacks.",Deepfake Fingerprint Detection;Intellectual Property Protection;Feature Knowledge;Model Watermarking;Model Stealing,IEE
341,Classification of Deep Fake Audio Using MFCC Technique,S. M; A. Rajput; S. M,2024,"Voice forgery, often made possible by advanced generative models, is becoming a bigger problem in today's digital world. There's a urgent demand for a better way to spot AI-generated voices. Our research presents a new method for detecting fake audio by combining advanced signal processing and deep learning techniques. We analyzed a dataset containing both real and fake audio samples by extracting Mel-Frequency Cepstral Coefficients (MFCC) to understand the sound patterns. Using sophisticated neural networks like Convolutional Neural Networks (CNNs) and Fully Connected Layers, we examined voice samples on a large scale. Through systematic testing, we identified the most effective models for distinguishing real from fake audio. Our system includes a user-friendly interface for easy audio upload and analysis. This research advances audio forensics and helps combat the spread of deepfake content online.",Deep learning;Mel-Frequency Cepstral Coefficients (MFCC);Convolutional Neural Networks (CNNs);Classification algorithms;Fully Connected Layers;Deepfake identification,IEE
342,Image Feature Detectors for Deepfake Video Detection,F. F. Kharbat; T. Elamsy; A. Mahmoud; R. Abdullah,2019,"Detecting DeepFake videos are one of the challenges in digital media forensics. This paper proposes a method to detect deepfake videos using Support Vector Machine (SVM) regression. The SVM classifier can be trained with feature points extracted using one of the different feature-point detectors such as HOG, ORB, BRISK, KAZE, SURF, and FAST algorithms. A comprehensive test of the proposed method is conducted using a dataset of original and fake videos from the literature. Different feature point detectors are tested. The result shows that the proposed method of using feature-detector-descriptors for training the SVM can be effectively used to detect false videos.",DeepFake Video;HOG;ORB;BRISK;KAZE;SURF;FAST,IEE
343,An Overview of Deepfake Video Detection Using Remote Photoplethysmography,B. Yilmaz; S. Vatansever,2024,"Deepfake technology, which can create remarkably realistic videos through deep learning techniques, has many applications that serve humanity, including cinema and television productions, education, social media applications, art, fashion, and virtual assistants. However, this technology also brings with it potential abuse scenarios through manipulative content. Particularly in cases like fake news, identity fraud, blackmail, and slander, it can hasten the dissemination of false information and violate people�s privacy. Moreover, it may cause major legal and societal issues in crucial fields like politics and public security. In this context, developing solutions for detecting deepfake videos has become imperative. While some methods developed in the literature to detect deepfake video are based on spatial and frequency-based analysis of digital traces and residues, which emerge intrinsically during the fake content production stage, some are based on examining physiological signs. Remote photoplethysmography (rPPG)-based physiological approaches, which analyze imperceptible color changes on the skin surfaces of individuals, have gained significant attention due to their high performance. This study examined rPPG-based techniques and their effectiveness in detecting fake videos made with Generative Adversarial Network (GAN) and Autoencoder (AE), two of the most popular deep learning algorithms used to produce deepfake content, and discussed the technical challenges encountered.",remote photoplethysmography;rPPG;deep learning;fake video;deepfake,IEE
344,Detecting Deepfake Images: A Deep Learning Approach with Streamlit Integration,A. Gadde; G. D. K. Kishore; T. Talari; S. L. Nunna; R. C. Nannapaneni; K. M. S. K. Vamsi,2024,"According to sophisticated machine learning algorithms, deep fake technology can produce incredibly lifelike fake images and videos that may be exploited for fraud, disinformation, and public opinion manipulation. This has raised serious concerns about the technology. In response to this emerging threat, this research project proposes a deep fake detection system utilizing convolutional neural networks (CNNs) to distinguish between authentic and manipulated media. The project begins with the collection and preprocessing of a diverse dataset containing both real and fake images and videos. The dataset is then used to train a CNN model, consisting of multiple convolutional and pooling layers followed by fully connected layers, to learn discriminative features that can differentiate between genuine and manipulated media. Experimental results demonstrate the effectiveness of the proposed deep fake detection system in accurately identifying fake content with high precision, recall, and accuracy. Additionally, the system is capable of processing both individual images and video streams, enabling real-time detection of deep fake content. Overall, this research contributes to the ongoing efforts to combat the proliferation of deep fake technology by providing a robust and reliable solution for detecting manipulated media, thereby safeguarding the integrity of digital content and mitigating the potential negative consequences of deep fake misuse.",Deep Fake Detection;Convolutional Neural Network (CNN);Multi-Layer Perceptron (MLP);Data Preprocessing;Image Dataset;TensorFlow;Model Training;Model Evaluation;Streamlit Application;Image Input;Video Input;Data Augmentation;Dropout Regularization;Serialization;Model Deployment;Binary Classification;Real vs. Fake Images;Feature Extraction;Max-Pooling;Early Stopping,IEE
345,Multi-Definition Video Deepfake Detection via Semantics Reduction and Cross-Domain Training,C. Wang; C. Zhao; G. Hu,2022,"The recent development of Deepfake videos directly threatens our information security and personal privacy. Although lots of previous works have made much progress on the Deepfake detection, we empirically find that the existing approaches do not perform well on the low definition (LD) and crossdefinition (high and low) videos. To address this problem, in this paper, we follow two motivations: (1) high-level semantics reduction and (2) cross-domain training. For (1), we propose the Facial Structure Destruction and Adversarial Jigsaw Loss to reduce our model to learn high-level semantics and focus on learning low-level discriminative information; For (2), we propose a domain generalization method based on adversarial learning. We conduct extensive experiments on the FaceForensics++ dataset. Results show the great effectiveness of our method and we also achieve very competitive performance against state-of-the-art methods.",Deep Learning;Deepfake Detection,IEE
346,Deep Fake Detection using Transfer Learning: A Comparative study of Multiple Neural Networks,A. M; K. S. Charan; S. BN; S. Kanmani R,2024,"With the proliferation of sophisticated AI techniques, the creation and dissemination of deep fake images and videos have emerged as a pressing concern in today's digital landscape. Deep fake technology employs advanced machine learning algorithms to manipulate or synthesize realistic-looking media, often with malicious intent. This study evaluates the effectiveness of various pre-trained deep learning models using transfer learning for detecting deep fake images on the Face Forensics++ dataset. The models considered include MobileN etV2, ResN et50, Inception V3, EfficientN et, Xception, NASNetMobile, and a Custom CNN. Accuracies obtained from these models are compared to assess their performance in distinguishing between real and fake images. With the highest performance in MobileNetV2 with 89% followed by ResNet50 with 83 % and other models.",Deep Fake Detection;Pre-Trained models;Transfer Learning;Deep Fake;Neural Networks,IEE
347,Deepfake Speech Detection Through Emotion Recognition: A Semantic Approach,E. Conti; D. Salvi; C. Borrelli; B. Hosler; P. Bestagini; F. Antonacci; A. Sarti; M. C. Stamm; S. Tubaro,2022,"In recent years, audio and video deepfake technology has advanced relentlessly, severely impacting people�s reputation and reliability. Several factors have facilitated the growing deepfake threat. On the one hand, the hyper-connected society of social and mass media enables the spread of multimedia content worldwide in real-time, facilitating the dissemination of counterfeit material. On the other hand, neural network-based techniques have made deepfakes easier to produce and difficult to detect, showing that the analysis of low-level features is no longer sufficient for the task. This situation makes it crucial to design systems that allow detecting deepfakes at both video and audio levels. In this paper, we propose a new audio spoofing detection system leveraging emotional features. The rationale behind the proposed method is that audio deepfake techniques cannot correctly synthesize natural emotional behavior. Therefore, we feed our deepfake detector with high-level features obtained from a state-of-the-art Speech Emotion Recognition (SER) system. As the used descriptors capture semantic audio information, the proposed system proves robust in cross-dataset scenarios outperforming the considered baseline on multiple datasets.",deepfake;audio forensics;deep learning,IEE
348,HF-Detect A Hybrid Detector for Manipulated Face Detection*,A. Shakya; K. Jenni; M. Perumal; M. Srinivas,2023,"The recent advancement of fake face creation and fake face generation motivates the development of an excellent fake face detection method that can effectively detect the difference between fake and real. Various fake detection methods are available with adequate performance, but the limitation of those available methods is they are not performing well with highly compressed images with degraded quality. Manipulation of face images is getting advanced, and becoming difficult to trust the content over the media, and generating and detection should go parallelly to balance society. Therefore we are proposing a novel approach to solve this problem which uses the hybrid model HF-Detect, which combines the advantage of the Xception network along with the F3Net.",DeepFake Detection;Computer Vision;Deep Learning;Artificial Intelligence,IEE
349,Image forgery detection using Deep Neural Network,A. Singh; J. Singh,2021,"Due to the availability of deep networks, progress has been made in the field of image recognition. Images and videos are spreading very conveniently and with the availability of strong editing tools the tampering of digital content become easy. To detect such scams, we proposed techniques. In our paper, we proposed two important aspects of employing deep convolutional neural networks to image forgery detection. We first explore and examine different pre-processing method along with convolutional neural networks (CNN) architecture. Later we evaluated the different transfer learning for pre-trained ImageNet(via-fine-tuning) and implement it over our dataset CASIA V2.0. So, it covers the pre-processing techniques with basic CNN model and later see the powerful effect of the transfer learning models.",image tampering;convolution neural network (CNN);error level analysis (ELA);transfer learning;sharpening filter;fine-tuning,IEE
350,Learn Buddy � Transforming Education with Generative AI,S. Subramani; A. Jerish S; S. C; S. M; M. T; M. M,2024,"The future where everyone can have their own voice assisted educational chatbot that provides hands-free working experience is the idea behind this mini project of us. We make use of Generative AI techniques and models to bring this idea into life. The backbone of this project would be openAI library which is power full framework that contains the function to generate appropriate answer for each query. We use TTS to convert text to speech. And NLP and Speech to Text library is used to convert speech to text. Thus, providing hands free experience. GAN is used to replicate the AI avatars.",open AI;Generative AI;Text to speech;Speech to text;NLP;Hands free,IEE
351,Interpretable-through-prototypes deepfake detection for diffusion models,A. Aghasanli; D. Kangin; P. Angelov,2023,"The process of recognizing and distinguishing between real content and content generated by deep learning algorithms, often referred to as deepfakes, is known as deepfake detection. In order to counter the rising threat of deepfakes and maintain the integrity of digital media, research is now being done to create more reliable and precise detection techniques. Deep learning models, such as Stable Diffusion, have been able to generate more detailed and less blurry images in recent years. In this paper, we develop a deepfake detection technique to distinguish original and fake images generated by various Diffusion Models. The developed methodology for deepfake detection takes advantage of features from fine-tuned Vision Transformers (ViTs), combined with existing classifiers such as Support Vector Machines (SVM). We demonstrate the proposed methodology�s ability of interpretability-through-prototypes by analysing support vectors of the SVMs. Additionally, due to the novelty of the topic, there is a lack of open datasets for deepfake detection. Therefore, to evaluate the methodology, we have also created custom datasets based on various generative techniques of Diffusion Models on open datasets (ImageNet, FFHQ, Oxford-IIIT Pet). The code is available at https://github.com/lira-centre/DeepfakeDetection.",deepfake;stable diffusion;diffusion models;interpretability;vision transformers,IEE
352,Scene and Texture Based Feature Set for DeepFake Video Detection,A. N. Ramkissoon; V. Rajamanickam; W. Goodridge,2022,"The existence of fake videos is a problem that is challenging today's social media-enabled world. There are many classifications for fake videos with one of the most popular being DeepFakes. Detecting such fake videos is a challenging issue. This research attempts to comprehend the characteristics that belong to DeepFake videos. In attempting to understand DeepFake videos this work investigates the characteristics of the video that make them unique. As such this research uses scene and texture detection to develop a unique feature set containing 19 data features which is capable of detecting whether a video is a DeepFake or not. This study validates the feature set using a standard dataset of the features relating to the characteristics of the video. These features are analysed using a classification machine learning model. The results of these experiments are examined using four evaluation methodologies. The analysis reveals positive performance with the use of the ML method and the feature set. From these results, it can be ascertained that using the proposed feature set, a video can be predicted as a DeepFake or not and as such prove the hypothesis that there exists a correlation between the characteristics of a video and its genuineness, i.e., whether or not a video is a DeepFake.",Classification;DeepFakes;Features;Scene Detection;Texture Detection,IEE
353,Deepfake Detection Techniques and Analysis,P. Chandra; A. Verma; A. Gupta,2023,As we are in the 21st century there we are sharing our data on the public domain. Sometime our data (our images or videos) can alter and used in other ways. Deepfake is a technology that can create the fake images and videos with the help of deep learning that is a sect of the artificial intelligence. In this paper we are presenting that how we can detect the fake videos that are afloat on the public domain. We are proposing and presenting a new detection method as the comparative product of different types of deepfake detection algorithm that is implementable and scalable to higher volumes with the use of cutting-edge hardware under special conditions. We use MTCNNs and Inception ResNet models to do so.,Generative Adversarial Nets;Deepfakes;Deep Learning,IEE
354,An Automated Workflow For Deepfake Detection,A. Joshi; C. P. Chavan,2023,"The lightning development of Artificial Intelligence (AI) has brought significant changes to modern society, including the emergence of AI-generated art and image enhancement techniques. However, one of the most alarming consequences of AI advancement is the creation of deepfake images and videos through the use of General Adversarial Networks (GANs). As these deepfakes become increasingly convincing and widespread, there is an urgent need for measures to detect and prevent their dissemination, especially on independent social-media websites. The proposed approach results in accuracy scores comparable to and surpassing several SOTA(State-of-the-art) approaches on three benchmark datasets, while consuming considerably lesser computational overhead, and containing over 100x lesser trainable parameters which was achieved using the extraction and manipulation of geometrical features.",Deep-fake detection;Lucas-Kande;Autonmation;Bi-LSTM;Computer Vision;Facial Landmarks,IEE
355,Web Front-End Realtime Face Recognition Based on TFJS,C. Li; C. Li,2019,"Web front-end face recognition enables developers to run models on browser-side to reduce latency and server load. In this paper, we first analyzed different algorithms, standard APIs and frameworks that can be used in web front-end face recognition. Then, we designed a workflow for this and implemented it in JavaScript. In the end, we tested it on different scenarios, and the result shows that front-end real-time face recognition is possible and user acceptable.",face recognition;tensorflow.js;video understanding,IEE
356,Detection of GAN-manipulated Medical Images through Deep Learning Techniques,A. S; S. Narayan,2024,"with advancements in technology, telemedicine has become popular to provide remote clinical services in real-time using digital audio-visual communication means. Medical images like scans and reports are transferred over the internet to facilitate remote diagnosis. While transferring these medical images over various communication channels, medical images are susceptible to deliberate manipulations by attackers. Medical image tampering is the deliberate manipulation of medical images with potential consequences for patient safety, healthcare confidence, and research integrity. The integrity of healthcare institutions, patient safety, and ethical norms are all upheld by forgery detection. In this paper, we propose a framework to enhance the model's resilience against potential manipulations in CT scans, alleviating concerns about deep fake attacks on medical images. The framework integrates L2 Regularization, LBP pre-processing approach, SVM Classifier, and U-Net architecture for efficient detection of forgery. The proposed model achieves a detection accuracy of 93.9%, precision of 94.4%, recall of 93.9%, F1 score of 94% and the area under the ROC curve of the receiver is 99.2%",Authentication of medical images;CT scans;Deep fake detection;LBP pre-processing;SVM Classifier,IEE
357,"Deepfake Detection: Analyzing Model Generalization Across Architectures, Datasets, and Pre-Training Paradigms",S. A. Khan; D. -T. Dang-Nguyen,2024,"As deepfake technology gains traction, the need for reliable detection systems is crucial. Recent research has introduced various deep learning-based detection systems, yet they exhibit limitations in generalising effectively across diverse data distributions that differ from the training data. Our study focuses on understanding the generalisation challenge by exploring different aspects such as deep learning model architectures, pre-training strategies and datasets. Through a comprehensive comparative analysis, we evaluate multiple supervised and self-supervised deep learning models for deepfake detection. Specifically, we evaluate eight supervised deep learning architectures and two transformer-based models pre-trained using self-supervised strategies (DINO, CLIP) on four different deepfake detection benchmarks (FakeAVCeleb, CelebDF-V2, DFDC and FaceForensics++). Our analysis encompasses both intra-dataset and inter-dataset evaluations, with the objective of identifying the top-performing models, datasets that equip trained models with optimal generalisation capabilities, and assessing the influence of image augmentations on model performance. We also investigate the trade-off between model size, efficiency and performance. Our main goal is to provide insights into the effectiveness of different deep learning architectures (transformers, CNNs), training strategies (supervised, self-supervised) and deepfake detection benchmarks. Following an extensive empirical analysis, we conclude that Transformer models surpass CNN models in deepfake detection. Furthermore, we show that FaceForensics++ and DFDC datasets equip models with comparably better generalisation capabilities, as compared to FakeAVCeleb and CelebDF-V2 datasets. Our analysis also demonstrates that image augmentations can be beneficial in achieving improved performance, particularly for Transformer models.",Deepfake detection;image classification;convolutional neural networks;transformers;video processing,IEE
358,First Order Motion Model for Image Animation and Deep Fake Detection: Using Deep Learning,B. P. M; J. F. Daniel,2022,"Image animation involves animating an image using a video. In our case, the image contains the face of a person. This face is animated (creation of facial expression) based on the motion of the video frame (may contain a person talking). Current methods involve animating an image with respect to different videos. Our findings show that these methods lack certain features � such as audio capabilities (mimicking the voice of the person in the video). We propose that the chosen image be trained with a variety of videos which contain items of the same classification � say facial features of humans such as eyes, lips, nose etc. and along with the audio output of these items. Self-supervised formulation approach is adapted for the training purpose. Mapping between the motion of the item in the video and the image can be achieved with the help of generator network models. The result is a generation of a model that can mimic any video of the specified classification with the desired audio output.",Deep Faking;Video;Animation;Deep Learning,IEE
359,Deepfake Detection via a Progressive Attention Network,S. Guo; M. Gao; Q. Li; G. Jeon; D. Camacho,2024,"The rapid advancement of deepfake technology has enabled the creation of highly realistic forged face images or videos. While deepfake technology adds entertainment to people�s lives, it also poses a potential threat to social security. Deepfake detection is a crucial technology for identifying forged images. However, existing deep learning-based models for deepfake detection often overlook subtle forged traces. To solve this problem, we propose a Progressive Attention Network (PANet). The PANet incorporates two attention modules, namely the Efficient Multi-Scale Attention Module (EMAM) and the Spatial and Channel Attention Module (SCAM), in a progressive manner. The EMAM focuses on crucial facial regions, such as the eyes, nose, and mouth, rather than the entire face. The SCAM facilitates fine-grained feature extraction. Experimental results demonstrate that the proposed method achieves state-of-the-art results on deepfake detection datasets.",Deepfake Detection;Efficient Multi-Scale Attention;Feature Extraction;Information Disorder;Forged Traces,IEE
360,A Comparative Study of DenseNet121 and InceptionResNetV2 model for DeepFake Image Detection,R. Manoranjitham; S. S. Swaroop,2024,"The rise of deep fake technology poses a significant challenge to societal integrity, necessitating robust detection methods. This research study investigates the effectiveness of DenseNet121 and InceptionResNetV2 deep learning models in detecting deep fake images. The study starts with the curation of the dataset and then applies different preprocessing methods to improve the quality of the dataset like scaling, normalization, and data augmentation. The DenseNet121 and InceptionResNetV2 models are trained to differentiate authentic and manipulated images based on distinctive features. DenseNet121�s dense connectivity facilitates feature reuse, enabling effective extraction of discriminative features crucial for identifying manipulated content. In contrast, InceptionResNetV2�s sophisticated architecture exploits both inception and residual connections, enhancing its ability to capture intricate patterns indicative of deep fake manipulation. The comparative analysis of performance metrics reveals InceptionResNetV2�s superiority, achieving an impressive accuracy rate of 99.78% compared to DenseNet121. These findings underscore the efficacy of leveraging existing architectures for identifying deep fake images, thereby contributing to the ongoing efforts to combat misinformation and safeguard digital content integrity.",DenseNet121;InceptionResNetV2;Deep Learning;Deep Fake;Images,IEE
361,DeepFake Detection using Transfer Learning,R. Thakur; A. K. Samanta; Amrit; D. Garg,2023,"A deepfake is a computer-generated fake image or video that combines images to create a new image or video that depicts an event, comment, or activity that did not actually occur. This has become a real problem nowadays to decide the originality of a video. For the same reason we are trying to create a machine learning model using transfer learning which will help us to distinguish between different videos to decide which video is real and which one is fake. For that we are using four different models and comparing their results. The overall best model is InceptionResNetV2 considering its training time and accuracy. In our results the InceptionResNetV2 performs best and gives an accuracy of 97.1 percent.",ResNet50V2;InceptionResNetV2;NASNet;Deepfake;Inception V3;Transfer Learning,IEE
362,Empirical Assessment of Deepfake Detection: Advancing Judicial Evidence Verification Through Artificial Intelligence,E. Hydara; M. Kikuchi; T. Ozono,2024,"Deepfake technology poses a profound challenge to the integrity of facial evidence in criminal justice, threatening the authenticity and admissibility of such evidence in the courtroom. In this research, a specialized deepfake detection system tailored for facial evidence verification was developed, aiming to counteract the influence of deepfake technology. The proposed system integrates a unique combination of video-frame selection, confidence thresholds, prediction timestamps, and heat maps for individual frames of suspect videos. This methodological fusion is designed to support forensic analysts by enhancing the reliability and trustworthiness of video evidence used in judicial settings. Our comprehensive evaluation involved diverse user groups participating in experimental scenarios to assess the effectiveness of the system. The results indicated that the combined features of the system significantly enhanced the detection of fabricated evidence, fostering high levels of confidence and trust among users. Moreover, this study delves into the legal and ethical considerations surrounding the deployment of deep fake-detection technologies, underscoring the necessity for legal frameworks to evolve in response to emerging digital threats. By addressing both the technical and jurisprudential challenges, this research contributes to safeguarding the evidential value of facial recognition in the judicial process against the disruptive potential of deepfake technologies.",Artificial intelligence;criminal justice;deepfake detection;evidence verification;facial evidence,IEE
363,Exploring Generative Adversarial Networks (GANs) for Deepfake Detection: A Systematic Literature Review,J. Asan; I. Ekaputri; C. Natalie; K. Purwandari,2023,"This paper explores the application of Generative Adversarial Networks, also known as GANs for deepfake detection. It investigates the use of various GAN models in deepfake detection, subjecting them through training against other models, and in many different datasets. Through that process, this paper aims to improve detection performance and adaptability to many evolving deepfake techniques. Evaluations are conducted on benchmark deepfake datasets, evaluation metrics, and comparation between the proposed GAN-based detection methods with the most prominent approaches. The results provide insights to the strengths and weaknesses of GANs for deepfake detection and help to develop more robust systems in the same field.",Deepfake;Deepfake Detection;Fake Images Generation;GAN;Deep Learning,IEE
364,Using Self Attention DNNs to Discover Phonemic Features for Audio Deep Fake Detection,H. Dhamyal; A. Ali; I. A. Qazi; A. A. Raza,2021,"With the advancement in natural-sounding speech production models, it is becoming important to develop models that can detect spoofed audios. Synthesized speech models do not explicitly account for all factors affecting speech production, such as the shape, size and structure of a speaker's vocal tract. In this paper, we hypothesize that due to practical limitations of audio corpora (including size, distribution, and balance of variables like gender, age, and accents), there exist certain phonemes that synthesized models are not able to replicate as well as the human articulation system and such phonemes differ in their spectral characteristics from bonafide speech. To discover such phonemes and quantify their effectiveness in distinguishing between spoofed and bonafide speech, we use a deep learning model with self-attention, and analyze the attention weights of the trained model. We use the ASVSpoof2019 dataset for our analysis and find that the attention mechanism picks most on fricatives: /S/,/SH/, nasals: /M/,/N/, vowels: /Y/, and stops: /D/. Furthermore, we obtain 7.54% EER on train and 11.98% on dev data when using only the top-16 most attended phonemes from input audio, better than when any other phoneme classes are used.",spoof;bonafide;countermeasure;attention;phonemes;deep neural network;senet;explainable;fair;small datasets;forensics;deepfake,IEE
365,Deep Fake Detection for Preventing Audio and Video Frauds Using Advanced Deep Learning Techniques,A. O. Vaidya; M. Dangore; V. K. Borate; N. Raut; Y. K. Mali; A. Chaudhari,2024,"Deepfakes allow for the automated gen- eration of fake video content, often accomplished through the use of generative adversarial networks. To address the increasing issue of deepfakes, this study focuses on constructing a model that incorporates advanced techniques. The researchers combined the ResNeXt, Long Short-Term Memory (LSTM), and ResNet architectures, selecting them based on their effectiveness in handling complex visual data and capturing temporal dependencies. Prior to detection, the dataset underwent pre-processing using the Multi-Task Cascaded Convolutional Neural Network (MTCNN), which facilitated the accurate extraction of facial regions. Importantly, the study evaluated the model across three diverse and significant datasets: the Face Forensics++ dataset (FF-DF), the Celeb-DF dataset, and the Facebook Deepfake Detection Challenge (DFDC) dataset. This comprehensive evaluation en- sured the model's ability to generalize and its suitability for real-world scenarios, as demonstrated by its exceptional detection accuracy. The combination of models employed in this study yielded highly accurate results and remained robust in the face of evolving deepfake technology.",Preprocessing;MultiTask Cascaded Convolutional Neural Network (MTCNN);Model Architecture;ResNeXt;LSTM;ResNet;Face Forensics++;CelebDF;DFDC;Detection Accuracy,IEE
366,A Comparative Analysis and Study of a Fast Parallel CNN Based Deepfake Video Detection Model with Feature Selection (FPC-DFM),A. Das; L. Sebastian,2023,"Deep learning is an efficient and practical method that has been widely applied in numerous fields. Videos created with swapped faces in a video, altered facial emotions, changed genders, fraudulent video content generation, and altered facial features are referred to as �DeepFake� videos. These videos are created utilizing deep learning technology called generative adversarial networks. Fake videos are used to stir up political agitation, commit acts of terrorism, and demand money. A fast Parallel CNN-based deepfake video detection model with feature selection is the new model we presented in this project (FPC-DFM). In order to identify Deepfake videos, the FPC DFM architecture uses feature extraction, feature selection, and prediction. The FPC-DFM model extracted features using three convolutional models: EfficientN et, VGG16, and ResNet as well as Principal Component Analysis (PCA)-based feature selection and Support Vector Machine-based classification. We offer a new architecture for capturing the video frame features that will be utilized to determine if the video is real or fake by utilizing deep learning techniques. In comparison to other pre-trained models like VGG16-TL, EfficientNet-TL and Resnet50-TL and our results demonstrated that FPC-DFM has the best performance and the highest accuracy of 96.50%.",Deepfake video detection;Convolutional neural network (CNN);Principal Component Analysis;Support vector machine (SVM),IEE
367,Comparative Analysis of Facial Forgery Detection using Deep Learning,R. R. Sekar; K. R. Anne,2023,"Nowadays the facial forgery detection becomes a challenging role in real time application. Even after the introduction of many new techniques in the research domain, still it fails to detect the unknown attacks that were not seen during training. This paper will provide a crystal-clear analysis of Face Forgery Detection (FFD) in point of different methodologies and standard databases available so for in the field of FFD. Face forgery detection is a process of gaining access to the robust face recognition system by intruding the real faces using printed photos (print attack), replay attacks (video attack), 3D masks, etc. The standard databases available for the researchers are SiW, SiW-M, CASIA-FASD, OULUNPU, Replay-Attack, MSU-MFSD, FaceForensics++ which includes four methods DeepFakes, Face2Face, FaceSwap and NeuralTextures, Celeb-DF, DFDC, DFFD, FFHQ, KoDF and WildDeepFake. The researchers used several deep learning algorithms over the above listed databases to validate their results according to their chosen applications which will be discussed further. The main motivation of this work is to analyze the challenges faced in FFD. Also, this study concludes that still lot of improvement can be done in cross dataset validation. This is because, the cross-dataset results are shown as major limitation in most of our survey. Hence, this work will provide good perceptions for further researches to do a lot in the field of FFD.",Facial Anti-Spoofing;Face Presentation Attack;Face Forgery Detection;Deep Fake Detection,IEE
368,Learning Face Forgery Detection in Unseen Domain with Generalization Deepfake Detector,V. Tran; S. Lee; H. Le; B. Kim; K. Kwon,2023,"Face forgery generation algorithms have advanced rapidly, resulting in a diverse range of manipulated videos and images which are difficult to identify. As a result, face manipulation using deepfake technique has a significantly increased societal anxiety and posed serious security problems. Recently, a variety of deep fake detection techniques have been presented. Convolutional neural networks (CNN) architecture are used for most of the deepfake detection models as binary classification problems. These methods usually achieve very good accuracy for specific dataset. However, when evaluated across datasets, the performance of these approaches drastically declines. In this paper, we propose a face forgery detection method to increase the generalization of the model, named Generalization Deepfake Detector (GDD). The Generalization Deepfake Detector model has ability to instantly solve new unseen domains without the requirement for model updates.",Deepfake detection;meta learning;machine learning;deepfake dataset,IEE
369,MobiDeep: Mobile DeepFake Detection through Machine Learning-based Corneal-Specular Backscattering,M. Mohzary; K. J. Almalki; B. -Y. Choi; S. Song,2023,"DeepFake has accomplished notable advancement with the AI-leveraged production and manipulation techniques of fictitious human facial images. Despite many benign and fun applications, the generated fake images can negatively influence the authenticity of online information by originating deception, manipulation, persecution, and seduction, defying societal quality and human rights, which becomes critical security and privacy threat in social networks. Hence, real-time DeepFake detection and limitation technologies on the mobile platform are essential to building a controlled, harmless DeepFake ecosystem. This paper presents a real-time, cloudless, lightweight mobile app for human visual DeepFake detection using machine learning technologies named MobiDeep (Mobile DeepFake Detection through Machine Learning-based Corneal-Specular Backseat-tering). MobiDeep stems from a hypothesis that the existing DeepFake creation methods, including replacement, editing, and synthesis, lack the ensemble with the reflective objects. Focusing on the most reflective area of a human face, corneal-specular backscatter images of eyes, we seek the similarity and consistency with multiple surrounding environment features, including color components, shapes, and textures. We have implemented a cross-platform mobile application to evaluate the performance using various input parameters and lightweight Deep Neural Network (DNN) architectures. The empirical results show that MobiDeep achieves high accuracy (98.7%) and rapid detection speed (less than 200 ms) in detecting sophisticated DeepFake images within a subsecond.",DeepFake;Corneal-Specular Backscattering,IEE
370,Recognition of Deep Fake Voice Acoustic using Ensemble Bagging Model,S. A. Yunus Basha; K. U. Priya,2024,"As artificial speech generates technological evolution; fake voice information has become an increasingly prevalent avenue for fraud. Numerous investigations have been carried out into machine learning techniques, signal processing techniques, and the Automatic Speaker Verification System to address such issues. Since there are increasing methods to create fake information, techniques must be developed to determine when audio recordings employed as electronic proof are corrupted. Such recordings contain the potential to be manipulated. Hence, this research work identified the data regarding audio systems as either fake or real by i) extracting features from audio file metadata using oversampling techniques and ii) Developing an Ensemble Bagging Model appropriate for analyzing input audio signal followed by classification of fake (fraudulent) and real (authentic) audio. Our experimental results reveal that the ensemble bagging model attained an accuracy of 99.5%, precision of 99%, 99.6% recall, and 99.9% Fl-measure in the prediction of the audio system compared with traditional approaches.",Ensemble Bagging Model (EBM);Zero Crossing Rate (ZCR);Validation accuracy and loss;Sequential model;Automatic Speaker Verification;Audio Signal Processing;Data Efficiency,IEE
371,DeepFake Videos Detection by Using Recurrent Neural Network (RNN),A. A. M. Albazony; H. A. Al-Wzwazy; A. S. Al-Khaleefa; M. A. Alazzawi; M. Almohamadi; S. E. Alavi,2023,"In the last few years, the increasing development of various tools to make fake videos from real videos has been raised. Thus, several models/approaches have been constructed to detect and reveals fake video. Consequently, this research is conducted to propose a new model based on combining Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), and image preprocessing techniques to classify and find the fake video from the real video. To implement and evaluate the proposed model, a MATLAB simulator has been used. The deepFake Images dataset is used for evaluations. This dataset contains 135 real videos as well as 677 fake videos created using different tools on real videos. Two scenarios have been utilized to evaluate the performance of the proposed model which are; dimensions of the training data and different sizes of the training data. The results show that the proposed model has been able to provide better results than the previous model.",Deep learning;DeepFake Detection;convolutional Neural Network (CNN);Recurrent Neural Network (RNN),IEE
372,Deepfake Generation and Detection: Case Study and Challenges,Y. Patel; S. Tanwar; R. Gupta; P. Bhattacharya; I. E. Davidson; R. Nyameko; S. Aluvala; V. Vimal,2023,"In smart communities, social media allowed users easy access to multimedia content. With recent advancements in computer vision and natural language processing, machine learning (ML), and deep learning (DL) models have evolved. With advancements in generative adversarial networks (GAN), it has become possible to create fake images/audio/and video streams of a person or use some person�s audio and visual details to fit other environments. Thus, deepfakes are specifically used to disseminate fake information and propaganda on social circles that tarnish the reputation of an individual or an organization. Recently, many surveys have focused on generating and detecting deepfake images, audio, and video streams. Existing surveys are mostly aligned toward detecting deepfake contents, but the generation process is not suitably discussed. To address the survey gap, the paper proposes a comprehensive review of deepfake generation and detection and the different ML/DL approaches to synthesize deepfake contents. We discuss a comparative analysis of deepfake models and public datasets present for deepfake detection purposes. We discuss the implementation challenges and future research directions regarding optimized approaches and models. A unique case study, IBMM is discussed, which presents a multi-modal overview of deepfake detection. The proposed survey would benefit researchers, industry, and academia to study deepfake generation and subsequent detection schemes.",Artificial intelligence;Deepfake generation;Deepfake detection;fake content;generative adversarial networks,IEE
373,Deepfake Detection Using SVM,H. Agarwal; A. Singh; R. D,2021,"In recent years the Deep generative networks have made it easy to create real face swaps in images and videos with less traces of manipulation, significantly improving the quality of these deepfakes. This improvement in fake media have gained more concern as for their use in fake terrorism, blackmail etc. This has drawn attention of both industry and government to distinguish and restrict their utilization. In spite of the way that these AI generated fake media produce realistic images upon detailed assessment, the proposed method can find some features that are unnatural which are not visible to the naked eyes. This paper uses a method known as frequency domain analysis after which a classifier will be used to differentiate the real and fake image. This paper evaluates our method on dataset of deepfake images collected from different website. Our work can show promising performance for detecting these deepfake images.",DeepFake;Image Processing;SVM;Generative Adversarial Net;DFT;classification,IEE
374,Deepfake as an Artificial Intelligence tool for VFX Films,H. Singh; K. Kaur; F. Mohan Nahak; S. K. Singh; S. Kumar,2023,"Deepfake refers to the technique of replacing human bodies in movie scenes through the utilization of a method called Deepfake, which uses AI's (Artificial Intelligence) most recent advancements. Since we cannot see the reality of these shots, filmmakers use this as an opportunity to express their creativity. In order to advance VFX production, Deepfake is combined with AI. We have discussed the potential impact of Deepfake in future in this study. Students at a university were exposed to Deepfake footage and engaged in a questionnaire-based poll to learn more about the software's value for VFX. Additionally, the Deepfake approach, like Facial Landmarks, Voice Features, Body Movements, Background and Lighting that was employed in two films, has been elaborated. Results have shown that using AI's Deepfake technology improves the calibre of VFX film production and increases box office success.",component;Deepfake;AI;VFX;Film production,IEE
375,Deepfake Video Prediction Using Attention-Based CNN and Mel-Frequency Cepstral Coefficients,G. S; S. G. A; J. D; A. J,2024,"Deepfake technology seriously threatens the integrity of digital media since it makes it harder to detect fraudulent deepfake videos using traditional methods. In this research, we describe a unique method for audio and visual analysis utilizing Mel-Frequency Cepstral Coefficients (MFCCs) and Attention-based CNN to detect fraudulent deepfakes. Our methodology addresses the evolving field of deepfake manipulation and offers a more comprehensive and dependable detection framework by combining audio and visual modalities. Utilizing the FakeAVceleb dataset, a carefully chosen collection of audio-visual deepfake videos created especially for research is one of the keystones of our methodology. The breadth of actual and deepfake sounds and videos provided by the FakeAVceleb dataset makes it possible to test and evaluate our detection model in great detail. We use attention-based CNN to analyze extracted visual features from video frames, with a focus on regions that can be manipulated to detect subtle audio features that indicate deepfake manipulation, thereby increasing our model's overall discriminative capability. We assess how well our method works for identifying deepfake audio and video. Our results demonstrate the efficacy of combining audio and visual analysis in deepfake detection, as our model achieves promising performance metrics including an accuracy of 94.00% using the FakeAVceleb dataset.",Deepfake Detection;Audio Analysis;Visual Analysis;Attention-based CNN;Mel-Frequency Cepstral Coefficients;Audio-Visual Integration;FakeAVCeleb,IEE
376,Speech Audio Deepfake Detection via Convolutional Neural Networks,L. P. Valente; M. M. S. de Souza; A. M. D. Rocha,2024,"The production of artificial media content brings on ethical, legal and social implications for journalism, education, entertainment and industry. Software tools are currently available for anyone who intent to maliciously generate or tamper with digital audio voices. In this context, detecting voice authenticity is important to avoid the consequences of its criminal use. Here, we propose the application of convolutional neural networks (CNN) and Mel spectograms in detection of artificially generated voices. Supervised experiments with speech samples signals, collected from several voice datasets, were conducted to find the best CNN topology that performs the detection, in terms of accuracy, regardless of the language spoken. The best accuracy scores found are: 99% for the FoR dataset, 94% for the ASV and 98% for the WaveFake. Training the model with all datasets together, and testing with individual datasets, yields accuracies of 98% for the FoR base, 92% for the ASV and 96% for WaveFake. These results are compatible with those found in state-of-the-art, proving the viability of the model.",Forensics analysis;Deepfake;Voice cloning;Computer vision;Machine learning;Deep learning,IEE
377,An Effective Blockchain Technique to Resist Against Deepfake Videos,U. Patil; P. M. Chouragade; P. Ambhore,2021,"Recently, with growth in artificial intelligence as well in deep learning, fake digital data like images, footage, videos and audios has escalated. This fake data is termed as deep fakes. It is a dangerous scenario which is responsible to alter the truth and grind down the trust because of spreading wrong or false message. So it is necessary to secure data. There is one important technique which is used to resist the deep fake videos: blockchain. This paper aimed to identify the origin of video and verify the authenticity of video, to integrate the work with scalable verification mechanism and to implement blockchain based technique for effective deepfake video recognition. In short, it provides the analysis for video signal for identification of the originality of the video.SHA3-256 algorithm which is base for encryption is utilized in blockchain to obtain the hash function.In proposed method the results are compared with the implementation of metadata extraction in which the various properties of the video file are taken for consideration like bitrate, frame rate, etc. for the exact data determination along with the hash value.",Alteration factor;Blockchain;Deepfake;Deepfake videos;SHA3-256,IEE
378,Using Graph Neural Networks to Improve Generalization Capability of the Models for Deepfake Detection,H. She; Y. Hu; B. Liu; J. Li; C. -T. Li,2024,"Deepfake detection plays a key role in preventing the misuses of artificial intelligence in video editing. Current deep learning-based deepfake detection methods often perform quite well in intra-dataset testing, but they may lose good performance in cross-dataset testing. In other words, generalization capability is still a crucial problem to be resolved. In this paper, we address deepfake detection by treating an image as non-Euclidean data and representing it as a graph so as to infer the informative connections between image patches/nodes to improve the detector�s generalization capability. Specifically, we propose a graph neural network-based paradigm that casts deepfake detection as a graph binary classification problem. First, we propose a dual-branch network to extract node features from both RGB images and their color difference images (CDIs) via the Transformer-based trainable node encoder module (TNEM). Second, we adopt the adjacency matrix to establish the connections of the nodes and further optimize the graph representation by applying the adaptive threshold to the adjacency matrix. Third, multi-head graph convolutional neural networks are carried out for node feature extraction. RGB node features and CDI node features are concatenated and separately fed into the graph classifier and node classifier for forgery detection and forgery localization. Experimental results demonstrate that our method can overall outperform other state-of-the-art methods on 7 popular benchmark datasets. Notably, our model achieves the highest AUC values of 96.19%, 80.99% and 87.68% on Celeb-DF-V2, DFDC and DFDCP in turn when trained on FF++ (C23). The visualization of node classification results also provides good interpretability of our proposed approach.",Deepfake detection;graph neural network;generalization;transformer;color difference;graph classification,IEE
379,Deep Learning based Model for Deepfake Image Detection: An Analytical Approach,Neha; B. Arora,2023,"Recent years have witnessed great improvement in deepfake technology, spurred by advancements in deep learning models and improved processing capacity. Generative models at the cutting edge of technology have made it possible to produce convincingly realistic synthetic videos, images, and even audio recordings. Deeply fabricated media has the power to harm not just individuals but also our society, institutions, countries, religions, and others. These fake images may circulate online in low quality and contain many forms of distortion that could impair the effectiveness of detection methods. Our study employed a dataset of 140K Real and Fake images to analyse how image distortions affect the detection model using one of the deep learning models, DenseNet. This is accomplished by adding blur and noise to the original dataset and feeding it to the trained neural network to discriminate real and deepfake images. The results demonstrate that the model�s accuracy decreased with the low-quality dataset.",Deepfake Generation;Deepfake Detection;Deep Learning;Generative Adversarial Networks;Face Manipulation;Image Distortions,IEE
380,Exploring Generalization Capability for Video Forgery and Detection based on Generative Adversarial Network,Y. Lin; Y. Qu; Y. Li; Z. Nie,2020,"With the development of digital image processing technology based on deep learning, the potential risk of using related technologies to threaten the security of multimedia information is increasing. Because the generated human face effect largely depends on the completeness of the input sample set, most of the current deep forgery models have the problem of human side-face collapse. This paper has studied the deep forgery technology of Deepfacelab and Faceswap, and adjusts the original auto-encoder-based model architecture to a generative adversarial network. By using the harmonic mean of cross entropy and mean square error as the loss function, the improved model can reduce the probability of some frames being discarded during training. Meanwhile, by adjusting key characteristics and the weights of features in different frames, it further optimizes the cross-dataset detection performance. Experimental results have shown that the improved model can keep more facial details while still maintain high human face clarity. The detection performance is improved and the cross-dataset average error rate of the deep detection model is about 35%.",Deepfake;Deepfake Detection;Generative Adversarial Network;Face Swap;Detection Generalization,IEE
381,Deepfake Detection System,S. Shrivas; A. Rai; M. Lakshmi,2024,"Detecting deepfake content presents a formidable challenge, necessitating advanced methodologies. This paper proposes a holistic strategy employing Facenet_pytorch, MTCNN, and InceptionResnetV1 for robust deepfake detection. Facenet_pytorch serves as the cornerstone for facial feature recognition, while MTCNN efficiently identifies faces in images during preprocessing. InceptionResnetV1 scrutinizes visual details to detect subtle anomalies indicative of manipulation, such as unnatural facial expressions and incongruent lip synchronization. Our approach underscores the importance of maintaining a delicate balance between accurate detection and individual privacy rights. By leveraging these advanced models, we achieve significant strides in differentiating manipulated content from authentic media, contributing to the ethical deployment of deepfake detection technologies.",MTCNN;InceptionResNetV1;FaceNet;Pytorch,IEE
382,Video Morphing Attack Detection using Convolutional Neural Networks on Deep Fake Algorithm,S. Boovaneswari; N. Palanivel; S. NihilRS; R. Madhavan; A. Daniyel,2024,"A method called deepfake produces fake video and films with artificial or substituted faces. Deepfakes are turning into a worrying societal phenomenon because they may be used maliciously to spread harmful information, fabricate electronic convincing proof, make fake political news, and even participate in online harassment and fraud. These masks make it harder to distinguish facial features, making it more difficult to detect fake video. To detect the fake morphed video, we are using the deepfake algorithm to detect the morphed face in the video. Deepfake technology is not using to create the morphed video and also it is used to detect the video by using the CNN.As a result, more sophisticated deepfake detection technology is required. Because the field does not yet have the necessary dataset for detection-model training, the research generates a real or fake video dataset with face masks The study attempts to improve accuracy by improving CNN topologies, detecting important visual signals, and comparing model performance against various morphing strategies. Real-world application of the effect of dataset size and diversity on training is investigated. By protecting multimedia material against changing digital tampering, this research helps combat the threat posed by deepfake technology.",Morphing Detection;CNN;Machine Learning;DFFMD;Deep Learning,IEE
383,Inconsistency-Aware Wavelet Dual-Branch Network for Face Forgery Detection,G. Jia; M. Zheng; C. Hu; X. Ma; Y. Xu; L. Liu; Y. Deng; R. He,2021,"Current face forgery techniques can generate high-fidelity fake faces with extremely low labor and time costs. As a result, face forgery detection becomes an important research topic to prevent technology abuse. In this paper, we present an inconsistency-aware wavelet dual-branch network for face forgery detection. This model is mainly based on two kinds of forgery clues called inter-image and intra-image inconsistencies. To fully utilize them, we firstly enhance the forgery features by using additional inputs based on stationary wavelet decomposition (SWD). Then, considering the different properties of the two inconsistencies, we design a dual-branch network that predicts image-level and pixel-level forgery labels respectively. The segmentation branch aims to recognize real and fake local regions, which is crucial for discovering intra-image inconsistency. The classification branch learns to discriminate the real and fake images globally, thus can extract inter-image inconsistency. Finally, bilinear pooling is employed to fuse the features from the two branches. We find that the bilinear pooling is a kind of spatial attentive pooling. It effectively utilizes the rich spatial features learned by the segmentation branch. Experimental results show that the proposed method surpasses the state-of-the-art face forgery detection methods.",Face forgery detection;stationary wavelet decomposition;dual-branch network;bilinear pooling,IEE
384,DeepFake Face Detection using Machine Learning with LSTM,T. Vignesh; P. H. Tarun; R. Parthav; V. Bhargavi,2024,"Fake face images that are increasingly convincing and realistic can be created because to the development of face image manipulation (FIM) technologies like Face to Face and Deepfake, which can damage the legitimacy and trustworthiness of online content. Malicious uses of these technology include blackmailing people, posing as celebrities, and disseminating false information. As a result, creating trustworthy and strong techniques to identify FIM and safeguard the integrity of digital media is essential. Numerous current techniques utilize on models built on convolutional neural networks (CNNs), which are capable of detecting FIM by examining a face�s visual characteristics. But because these models are frequently tested and trained on certain datasets or circumstances. Furthermore, they might not be able to record the temporal information that is included in video data and can be used to identify irregularities or strange anomalies in FIM videos. We provide a novel method that uses both geographical and temporal information to detect FIM in order to get over these difficulties. We present a new type of residual network called CRNet, which is dependent on Convolutional Long Short-Term Memory (LSTM) and is capable of processing a series of consecutive pictures taken from a movie. The model can learn temporal information because to its design, which is essential for spotting oddities that occur in between frames of FIM movies. We performed extensive tests with several kinds of FIM videos from the Kaggle dataset.",Deepfake detection;Long-Short Term Memory (LSTM);Kaggle;Residual next convolution neural network (Xception CNN);Image manipulation,IEE
385,Deepfake and Security of Video Conferences,A. S. U�an; F. M. Bu�ak; M. A. H. Tutuk; H. ?. Aydin; E. Semiz; ?. Bahtiyar,2021,"Deep learning is widely used to create artificial contents on the Internet. Similarly, it is also used to detect fake contents. Fake frames created and integrated with deep learning algorithms are known as deepfake. Recently, malicious users tend to use deepfake to manipulate genuine contents to carry out variety of attacks. Video conferencing applications has been a significant target of the malicious users since the beginning of Covid-19 pandemic who use deepfake models to create fake virtual identities in online video conferences. We propose a lightweight deepfake detection model that may be integrated with video conference applications to detect fake faces. Experimental analyses show that the proposed model provides acceptable accuracy to detect fake images on video conferences.",Security;Machine Learning;Deepfake;Inception-Resnet;Video Conference;Detection,IEE
386,Deepfakes Creation and Detection Using Deep Learning,H. A. Khalil; S. A. Maged,2021,"Deep learning has been used in a wide range of applications like computer vision, natural language processing and image detection. The advancement in deep learning algorithms in image detection and manipulation has led to the creation of deepfakes, deepfakes use deep learning algorithms to create fake images that are at times very hard to distinguish from real images. With the rising concern around personal privacy and security, Many methods to detect deepfake images have emerged, in this paper the use of deep learning for creating as well as detecting deepfakes is explored, this paper also propose the use of deep learning image enhancement method to improve the quality of deepfakes created.",deepfake;deep learning;Artificial intelligence;machine learning;tensorflow,IEE
387,Deepfake Audio Detection: A Deep Learning Based Solution for Group Conversations,R. L. M. A. P. C. Wijethunga; D. M. K. Matheesha; A. A. Noman; K. H. V. T. A. De Silva; M. Tissera; L. Rupasinghe,2020,"The recent advancements in deep learning and other related technologies have led to improvements in various areas such as computer vision, bio-informatics, and speech recognition etc. This research mainly focuses on a problem with synthetic speech and speaker diarization. The developments in audio have resulted in deep learning models capable of replicating natural-sounding voice also known as text-to-speech (TTS) systems. This technology could be manipulated for malicious purposes such as deepfakes, impersonation, or spoofing attacks. We propose a system that has the capability of distinguishing between real and synthetic speech in group conversations.We built Deep Neural Network models and integrated them into a single solution using different datasets, including but not limited to Urban-Sound8K (5.6GB), Conversational (12.2GB), AMI-Corpus (5GB), and FakeOrReal (4GB). Our proposed approach consists of four main components. The speech-denoising component cleans and preprocesses the audio using Multilayer- Perceptron and Convolutional Neural Network architectures, with 93% and 94% accuracies accordingly. The speaker diarization was implemented using two different approaches, Natural Language Processing for text conversion with 93% accuracy and Recurrent Neural Network model for speaker labeling with 80% accuracy and 0.52 Diarization-Error-Rate. The final component distinguishes between real and fake audio using a CNN architecture with 94 % accuracy. With these findings, this research will contribute immensely to the domain of speech analysis.",Deep Neural Networks;Natural Language Processing;Speaker Diarization;Deepfake;Deep learning,IEE
388,Employing Transfer-Learning based CNN architectures to Enhance the Generalizability of Deepfake Detection,S. Suratkar; E. Johnson; K. Variyambat; M. Panchal; F. Kazi,2020,"Advancements in machine learning have given rise to technologies and methodologies that are being put to use for immoral purposes, especially after the inception of Generative Adversarial Networks in 2014. Generative Adversarial Networks are capable of synthesizing hyper-realistic fake images and even videos. Various sophisticated machine learning techniques capable of creating ultra-realistic Deep Fake videos are being used to harass, blackmail women and children, induce political instability by spreading false, malicious propaganda which could in turn lead to social, political conflicts and outbursts with dire consequences. This poses a serious threat to personal safety and also endangers national security which calls for automated ways to detect deep fake videos. This paper proposes a method to expose such fake videos by using a CNN architecture and leveraging the technique of Transfer Learning. The proposed model implements an algorithm that uses a CNN for feature extraction from every frame in a video to train a binary classifier that learns to efficiently differentiate between real and manipulated videos. The method is evaluated against an extensive set of deepfake videos gathered from various datasets.",Generalization;Deepfake;Convolution;Transfer learning;Models,IEE
389,Face Forgery Detection Algorithm Based on Improved MobileViT Network,T. Wang; X. Lu,2023,"DeepFakes blur the boundaries between reality and forgery, resulting in the collapse of exiting credit system, causing immeasurable consequences for national security and social order. Through analysis of existing face forgery techniques, it is found that most generation techniques rely on random noise distribution, and global information will be lost after up sampling. Therefore, we propose a deepfake detection algorithm based on improved MobileViT, which uses CNN local space biasing and the global space representation of the Transformer network to learn the local features and global representation of forged faces, respectively. Coordinate attention is introduced to obtain directional perception and position sensitive information, making the model locate synthetic traces of fake faces better and fusion local and global representation more effectively. For the improved generalization of the model, with the GELU activation function to solve the problem of neuron death. Our model achieved 96.2% on FF++(C23) datasets, and 93.7%,94.1%,96.3%,87.9% on DF, F2F, FS, and NT datasets, respectively. Comparing with previous methods, our model has shown detection robustness and better generalization.",Deepfake Detection;MobileViT;Coordinate Attention;GELU,IEE
390,Preserving Information Integrity: A Novel Machine Learning Approach for Fake News Detection,Ritu,2023,"Fake News Detection using Machine Learning presents an innovative approach to combat the proliferation of misinformation in today's digital age. Leveraging advanced machine learning techniques, the system aims to automatically distinguish between genuine news articles and fake news stories by analysing textual content and identifying patterns indicative of falsehoods. In this paper, It have discussed a model to provide accurate and efficient classification, offering a valuable tool for users and platforms to make informed decisions about the credibility of news sources, ultimately contributing to the preservation of information integrity in the online ecosystem. Furthermore, the algorithm analyses textual material to look for patterns that point to lies in order to automatically discern between real news articles and fake news items.",Random Forest;Naive Bayes;Logistic Regression;Support Vector Machine and Gradient Boosting,IEE
391,"AI and Security, From an Information Security and Risk Manager Standpoint",P. Shetty,2024,"Fields such as machine learning and artificial intelligence are proven business enablers, we have several use cases in the field of technology from basic implementations such as automated scanners, and weak forms such as Alexa and Siri that have paved the way for further development. Search for more avenues of investment in this field continues till date. It�s also evident that researchers and organizations have barely scratched the surface in terms of exploring and using AI (Artificial intelligence) as a technology. Theoretical forms of AI have not yet been implemented. This paper aims to provide some context around the various forms of AI currently used and can be explored in the near future. It�s important to be mindful that, with the use of any technology, even AI, there are challenges, regulations, and security risks that tag along. Firms need to pay close attention to the macro factors that could impact the adoption and AI in their respective businesses. This study aims to provide a brief overview of the aforementioned road blocks that could impact AI adoption, however, there are some solution strategies or approaches that could help firms along the way to overcome those road blocks. These strategies might take time to build and take effect but they will be beneficial in the long run and thus help with not only sustainable implementation, but also complete and successful adoption of AI as a technology enabler.",Artificial intelligence;generative AI;security;risk;risk management;AI for security;security for AI;AI security,IEE
392,A deepfake video detection method based on multi-modal deep learning method,Y. Zhang; X. Li; J. Yuan; Y. Gao; L. Li,2021,"Recently, most deepfake video classification tasks depend on frame-level features and try to train deep neural networks to characterize fake videos. Although this kind of methods can achieve good results, they also waste the audio information and timing information of the deepfake video dataset. Therefore, to make better use of the audio information, we propose a multi-modal method to detect deepfake videos. The principle of our method is based on the mismatch between audio information and visual information, such as the inconsistency of mouth shape and voice. We calculate the modality dissonance score(MDS score) of videos to classify true/false videos. Extensive experiments reach 84.4% accuracy on the DFDC dataset, which demonstrates the effectiveness of our method.",deepfake detection;multi-modality;adaptive modality dissonance;deep learning;deep neural network,IEE
393,SpecRNet: Towards Faster and More Accessible Audio DeepFake Detection,P. Kawa; M. Plata; P. Syga,2022,"Audio DeepFakes are utterances generated with the use of deep neural networks. They are highly misleading and pose a threat due to use in fake news, impersonation, or extortion. In this work, we focus on increasing accessibility to the audio DeepFake detection methods by providing SpecRNet, a neural network architecture characterized by a quick inference time and low computational requirements. Our benchmark shows that SpecRNet, requiring up to about 40% less time to process an audio sample, provides performance comparable to LCNN architecture � one of the best audio DeepFake detection models. Such a method can not only be used by online multimedia services to verify a large bulk of content uploaded daily but also, thanks to its low requirements, by average citizens to evaluate materials on their devices. In addition, we provide benchmarks in three unique settings that confirm the correctness of our model. They reflect scenarios of low�resource datasets, detection on short utterances and limited attacks benchmark in which we take a closer look at the influence of particular attacks on given architectures.",DeepFake Detection;Speech Processing;Neural Networks;Deep Learning,IEE
394,Hidden-in-Wave: A Novel Idea to Camouflage AI-Synthesized Voices Based on Speaker-Irrelative Features,X. Liu; Y. Tan; X. Hai; Q. Yu; Q. Zhou,2023,"Voice is an essential medium for human communication and collaboration, and its trustworthiness is of great importance to humans. Synthesizing fake voices and detecting synthesized voices are two sides of a coin. Both sides have made great strides with the recently prospering deep learning techniques. Attackers started using AI techniques to synthesize, even clone, human voices. Researchers also proposed a series of AI-synthesized voice detection approaches and achieved promising results in laboratory environments.In this paper, we introduced the concept of speaker-irrelative features (SiFs) and a novel detection-bypass idea to camouflage AI-synthesized voices: replacing SiFs of AI-synthesized voices with crafted ones. We implemented a proof-of-concept framework named SiF-DeepVC based on our detection-bypass idea. Experiments show that the existing detection systems would consider the voices output by SiF-DeepVC more human-like than human voices, proving our detection-bypass idea is effective and SiFs are noteworthy in camouflaging AI-synthesized voices.",AI-Synthesized Voice;DeepFake;Voice Clone;Malicious Detection;Deep Learning,IEE
395,Fine-Grained Open-Set Deepfake Detection via Unsupervised Domain Adaptation,X. Zhou; H. Han; S. Shan; X. Chen,2024,"Deepfake represented by face swapping and face reenactment can transfer the appearance and behavioral expressions of a face in one video image to another face in a different video. In recent years, with the advancement of deep learning techniques, deepfake technology has developed rapidly, achieving increasingly realistic effects. Therefore, many researchers have begun to study deepfake detection research. However, most existing studies on deepfake detection are mainly limited to binary classification of real and fake images, rather than identifying different methods in an open-world scenario, leading to failures in dealing with unknown deepfake categories in practice. In this paper, we propose an unsupervised domain adaptation method for fine-grained open-set deepfake detection. Our method first uses labeled data from the source domain for model pre-training to establish the ability of recognizing different deepfake methods in the source domain. Then, the method uses a Network Memorization based Adaptive Clustering (NMAC) approach to cluster unlabeled images in the target domain and designs a Pseudo-Label Generation (PLG) to generate virtual class labels for unknown deepfake categories by matching the adaptive clustering results with the known deepfake categories in the source domain. Finally, we retrain the initial multi-class deepfake detection model using labeled data of the source domain and pseudo-labeled data of the target domain to improve its generalization ability to unknown deepfake classes presented in the target domain. We validate the effectiveness of the proposed method under multiple open-set fine-grained deepfake detection tasks based on three deepfake datasets (ForgerNet, FaceForensics++, and FakeAVCeleb). Experimental results show that our method has better domain generalization ability than the state-of-the-art methods, and achieves promising performance in fine-grained open-set deepfake detection.",Deepfake detection;domain adaptation;unsupervised learning;fine-grained classification,IEE
396,Exploiting Style Latent Flows for Generalizing Deepfake Video Detection,J. Choi; T. Kim; Y. Jeong; S. Baek; J. Choi,2024,"This paper presents a new approach for the detection of fake videos, based on the analysis of style latent vectors and their abnormal behavior in temporal changes in the generated videos. We discovered that the generated facial videos suffer from the temporal distinctiveness in the temporal changes of style latent vectors, which are inevitable during the generation of temporally stable videos with various facial expressions and geometric transformations. Our framework utilizes the StyleGRU module, trained by contrastive learning, to represent the dynamic properties of style latent vectors. Additionally, we introduce a style attention module that integrates StyleGRU-generated features with content-based features, enabling the detection of visual and temporal artifacts. We demonstrate our approach across various benchmark scenarios in deepfake detection, showing its superiority in cross-dataset and cross-manipulation scenarios. Through further analysis, we also validate the importance of using temporal changes of style latent vectors to improve the generality of deepfake video detection.",Deepfake Detection;Face Forgery Detection,IEE
397,Detection of Manipulated Multimedia In Digital Forensics Using Machine Learning,P. Anvekar; A. Gudnavar; K. Naregal; S. Nagarmunoli,2024,"The surge in digital media usage has spurred an uptick in multimedia manipulation., spanning images., videos., and audio. This manipulation., with its potential to spread misinformation and manipulate public opinion., poses serious threats. Detecting genuine from fake media is challenging due to the diverse tools employed. Consequently., cybercrime involving manipulated media is on the rise. Researchers are countering this issue with machine learning techniques., particularly Convolutional Neural Networks (CNNs). This paper presents an application leveraging CNN s to identify genuine and fake media., bolstered by results from experiments on real and manipulated datasets., yielding high accuracy and robustness. Deep learning models excel in detecting various manipulation types., positioning them as potent weapons against manipulated content proliferation. To ascertain the models' effectiveness., the study includes comprehensive validation., testing procedures., and robustness analyses against sophisticated manipulations., including adversarial attacks and deepfake variations. This research advances multimedia forensics., offering a holistic approach to detect manipulated media with deep learning models., underscoring CNN s' effectiveness in curbing manipulated content dissemination., and emphasizing the necessity of ongoing advancements to tackle the evolving multimedia manipulation landscape.",Manipulated media;CNN;Machine learning;Digital forensics;Cyber security,IEE
398,DeepFake Image Detection and Classification using EfficientNet Model,S. Singh; P. Sarala; S. K. Chandra; M. D. Kumar,2024,"Deep learning models such as Vision Transformer (VIT) and EfficientNet, have brought significant advancements to computer vision tasks like image classification, object detection, and image generation. In this paper, comparative analysis of VIT and EfficientNet models has been done with more attention of on their architectural disparities, training procedures, and performance characteristics. Deep learning models like Vision Transformer (VIT) and EfficientNet have revolutionized computer vision. VIT uses self-attention techniques instead of convolutional layers to capture global relationships but with higher computational. EfficientNet models, with compound scaling offer a trade-off between accuracy and efficiency. EfficientNet models are computationally fast with competitive accuracy and is suitable for resource-limited contexts. The paper suggests choosing the best model based on specific use cases and resource limitations. Quantitative analysis of the present work has been done using confusion matrix. It has been observed that EfficientNet models are providing higher performance ratio.",Vision Transformer (VIT);EfficientNet;deep learning models;computer vision;image classification;object detection;comparative analysis,IEE
399,Deepfake Image Detection using CNNs and Transfer Learning,N. Kumar; P. P; V. Nirney; G. V,2021,"Headways in deep learning has enabled the creation of fraudulent digital content with ease. This fraudulent digital content created is entirely indistinguishable from the original digital content. This close identicalness has what it takes to cause havoc. This fraudulent digital content, popularly known as deepfakes having the potential to change the truth and decay faith, can leave impressions on a large scale and even our daily lives. Deepfake is composed of two words, the first being deep: deep learning and the second being fake: fake digital content. Artificial intelligence forming the nucleus of any deepfake formulation technology empowers it to dodge most of the deepfake detection techniques through learning. This ability of deepfakes to learn and elude detection technologies is a matter of significant concern. In this research work, we focus on our efforts towards the detection of deepfake images. We follow two approaches for deepfake image detection, and the first is to build a custom CNN based deep learning network to detect deepfake images, and the second is to use the concept of transfer learning.",Deepfakes;Error Level Analysis(ELA);Convolutinal Neural Networks (CNNs);Transfer-learning,IEE
400,"Face Segmentation: A Journey From Classical to Deep Learning Paradigm, Approaches, Trends, and Directions",K. Khan; R. U. Khan; K. Ahmad; F. Ali; K. -S. Kwak,2020,"Face segmentation represents an active area of research within the bio-metric community in particular and the computer vision community in general. Over the last two decades, methods for face segmentation have received increasing attention due to their diverse applications in several human-face image analysis tasks. Although many algorithms have been developed to address the problem, face segmentation is still a challenge not being completely solved, particularly for images taken in wild, unconstrained conditions. In this paper, we present a comprehensive review of face segmentation, focusing on methods for both the constrained and unconstrained environmental conditions. The article illustrates the advantages and disadvantages of previously proposed methods in state-of-the-art (SOA). The approaches presented comprise the seminal works on face segmentation and culminating in SOA approaches of the deep learning architecture. An extensive comparison of the previous approaches is intuitively presented, with a discussion of the potential directions for future research on the topic. We believe this comprehensive review and recap will contribute to a number of application domains, and will augment the knowledge of the research community.",Face segmentation;face image analysis;deep learning;machine learning,IEE
401,Development of a Deepfake Detection Method: Application of Frequency Analysis and Reduction of the Image Color Space to Improve Classification Accuracy,V. Rogovoi; V. M. Korzhuk; O. A. Kokorina,2024,"With the development of generative and diffusion models of neural networks, it has become possible to create high-quality realistic images that are visually indistinguishable from real photos. This expands the horizons of using technology to synthesize data and media content, however, with the help of this technology, it becomes possible to generate or replace the faces of real people using deepfake methods. Although modern deepfake recognition methods show high results on synthetic data, they suffer from the problem of false positives when working with processed images of real and synthetic faces. Moreover, resizing the image according to the input layer of classifiers based on convolutional neural networks can lead to additional distortions, which can affect the classification process. In this paper, we propose a method based on the reduction of the color palette and spectral analysis of images to improve the accuracy of the classification of deepfakes. The proposed method allowed to increase the accuracy of recognition of modified deepfakes to 99.4%.",digital image processing;deep learning;deepfake;identity forgery,IEE
402,Enhancing Deepfake Detection: An Ensemble Deep Learning Approach for Efficient Attribute Manipulation Identification,S. P P; R. R R; D. A; G. R; A. R; G. B. P,2024,"The increasing use of deepfake technology by incorporating Artificial Intelligence (AI) to seamlessly replace faces in videos, poses a significant threat to individuals, societies, and national security. This research study addresses this growing concern by detecting deepfake classification with the integration of two powerful Convolutional Neural Network (CNN) models: InceptionV3 and EfficientNetB0. The existing deepfake detection systems predominantly rely on facial feature analysis, analyzing subtle inconsistencies; however, these methods are susceptible to evolving deepfake techniques. In response, the proposed ensemble model exploits the advantages of InceptionV3 and EfficientNetB0 models to capture intricate features and computational efficiency. The synergy between these models significantly enhances the accuracy upto 93% and adaptability of the proposed deepfake detection system. When compared with conventional facial feature analysis, this approach establishes a resilient defense against emerging deepfake threats. As deepfake technology continues to advance, necessitating continual research in face-based detection systems, this study proposes a cutting-edge ensemble approach that not only mitigates the risks associated with social media manipulation but also serves as a proactive measure against potential challenges in future.",Deepfake Detection;Ensemble Learning;Facial Feature Analysis;Attribute Manipulation;Efficient Net;Inception Net,IEE
403,Evaluating Acoustic Parameters for DeepFake Audio Identification,A. E. Djir�; A. Saban�; A. -K. Kabore; R. Kafando; T. F. Bissyand�,2023,"The progress made in the field of machine learning applied to signal processing offers interesting perspectives in terms of technological evolution but also causes some troubles in terms of ethics and security. For example, we are witnessing the emergence of audio deepFakes used to orchestrate scams. However, although the tools used in the generation of these deepFake audios show good results which can sometimes produce audios that seem to be confused with real audio, it is not impossible to dissect them. In order to detect them, many methods exist, in particular the analysis of the acoustic parameters which can attest to the authenticity of an audio extract. These parameters include energy, power, pitch, signal spectrum, cepstral coefficients, etc. However, these acoustic parameters are numerous and not all of them are suitable for detecting deepFake audio. This paper presents a comparative review of acoustic parameters useful in detecting DeepFake audio. Among them, we highlight the relevance of the study of cepstral parameters such as MFCC compared to other acoustic parameters such as mel-spectograms. The objective is to provide reliable leads in the detection of deepFake audio.",deepFake audio;detection;mel-spectogram;MFCC,IEE
404,DeepFake Detection on Publicly Available Datasets using Modified AlexNet,D. Xie; P. Chatterjee; Z. Liu; K. Roy; E. Kossi,2020,"Deep learning has been applied successfully in many areas, including computer vision, natural language processing, cyber physical systems and big data analytics. Recently, a synthesis of deep leaning techniques has been deployed to create fake images and videos that are not easily distinguishable from the real ones; this technology is known as DeepFakes. In this paper, we looked at various DeepFakes related datasets and created a model in order to identify whether a frame of a video is fake or real. This is important as videos can be easily manipulated in a way that can spread misinformation, and that can cause major problems in the world today, especially if the videos have political implications. In order to create a model, we utilize a modified AlexNet constructed of an arrangement of 6 layers: convolution2d, max pooling, dense, flatten, activation and dropout layers. UADFV, FaceForensics++, and Celeb-DF are the 3 datasets used in this research. There are many publicly available datasets, however, we found the UADFV, FaceForensics++ and Celeb-DF to be the most convenient in how the data was formatted. All data for each dataset was organized into videos of varying classes. While the UADFV dataset is straightforward and only has 2 classes: real and fake, the FaceForensics++ dataset looks at the various kinds of video manipulations and has 5 different classes. Our model was able to achieve a 9S.73% accuracy when identifying whether a video is real or fake on the UADFV dataset, a slightly adjusted version was able to accomplish an 87.49% accuracy with the FaceForenisics++dataset, and reached 98.85% accuracy on the Celeb-df dataset.",Image Manipulation;Deep Learning;DeepFakes;UADFV;FaceForensics;AlexNet,IEE
405,Deepfake Detection Models Based on Machine Learning Technologies,K. Smelyakov; Y. Kitsenko; A. Chupryna,2024,"The paper is devoted to efficiency evaluation of modern deepfake detection models based on convolutional neural networks (CNN). In the context of rapid development of digital technologies and increasing volume of information on the internet, the relevance of detecting fake images, videos, and textual materials becomes increasingly significant. Fake content, spread through social networks and other platforms, can have serious consequences, ranging from individual malicious attacks to manipulations of public opinion on a global level. We have built and trained several models for detecting fake content using convolutional neural networks. The training was performed using Deepfake Detection Challenge Dataset. During the study, we carried out the comparative analysis of the created models. Obtained results were compared with a number of recent publications.",Deepfake;Convolutional Neural Network;Face detection;EfjicientNet;Effectiveness,IEE
406,Deepfake Detection: Current Challenges and Next Steps,S. Lyu,2020,"High quality fake videos and audios generated by AI- algorithms (the deep fakes) have started to challenge the status of videos and audios as definitive evidence of events. In this paper, we highlight a few of these challenges and discuss the research opportunities in this direction.",DeepFake videos;detection techniques;digital media forensics,IEE
407,EfficientNetB0 Ensemble Model for Unified Deepfakes Detection,S. A. Minhas; S. Mushtaq; A. Javed,2023,"In recent years, we have witnessed the generation of exceptional authentic deepfake images and videos due to the availability of cutting-edge Artificial Intelligence and deep learning techniques. Deepfakes represent synthetic multimedia content used to propagate disinformation for defamation, political unrest, manipulating elections, committing crimes, etc. In this paper, we present a novel ReLU-Swish EfficientNet (RSE-Net) for deepfakes detection. Our proposed RSE-Net is capable of reliably detecting deepfakes videos that are generated using different techniques. Our model leverages an ensemble of EfficientNet architectures, which are combined using a fusion technique to enhance the model�s performance in detecting deepfakes. We suggested the ReLU activation in conv2D layers in place of regular Swish activation in EfficientNetB0 first variant as ReLU is computationally more efficient and reduces the risk of overfitting. We evaluated our model on two large-scale challenging deepfake datasets: FaceForensics ++ and CelebDF. Our RSE-Net attained an average accuracy of 99.7% on the FaceForensics++ dataset, and 96.09% on the CelebDF dataset. Furthermore, our model generalizes well and effectively detects deepfake videos in realworld scenarios. Thus, it is a valuable tool for analyzing and detecting potentially manipulated content.",Deepfake detection;Celeb-DF;FaceForensics ++;Ensemble model;Fused-EfficientNet,IEE
408,AdvShadow: Evading DeepFake Detection via Adversarial Shadow Attack,J. Liu; M. Zhang; J. Ke; L. Wang,2024,"With the emergence of techniques called DeepFakes, there has been a notable proliferation of DeepFake detectors rooted in deep learning. These detectors aim to expose subtle distinctions between genuine and counterfeit facial images across spatial, frequency, and physiological domains. Unfortunately, these detectors are susceptible to adversarial attacks. In this study, we introduce a novel transferable adversarial attack named AdvShadow, designed to attack DeepFake detectors by leveraging natural shadows in real-life. The proposed AdvShadow comprises three components: random shadow generator, shadow overlay network, and adversarial shadow generation. Initially, we construct a random shadowed facial dataset, utilizing additional shadow overlay network to produce adversarial samples for training. Then we generate adversarial shadows for DeepFake datasets, mitigating the disparities of luminance between real and synthesized images. Through extensive experiments, we demonstrate the effectiveness and transferability of AdvShadow for attacking under black-box settings.",DeepFakes;DeepFake detection;transferable adversarial shadows,IEE
409,Detection of Compressed DeepFake Video Drawbacks and Technical Developments,A. -S. Humidan; L. N. Abdullah; A. A. Halin,2022,"The rapid advancement in artificial intelligence (AI) has revolutionized the creation of synthesized multimedia and given rise to DeepFake, a highly realistic fake video or image depicting a person doing or saying something he/ she has never done or said in reality. Attackers use DeepFake to tarnish individuals� reputations and disseminate fake news, which in turn undermines societies� stability and security. In response to this cyber security threat, many DeepFake detection methods have been proposed, which show outstanding performance in detecting high-quality DeepFake videos. However, their performance decreases when detecting compressed fake videos. This article investigates the problem of compressed DeepFake video detection. Firstly, popular detection methodologies are reviewed focusing on their abilities to distinguish between real and fake compressed video footage. Then, we attempt to identify and discuss the weaknesses of the methods by examining factors that contribute to decreasing detection efficiency. At the end of this article, we present new generation DeepFake detector techniques that reportedly exhibit improved performance and robustness against video compression. We hope that the contribution from this work inspires innovation for more reliable solutions to combat potential security threats posed by DeepFake videos.",Compressed DeepFake video;digital media forensics;social media disinformation;video manipulation detection,IEE
410,Machine Learning Methods to identify Hindi Fake News within social-media,D. K. Sharma; S. Garg,2021,"Over the last decades, Fake news has exploded online. Fabricated stories go viral on digital media. The rise in the use of digital media has accelerated the pace of fake news. It affects the offline public and also threatens human safety. It is critical to check the veracity of news over social media platforms to mitigate its grave impacts. Finding accurate information within this ocean of data is where fake news detection comes into the picture. Most of the existing work is based on the English language. A little work is done using resource scare language for fake news identification. This paper presents an Indian dataset for Hindi Language using Devanagari lipi. Indian Hindi news is collected using the Parsehub scrapping tool. We performed several experiments by using an existing machine learning algorithm and achieved satisfactory results. The outcome reflects the effectiveness of our proposed dataset.",Fake news;Hindi dataset;Machine-learning classifier;Natural language processing,IEE
411,Differential Detection of Facial Retouching: A Multi-Biometric Approach,C. Rathgeb; C. . -I. Satnoianu; N. E. Haryanto; K. Bernardo; C. Busch,2020,"Facial retouching apps have become common tools which are frequently applied to improve one's facial appearance, e.g. before sharing face images via social media. Beautification induced by retouching has the ability to substantially alter the appearance of face images and hence might represent a challenge for face recognition. Towards deploying secure face recognition as well as enforcing anti-photoshop legislations, a robust and reliable detection of retouched face image is needed. Published approaches consider a single image-based (no-reference) scenario where a potentially retouched face image serves as sole input to the retouching detector. However, in many cases a trusted unaltered face image of a subject examined is available which enables an image pair-based (differential) detection scheme. In this work, ICAO-compliant subsets of the FERET and FRGCv2 face databases are used to automatically create a database containing 9,078 retouched face images together with unconstrained probe images. In evaluations employing the commercial Cognitec FaceVACS and the open-source ArcFace face recognition system, it is shown that facial retouching can negatively impact face recognition performance. Further, a differential facial retouching detection system is proposed which processes pairs of a potentially retouched reference image and corresponding unaltered probe image of single subjects. Estimated differences in feature vectors obtained from texture descriptors, facial landmarks, and deep face representations are leveraged by machine learning-based classifiers of which the detection scores are fused to distinguish between retouched and unaltered face images. The proposed scheme is evaluated in a cross-database scenario where training and testing are performed on the FERET and FRGCv2 databases and vice versa. In the scenario where the used retouching algorithm is known by the detection algorithm, a competitive average D-EER of approximately 2% is achieved. Further, the scenario in which the employed retouching algorithm is not known by the detection algorithm is evaluated. In the latter scenario, the proposed approach obtains an average D-EER below 10% and is shown to outperform several state-of-the-art single image-based detection schemes.",Biometrics;face recognition;facial retouching;beautification;differential detection,IEE
412,DeepFake Video Detection Using Machine Learning and Deep Learning Techniques,L. Sarala; C. Sridevi; R. A. Chowdary; M. H. G. P. Gargeye,2024,"The current issue facing the community is determining the legitimacy of online content, including movies and pictures generated by machine learning, in light of the development of Generative adversarial networks (GAN) and other deep learning-based DeepFake approaches. There is an extraordinary chance that we may severe violations of fundamental human rights combined with an inevitable, fundamental shift in the way people interact in society. Evidence of misinformation and manipulation of news headlines, medical (dis)information, and invasions of privacy have already been demonstrated. The objective of this proposed project is to efficiently identify DeepFake photos using an online image database. The categorization of real from false photos using convolutional neural networks and data from a sizable internet database is the main topic of this study. Our comparison of three distinct convolutional neural networks was our goal. 1) DenseNet, 2) VGG Face and 3) personalized CNN structure. Future research will examine whether real and false pictures cluster independently using unsupervised clustering techniques or auto-encoders. It would also involve using CNN visualization techniques to give our models more interpretability and transparency.",Convolution neural networks (CNN);Generative Adversarial Networks (GAN);DeepFake;VGG Face;DenseNet;Artificial neural network (ANN),IEE
413,Deep Fake Face Detection using Efficient Convolutional Neural Networks,M. Umadevi; S. B. Krishna; N. S. Kumar,2024,"Deep fake content, especially in images and videos, is spreading at an unprecedented rate. Fake content are generated with the help of advanced deep learning (DL) algorithms such as GANs, autoencoders, and variation autoencoders. This fake content spreads misinformation, causing a severe impact on society by degrading the trustworthiness of content on social media. Mitigating the risk of these techniques can be done by utilizing the power of one of the DL models, which is CNN. This research study focuses on analysing various Deep-Fake (DF) identification techniques that are trained on various datasets with a small number of samples. The proposed work demonstrates an efficient CNN model and three other CNN pre-trained models through transfer learning on a large dataset available on Kaggle, consisting of 140k images of faces. The proposed CNN model achieved a high accuracy of 96%, while DenseNet121 reached 97%. Both EfficientNetB0 and MobileNet demonstrated even higher performance, each achieving an accuracy of 98% within 15 epochs.",Deep-Fakes (DF);Deep Learning (DL);CNN: Convolutional Neural Networks;GAN: Generative Adversarial Neural Network;Autoencoders,IEE
414,Deep Fake and Digital Forensics,H. Alshammari; K. Elleithy,2023,"Deepfakes have posed a significant challenge to digital forensics, and there is an increasing need for high accuracy deepfake (DF) detection models in real-world scenarios. This research examines and fine-tunes the MesoNet model to improve its performance on a large dataset of 140K authentic and manipulated images. The original MesoNet model achieved an accuracy of 87.1%. However, after fine-tuning and optimizing the model�s weights, the accuracy improved to 96.20%. This was accompanied by a sensitivity of 97.48% and a specificity of 94.75%, indicating that the model is highly effective at detecting genuine images and accurately identifying forged ones. This research contributes to the advancement of DF detection mechanisms in real-world scenarios.",Digital forensics;AI forensics;Data science and digital forensics;Deep fake;Face swapping,IEE
415,A New Era of Cybersecurity: The Influence of Artificial Intelligence,R. R. Shanthi; N. K. Sasi; P. Gouthaman,2023,"Artificial Intelligence (AI) has been rapidly advancing in recent years and has the potential to significantly impact the field of cybersecurity. One of the keyways in which AI is changing cybersecurity is by enabling more advanced and efficient threat detection and response. AI-powered systems can analysis vast amounts of data and identify patterns that would be difficult or impossible for a human to detect and can also automatically respond to threats in real-time. Additionally, AI can help organizations to better manage and secure their networks and devices, and to identify and mitigate vulnerabilities. However, AI also presents new challenges in the field of cybersecurity, as it can also be used to enable more sophisticated forms of cyber-attacks, such as AI-powered malware or �deepfake� phishing attempts. As AI continues to evolve, it will likely play an increasingly important role in the field of cybersecurity and will have a significant impact on the way organizations and individuals protect themselves from cyber threats.",Cybersecurity;AI;Threat Detection & Response,IEE
416,Document Image Forgery Detection Based on Deep Learning Models,P. Yang; W. Fang; F. Zhang; L. Bai; Y. Gao,2022,"With the improvement of the communication speed and the popularization of the Internet, images have become the most common information medium in life. At the same time, the adverse effects of forged images in the media, credit investigation, finance and academic fields are becoming more and more significant. Therefore, in recent years, the research on forged image identification algorithms has been active worldwide. Image forgery has different classification methods. According to whether the forgery uses deep learning methods, it can be divided into deep forged images and traditional forged images. It can also be divided into ordinary image forged and document image forged according to whether the image is a text image. Different forgery methods will leave different forgery traces in the image, corresponding to different forgery identification methods. Aiming at document forgery images, this paper proposes a forgery detection algorithm based on deep learning and fusion of error level analysis (ELA) information. Compared with the previous forgery identification algorithms, the algorithm in this paper can not only identify whether the document image is forged, but can also locate the forged text area. The algorithm proposed in this paper supports the detection of document image forgery generated by cutting, copying, erasing and deep learning methods. The detection algorithm of this paper participated in the fifth forgery detection competition of Ali Tianchi and won the 32nd place among 1470 participating teams.",Document Image Forgery Identification;Deep Learning;ELA Image Processing,IEE
417,Using Deep Learning to Detecting Deepfakes,J. Mallet; R. Dave; N. Seliya; M. Vanamala,2022,"In the recent years, social media has grown to become a major source of information for many online users. This has given rise to the spread of misinformation through deepfakes. Deepfakes are videos or images that replace one person's face with another computer-generated face, often a more recognizable person in society. With the recent advances in technology, a person with little technological experience can generate these videos. This enables them to mimic a power figure in society, such as a president or celebrity, creating the potential danger of spreading misinformation and other nefarious uses of deepfakes. To combat this online threat, researchers have developed models that are designed to detect deepfakes. This study looks at various deepfake detection models that use deep learning algorithms to combat this looming threat. This survey focuses on providing a comprehensive overview of the current state of deepfake detection models and the unique approaches many researchers take to solving this problem. The benefits, limitations, and suggestions for future work will be thoroughly discussed throughout this paper.",deep learning;deepfake;fake detection,IEE
418,An Efficient Algorithm for Fake Video Detection,N. Nibras; S. Fahim; S. Sakib; S. U. Rashid; A. Rahman,2024,"In recent times, the circulation of fake videos has caused significant uproar among the general people. Fake videos have caused considerable inconvenience in the daily lifestyle of some people. The intervention of fake videos is now regarded as a serious obstacle due to its manipulating and convincing power. Researchers and scientists have been trying to implement different methods and techniques to overcome this new technical barrier. Various procedures and algorithms have been implemented, which showed a wide variety of results in controlling and defeating this technological hazard. However, it is yet to be concluded on which method should be followed to stop fake videos from causing us problems. This is due to the broad range of results achieved by them and the deficiencies that these methods contain. None of these methods produced the perfect protection in all aspects of fake videos. Hence, our project emphasizes on detecting fake videos by implementing algorithms that will provide the most efficient and accurate result. In our project, a video will be uploaded in the web application, which will then undergo different machine learning techniques which will involve filtering, feature extraction, and classification. Finally, after completing the procedure, the output will be displayed whether the video is fake or real. According to our model, the accuracy rate achieved was 83.456%, 87.349% and 88.965% for the length of sequence 10, 20 and 40 respectively. The best accuracy was achieved when the length of sequence is 40.",Convolutional neural network;Deepfake video;Machine learning;Recursive neural network,IEE
419,Deepfake Facial Recognition for Video Clips,Adarsh; N. Bhaal; G. Padmapriya,2024,"The accessibility of deep learning tools has fueled the rise of convincing Deepfake videos. This research focuses on developing and evaluating an advanced Deepfake Facial Recognition system, integrating Long Short-Term Memory (LSTM) and ResNeXt CNNs. Utilizing CNNs for frame-level facial feature extraction and LSTM for temporal dependencies, the system excels in discerning nuanced manipulations. Extensively tested on diverse Deepfake content, our findings demonstrate the system's considerable accuracy in distinguishing between authentic and manipulated facial features. The integrated LSTM enhances sensitivity to subtle manipulations often overlooked by frame-based methods, while the ResNeXt CNN architecture improves overall precision. Rigorously evaluated on a diverse set of Deepfake-containing video clips, the system proves highly effective. The research also addresses challenges in Deepfake facial recognition, exploring potential countermeasures and contributing valuable insights to the development of robust systems mitigating risks associated with manipulated video content. The FaceForensic++ dataset model stands out with its remarkable precision, achieving an impressive accuracy rate of 97.76%. Meanwhile, the Celeb-DF dataset model has also performed admirably, boasting a competitive accuracy score of 93.97%.",Deepfake Video Detection;ResNext CNN;LSTM,IEE
420,Video Integrity Detection with Deep Learning,C. R; A. V. R; P. R,2024,"In today's digital age, ensuring information integrity against deepfakes is essential. This project addresses this challenge by developing a scalable video integrity detection system through the fusion of convolutional neural networks (CNNs) for analyzing video frames and recurrent neural networks (RNNs) for temporal behavior. The model incorporates advanced architectures designed to capture subtle inconsistencies and manipulation artifacts, leveraging cutting-edge techniques for enhanced detection compared to traditional methods. Its adaptability is enhanced through the utilization of domain adaptation and adversarial training strategies, ensuring durability against evolving manipulation techniques. Designed for real-time capabilities, the system is optimized for efficient inference, enabling proactive identification and mitigation of manipulated content on online platforms. Expected outcomes include achieving high accuracy in discriminating real from manipulated videos, promoting improved trust and transparency in the digital media landscape. By providing a reliable means to verify the integrity of video content, the system contributes to a more trustworthy and secure digital ecosystem. This multi-modal fusion approach, coupled with advanced architectures, effectively addresses the necessity for identifying and controlling the spread of manipulated video content.",Deep learning;Video integrity detection;Convolutional neural networks (CNNs);Recurrent neural networks (RNNs);Deepfake (DF);Adversarial training;Long Short-Term Memory (LSTM);ResNeXt,IEE
421,EDL-Det: A Robust TTS Synthesis Detector Using VGG19-Based YAMNet and Ensemble Learning Block,R. Mahum; A. Irtaza; A. Javed,2023,"Various audio deep fake synthesis algorithms exist, such as deep voice, tacotron, fastspeech, and imitation techniques. Despite the existence of various spoofing speech detectors, they are not ready to distinguish unseen audio samples with high precision. In this study, we suggest a robust model, namely an Ensemble Deep Learning Detector (EDL-Det), to detect text-to-speech (TTS) and categorize it into spoofed and bonafide classes. Our proposed model is an improved method based on Yet Another Multi-scale Convolutional Neural Network (YAMNet) employing VGG19 as a base network combined with two other deep learning(DL) techniques. Our proposed system effectively analyzes the audio to extract better artifacts. We have added an ensemble learning block that consists of ResNet50 and InceptionNetv2. First, we convert speech into mel-spectrograms that consist of time-frequency representations. Second, we train our model using the ASVspoof-2019 dataset. Ultimately, we classified the audios, transforming them into mel-spectrograms using our trained binary classifier and a majority voting scheme by three networks. Due to ensemble architecture, our proposed model effectively extracts the most representative features from the mel-spectrograms. Furthermore, we have performed extensive experiments to assess the performance of the suggested model using the ASVspoof 2019 corpus. Additionally, our proposed model is robust enough to identify the unseen spoofed audios and accurately classify the attacks based on cloning algorithms.",Deep learning;DeepFake audios;fake speech;text-to-speech detection;VGG19;mel-spectrograms,IEE
422,An Overview of Deepfake: The Sword of Damocles in AI,X. Tong; L. Wang; X. Pan; J. g. Wang,2020,"Deepfakes, which are used to generate and modify human faces, have developed rapidly in recent years. However, as they transfer facial features to target pictures and videos, it is difficult to distinguish the original faces, which has a serious impact on individuals and society. In this survey, we introduce deepfakes technology and classify them into face generation, face swap and facial attribute editing. Moreover, we discuss and summarize the current situation, classic technology, cutting-edge models and public fake datasets of the three aspects. Lastly, we provide an outlook of the development trend of deepfakes in terms of improving authenticity and strengthening confrontation detection.",DeepFake;Face Manipulation;Deep Learning;Generative Adversarial Networks;Variational Auto-Encoder,IEE
423,Detection of Facial Forgery in Digital Images,H. A. Khan; S. Tehsin; M. Humayun; G. N. Alwakid,2023,"Detection of facial forgery in images and videos is a complex and challenging task. For the last years, different methods have been employed to detect facial forgeries. However, facial forgeries are still very challenging to detect. In this paper, a modern facial forgery detection method is presented which automatically detects facial forgeries in videos and images. The proposed method classifies fake and original videos and images. To classify the images, deep learning model, Inception-ResNet has been adopted. The proposed method is validated on publicly available Deepfake TIMIT dataset and effective results have been reported.",Facial Forgery;Deepfake;Image Forensics;Fake Image;deep learning,IEE
424,Robust Frame-Level Detection for Deepfake Videos With Lightweight Bayesian Inference Weighting,L. Zhou; C. Ma; Z. Wang; Y. Zhang; X. Shi; L. Wu,2024,"Deepfake threatens the authenticity of the information in artificial intelligence Internet of Things (IoT) systems. Recently, several deepfake detection methods have been proposed in academia and industry for securing the authenticity of visual information in the face of artificial intelligence advances. Frame-level detection methods, a widely employed security method against deepfake, have a small model size and offer real-time responsiveness, despite basing their classification decision only on the information contained within the frame they are evaluating. We propose a new lightweight frame-level detection technique based on Bayesian inference weighting (BIW) to improve the robustness of existing frame-level detection models. Our proposed BIW technique employs the Naive Bayesian algorithm to estimate the reliability of any candidate model�s detection results. Comprehensive experiments were conducted on the attacked data sets by four designed video interference approaches and edge computing platform, showing that BIW enhances the robustness of all the baselines and improves their detection accuracy with a real-time response.",Bayesian inference;deepfake video;frame-level detection;IoT security,IEE
425,Ethical and Legal Principles of Publishing Open Source Dual-Purpose Machine Learning Algorithms,K. Nikolskaia; V. Naumov,2020,"In today's world there is an active introduction of artificial intelligence technologies in various fields of science and technology. On the one hand, the publication by open source researchers of their achievements can be called the force for progress. On the other hand, some studies have a dual purpose like the analysis of computer traffic using machine learning methods. A number of questions arise regarding the ethical side of the issue of publishing such information in the public domain. The paper discusses the ethical and legal foundations of publishing open source dual-purpose machine learning algorithms. And also the problems associated with it.",DDoS attacks;cybersecurity;legal liability;open source machine learning algorithms,IEE
426,Research on Technology Against Deepfake,X. Wei; W. Zhang; G. Bai; B. Li,2023,"With the help of social networks, Deepfakes enable false information to be presented to netizens in a highly credible manner, which will have a huge impact on individuals, organizations, and countries. It will also pose huge information security risks to individuals, organizations, and countries. Some countries are even seeking to weaponize �deep counterfeiting technology�, which poses significant security risks and has become a focus and difficulty of research both domestically and internationally. Scholars both domestically and internationally are exploring different deep forgery detection countermeasures to eliminate negative impacts. It was found that at the technical level, it can be divided into two types based on processing methods: passive detection algorithms and active defense technologies. According to the different processing objects, passive detection algorithms can be divided into two categories: deep forged image detection and deep forged video detection. In terms of active defense technology, content traceability technology is mainly used to build a trusted system for digital content in the internet to ensure the source security of content. This paper summarizes the current research situation of combating deepfake technology based on blockchain technology from three aspects of building a trusted network, tracing deepfake and content Tamper resistance prevention, analyzes the limitations and risks of using blockchain technology against deepfake technology, and discusses the future research direction.",Deepfake;Blockchain;Traceability;Tamper-proof;Trusted-network,IEE
427,MCL: Multimodal Contrastive Learning for Deepfake Detection,X. Liu; Y. Yu; X. Li; Y. Zhao,2024,"Advancements in computer vision and deep learning have led to difficulty in distinguishing Deepfake and real videos. In particular, forgery audios are also generated to accompany fake videos and make them more realistic, which makes Deepfake detection more difficult. Existing Deepfake detection methods that use multimodal information ignore the representation gap between different modalities, resulting in limited performance. To address this problem, in this paper, a novel Deepfake detection method utilizing multimodal contrastive learning (MCL) is proposed to better explore intra-modal and cross-modal forgery clues. To reduce the cross-modal gap and explore multimodal forgery artifacts, a cross-modal contrastive learning strategy is designed to learn a compositional embedding from multimodal information, which facilitates pulling together representations across uni-modalities and multi-modalities. Moreover, to supplement the intra-frame forgery clues mining ability of the video network, the frame knowledge is distilled to the video network without adding additional computation. Specifically, to mine intra-modal clues, three modality features are first extracted from audio, frame and video, respectively. Secondly, the audio and frame features are separately composed with the video feature to derive two cross-modal representations. Subsequently, these cross-modal features are contrastive with the intra-modal features to reduce cross-modal gap. By jointly pulling together the unimodal and multimodal features through MCL, a more effective representation that contains intra-modal and cross-modal forgery artifacts can be learned. Finally, a noise-based feature augmentation (NFA) module is proposed to adaptively perturb the audio-visual feature and further improve generalization performance. Extensive experiments demonstrate that the proposed framework outperforms SOTA methods.",Deepfake detection;contrastive learning;knowledge distillation,IEE
428,A Systematic Review on Fake Image Creation Techniques,R. Chauhan; R. Popli; I. Kansal,2023,"In the last few decades, Deep Learning has experienced remarkable growth, which has improved computer vision tasks. Deep fake is a technology that uses deep learning algorithms that manipulates the features of original content digitally to produce fake realistic-looking content that can be audio, video, photos, etc. There are various methods available in literature for creating deep fake such as GAN (General Adversarial Network), Auto Encoders, pix2pixGAN, Cycle GAN, Style GAN, Wave Net etc. and some of the open source digitally available tools are Deep Face Lab, Face Swap, etc. In the video game and film sectors, the adoption of the aforementioned techniques has expanded significantly. This study elaborates on a survey that was performed by several research organisations and focused on the feasibility gaps that need to be recovered for deep fakes. In this work, many contemporary strategies for creating false images are explained, along with the various dataset types that authors used. Finally, numerous research gaps and potential future directions are highligh ted.",Deep Fake;GAN;Auto Encoders;StyleGAN;DeepFaceLab;Face Swap,IEE
429,"A Comprehensive Comparative Analysis of Deepfake Detection Techniques in Visual, Audio, and Audio-Visual Domains",A. A. Bekheet; A. Ghoneim; G. Khoriba,2024,"In recent years, the rise of social media platforms has made them vital channels for sharing news, where audio and visual content play a crucial role in enhancing the credibility of news content. However, significant Artificial Intelligence (AI) progress has introduced new techniques and tools for manipulating multimedia content. These advancements have made it easier to create fabricated digital media, leading to a harmful impact on sharing misinformation, especially in fake news. Consequently, an urgent need arises to explore prevailing methodologies for detecting fake images, audio, and videos, accompanied by a comprehensive exposition of their strengths and limitations. Our survey addresses these methodologies and conducts a rigorous comparative analysis of diverse approaches using various metrics and datasets. We categorize these approaches into visual-based, audio-based, and audio-visual-based deepfake detection methods, encompassing techniques employed across domains. Additionally, we examine notable datasets utilized in detecting image, video, and audio deepfakes, offering insights into their attributes and appropriateness for evaluation purposes. Our findings highlight the effectiveness and limitations of current detection methods, providing a roadmap for future research in multimodal deepfake detection. This includes exploring emerging facets of video manipulation, such as text overlays and motion patterns, investigating advanced deep learning architectures like Transformers, and emphasizing the need for extensive, diverse, and publicly accessible datasets to enhance the robustness and validation of detection methods.",Audio-visual Deepfake Detection;Convolutional Neural Networks (CNNs);Recurrent Neural Networks (RNNs);Transformers;Mel Frequency Cepstral Coefficients (MFCC);Mel-spectrogram;Text-to-Speech Synthesis (TTS) Voice Conversion (VC),IEE
430,Joint Audio-Visual Deepfake Detection,Y. Zhou; S. -N. Lim,2021,"Deepfakes (""deep learning"" + ""fake"") are videos synthetically generated with AI algorithms. While they could be entertaining, they could also be misused for falsifying speeches and spreading misinformation. The process to create deepfakes involves both visual and auditory manipulations. Exploration on detecting visual deepfakes has produced a number of detection methods as well as datasets, while audio deepfakes (e.g. synthetic speech from text-to-speech or voice conversion systems) and the relationship between the video and audio modalities have been relatively neglected. In this work, we propose a novel visual / auditory deepfake joint detection task and show that exploiting the intrinsic synchronization between the visual and auditory modalities could benefit deepfake detection. Experiments demonstrate that the proposed joint detection framework outperforms independently trained models, and at the same time, yields superior generalization capability on unseen types of deepfakes.",Image and video manipulation detection and integrity methods;Vision + other modalities,IEE
431,Improved Deepfake Video Detection Using Convolutional Vision Transformer,D. W. Deressa; P. Lambert; G. Van Wallendael; S. Atnafu; H. Mareen,2024,"Deepfakes are hyper-realistic videos in which the faces are replaced, swapped, or forged using deep-learning models. This potent media manipulation techniques hold promise for applications across various domains. Yet, they also present a significant risk when employed for malicious intents like iden-tity fraud, phishing, spreading false information, and executing scams. In this work, we propose a novel and improved Deepfake video detector that uses a Convolutional Vision Transformer (CViT2), which builds on the concepts of our previous work (CViT). The CViT architecture consists of two components: a Convolutional Neural Network that extracts learnable features, and a Vision Transformer that categorizes these learned features using an attention mechanism. We trained and evaluted our model on 5 datasets, namely Deepfake Detection Challenge Dataset (DFDC), $\mathbf{FaceForensics++} \ (\text{FF}++)$ I, Celeb-DF v2, Deep-fakeTIMIT, and TrustedMedia. On the test sets unseen during training, we achieved an accuracy of 95 %, 94.8 %, 98.3 % and 76.7% on the DFDC, $\mathbf{FF ++}$, Celeb-DF v2, and TIMIT datasets, respectively. In conclusion, our proposed Deepfake detector can be used in the battle against misinformation and other forensic use cases.",Deepfake Video Detection;Vision Transformer;Convolutional Neural Network;Misinformation Detection;Mul-timedia Forensics,IEE
432,Deep Inception V5 Convolution Neural Network to detect and prevent the propagation of deepfake information in Social Media Applications and Research Databases,K. K; S. S; S. G; S. P; S. A,2024,"Online social media application and research databases are witnessing an exponential growth of deep cloned and deepfake information due to AI tools like ChatGPT. Online social media application and Research databases has been envisioned as knowledge sharing medium among the researchers and subscribers. Especially many plagiarism detection tools using machine learning architectures has devised to mitigate the submission of the duplicate and similar content but still leads to numerous challenges in managing cloned and optimized information by Artificial intelligence tools. In this article, a novel objective is set to design a quality assessment tool for research article and information uploaded to the social media and research databases. In order to achieve that objective, deep learning architecture entitled deep inception V5 convolution Neural Network is designed to detect and prevent propagation of the deep cloned and AI optimized content in research databases and social media. To perform the model training and testing, twitter dataset and Scopus dataset in the specified area during years from 2019 to 2024 has been extracted. Initially data preprocessing is carried out to normalize and annotate the sentences. Latent discriminant analysis approach is applied to extract the concept drift and vocabulary edited features from the pre-processed sentences. Those features are represented as word embedding vector. Embedding vector is projected to the deep inception V5 Convolutional Neural Network to generate feature map through inception layers. Further fully connected layer composed of the activation function incorporating ReLu approach, Softmax function incorporating the random forest classifier is to detect the deep cloned content and loss function incorporating the cross entropy is to eliminate over fitting and underfitting issues. Next, testing data is applied to trained model to evaluate the effectiveness of the detection approach using cross fold validation. Experimental analysis of the trained model on cross validation proves its effectiveness in detecting the deep cloned contents with high accuracy and efficiency. On those evaluations, proposed model achieves 99.78 percent accuracy.",ChatGPT;Inception Network;Convolution Neural Network;Deep learning;Natural Language Processing;Deepfake information;DeepCloned information,IEE
433,Analyzing Deep Learning Models� Generalization Ability Under Different Augmentations on Deepfake Datasets,I. Huseynli; S. Varli,2021,"Deepfakes allow users to manipulate the identity of a person in a video or an image. Improvements on GAN-based techniques also generate more realistic and hard to detect fake faces. This threatens individuals and decreases trust in social media platforms. In this work, our goal is to report eight different models� learning ability on, by far, the largest fake face dataset - DFDC. The models� generalization ability was tested on the DFDC test set and Celeb-DF-v2 dataset. Effect of the various cut-out like augmentations to the learning was also reported.",deepFake;dFdc;face manipulation;digital video forensics,IEE
434,A Visually Interpretable Forensic Deepfake Detection Tool Using Anchors,K. Jayakumar; N. Skandhakumar,2022,"�Deepfakes� have seen a dramatic rise in recent times and are becoming quite realistic and indistinguishable with the advancement of deepfake generation techniques. Promising strides have been made in the deepfake detection area even though it is a relatively new research domain. Majority of current deepfake detection solutions only classify a video as a deepfake without providing any explanations behind the prediction. However, these works fail in situations where transparency behind a tool�s decision is crucial, especially in a court of law, where digital forensic investigators maybe called to testify if a video is a deepfake with evidence; or where justifications behind tool decisions plays a key role in the jury�s verdict. Explainable AI (XAI) has the power to make deepfake detection more meaningful, as it can effectively help explain why the detection tool classified the video as a deepfake by highlighting forged super-pixels of the video frames. This paper proposes the use of �Anchors� XAI method, a model-agnostic high precision explainer to build the prediction explainer model, that can visually explain the predictions of a deepfake detector model built on top of the EfficientNet architecture. Evaluation results show that Anchors fair better than LIME in terms of producing visually explainable and easily interpretable explanations and produces an anchor affinity score of 70.23%. The deepfake detector model yields an accuracy of 91.92%.",Deepfake Detection;XAI;Computer Vision;Deep Neural Networks;Anchors;Digital Media Forensics,IEE
435,Beyond the Illusion: Ensemble Learning for Effective Voice Deepfake Detection,G. Ali; J. Rashid; M. Rameez Ul Hussnain; M. Usman Tariq; A. Ghani; D. Kwak,2024,"Deepfake synthetic media, manipulated using artificial intelligence to mimic authenticity, has become more dangerous in the modern digital era. Despite significant progress in video deepfake detection, audio deepfake detection relies on specific datasets and machine learning algorithms. This study addresses this limitation by developing a deep ensemble learning approach. The proposed deep ensemble approach for audio deepfake detection is called the Ensemble Convolutional Neural Network-Mel Frequency Cepstral Coefficient (ECN-MF). The ECN-MF model comprises a recurrent neural network, a 1D convolutional neural network, long short-term memory networks, and a convolutional long short-term memory network to extract a wider range of audio features, including mel-frequency cepstral coefficient, chroma features, and zero crossing rate. The data processing step was carried out through the creation of a preprocessing pipeline, inclusive of feature extraction, dimensionality standardization, and data normalization. The summarized features were incorporated into the feature vector, which was then normalized before being standardized in order to enhance consistency and stability across the audios. The investigation of the suggested ECN-MF model was carried out using the Fake-or-Real dataset. The dataset comprises four sub-datasets (�for-original�, �for-norm�, �for-2sec�, and �for-rerec�), categorized by audio duration and bit rate. To evaluate the performance of the proposed ensemble model, we utilized all sub-datasets with fake and real audio. The proposed ensemble approach achieved state-of-the-art accuracies of 99.5% on the �for-original� sub-dataset, closely matching the CNN model at 99.6%. It also achieved accuracies of 98% on �for-norm,� 96.9% on �for-2sec,� and 92.8% on �for-rerec� sub-datasets. By applying the proposed ensemble model to the �for-merged� dataset, which comprises all sub-datasets, we obtained a state-of-the-art accuracy of 98%. These results demonstrate the effectiveness of the proposed approach, which outperforms the results of the individual models.",Voice deepfake;fake-or-real dataset;ensemble model;RNN;1D CNN;LSTM;ConvLSTM;machine learning approach,IEE
436,Constructing New Backbone Networks via Space-Frequency Interactive Convolution for Deepfake Detection,Z. Guo; Z. Jia; L. Wang; D. Wang; G. Yang; N. Kasabov,2024,"The serious concerns over the negative impacts of Deepfakes have attracted wide attentions in the community of multimedia forensics. The existing detection works achieve deepfake detection by improving the traditional backbone networks to capture subtle manipulation traces. However, there is no attempt to construct new backbone networks with different structures for Deepfake detection by improving the internal feature representation of convolution. In this work, we propose a novel Space-Frequency Interactive Convolution (SFIConv) to efficiently model the manipulation clues left by Deepfake. To obtain high-frequency features from tampering traces, a Multichannel Constrained Separable Convolution (MCSConv) is designed as the component of the proposed SFIConv, which learns space-frequency features via three stages, namely generation, interaction and fusion. In addition, SFIConv can replace the vanilla convolution in any backbone networks without changing the network structure. Extensive experimental results show that seamlessly equipping SFIConv into the backbone network greatly improves the accuracy for Deepfake detection. In addition, the space-frequency interaction mechanism does benefit to capturing common artifact features, thus achieving better results in cross-dataset evaluation. Our code will be available at https://github.com/EricGzq/SFIConv.",Deepfake detection;space-frequency interactive convolution;backbone network;manipulation traces,IEE
437,FGSM Adversarial Attack Detection On Deepfake Videos,S. N. Mohamed; A. A. Ahmed; W. Elsersy,2024,"Our goal in this work is to create robust detection models that will counter the danger of adversarial attacks on deepfake videos. We selected a subset of the FaceForensics++ dataset, consisting of 1600 movies evenly divided into actual and fake categories, in order to overcome computational limitations.For FGSM attack detection, we used two sophisticated deep learning models: ResNet50 and Xception. In order to enhance the models' capacity to identify pertinent characteristics, we preprocessed the dataset prior to training by removing frames and concentrating on facial areas. We also added several intensities of FGSM adversarial attacks to improve the dataset's durability and diversification. The outcomes of our experiments were encouraging. With very little loss, the Xception model demonstrated remarkable performance, attaining high accuracies of 98.85% in training, 98.58% in validation, and 93.75% in testing. Never-theless, the ResNet50 model encountered difficulties, exhibiting reduced training, validation, and testing accuracies of 85.26%, 83.18%, and 82.50%, coupled with increased losses. Overall, by offering useful techniques for identifying misleading content, our research strengthens the authenticity and reliability of videos.",,IEE
438,Demystifying Attention Mechanisms for Deepfake Detection,A. Das; S. Das; A. Dantcheva,2021,"Manipulated images and videos, i.e., deepfakes have become increasingly realistic due to the tremendous progress of deep learning methods. However, such manipulation has triggered social concerns, necessitating the introduction of robust and reliable methods for deepfake detection. In this work, we explore a set of attention mechanisms and adapt them for the task of deepfake detection. Generally, attention mechanisms in videos modulate the representation learned by a convolutional neural network (CNN) by focusing on the salient regions across space-time. In our scenario, we aim at learning discriminative features to take into account the temporal evolution of faces to spot manipulations. To this end, we address the two research questions �How to use attention mechanisms?�, and �What type of attention is effective for the task of deepfake detection?� Towards answering these questions, we provide a detailed study and experiments on videos tampered by four manipulation techniques, as included in the FaceForensics++ dataset. We investigate three scenarios, where the networks are trained to detect (a) all manipulated videos, (b) each manipulation technique individually, as well as (c) the veracity of videos pertaining to manipulation techniques not included in the train set.",,IEE
439,Towards Generalized Deepfake Detection With Continual Learning On Limited New Data,H. Huang; N. Sun; X. Lin; N. Moustafa,2022,"Advancements in deep learning make it increasingly easy to produce highly realistic fake images and videos (also known as deepfakes), which could undermine trust in public discourse and pose threats to national and economic security. Despite the diligent efforts in developing deepfake detection techniques, existing approaches often generalize poorly when the characteristics of new data and tasks differ significantly from the ones involved in their initial training phase. The detectors' limited generalizability hinders their widespread adoption if they cannot handle unseen manipulations in an open set. A promising remedy is to endow the deepfake detectors with the capability of lifelong learning from the new data to improve themselves. However, it is not uncommon in real-world scenarios that the amount of training data associated with a certain deepfake algorithm is limited. Therefore, the effectiveness and agility of a continual learning scheme depend heavily on its ability to learn from limited new data. In this work, we propose a deepfake detection approach that combines spectral analysis and continual learning methods to pave the way towards generalized deepfake detection with limited new data. The experimental results on five datasets of deepfakes show that our proposed approach generalizes well on unseen datasets. Furthermore, it effectively addresses catastrophic forgetting despite limited new data, with the average forgetting rate reduced by 35.04% and the average accuracy improved by 22.45% as compared to without continual learning.",deepfake detection;spectral analysis;continual learning;generalization;limited data,IEE
440,Efficientnet-Based Deep Learning Approach for Video Forgery Detection and Authentication,V. Gowri Priyaa; M. Jaya Harrish; M. Udhayakumar; N. Jothieswaran; K. Dinesh,2024,"The technological advancements in artificial intelligence have made it a lot easier to create forged videos that are difficult to distinguish from reality. Fake videos also called deep fakes are created with greater accuracy and precision. Detecting and removing fake data on the internet can prevent misinformation and rumors from spreading. To achieve this, detection methods must be robust, generalized, fast, and accurate enough to detect fake data. In this paper, deepfakes are created using Generative Adversarial Network (GAN) and used for dataset training. The deepfakes are found to be different from real ones by various parameters like facial expressions, irregularities in the image, etc. This project focuses on detecting the manipulated face of the person in a frame using the EfficientNet B4 algorithm. The EfficientNet B4 model is more accurate than EfficientNet B0 and less complex than EfficientNet B7. The modified EfficientNet B4 outperforms the existing EfficientNet B0 in terms of accuracy. The probabilities of deep fakes in each frame are calculated and on average the video is detected as real or fake. This model demonstrates a very successful detection rate of more than 92%. Finally, modified EfficientNet B4 is compared with other models� performance.",Deepfake;EfficientNet;Compound scaling;Generator;Discriminator,IEE
441,Face Swapping for Film and Television Video based on FaceNet and Local Translation Warp,P. Du; C. Li; C. Dong,2022,"Face swapping, a study of editing the face identity attributes, has received more attention in recent years due to the breakthrough progress of deep learning. Due to its application and technical value, this paper attempts to swap faces in a selected video clip. To begin with, we use the deep learning framework facenet pytorch to build a MTCNN model for face detection, next obtain the face feature vector based on FaceNet, and compare the Euclidean distance for target face recognition. Then use the InsightFace library to locate the 106 facial landmarks of the target person. Lastly, select the appropriate facial landmarks on the two-dimensional image to realize the pixel-based local translation operation, so that the face contour changes.",face swapping;face recognition in video;MTCNN;FaceNet;local translation warp,IEE
442,Detecting Deepfake Videos via Frame Serialization Learning,X. Zhou; Y. Wang; P. Wu,2020,"Deepfake, a video forgery technique based on Generative Adversarial Network (GAN), has been proved to be a serious threat to the public security. The images and videos generated with it can even fool human eyes. In this paper, we propose a deep learning-based method to hunt Deepfake videos. A 3D-ResNext based model is developed to effectively learn the leverageable difference between fake videos and benign ones from multiple serialized frames. Furthermore, to address the information loss in compressed videos, the data enhancement technique is introduced in data preprocessing to collect sufficient training samples from public datasets, e.g., FaceForensics++, DeepFakeDetection and DFDC. The experiments demonstrated that our method has good performance and generalization ability in the task of Deepfake videos detection.",Deepfakes;deep learning;ResNext;3D-ResNext;WS-DAN,IEE
443,Securing Phygital Gameplay: Strategies for Video-Replay Spoofing Detection,V. D. Husz�r; V. K. Adhikarla,2024,"Physical Virtual Sports (PVS) utilize digital technologies for the analysis and evaluation of sports performances. This research article addresses the challenge of detecting video-replay spoofing in PVS, with a specific focus on a digital football sport aimed at assessing and improving a player�s football juggling skills. In the context of the growing presence of digital coaches as well as PVS, accurate assessment of player performance and identification of deceptive practices in these applications are paramount. The proliferation of sophisticated technologies, such as deepfake algorithms and computer vision techniques, has facilitated the manipulation of video replays, deceiving both viewers and officials. To tackle the challenges associated with video-replay spoofing, this article introduces a meticulously curated dataset comprising 600 players engaged in the digital football sport. Additionally, the dataset includes video-replay spoofing videos captured on a wide range of display devices. A deep learning-based model is developed and trained on this dataset, achieving an accuracy rate of approximately 95%. Generalization studies were also conducted to assess the model�s ability to generalize to unseen scenarios and datasets. The ROC-AUC score highlighted the model�s discriminative power across different threshold values, validating its effectiveness in distinguishing between genuine and spoofed video replays. The results demonstrate that our trained model exhibited consistent performance across multiple public face biometric spoofing datasets, underscoring its robustness against sophisticated video-replay attacks in various domains. Additionally, ablation studies were carried out by systematically removing or modifying the model�s backbone architectures to analyze their effects on detection accuracy and reliability. Furthermore, computational complexity analysis was presented to evaluate the model�s efficiency in terms of time and space requirements. The findings underscore the scientific significance and relevance of video replay spoof detection in PVS. By presenting a novel dataset (https://www.fiteq.org/research) and employing an advanced deep learning approach, this article contributes to the scientific community�s understanding and progress in combating fraudulent practices, ultimately preserving the integrity and fairness of digital sports applications.",Active virtual sports;computer vision;dataset;deepfake detection;deep learning;deceptive practices;digital sports applications;fraudulent practices;integrity;video-replay spoofing,IEE
444,Anti-Counterfeit Handwritten Signature via DCGAN with SGPD Network,Hendry; D. H. F. Manongga; Y. Nataliani; T. Wellem,2021,"In recent years, the growth of machine learning makes the computer can learn many things by using artificial intelligence. One method that is feared nowadays is the computer's capability to imitate something. This capability is called deep-fake. Deep-fake is the capability of the computer to imitate human characteristics such as voice, images, and video through artificial intelligence. Deep-fake is used to combine put the consisted image and video to another source of images and video using machine learning which is known as a generative adversarial network. With these capabilities, deep-fake is already used to make a counterfeit video, signature, voice signature, and much fake news. This paper is about to combine the capabilities of deep learning and the Generative Adversarial Network (GAN) to deal with detecting the fraud in the handwritten signature. We will focus on several types of ways to sign with the characters. The system will recommend if the hand signature of the user is fake or genuine. This is under the capabilities of GAN to synthesize the signature, it can make the computer automatically generate hand signature by using a machine. Many researchers called this capability is deep-fake. This research aims to learn the hand signature to do fraud detection. We propose an architecture to build the anti-counterfeiting hand signature which is utilized deep learning with a self-growing probabilistic method.",Deep Learning;Deep-Fake;Generative Adversarial Network;Self-Growing Probabilistic Method,IEE
445,"A Survey on the Detection and Impacts of Deepfakes in Visual, Audio, and Textual Formats",R. Mubarak; T. Alsboui; O. Alshaikh; I. Inuwa-Dutse; S. Khan; S. Parkinson,2023,"In the rapidly evolving digital landscape, the generation of fake visual, audio, and textual content poses a significant threat to the trust of society, political stability, and integrity of information. The generation process has been enhanced and simplified using Artificial Intelligence techniques, which have been termed deepfake. Although significant attention has been paid to visual and audio deepfakes, there is also a burgeoning need to consider text-based deepfakes. Due to advancements in natural language processing and large language models, the potential of manipulating textual content to reshape online discourse and misinformation has increased. This study comprehensively examines the multifaceted nature and impacts of deep-fake-generated media. This work explains the broad implications of deepfakes in social, political, economic, and technological domains. State-of-the-art detection methodologies for all types of deepfake are critically reviewed, highlighting the need for unified, real-time, adaptable, and generalised solutions. As the challenges posed by deepfakes intensify, this study underscores the importance of a holistic approach that integrates technical solutions with public awareness and legislative action. By providing a comprehensive overview and establishing a framework for future exploration, this study seeks to assist researchers, policymakers, and practitioners navigate the complexities of deepfake phenomena.",Deepfakes;visual;audio;text,IEE
446,Deep learning algorithm for digital image forensics,S. Verma; R. Chauhan; R. Rawat; Pratibha,2024,"The creative population uses easy ways of editing and generating data, which has become easy to share and edit all over the Internet. Therefore, it has become crucial to verify the authenticity and to use more innovative methods to avoid problems like copy paste and deepfake. There are a number of methods that can help people come out of these problems in a minute, like using deep learning techniques to analyze images practically. These techniques would help us to separate out the real and artificially generated contents, or abstracts. Nowadays, deep learning is the most technical and intellectual concept to overcome from deepfake. This survey demonstrates how deep learning can help distinguish between real and fraudulent images: Through this technique, it provides reliability for creating and evolving it. This method allows us to examine the advantages and disadvantages of the above model with respect to its limitations as well. Assuming this article represents all the awaited potential to give a correct direction to the development and innovation that helps others. It helps people and society in a way to input their problem, process it, and give a useful output. This comprehensive guide is made to support image forgery and its detection and to provide rigid boundary against proliferation of contents.",Image forgery;proliferation;deep learning;copying and moving;artificially generated;deepfake;authenticity,IEE
447,Machine learning approach to quick incident response,C. Nil?; I. Apostol; V. Patriciu,2020,"Tracking the evolution from the first DARPA set designed for IDS ML solutions, more than twenty years later, it can be noticed, that every time a new cybersecurity problem is discovered, unconsidered by previous solutions, a higher-level system is developed to solve it. Training on data specific to the defended system is more effective than training on publicly available datasets. This fact is arguable for the security solutions reviewed, but it is sure for solutions dedicated to incident response and forensics operations. This paper's objective is to design a machine learning-based schema for triage solutions used in quick incident response. More precisely, we evaluated the applicability of machine learning techniques for classifying unknown web access logs.",machine learning;incident response;cybersecurity,IEE
448,Audio Deepfakes: Feature Extraction and Model Evaluation for Detection,R. K. Bhukya; A. Raj; D. N. Raja,2024,"Cutting-edge AI-driven tools are currently employed for replicating human voices, leading to the emergence of audio deepfakes. Initially designed to enhance experiences like audio-books, the potential misuse of audio deepfakes poses significant risks to public safety. Despite advancements in detecting video deepfakes, identifying audio deepfakes remains challenging. We employ methods to extract features such as Mel-frequency cepstral coefficients, chromagrams, spectral contrast, tonnetz, and Mel-spectrograms from audio samples. The extracted deep features are concatenated together and then employed in machine learning and deep learning models to evaluate the ASVspoof2021 dataset to categorize it into bonafide and spoofed speech utterances. The experimental results reveal that the multilayer perceptron model achieves the highest accuracy rate of 96.073%, while SVM, k-NN, XGBoost, and RF produce accuracy rates of 93.58%, 94.58%, 93.544%, and 93.58%, respectively. Additionally, DL models, including CNN, achieve an accuracy rate of 98.2%, DNN of 97.6%, and LSTM of 97.7%, showcasing the superiority of CNN in identifying deepfake audio amidst the evolving landscape of synthetic media.",Deepfake;MFCCs;ML;DL;LSTM,IEE
449,AI in Cybersecurity,M. Corbett; S. Sajal,2023,"Huge strides have been made recently in AI-generated media. Writing, videos, audio, and images are being created, bearing more and more resemblance to work created by humans. There is still a way to go, but the Turing Test may be passed trivially if things continue at the current rate. AI's continued development will cause a litany of new innovations and security issues. This research details the impact of this development so far and the impending changes soon to come. The objective of the research is to evaluate the ability of implementations of AI to either bypass or reinforce preexisting security measures. This is exploratory research that will focus on qualitative research. AI has already had a lot of impact on implementing new security measures. AI leads to new levels of data analysis and detecting unusual behavior across an entire network, which can rapidly increase security response times. There will also be more proactive AI that attempts to locate security vulnerabilities so that they can be secured. However, there are several new threats from AI. Attacks that use AI to mimic a voice ideally mean phishing attacks will increase complexity and begin training algorithms. When AI can simulate realistic conversation all on its own, this will lead to many growing security risks. AI will also become a new target for threats, for which entirely new security features must be generated.",AI;Security;Machine Learning;Development,IEE
450,Enhancing Deepfake Detection With Diversified Self-Blending Images and Residuals,Q. Liu; Z. Xue; H. Liu; J. Liu,2024,"The advancement of deep forgery technology has significantly impacted the credibility of media content, making the detection of deep forgeries crucial for ensuring media security. Although research on deepfake detection methods has been progressively advancing, current approaches predominantly rely on detecting and identifying artifacts. As deep forgery technology continually improves, high-quality synthetic images and those produced through reconstruction methods have become increasingly sophisticated, rendering artifact and trace detection methods somewhat limited. To address this issue, we introduce a deep forgery detection method that integrates deep neural networks with fine-grained artifact features. Our proposed method simulates diverse facial synthesis data by employing facial color conversion, facial frequency domain conversion, and facial mask deformation and blurring. This trains the deepfake detection model to adapt to various synthesis techniques. The classifier model is trained using multiple perturbations of authentic images, with fine-grained artifact features ensuring the stability of the detection process. Our approach achieves superior accuracy and AUC values on the FF++ and WildDeepfake datasets, demonstrating its effectiveness and adaptability in detecting deep forgeries.",Deep learning;deepfake;synthetic data;image forensics,IEE
451,MeDiFakeD: Medical Deepfake Detection using Convolutional Reservoir Networks,R. Budhiraja; M. Kumar; M. K. Das; A. S. Bafila; S. Singh,2022,"Generation of photo-realistic fake content using Artificial Intelligence (AI)-based Generative Adversarial Networks has not only engulfed media, facial recognition or social networks, but is now rapidly surging ahead in the realm of medical imaging and is further facilitated by worldwide Covid-19 outbreak. Medical Deepfake pertains to application of AI-triggered deepfake technology on to medical modalities like Computed Tomography (CT) scan, X-Ray, Ultrasound etc. Owing to its high degree of privacy and sensitivity, any threats originating from exposed vulnerabilities, or, attacks on patients medical imagery takes an extremely threatening stance, either devastating the patients remaining lifespan, or resulting in grave financial frauds while satiating corrupt business motives. These tampering attacks, involve either insertion or removal of certain disease conditions, tumors in/from the modality under analysis. This paper implements and demonstrates a practical, lightweight technique which aims to accelerate deepfake detection for biomedical imagery by detecting malignant tumors injected in modalities of healthy patients. The developed technique makes use of convolutional reservoir networks (CoRN), which enable ensemble feature extraction and results in improved classification metrics. We further corroborate its effectiveness while working with a miniscule (< 100) set of images and illustrate the extent of generalization attained with different forms of the same medical imagery.",Medical Image Tampering;Medical Deepfake Detection;Convolutional Reservoir Network;Convolution Neural Networks;Reservoir Computing;Computed Tomography,IEE
452,Joint Physical-Digital Facial Attack Detection Via Simulating Spoofing Clues,X. He; D. Liang; S. Yang; Z. Hao; H. Ma; B. Mao; X. Li; Y. Wang; P. Yan; A. Liu,2024,"Face recognition systems are frequently subjected to a variety of physical and digital attacks of different types. Previous methods have achieved satisfactory performance in scenarios that address physical attacks and digital attacks, respectively. However, few methods are considered to integrate a model that simultaneously addresses both physical and digital attacks, implying the necessity to develop and maintain multiple models. To jointly detect physical and digital attacks within a single model, we propose an innovative approach that can adapt to any network architecture. Our approach mainly contains two types of data augmentation, which we call Simulated Physical Spoofing Clues augmentation (SPSC) and Simulated Digital Spoofing Clues augmentation (SDSC). SPSC and SDSC augment live samples into simulated attack samples by simulating spoofing clues of physical and digital attacks, respectively, which significantly improve the capability of the model to detect ""unseen"" attack types. Extensive experiments show that SPSC and SDSC can achieve state-of-the-art generalization in Protocols 2.1 and 2.2 of the UniAttackData dataset, respectively. Our method won first place in ""Unified Physical-Digital Face Attack Detection"" of the 5th Face Anti-spoofing Challenge@CVPR2024. Our final submission obtains 3.75% APCER, 0.93% BPCER, and 2.34% ACER, respectively. Our code is available at https://github.com/Xianhua-He/cvpr2024-face-anti-spoofing-challenge.",,IEE
453,Fairness Evaluation in Deepfake Detection Models using Metamorphic Testing,M. Pu; M. Y. Kuan; N. T. Lim; C. Y. Chong; M. K. Lim,2022,"Fairness of deepfake detectors in the presence of anomalies are not well investigated, especially if those anomalies are more prominent in either male or female subjects. The primary motivation for this work is to evaluate how deepfake detection model behaves under such anomalies. However, due to the black-box nature of deep learning (DL) and artificial intelligence (AI) systems, it is hard to predict the performance of a model when the input data is modified. Crucially, if this defect is not addressed properly, it will adversely affect the fairness of the model and result in discrimination of certain sub-population unintentionally. Therefore, the objective of this work is to adopt metamorphic testing to examine the reliability of the selected deepfake detection model, and how the transformation of input variation places influence on the output. We have chosen MesoInception-4, a state-of-the-art deepfake detection model, as the target model and makeup as the anomalies. Makeups are applied through utilizing the Dlib library to obtain the 68 facial landmarks prior to filling in the RGB values. Metamorphic relations are derived based on the notion that realistic perturbations of the input images, such as makeup, involving eyeliners, eye shadows, blushes, and lipsticks (which are common cosmetic appearance) applied to male and female images, should not alter the output of the model by a huge margin. Furthermore, we narrow down the scope to focus on revealing potential gender biases in DL and AI systems. Specifically, we are interested to examine whether MesoInception-4 model produces unfair decisions, which should be considered as a consequence of robustness issues. The findings from our work have the potential to pave the way for new research directions in the quality assurance and fairness in DL and AI systems.",Metamorphic testing;fairness testing;robustness testing;oracle problem,IEE
454,Tensor-Based Deepfake Detection in Scaled and Compressed Images,S. Concas; G. Perelli; G. L. Marcialis; G. Puglisi,2022,"When deepfakes are widespread on chatting platforms, they are expected to be subject to heavy resizing and compressing steps. In this paper, we present a tensor-based representation of compressed and resized images. Tensor embeds DCT features computed on multi-scaled and multi-compressed versions of the input facial image. Moreover, a custom deep-architecture is designed and trained on the proposed representation. Experimental results show its pros and cons with respect to state-of-the-art methods.",Deepfake;face;biometric,IEE
455,Deepfake Detection Using EfficientNet and XceptionNet,B. Yasser; J. Hani; S. El-Gayar; O. Amgad; N. Ahmed; H. M. Ebied; H. Amr; M. Salah,2023,"The increasing prevalence of manipulated media, particularly deepfake videos, poses significant challenges in distinguishing real from fake content. This paper addresses the issue of detecting deepfake videos using advanced CNN architectures such as EfficientNet-B4 and XceptionNet. The FF++ and Celeb-DF (v2) datasets are used to compare real and fake videos. The methodology involves preprocessing the Celeb- DF dataset by extracting frames and isolating faces, training the models, and evaluating their performance using log loss and Area Under the Curve (AUC) metrics. The study shows that both models are effective in accurately classifying real and fake videos and highlights the importance of continuously updating deepfake detection algorithms in response to evolving deepfake generation techniques.",Deepfake Detection;Extracting Frames;cropping faces;accuracy;XceptionNet;EfficientNet,IEE
456,A Study on Combating Emerging Threat of Deepfake Weaponization,R. Katarya; A. Lal,2020,"A breakthrough in the emerging use of machine learning and deep learning is the concept of autoencoders and GAN (Generative Adversarial Networks), architectures that can generate believable synthetic content called deepfakes. The threat lies when these low-tech doctored images, videos, and audios blur the line between fake and genuine content and are used as weapons to cause damage to an unprecedented degree. This paper presents a survey of the underlying technology of deepfakes and methods proposed for their detection. Based on a detailed study of all the proposed models of detection, this paper presents SSTNet as the best model to date, that uses spatial, temporal, and steganalysis for detection. The threat posed by document and signature forgery, which is yet to be explored by researchers, has also been highlighted in this paper. This paper concludes with the discussion of research directions in this field and the development of more robust techniques to deal with the increasing threats surrounding deepfake technology.",Deep Learning;Generative Adversarial Networks;autoencoders;Deepfake detection;Fake image;Fake Video,IEE
457,Human vs. Automatic Detection of Deepfake Videos Over Noisy Channels,S. S. Prasad; O. Hadar; T. Vu; I. Polian,2022,"Identification of DeepFake video content is a challenging scientific problem that addresses a growing societal concern. We investigate the relationship between DeepFake detection by humans and by automatic methods based on state-of-the-art deep learning algorithms. The main novelty of our work is the consideration of videos that are transmitted through noisy channels and arrive with distortions. This reflects many practical environments, including surveillance based on cameras connected via noisy wireless links and videoconferencing in driving vehicles. We conduct a user study with 192 probands who classify real (genuine) and DeepFake videos with and without various classes of distortions. We find that today's deep neural networks (DNNs) outperform humans by far, whereas humans are heavily distracted by random noise from the channel. Moreover, DNNs are robust under distortions, achieving perfect classification on distorted data even when trained on distortion-free content. It appears that the human visual system and DNNs are approaching the DeepFake classification problem quite differently and their respective strengths and weaknesses are largely uncorrelated.",DeepFake Detection;Deep Learning;Noisy Channels,IEE
458,Enhancing Deepfake Detection using SE Block Attention with CNN,S. Dasgupta; J. Mason; X. Yuan; O. Odeyomi; K. Roy,2024,"In the digital age, Deepfake present a formidable challenge by using advanced artificial intelligence to create highly convincing manipulated content, undermining information authenticity and security. These sophisticated fabrications surpass traditional detection methods in complexity and realism. To address this issue, we aim to harness cutting-edge deep learning methodologies to engineer an innovative deepfake detection model. However, most of the models designed for deepfake detection are large, causing heavy storage and mem-ory consumption. In this research, we propose a lightweight convolution neural network (CNN) with squeeze and excitation block attention (SE) for Deepfake detection. The SE block module is designed to perform dynamic channel-wise feature recalibration. The SE block allows the network to emphasize informative features and suppress less useful ones, which leads to a more efficient and effective learning module. This module is integrated with a simple sequential model to perform Deepfake detection. The model is smaller in size and it achieves competing accuracy with the existing models for deepfake detection tasks. The model achieved an overall classification accuracy of 94.14% and AVC-ROC score of 0.985 on the Style GAN dataset from the Diverse Fake Face Dataset. Our proposed approach presents a promising avenue for combating the Deepfake challenge with minimal computational resources, developing efficient and scalable solutions for digital content verification.",SE Block;CNN;Deepfake Detection;Entire Face Synthesis,IEE
459,Comparative Analysis of Deepfake Video Detection Using Inception Net and Efficient Net,G. R. E; M. E; G. K. C; T. Bellam; B. P; K. Rengaraju,2022,"Human beings have the most distinctive feature that is human face. We can exchange somebody faces with anybody else's faces that appear realistic because many have another type of algo is based upon deepfake tech. Deepfake videos / photos is revolutionary subdual of AI tech by using someones human face can overwrite of someones face. More generously, with many different methods based on productive pictures. Unwillingly the overuse of smartphone and organizing by multiple internet web using AI manipulated data is reaching quicker in something which can we see in the 20th century, global danger is made up by these products Deepfakes are digital manipulation techniques that use machine learning to produce misleading videos. Identification is most difficult part to find from the original. Previously, CNN networks were used to perform identify the deep fake verification. Due to the increasing popularity of deep fakes identification of real one is more important find ways to detect manipulated videos that are presented as real ones. In this project, we will study different methods that can be used to detect such images as well as videos. This study shows that they can also be done using a convolutional algorithm known as Efficient Net and Inception Net. In this Paper, we compare various versions of Convolutional Inception Net with various versions of convolutional Efficient Net combined with Vision Transformers and different Data files to obtain best possible results in Deepfake detection. To get the highly accurate percentage to identify the video is fake or real by using efficient net and by inception net. tract)",Deepfake;Inception net;Efficient net;CNN;Vision Transformers,IEE
460,AVFF: Audio-Visual Feature Fusion for Video Deepfake Detection,T. Oorloff; S. Koppisetti; N. Bonettini; D. Solanki; B. Colman; Y. Yacoob; A. Shahriyari; G. Bharaj,2024,"With the rapid growth in deepfake video content, we re-quire improved and generalizable methods to detect them. Most existing detection methods either use uni-modal cues or rely on supervised training to capture the dissonance be-tween the audio and visual modalities. While the former disregards the audio-visual correspondences entirely, the lat-ter predominantly focuses on discerning audio-visual cues within the training corpus, thereby potentially overlooking correspondences that can help detect unseen deepfakes. We present Audio- Visual Feature Fusion (AVFF), a two-stage cross-modal learning method that explicitly captures the correspondence between the audio and visual modalities for improved deepfake detection. The first stage pursues representation learning via self-supervision on real videos to capture the intrinsic audio-visual correspondences. To extract rich cross-modal representations, we use contrastive learning and autoencoding objectives, and introduce a novel audio-visual complementary masking and feature fusion strategy. The learned representations are tuned in the second stage, where deepfake classification is pursued via super-vised learning on both real and fake videos. Extensive exper-iments and analysis suggest that our novel representation learning paradigm is highly discriminative in nature. We report 98.6% accuracy and 99.1% AUC on the FakeAVCeleb dataset, outperforming the current audio-visual state-of-the-art by 14.9% and 9.9%, respectively.",video deepfake detection;representation learning;audio visual;multimodal,IEE
461,Deepfakes Audio Detection Techniques Using Deep Convolutional Neural Network,B. Kumar; S. R. Alraisi,2022,"This article will introduce and discuss a new tool for detecting AI-generated audio deepfake. The convolutional neural network (CNN), is a kind of black box to detect acoustic objects, is used to build the technique in deep learning. The proposed models could be used as trustable standard networks for audial categorization. XCeption is an abbreviation for �extreme inception,� It takes the principles of Inception to their logical conclusion. It is the deep convolutional neural network architecture composed of Depth Wise Separable Convolutions, which CNN employs for audio detection. To streamline the overall system and produce real-time results",Deepfake;Used algorithms;CNN;Analyzation;Deep learning,IEE
462,A Survey paper on Understanding the Rise of AI-driven Cyber Crime and Strategies for Proactive Digital Defenders,G. V. Sai Meghana; S. Saqlain Afroz; R. Gurindapalli; S. Katari; K. Swetha,2024,"As artificial intelligence (AI) continues to evolve, so too does its integration into cyber criminal activities, presenting a formidable challenge to digital security. These findings investigate the escalating nexus between AI and cybercrimes, highlighting the emergent dangers posed by AI-driven malicious activities. The study delves into the various ways in which AI technologies are leveraged by cyber criminals to orchestrate sophisticated attacks, incorporating, data breaches, malware propagation, phishing, and social engineering tactics. Furthermore, the methodologies propose proactive research strategies aimed at mitigating the threats posed by AI-facilitated cybercrimes through the lens of digital forensic techniques. By analyzing current trends in AI-driven cyber offenses and their repercussions on digital security frameworks, this research endeavors to elucidate the imperative for novel approaches in digital forensics. Such proactive strategies encompass the establishment of AI-powered forensic tools, the enhancement of detection and attribution methodologies, and the augmentation of cyber resilience through predictive analytics and preemptive measures. Through a comprehensive review of existing literature, case studies, and empirical data, paper analysis seeks to offer insights into the changing landscape of AI-facilitated cybercrimes and the critical importance of digital forensics in countering these threats. By Gaining a more comprehensive grasp of the combined effects or interactions between AI technologies and cyber criminality, this research endeavors to inform stakeholders in the realms of cybersecurity, law enforcement, and policy-making, thereby contributing to the progress or development in proactive measures aimed at safeguarding digital ecosystems against emerging threats.",Artificial Intelligence;Cyber Crime;Digital Security;Digital Forensic;Cyber Resilience;Law enforcement;AI-Driven vehicles;Deep- Fake technology;Human Safety,IEE
463,Trusted Data Anomaly Detection (TaDA) in Ground Truth Image Data,W. Boler; A. Dale; L. Christopher,2022,"Current state-of-the-art Artificial Intelligence (AI) anomaly detection from images is primarily used for defect detection and relies on relatively homogeneous datasets of images with similar foregrounds and backgrounds. This type of anomaly detection uses human labelled ground-truth data. In our research, we have extremely heterogeneous datasets and want to identify outliers. We use self-supervised Variational Autoencoders (VAEs) to identify anomalies in the latent vector feature space. Understanding the outliers in a large training data set is important for establishing trustworthiness of the AI models learned from these data, a strong requirement for military AI applications. Our study uses 8984 examples from Kaggle military planes and 4300 examples from Kaggle landscape data. We present the results of the combined heterogeneous dataset on the localized methods, with one such result exhibiting inliers as landscapes/backgrounds and outliers as all aircraft, detecting aircraft as anomalies with a 0.87 AUC. Results also include the inter-class AUC across the different aircraft classes. Our contribution to the state-of-the-art is to apply isolation forests to the latent space data after UMAP embeddings in a strongly heterogeneous image dataset for military applications to identify anomalies.",Trusted AI;Unsupervised Anomaly Detection;VAE;UMAP;Isolation Forest,IEE
464,3D Attention Network for Face Forgery Detection,Z. Ma; X. Mei; J. Shen,2023,"With the rapid development of face forgery techniques, a large number of face synthesis videos are widely spread on the Internet, which threatens the security and trustworthiness of digital content online. It is necessary to develop face forgery detection methods. Many existing methods use only 2D CNNs to detect video frames. There are few 3D networks designed for face forgery detection. In this work, we propose to use 3D CNN for video-level face forgery detection and add a lightweight attention module to construct a 3D attention network. The network extracts both spatial and temporal features. The attention maps generated by the attention module focus on several forged regions of the fake face. To avoid the discrepancy of different regions affecting the detection results, a global attention pool is designed to replace the global average pool. The experiments implemented on FaceForensics++ show that our model achieves great accuracy and exceeds most existing methods. Cross-dataset evaluation implemented on Celeb-DF verifies that our model has strong transferability and generalization ability.",Face forgery detection;DeepFake detection;Face forgery;Digital video forensics;3D convolutional neural network,IEE
465,DeepFake Detection by Analyzing Convolutional Traces,L. Guarnera; O. Giudice; S. Battiato,2020,"The Deepfake phenomenon has become very popular nowadays thanks to the possibility to create incredibly realistic images using deep learning tools, based mainly on ad-hoc Generative Adversarial Networks (GAN). In this work we focus on the analysis of Deepfakes of human faces with the objective of creating a new detection method able to detect a forensics trace hidden in images: a sort of fingerprint left in the image generation process. The proposed technique, by means of an Expectation Maximization (EM) algorithm, extracts a set of local features specifically addressed to model the underlying convolutional generative process. Ad-hoc validation has been employed through experimental tests with naive classifiers on five different architectures (GDWCT, STARGAN, ATTGAN, STYLEGAN, STYLEGAN2) against the CELEBA dataset as ground-truth for non-fakes. Results demonstrated the effectiveness of the technique in distinguishing the different architectures and the corresponding generation process.",,IEE
466,Deepfake Detection using Multi-path CNN and Convolutional Attention Mechanism,R. B. P.; M. S. Nair,2022,"Image and video forgery using cutting-edge deep learning techniques has become one of the major issues in the social networking era. Media manipulation in which one person�s face is swapped out for another�s or has additional features added is referred to as deepfakes. Despite the fact that it has many beneficial purposes, fraudsters generally utilise it to create celebrity porn, revenge porn, and fake news, among other things. One of the biggest risks that deepfake presents is that people�s belief in the reality of many things may decline. The motivation behind deepfake detection is the need to prove that the real thing is real and the fake thing is fake. In this paper a multi-CNN approach for detecting deepfakes is being proposed. Here, a multipath convolutional neural network (CNN) with three modules is used, each of which is stacked with a convolutional block attention mechanism. The first two modules in the dual-path paradigm are a Resnet module and a Densenet module. The Resnet component enables for feature reuse while Densenet allows for the investigation of new features. The parallel InceptionResnet module contains a one-dimensional feature reduction module with residual connections. When the performance of the proposed model is compared with that of four deep learning based approaches, it is found that the proposed method gave the best outcomes, with an accuracy and F1-score of 0.940 and 0.939, respectively.",deepfake detection;deep learning;feature extraction;attention mechanism;classifier,IEE
467,Using the Swin-Transformer for Real & Fake Data Recognition in PC-Model,J. Park,2024,"Recently, due to the rapid development of generative AI technologies, the use of AI-generated images has increased significantly, making the distinction between real and fake images crucial. Generative images may be used in various ways such as data training and fast image generation, but a potential for misuse, such as in Deep fake or spreading false information, still exists. This study explores a novel model using the architecture ofSwin-Transformer to distinguish between fake and real images generated based on CNN (Convolutional Neural Networks) and GAN (Generative Adversarial Networks). The Swin-Transformer, a successor model of Vision in Transformer (ViT), applies the structure of the Transformer, which has shown outstanding performance in natural language processing, to the field of images and demonstrates excellent pixel-level segmentation performance. Real and fake images require detailed pixel-level analysis, in which the Swin-Transformer exhibits higher accuracy. Improving the performance of distinguishing between real and fake images is expected to set limits on indiscreet image generation, bringing further effects such as preventing the indiscriminate use of AI images through program-based discrimination/legal sanctions.",Artificial Intelligence;Convolution Neural Network;Generative Adversarial Network;Real&Fake,IEE
468,Unmasking DeepFake Visual Content with Generative AI,M. Roy; M. S. Raval,2023,"Recent advances in deep learning-based generative models have increased the proliferation of fake media, which has caused severe unrest globally. These generative models can create ultra-realistic images and videos that are almost impossible to differentiate from traditional image and video processing techniques. As a result, there has been a considerable demand for effective fake multimedia detection methods. This paper provides an in-depth review of different approaches to deepfake to understand and exploit counterfeit media content. The available learning techniques for creating and detecting forensic setups have been investigated in this paper as the authenticity and integrity of multimedia content play a significant role in decision-making or providing verdicts. Ultimately, we point out various futuristic technologies that can rejuvenate research to design a full-proof deepfake ecosystem.",Computer vision;deep learning;detection;fake news;generative AI,IEE
469,Deepfake Face Provenance for Proactive Forensics,J. Ai; Z. Wang; B. Huang; Z. Han; Q. Zou,2023,"Malicious deepfake face not only violates the privacy of personal identities, but also confuses the public and causes huge social harm. The current deepfake detection only stays at the level of distinguishing between true and false, but cannot trace the original genuine face corresponding to the fake face, that is, it does not have the ability to trace the source of evidence. The deepfake countermeasure technology for judicial forensics urgently calls for deepfake inversion. This paper pioneers an interesting question about face deepfake, active forensics that ""know what it is and how it happened"". Given that deepfake faces do not completely discard the features of original faces, especially facial expressions and poses, we argue that original faces can be approximately speculated from their deepfake counterparts. Correspondingly, we design a disentangling reversing network that decouples latent space features of deepfake faces under the supervision of real-fake face pair samples to infer original faces in reverse.",Deepfake;Deepfake Inversion;Disentangling Network;Inverse Mapping,IEE
470,"Deepfake Detection in Media Files - Audios, Images and Videos",B. F. Nasar; S. T; E. R. Lason,2020,"Recent advancement in deep learning has applied to solve various complex problems ranging from big data analytic to computer vision and human-level control. One among them is the deepfake technology which becomes a real threat to privacy, democracy, and national security. Deepfake is hyper-realistic digitally manipulated videos to depict people saying and doing things that never actually happened. This technology has been used in many fields in film industries for recreating videos without re-shooting, awareness video generation such as creating voices of those who have lost theirs or updating episodes of movies without re-shooting them at very low cost. This technology has many harmful usages in social media, pornographic sites, etc. to deface peoples which largely dominate the positive side of this application of deep learning. Also, the creation and spreading of these videos are increasing rapidly along all fields of media files. Therefore, it is very much important to develop efficient tools that can automatically detect the deepfake in these videos and thus reduce the public harm caused by such videos. In the early stages of deepfake detection, traditional technologies like signal processing, image processing, lip-syncing, etc were used but this provides very little accuracy when combined with the recent technologies of deep learning. So, here a system is proposed that can automatically detect the deepfake in media files such as images, videos, and audios. This uses an image processing approaches combined with deep learning which detects the inconsistency that exists in fake media.",GAN;CNN;LSTM,IEE
471,Unsupervised Learning-Based Framework for Deepfake Video Detection,L. Zhang; T. Qiao; M. Xu; N. Zheng; S. Xie,2023,"With the continuous development of computer hardware equipment and deep learning technology, it is easier for people to swap faces in videos by currently-emerging multimedia tampering tools, such as the most popular deepfake. It would bring a series of new threats of security. Although many forensic researches have focused on this new type of manipulation and achieved high detection accuracy, most of which are based on supervised learning mechanism with requiring a large number of labeled samples for training. In this paper, we first develop a novel unsupervised detection manner for identifying deepfake videos. The main fundamental behind our proposed method is that the face region in the real video is taken by the camera while its counterpart in the deepfake video is usually generated by the computer; the provenance of two videos is totally different. Specifically, our method includes two clustering stages based on Photo-Response Non-Uniformity (PRNU) and noiseprint feature. Firstly, the PRNU fingerprint of each video frame is extracted, which is used to cluster the full-size identical source video (regardless of its real or fake). Secondly, we extract the noiseprint from the face region of the video, which is used to identify (re-cluster for the task of binary classification) the deepfake sample in each cluster. Numerical experiments verify our proposed unsupervised method performs very well on our own dataset and the benchmark FF++ dataset. More importantly, its performance rivals that of the supervised-based state-of-the-art detectors.",Deepfake detection;unsupervised learning;video clustering;PRNU;noiseprint,IEE
472,Improved Generalizability of Deep-Fakes Detection using Transfer Learning Based CNN Framework,P. Ranjan; S. Patil; F. Kazi,2020,"Deep-Fakes are emerging as a significant threat to society, with potential to become weapons of mass disinformation and chaos. Simple tools provide ways to produce such digital forgeries at a large scale which makes it crucial to develop counter-attacking approaches for detection of these Deep-Learning based manipulations. This work analyzes a Transfer Learning based Convolutional Neural Network framework for the task of Deep-Fake Detection on three of the latest released datasets � DeepFakeDetection (DFD), Celeb-DF, and DeepFakeDetectionChallenge (DFDC) Preview. Additionally, a custom dataset of high-quality Deep-Fakes is compiled and used for evaluation of models. The intuition behind Transfer Learning for Deep-Fakes Detection is explored using the Explainable-AI technique of visualizing intermediate activations to provide interpretability. The critical problem of dataset shift and its effect on domain adaptation is explored by comparing cross-dataset test accuracies, with and without the usage of Transfer Learning. The results of this work indicate that even though Deep-Fake Detection is a highly domain specific task, there is a significant improvement in performance in terms of both single-domain classification accuracy and generalizability by utilizing Transfer Learning.",deep-fakes;digital forgeries;manipulation detection;convolutional neural network;transfer learning;generalizability;dataset shift;domain adaptation,IEE
473,"Content-based fake news detection using deep learning techniques: Analysis, challenges and possible solutions",S. Hangloo; B. Arora,2022,"Since the past decade, social media platforms are used widely for sharing information which may or may not be credible. Due to this many incidents have occurred that show how false news can have detrimental effect on the people and hence it becomes imperative to check the credibility of online news articles. Platforms like Facebook and Twitter have also taken multiple initiatives in past years to check the spread of misleading content on their platforms. Researchers have been continuously working on providing solutions to tackle the issue of fake news and its implications. This paper focuses on the Content-Based Fake News Detection (FND) which deploys text-based and visual-based approaches. In the past few years, a more sophisticated approach i.e the Multimodal approach is being used that combines the features of textual and visual data. This paper highlights various techniques for content-based FND using Deep Learning (DL) approach. These deep learning models and frameworks have been analyzed in detail and the results depict that there is a considerable improvement in the overall performance when the multimodal methods are used. Also, various techniques that might help for improving the efficiency of the FND frameworks are also included as future directions. This paper also presents numerous challenges that a researcher may encounter while modelling a FND framework and provides probable solution that might be applicable to overcome these challenges.",Fake news detection;Deep Fake;Image tempering;Content-based;Multimodal;Deep learning,IEE
474,The Threat of Deep Fake Technology to Trusted Identity Management,A. Ali; Y. K. Jadoon; Z. Farid; M. Ahmad; N. Abidi; H. M. Alzoubi; A. A. Alzoubi,2022,"With the rapid development of artificial intelligence technology, deepfake technology based on deep learning is receiving more and more attention from society or the industry. While enriching people's cultural and entertainment life, in-depth fakes technology has also caused many social problems, especially potential risks to managing network credible identities. With the continuous advancement of deep fakes technology, the security threats and trust crisis caused by it will become more serious. It is urgent to take adequate measures to curb the abuse risk of deep fakes. The article first introduces the principles and characteristics of deep fakes technology and then deeply analyzes its severe challenges to network trusted identity management. Finally, it researches the supervision and technical level and puts forward targeted preventive countermeasures.",Artificial intelligence;deep fakes;forgery;network trusted identity management,IEE
475,"GenAI in the Cyber Kill Chain: A Comprehensive Review of Risks, Threat Operative Strategies and Adaptive Defense Approaches",A. S. Deshpande; S. Gupta,2023,"Generative artificial intelligence (GAI) has become an effective instrument capable of creating realistic content on its own in a variety of fields. GAI's growing adoption raises concerns about potential misuse for cyber threats, such as creating, convincing, phishing emails, producing deep fake videos and distributing false information through posts that appear to be genuine on social media. This is accurate even though its potential uses in data synthesis, virtual assistants, content development and the creative arts are exciting. These difficulties appeal for a careful analysis of GAI's place in cybersecurity (CS). This paper offers a comprehensive analysis of the possible threats connected to the offensive GAI technique used in the Cyber Kill Chain (CKC) framework. In addition, our proposal includes defense tactics that leverage GAI capabilities. These strategies include the areas of detection, deception and adversarial training, with the aim of reducing the potential risks associated with cyber threats induced by GAI. Threat actors employ the use of GAI to augment Evasion, obfuscation and deception techniques, hence increasing the effectiveness and difficulty of detecting their attacks. This study highlights the importance of using proactive defense measures. The dual capability of GAI for legal and illegal usage highlights the need to comprehend and mitigate its influence inside the CKC framework. To combat the evolving gamut of GAI-induced cyber threats, organizations should employ attack-aware and adaptable GAI-enabled defense strategies.",Generative artificial intelligence (GAI);Cyber Security (CS);Cyber Kill Chain (CKC);Security,IEE
476,Utilizing Data Augmentation Methods to Generalize DeepFake Classifier,J. G. Pho; C. A. Gouw; H. Lucky; D. Suhartono,2024,"DeepFakes are fabricated audiovisual media. As technology advances, the tools for making DeepFakes have increased. Due to this, making DeepFakes are more accessible to a lot of people. As a result, some people use it irresponsibly such as hoaxes and scams. To combat this, a reliable DeepFake detector is needed. EfficientNet-B0has been used and has the highest success rate in detecting DeepFakes. Moreover, utilizing dynamic face cutout has only been proven to increase the accuracy rate of detecting DeepFakes. Because of this, we decide to implement EfficientNet-B0and face augmentation with the hopes of having a reliable DeepFake detection model. For comparison, three experiments using three different models were done. The three models include EfficientNet-B0 with Multi-task Cascaded Convo-lutional Networks (MTCNN), EfficientNet-B0 with MTCNN and Face-CutOut, and EfficientNet-B0 with MTCNN and a common data augmentation method. The experiments showed that The EfficientNet-B0and MTCNN model yielded the best results, reaching above the 90% mark on the Accuracy, AUC-ROC, and Fl-Score. When face augmentation was implemented, the results faced a slight decrease of around 1% on the Accuracy, AUC-ROC, and Fl-Score compared to the model using only EfficientNet-B0 and MTCNN. However, the EfficientNet-B0 and MTCNN model implemented with Face-Cutout has the best AUC-ROC score, above the model using only EfficientNet-B0 and MTCNN, which has a score of 97.82%. The results demonstrate that data augmentation is effective in enhancing model generalization.",EfficientNet-B0 DeepFake classifier;Multi-task Cascaded Convolutional Networks (MTCNN);Face-Cutout Data augmentation,IEE
477,Investigating Fake News Detection by Means of Deep Learning on a Limited Data Set,O. Ngada; B. Haskins,2022,"Advancements in web technologies have fostered an environment where information is easily distributed in a cost-effective manner, with organizations of varying sizes enjoying the same benefits in the online world. These advantages posed by web technologies have aided in the continuous rise and spread of fake news. The problem of misinformation dissemination is complex for several reasons, including differing opinions on what is perceived as fake news, the variety of data sets and the different languages and structures used in online news articles. Machine learning and deep learning technologies have shown great promise in the identification of fake news articles. This work demonstrates the feasibility of constructing deep learning neural network models, with the ability to yield highly accurate results, using a smaller data set and limited computing resources.",Fake news;Machine learning;Deep learning,IEE
478,Motion Magnified 3-D Residual-in-Dense Network for DeepFake Detection,A. Mehra; A. Agarwal; M. Vatsa; R. Singh,2023,"Driven by the advances in deep learning, highly photo-realistic techniques capable of switching the identity and expression of faces have emerged. Cheap access to computing has brought such technology within the reach of anyone with a computer and Internet including people with sinister motives. To detect these forgeries, we present a novel compression resilient approach for deepfake detection in videos. The proposed approach employs motion magnification as a pre-processing step to amplify temporal inconsistencies common in forged videos. Utilizing these processed videos, we propose the 3D Residual-in-Dense ConvNet, which captures low level spatiotemporal features, which help classify a video as pristine or forged. The proposed method yields more than 93% average detection accuracy on the high compression variant of the FaceForensics++ dataset and achieves state-of-the-art performance on multiple benchmarks across the FaceForensics++ and CelebDF datasets. Further, we study the behavior of deepfake detection algorithms across ethnicities and demonstrate how the proposed method reduces the inherent bias against minority ethnicities prevalent in existing algorithms.",Deepfake;motion magnification;security;face recognition,IEE
479,Compliance Challenges in Forensic Image Analysis Under the Artificial Intelligence Act,B. Lorch; N. Scheler; C. Riess,2022,"In many applications of forensic image analysis, state-of-the-art results are nowadays achieved with machine learning methods. However, concerns about their reliability and opacity raise the question whether such methods can be used in criminal investigations. So far, this question of legal compliance has hardly been discussed, also because legal regulations for machine learning methods were not defined explicitly. To this end, the European Commission recently proposed the artificial intelligence (AI) act, a regulatory framework for the trustworthy use of AI. Under the draft AI act, high-risk AI systems for use in law enforcement are permitted but subject to compliance with mandatory requirements. In this paper, we review why the use of machine learning in forensic image analysis is classified as high-risk. We then summarize the mandatory requirements for high-risk AI systems and discuss these requirements in light of two forensic applications, license plate recognition and deep fake detection. The goal of this paper is to raise awareness of the upcoming legal requirements and to point out avenues for future research.",forensic image analysis;artificial intelligence act,IEE
480,DeepFake-o-meter v2.0: An Open Platform for DeepFake Detection,Y. Ju; C. Sun; S. Jia; S. Hou; Z. Si; S. K. Datta; L. Ke; R. Zhou; A. Nikolich; S. Lyu,2024,"Deepfakes, as AI-generated media, have increasingly threatened media integrity and personal privacy with realistic yet fake digital content. This work introduces an open-source and user-friendly online platform, DeepFake-O-Meter v2.0, that integrates state-of-the-art methods for detecting DeepFake images, videos, and audio. Built upon DeepFake-O-Meter v1.0, we have significantly upgraded and improved the platform architecture design, including user interaction, detector integration, job balancing, and security management. The platform aims to offer everyday users a convenient service for analyzing DeepFake media using multiple state-of-the-art detection algorithms. It ensures secure and private delivery of the analysis results. Furthermore, it serves as an evaluation and benchmanrking platform for researchers in digital media forensics to compare the performance of multiple algorithms on the same input. We have also conducted a detailed usage analysis based on the collected data to gain deeper insights into our platform's statistics. This involves analyzing four-month trends in user activity and evaluating the processing efficiency of each detector.",,IEE
481,Detecting Manipulated Audio Using Adaboost Machine Learning Algorithm,B. V. Kumar; Y. Ayyappa; P. J. Sai; T. Varun; S. N. Babu; Y. U. S. S. Teja,2024,"The proliferation of deepfake audio necessitates robust detection methods. This work explores the efficacy of Mel- Frequency Cepstral Coefficients (MFCC) features and AdaBoost for deepfake audio identification. This proposed a pipeline involving extraction of MFCC features from segmented audio, followed by training an AdaBoost classifier on a labelled dataset of genuine and deepfake audio samples. The classifier leverages the discriminative power of MFCC features and AdaBoost ensemble learning capabilities to distinguish between authentic and manipulated audio. Among the advantages of this method are its ability to capture speech traits, strong resistance to noise and low computational requirements compared with certain deep learning methods. The recognition in this study is that we must keep updating models continuously and training them with various data sets as long as ever-changing tactics applied by creators of deepfakes continue to be an issue. Additionally, consider other audio functions which can be incorporated into it as well as hybrid methods where deep learning techniques would also be used. They have raised points about ethics concerning these technologies for detecting fake videos and call for their responsible development and use. With a research background, the proposed model described in this paper has achieved 92% accuracy rate; being better than any other models discussed here. In general terms then, what has been done here shows us just how much potential there could be behind MFCC features together with AdaBoost technique when it comes down detecting fake audios but still needs some adjustments here and there so that we apply them responsibly.",Mel-Frequency Cepstral Coefficients;AdaBoost Ensemble Learning;Deepfake Audio Detection;Lower Computational Demands,IEE
482,Implementation of Deep Learning Method for Forgery Detection on Social Media,A. Kohapare; K. Dhongade; R. Sukare; P. Maidamwar,2024,"In recent years, the surge in misinformation and rapid technological advancements has significantly increased the prevalence of media manipulation. The advent of AI-altered videos and sophisticated news content poses a serious threat to media integrity, particularly as these manipulations proliferate on social media platforms, creating challenges in discerning authenticity. The accessibility and user-friendliness of deepfake technology have compounded the issue, making the distinction between genuine and fabricated content increasingly challenging. This presents substantial risks, ranging from the dissemination of false information to fostering a general sense of scepticism toward online visuals. This research aims to comprehensively analyze the process of creating deepfakes and assess their broader societal impact, while also proposing potential solutions to mitigate this problem. The methodology employed has achieved accuracy of 87% that involves utilizing ResN ext, a CNN architecture with LS TM, to analyse fake videos, and error level analysis followed by CNN algorithm to analyse fake images, this research outlines the specific steps and procedures involved in this analytical process.",Convolutional Neural Network;Deepfake Detection;Erroe Level Analysis;ResNext,IEE
483,Adversarial Machine Learning for Social Good: Reframing the Adversary as an Ally,S. Al-Maliki; A. Qayyum; H. Ali; M. Abdallah; J. Qadir; D. T. Hoang; D. Niyato; A. Al-Fuqaha,2024,"Deep neural networks (DNNs) have been the driving force behind many of the recent advances in machine learning. However, research has shown that DNNs are vulnerable to adversarial examples�input samples that have been perturbed to force DNN-based models to make errors. As a result, adversarial machine learning (AdvML) has gained a lot of attention, and researchers have investigated these vulnerabilities in various settings and modalities. In addition, DNNs have also been found to incorporate embedded bias and often produce unexplainable predictions, which can result in antisocial AI applications. The emergence of new AI technologies that leverage large language models (LLMs), such as ChatGPT and GPT-4, increases the risk of producing antisocial applications at scale. AdvML for social good (AdvML4G) is an emerging field that repurposes the AdvML bug to invent prosocial applications. Regulators, practitioners, and researchers should collaborate to encourage the development of prosocial applications and hinder the development of antisocial ones. In this work, we provide the first comprehensive review of the emerging field of AdvML4G. This paper encompasses a taxonomy that highlights the emergence of AdvML4G, a discussion of the differences and similarities between AdvML4G and AdvML, a taxonomy covering social good-related concepts and aspects, an exploration of the motivations behind the emergence of AdvML4G at the intersection of ML4G and AdvML, and an extensive summary of the works that utilize AdvML4G as an auxiliary tool for innovating prosocial applications. Finally, we elaborate upon various challenges and open research issues that require significant attention from the research community.",Adversarial machine learning (AdvML);AI for good;human-centered computing;ML for social good;socially good applications,IEE
484,MD-CSDNetwork: Multi-Domain Cross Stitched Network for Deepfake Detection,A. Agarwal; A. Agarwal; S. Sinha; M. Vatsa; R. Singh,2021,"The rapid progress in the ease of creating and spreading ultra-realistic media over social platforms calls for an urgent need to develop a generalizable deepfake detection technique. It has been observed that current deepfake generation methods leave discriminative artifacts in the frequency spectrum of fake images and videos. Inspired by this observation, in this paper, we present a novel approach, termed as MD-CSDNetwork, for combining the features in the spatial and frequency domains to extract a shared discriminative representation for classifying deepfakes. MD-CSDNetwork is a novel cross-stitched network with two parallel branches carrying spatial and frequency information, respectively. We hypothesize that these multi-domain input data streams can be considered as related supervisory signals and can ensure better performance and generalization. Further, the concept of cross-stitch connections is utilized where they are inserted between the two branches to learn an optimal combination of domain-specific and shared representations from other domains automatically. Extensive experiments are conducted on the popular benchmark datasets. We report improvements over all the manipulation types in the FaceForensics++ dataset and comparable results with state-of-the-art methods for cross-database evaluation on the Celeb-DF dataset and the Deepfake Detection Dataset.",,IEE
485,DeepFake on Face and Expression Swap: A Review,S. Waseem; S. A. R. S. Abu Bakar; B. A. Ahmed; Z. Omar; T. A. E. Eisa; M. E. E. Dalam,2023,"Remarkable advances have been made in deep learning, leading to the emergence of highly realistic AI-generated videos known as deepfakes. Deepfakes use generative models to manipulate facial features to create modified identities or expressions with impressive realism. These synthetic media creations can deceive, discredit, or blackmail individuals and threaten the integrity of the legal, political, and social systems. Consequently, researchers are actively developing techniques to detect deepfake content to preserve privacy and combat the dissemination of fabricated media. This article presents a comprehensive study examining existing methods of creating deepfake images and videos for face and expression replacement. In addition, it provides an overview of publicly available deepfake datasets for benchmarking, serving as important resources for training and evaluating deepfake detection systems. In addition, the study sheds light on the detection approaches used to identify deepfake face and expression swaps while discussing the challenges and issues involved. However, the focus of this study goes beyond identifying the existing barriers. It goes a step further by outlining future research directions and guiding future scientists to address the concerns that need to be addressed in deepfake detection methods. In this way, this paper aims to facilitate the development of robust and effective deepfake detection solutions for face and expression swaps, thereby contributing to ongoing efforts to protect the authenticity and trustworthiness of visual media.",Deepfake;deep learning;face manipulation;face swap;re-enactment;media forensic;generative adversarial networks,IEE
486,Autonomous Detection and Evaluation of Deepfakes: A Comprehensive Study,R. Sunil; P. Mer; A. Diwan,2023,"In recent times, there has been a notable advancement in deepfake techniques and the accessibility of extensive, cost-free databases. Consequently, even folks lacking technological expertise can now edit or produce visually authentic samples for various goals, both benign and harmful in nature. This paper provides a comprehensive analysis of the classification of methods used for deepfake generation and detection. The paper considers numerous factors, including the identified forgery, methodology or techniques used, evaluation metrics used for performance analysis, and the utilized dataset. By studying the development of deepfakes and the most up-to-date deepfake detecting methods, this study gives a full picture of deepfake techniques and makes it easier to come up with new, more reliable methods to fight the growing difficulty of deepfakes.",Deepfakes;CNN;Artifacts;Face Swap;Facial Reenactment;Synthetic Media;GANs;Deepfake Detection,IEE
487,Preserving Integrity: A Binary Classification Approach to Unmasking Artificially Generated Voices in the Age of Deepkakes,V. Kumar; A. Kapoor; R. R. Chaudhary; L. Gupta; D. Khokhar,2024,"Generative AI uses machine learning techniques like semi-supervised or unsupervised learning algorithms for the creation of digital content such as images, audio, and videos. There are ethical concerns arising from generative AI�s impact on speech technology, specifically, voice cloning and real-time voice conversion. To mitigate the associated risks of privacy breaches and misrepresentation, the research utilizes a DEEP-VOICE dataset that comprises audio clips from eight notable figures, converted using Retrieval-based Voice Conversion to detect Deepfake audio files. Framed as a binary classification problem, statistical analysis reveals significantly different distributions of temporal audio features between real and AI-generated speech. The experimental results show that the Random Forest Classifier over the 5-fold Cross-Validation technique results in a classification accuracy of 98.574%.",Artificial Intelligence;Machine Learning;Binary Classification;Deepfake;Audio Detection,IEE
488,Data Augmentation for Convolutional Neural Network DeepFake Image Detection,A. Jellali; I. B. Fredj; K. Ouni,2023,"We need to develop a technique for better identifying deepfakes because they can distort our perception of reality. This study offers a brand-new forensic technique for spotting falsified facial photos. We made advantage of the Kaggle- provided �real-and - fake- facial-detection� dataset. We are able to distinguish between probable facial alterations based on CNN's design. Thanks to data augmentation approaches, the results exhibit performances that are equivalent to those of previous works. The proposed approach fared better for this binary categorization into fake or real faces than the other cutting-edge studies. Our accuracy is close to 99 percent.",CNN;Deepfakes Detection;Deep Learning;Data Augmentation;Faces Manipulations,IEE
489,Spoofprint: A New Paradigm for Spoofing Attacks Detection,T. Chen; E. Khoury,2021,"With the development of voice spoofing techniques, voice spoofing attacks have become one of the main threats to automatic speaker verification (ASV) systems. Traditionally, researchers tend to treat this problem as a binary classification task. A binary classifier is typically trained using machine learning (including deep learning) algorithms to determine whether a given audio clip is bonafide or spoofed. This approach is effective on detecting spoofing attacks that are generated by known voice spoofing techniques. However, in practical scenarios, new types of spoofing technologies are emerging rapidly. It is impossible to include all types of spoofing technologies into the training dataset, and thus it is desired that the detection system can generalize to unseen spoofing techniques. In this paper, we propose a new paradigm for spoofing attacks detection called Spoofprint. Instead of using a binary classifier to detect spoofed audio, Spoofprint uses a paradigm similar to ASV systems and involves an enrollment phase and a verification phase. We evaluate the performance on the original and noisy versions of ASVspoof 2019 logical access (LA) dataset. The results show that the proposed Spoofprint paradigm is effective on detecting unknown type of attacks and is often superior to the latest state-of-the-art.",spoofing attack detection;deepfake detection;countermeasure;ASVspoof 2019,IEE
490,In-The-Wild Deepfake Detection using Adaptable CNN Models with Visual Class Activation Mapping for Improved Accuracy,M. S. Saealal; M. Z. Ibrahim; M. I. Shapiai; N. Fadilah,2023,"Deepfake technology has become increasingly sophisticated in recent years, making detecting fake images and videos challenging. This paper investigates the performance of adaptable convolutional neural network (CNN) models for detecting Deepfakes. In-the-wild OpenForensics dataset was used to evaluate four different CNN models (DenseNet121, ResNet18, SqueezeNet, and VGG11) at different batch sizes and with various performance metrics. Results show that the adapted VGG11 model with a batch size of 32 achieved the highest accuracy of 94.46% in detecting Deepfakes, outperforming the other models, with DenseNet121 as the second-best performer achieving an accuracy of 93.89% with the same batch size. Grad-CAM techniques are utilized to visualize the decision-making process within the models, aiding in understanding the Deepfake classification process. These findings provide valuable insights into the performance of different deep learning models and can guide the selection of an appropriate model for a specific application.",deepfake;deep learning;convolution neural network;batch size;Grad-CAM visualization,IEE
491,Detecting Deep-Fake Videos from Phoneme-Viseme Mismatches,S. Agarwal; H. Farid; O. Fried; M. Agrawala,2020,"Recent advances in machine learning and computer graphics have made it easier to convincingly manipulate video and audio. These so-called deep-fake videos range from complete full-face synthesis and replacement (face-swap), to complete mouth and audio synthesis and replacement (lip-sync), and partial word-based audio and mouth synthesis and replacement. Detection of deep fakes with only a small spatial and temporal manipulation is particularly challenging. We describe a technique to detect such manipulated videos by exploiting the fact that the dynamics of the mouth shape - visemes - are occasionally inconsistent with a spoken phoneme. We focus on the visemes associated with words having the sound M (mama), B (baba), or P (papa) in which the mouth must completely close in order to pronounce these phonemes. We observe that this is not the case in many deep-fake videos. Such phoneme-viseme mismatches can, therefore, be used to detect even spatially small and temporally localized manipulations. We demonstrate the efficacy and robustness of this approach to detect different types of deep-fake videos, including in-the-wild deep fakes.",,IEE
492,An Approach of Fake Videos Detection Based on Haar Cascades and Convolutional Neural Network,A. Jellali; I. Ben Fredj; K. Ouni,2023,"Because deep fakes might skew our impression of the truth, we need to come up with a method for better spotting them. This paper proposes a new forensic technique to detect manipulated facial images from videos. It is based on CNNs architecture that can distinguish possible face manipulations in the �real-and-fake-face-detection� dataset offered by Kaggle. The results obtained highlight comparable performances with the state-of-the-art methods. It showed an accuracy of approximately 99 % for this binary classification into fake or real faces. Then to validate this model we added a human face detection technique using the Haar Cascade method to this model in order to detect the manipulated videos from Deep Fake Detection Challenge (DFDC) dataset and we achieve an accuracy of 91 correct predictions out of 100 total videos.",CNN;Deepfakes Detection;Deep Learning;Haar-Cascade;Data Augmentation;Faces Manipulations;Fake and real videos,IEE
493,"AI powered attacks against AI powered protection: classification, scenarios and risk analysis",O. Veprytska; V. Kharchenko,2022,"The research focuses on the detection, classification, and analysis of artificial intelligence (AI)-based threats/attacks on various types of systems. AI is analyzed as an object of protection (OP), a means of attack (MA) and a means of protection (MP). Duel chain and set of scenarios for triad �MA-MP-OP� considering application AI was developed. As part of the IMECA analysis, the threats, vulnerabilities, effects and criticality (probability x severity) of the attacks are determined. The criticality matrixes of cyber risks of systems (initial, after implementing countermeasures with and without AI means) were built. The possibilities and efficiency of using AI to prevent some mentioned attacks.",Artificial intelligent;AI powered attacks;AI based pron;scenarios;IMECA analysis;countermeasures,IEE
494,SWYNT: Swin Y-Net Transformers for Deepfake Detection,F. Khalid; M. H. Akbar; S. Gul,2023,"Nowadays, less technical individuals can create false videos by only source and target images, using deepfakes generation tools and methodologies. Distributing false information on social media and other concerns related to the deepfakes have thus significantly increased. To deal with the challenges posed by incorrect details, efficient Deepfakes detection algorithms must be developed considering the tremendous advancement in deepfakes generating techniques. Existing techniques are not reliable enough to find deepfakes, especially when the videos are made with various deepfakes generation methods. The Swin Y-Net Transformers (SWYNT) architecture we created in this paper can visually discriminate between natural and artificial faces. The architecture uses a Swin transformer, encoder, and decoder in a U -Net architecture with a classification branch to build a model that can classify and segment deepfakes. The segmentation process creates segmentation masks and helps train the classifier. We have evaluated our suggested method using the extensive, standard, and diverse FaceForensics++ (FF++) and the Celeb-DF dataset. The generalizability evaluation of our process, which is part of the performance evaluation, reveals the model's promising performance in identifying deepfakes videos generated using various methodologies on both large-scale datasets.",Celeb-DF;Deepfake;Deepfake Detection;FaceForensics++;Swin Transformer;Swim Y-Net;U-Net,IEE
495,New Advances in Remote Heart Rate Estimation and Its Application to DeepFake Detection,Y. Xu; R. Zhang; C. Yang; Y. Zhang; Z. Yang; J. Liu,2021,"Estimation and monitoring of heart rate is an important indicator of a person�s physiological and psychological status. With breakthroughs in sensing, real-time signal processing and machine learning technologies, heart rate measurement techniques based on video analysis have been derived, remote photo plethysmography (rPPG), a technique that captures periodic changes in skin color caused by the heartbeat cycle through sensors such as cameras. Heart rate measurement based on rPPG has attracted widespread attention in recent years, especially with the growing maturity of deep learning-based methods and the improved accuracy of the algorithms, as well as the ability to better cope with the adverse effects of lighting changes and motion artifacts on the measurement, which has made possible the applications of rPPG in more fields, and a prominent emerging application is DeepFake videos detection based on rPPG technology. In this paper, we will introduce the principle, the recent progress of rPPG algorithms, and the applications of rPPG in the field of DeepFake detection.",remote photo plethysmography;DeepFake detection;heart rate estimation,IEE
496,Attending Generalizability in Course of Deep Fake Detection by Exploring Multi-task Learning,P. Balaji; A. Das; S. Das; A. Dantcheva,2023,"This work explores various ways of exploring multi-task learning (MTL) techniques aimed at classifying videos as original or manipulated in cross-manipulation scenario to attend generalizability in deep fake scenario. The dataset used in our evaluation is FaceForensics++, which features 1000 original videos manipulated by four different techniques, with a total of 5000 videos. We conduct extensive experiments on multi-task learning and contrastive techniques, which are well studied in literature for their generalization benefits. It can be concluded that the proposed detection model is quite generalized, i.e., accurately detects manipulation methods not encountered during training as compared to the state-of-the-art.",,IEE
497,Investigating the Impact of Visual Attention Models in Face Forgery Detection,A. Yadav; D. K. Vishwakarma,2023,"With the recent rise of realistic face manipulation methods, building robust face tampering detection methods has become more important than ever before. Visual attention has played an important role in highlighting discriminative regions within input which is important for making accurate predictions. This manuscript presents a comparative study of several recently proposed visual attention models for the problem of face forgery detection. Specifically, five visual attention models namely, coordinate, selective kernel, triplet, CoT, and shuffle attention have been tested by integrating with a baseline deep learning model. The modified visually attentive architectures are trained and tested on popular public benchmark dataset FaceForensics++. The experimental results achieved by different attention approaches are compared. Additionally, the computational costs involved in each type of attention have also been discussed specifying the accuracy and computation tradeoff. Experimental results prove that Triplet Attention performs best by achieving accuracy scores of 0.9543 and 0.7190 on DF and NT categories of the FF++ dataset. Triplet attention is also extremely lightweight with only 1200 trainable parameters compared to the other attention modules under study.",Visual attention;Face forgery;Face tampering;deepfake;attention;detection,IEE
498,Eff-YNet: A Dual Task Network for DeepFake Detection and Segmentation,E. Tjon; M. Moh; T. -S. Moh,2021,"Advances in generative models and manipulation techniques have given rise to digitally altered videos known as deepfakes. These videos are difficult to identify for both humans and machines. Modern detection methods exploit various weaknesses in deepfake videos, such as visual artifacts and inconsistent posing. In this paper, we describe a novel architecture called Eff-YNet designed to detect visual differences between altered and unaltered areas. The architecture combines an EfficientNet encoder and a U-Net with a classification branch into a model capable of both classifying and segmenting deepfake videos. The task of segmentation helps train the classifier and also produces useful segmentation masks. We also implement ResNet 3D to detect spatiotemporal inconsistencies. To test these models, we run experiments against the Deepfake Detection Challenge dataset and show improvements over baseline classification models. Furthermore, we find that an ensemble of these two approaches improves performance over a single approach alone.",Deepfake detection;computer vision;deep learning;image segmentation;image classification;U-Net,IEE
499,Deepfake: An Endanger to Cyber Security,K. N. Sudhakar; M. B. Shanthi,2023,"�Deepfake� got originated from the technology �deep learning� working behind it and the type of information it generates �fake� after manipulating the original information. It�s an AI-based innovation used to make counterfeit recordings and sound that look and sound genuine. The inventions and implication of digital technologies in all spheres of mankind, has posed a great challenge to mankind to come up with secure solutions against a digital problem called Deepfake resulting from the application of deep learning thereby compromising authentication or originality. The said technology creates digital images and videos all new and totally fake. But the consequence it creates on society is totally a negative impact. With the aid of AI in developing hyper realistic videos, Deepfake has extended its giant wings to harm societal health and resulting in a critical challenge against the authenticity of the source. The Internet has become the platform to deliver these Deepfakes to unlimited destinations within no time. There are lot many researches have been carried on how to detect this deep fakes. Most of the research works have used deep learning models like Convolution Neural Network (CNN) for analyzing the convolution traces in deepfakes. Some of the research works have used Recurrent Neural Networks (RNN) by combining the Long Short-Term Memory (LSTM) with Blockchain. This research study has presented the comprehensive literature study, which highlights the various approaches used in generation and detection of deepfakes.",Deepfake;Deep Learning;AI;Authenticity;Counter Techniques Algorithm;Digital Era,IEE
500,Audio Deepfake Approaches,O. A. Shaaban; R. Yildirim; A. A. Alguttar,2023,"This paper presents a review of techniques involved in the creation and detection of audio deepfakes, the first section provides information about general deep fakes. In the second section, the main methods for audio deepfakes are outlined and subsequently compared. The results discuss various methods for detecting audio deepfakes, including analyzing statistical properties, examining media consistency, and utilizing machine learning and deep learning algorithms. Major methods used to detect fake audio in these studies included Support Vector Machines (SVMs), Decision Trees (DTs), Convolutional Neural Networks (CNNs), Siamese CNNs, Deep Neural Networks (DNNs), and a combination of CNNs and Recurrent Neural Networks (RNNs). The accuracy of these methods varied, with the highest accuracy being 99% for SVM and the lowest being 73.33% for DT. The Equal Error Rate (EER) was reported in a few of the studies, with the lowest being 2% for Deep-Sonar and the highest being 12.24 for DNN-HLLs. The t-DCF was also reported in some of the studies, with the Siamese CNN performing the best with a 55% improvement in min-t-DCF and EER compared to other methods.",Deepfakes;artificial intelligence;deep learning;audio deepfakes;forensics;datasets;survey,IEE
501,Securing Voice Biometrics: One-Shot Learning Approach for Audio Deepfake Detection,A. Khan; K. M. Malik,2023,"The Automatic Speaker Verification (ASV) system is vulnerable to fraudulent activities using audio deepfakes, also known as logical-access voice spoofing attacks. These deepfakes pose a concerning threat to voice biometrics due to recent advancements in generative AI and speech synthesis technologies. While several deep learning models for speech synthesis detection have been developed, most of them show poor generalizability, especially when the attacks have different statistical distributions from the ones seen. Therefore, this paper presents Quick-SpoofNet, an approach for detecting both seen and unseen synthetic attacks in the ASV system using one-shot learning and metric learning techniques. By using the effective spectral feature set, the proposed method extracts compact and representative temporal embeddings from the voice samples and utilizes metric learning and triplet loss to assess the similarity index and distinguish different embeddings. The system effectively clusters similar speech embeddings, classifying bona fide speeches as the target class and identifying other clusters as spoofing attacks. The proposed system is evaluated using the ASVspoof 2019 logical access (LA) dataset and tested against unseen deepfake attacks from the ASVspoof 2021 dataset. Additionally, its generalization ability towards unseen bona fide speech is assessed using speech data from the VSDC dataset.",Voice Bio-metrics;Spoofing Detection;Speech Synthesis;Deepfake Detection;One shot learning,IEE
502,Detection of DeepFake Videos Using Computer Vision and Deep Learning,A. Rahman; F. Rahman; T. Labib; E. I. Uschash; S. J. Chowdhury Adiba; D. Z. Karim,2023,"DeepFakes are one of the most alarming concepts in this era of Metaverse and technological advancement. DeepFakes are artificially-generated manipulated photos or videos using Deep learning, Generated Adversarial Network (GAN), autoencoder-decoder pairing structure etc. There are several other Deepfaking tools such as; FaceSwap, DeepFace-Lab, DFaker, DeepFake-tensorflow etc. DeepFakes can become concerning if it is used for political purpose, committing fraud, spreading misinformation, pornography, defamation on social media etc. As a result, it is obvious that DeepFakes can be very distressing on the wrong hand if not detected properly. To address this issue, our research aims to develop effective methods for DeepFake video detection, focusing on deep learning approaches, and computer vision techniques. We deployed a dataset consisting of both real and fake videos, obtained from DeepFake Detection Challenge (DFDC) and FaceForensics++. To detect the fake videos, we followed the method of employing temporal feature and exploring visual artifacts within frames. Employing temporal feature uses LSTM and CNN whereas visual artifacts within frames mostly employs deep learning method to detect DeepFakes. We ensembled LSTM and CNN to detect DeepFakes successfully. ResNeXt101_32x8d have been used to extract features and a custom CNN model is added with LSTM for better accuracy for detecting DeepFake. Our ensemble model, which combines LSTM and CNN, successfully detects Deepfakes with an accuracy of 94.05%. Through further improvements and the implementation of learning rate schedulers, such as CosineAnnealingLR, CyclicLR, MultiStepLR, and ReduceLRonPlateau, we achieved even higher accuracy. Among these schedulers, MultiStepLR demonstrated the highest accuracy of 95.33%.",DeepFake;CNN;LSTM;LR Scheduler,IEE
503,Deepfake Detection From Face-swapped Videos Using Transfer Learning Approach,M. T. Hasan Fuad; F. Bin Amin; S. M. Masudul Ahsan,2023,"Deepfakes are synthetic media created using artificial intelligence and machine learning techniques. Deepfakes are produced by employing a generative model to alter photos, videos, or sounds and then producing a new piece of media that mimics the original. With improvements in AI technology and the availability of significant computer resources, deepfake production has become increasingly feasible. Although there are many potential uses for deepfakes in the domains of entertainment, art, and research, they also present significant ethical and security issues. Deepfakes have the potential to influence people and spread false information, which could have detrimental effects on both the individual and the larger society. To stop malicious exploitation, it's crucial to create methods for spotting deepfakes and to control their use. This paper focuses on proposing a model for detecting deepfake videos with higher accuracy on a created dataset and the existing state-of-the-art dataset. A transfer learning based model has been proposed for deepfake detection. Wide ResNet and CNN have been implemented in the proposed model. The proposed model has been tested on both the created dataset of 121 videos and 3762 videos from Deepfake Detection Challenge dataset and achieved 83.47% and 82.4% accuracy respectively which is better than other pretrained models. High computational requirement has been one of the major challenges of this work.",Deepfake;synthetic facial image;transfer learning;deep learning;detection,IEE
504,Quality-based Artifact Modeling for Facial Deepfake Detection in Videos,S. Concas; S. M. La Cava; R. Casula; G. Orr�; G. Puglisi; G. L. Marcialis,2024,"Facial deepfakes are becoming more and more realistic, to the point that it is often difficult for humans to distinguish between a fake and a real video. However, it is acknowledged that deepfakes contain artifacts at different levels; we hypothesize a connection between manipulations and visible or non-visible artifacts, especially where the subject�s movements are difficult to reproduce in detail. Accordingly, our approach relies on different quality measures, No-Reference (NR) and Full-Reference (FR), over the detected faces in the video. The measurements allow us to adopt a frame-by-frame approach to build an effective matrix-based representation of a video sequence. We show that the results obtained by this basic feature set for a neural network architecture constitute the first step that encourages the empowerment of this representation, aimed to extend our investigation to further deepfake classes. The FaceForensics++ dataset is chosen for experiments, which allows the evaluation of the proposed approach over different deepfake generation algorithms.",Deepfakes;deepfake detection;quality;quality measures;face patches,IEE
505,Deepfake audio detection with vision transformer based method,G. Ulutas; G. Tahaoglu; B. Ustubioglu,2023,"In addition to easy access to audio on the Internet, developments in deep learning methods have made it possible to produce deep fake audio. Deep fake audio spoofing is carried out with the aim of producing audio files in the content by cloning the voice of the speaker that is planned to be changed as if he said something he did not say. This forgery method, created using artificial intelligence approaches, poses a great threat, especially to speaker verification systems. This study proposes a new method to detect whether the audio is spoofed or original. Spectrogram images are obtained with the Constant-Q Transform approach then they are classified with the vision transformer network. The system is trained with a public dataset named ASVSpoof 2019 and the comparative performance analysis is done on this dataset.",audio forensics;audio copy-move forgery;vision transformer;Constant-Q Transform,IEE
506,Evading Deepfake Detectors via High Quality Face Pre-Processing Methods,J. Kim; T. Kim; J. Kim; S. S. Woo,2022,"Today, various multimedia content can be accessed and shared from any location via the Internet. In addition to normal content, an extensive amount of manipulated multimedia can raise various social concerns. Among the various types of manipulated media, deepfakes can be abused in impersonation or spreading fake information. Therefore, numerous studies have been performed to detect deepfakes to alleviate these concerns, and studies such as FaceForensics++ (FF++) and DeepFake Detection Challenge (DFDC) have sparked these studies by providing deepfake datasets. The deepfake datasets were utilized for supervised learning in conjunction with developing sophisticated neural networks and showed a high detection performance. Since powerful neural networks can learn even subtle details about an image, they must be trained on realistic deepfakes created by advanced deepfake generation technologies to improve the robustness of existing detectors. In order to boost the performance of deepfake detection models, we propose an approach to creating more realistic deepfake images by removing ""detectable"" artifacts from existing deepfake datasets� images, including GAN-based images. By applying the proposed method to the original deepfake dataset, we demonstrate that our technique can significantly reduce the detection performance of existing deepfake detectors. Our experimental results show the vulnerability of deployed detectors and pave the way for further improvement.",,IEE
507,Smart Visage: A Face Recognition and Anti-Spoofing System,C. Mittal; S. Debnath; S. Prabakeran,2024,"As technology advances, the demand for reliable and robust security systems becomes increasingly important. In recent years, AI-based algorithms have been employed to address a wide range of previously intractable issues. One area of focus in security research is the development of anti-spoofing systems, which manifest in various forms such as identity theft and email spoofing. These systems aim to prevent or detect fraudulent attempts to deceive security measures by spoofing, referring to the act of impersonating someone or something to gain unauthorized access or deceive a system. In this research, deep learning is utilized to analyze facial images for face detection and the integration of anti-spoofing measures. For model training, a diverse dataset is curated, featuring various real and spoof faces with versatile features to ensure effective identification of differences. This approach is expected to significantly enhance the security of systems.",CNN;Feature extraction;Python;Deep Learning;Face Recognition,IEE
508,How Close Are Other Computer Vision Tasks to Deepfake Detection?,H. H. Nguyen; J. Yamagishi; I. Echizen,2023,"In this paper, we challenge the conventional belief that supervised ImageNet-trained backbones have strong generalizability and are suitable for use as feature extractors in deepfake detection models. We present a new measurement, �backbone separability,� for visually and quantitatively assessing a backbone�s raw capacity to separate data in an unsupervised manner. We also present a systematic benchmark for determining the correlation between deepfake detection and other computer vision tasks using backbones from pre-trained models. Our analysis shows that before fine-tuning, face recognition backbones are more closely related to deepfake detection than other backbones. Additionally, backbones trained using self-supervised methods are more effective in separating deepfakes than those trained using supervised methods. After fine-tuning all backbones on a small deepfake dataset, we found that self-supervised backbones deliver the best results, but there is a risk of overfitting. Our results provide valuable insights that should help researchers and practitioners develop more effective deepfake detection models.",,IEE
509,Deep Fake Image Classification Engine Using Inception-ResNet-V1 Network,K. D; S. S. Narayanan; M. I. M; A. Yekopalli; S. K. S,2024,"The goal of this project is to develop a real or fake facial image classification system using deep learning techniques. The main focus is on the InceptionResnetVl model pretrained on the VGGFace2 dataset and Kaggle DeepFake Classification Dataset for face classification. The application uses the facenet_pytorch library to perform face detection and preprocessing. Main features of the project include predicting the authenticity of a given facial image as either �real� or �fake�. This is achieved by implementing the InceptionResnetVl model, which is fine-tuned for binary classification with a single output representing the probability of authenticity. The system is designed to run on the GPU when available, enabling faster computing. Grad-CAM (gradient-weighted class activation mapping) technique is used to ensure the explainability of classification decisions. This method creates class activation maps that visually highlight the regions of the input image that influenced the classification decision. The Grad-CAM printout is then superimposed on the original facial image, creating an interpretable visualization of the model's decision-making process. The Gradio user interface is used for the interactive presentation of the project. Users can upload their face and get real vs. false predictions and visual explanations generated by the Grad-CAM algorithm. The user interface also displays a confidence score for each forecast, giving users an idea of how reliable the model is. In general, this project provides a comprehensive system to classify real and fake faces, and the proposed method reaches the accuracy of 97% both in training and testing.",Deep Learning;InceptionResnetVl;VGGFace2;Kaggle;Binary Classification;Face Detection;Grad-CAM;Gradio Interface,IEE
510,Potential of Speech-Pathological Features for Deepfake Speech Detection,A. Chaiwongyen; S. Duangpummet; J. Karnjana; W. Kongprawechnon; M. Unoki,2024,"There is a great concern regarding the misuse of deepfake speech technology to synthesize a real person�s voice. Therefore, developing speech-security systems capable of detecting deepfake speech remains paramount in safeguarding against such misuse. Although various speech features and methods have been proposed, their potential for distinguishing between genuine and deepfake speech remains unclear. Since speech-pathological features with deep learning are widely used to assess unnaturalness in disordered voices associated with voice-production mechanisms, we investigated the potential of eleven speech-pathological features for distinguishing between genuine and deepfake speech, i.e., jitter (three types), shimmer (four types), harmonics-to-noise ratio, cepstral-harmonics-to-noise ratio, normalized noise energy, and glottal-to-noise excitation ratio. This paper proposes a method of combining two models on the basis of two different dimensions of speech-pathological features to greatly improve the effectiveness of deepfake speech detection, along with mel-spectrogram features, to enhance detection efficiency. We evaluated the proposed method on the datasets of the Automatic Speaker Verification Spoofing and Countermeasures Challenges ASVspoof 2019 and 2021. The results indicate that the proposed method outperforms the baselines in terms of accuracy, recall, F1-score, and F2-score, achieving 95.06, 99.46, 97.30, and 98.59%, respectively, on the ASVspoof 2019 dataset. It also surpasses the baselines on the ASVspoof 2021 dataset in terms of recall, F1-score, F2-score, and equal error rate, achieving 99.96, 96.65, 98.18, and 15.97%, respectively.",Deepfake speech detection;speech-pathological feature;jitter and shimmer;glottal-to-noise;harmonics-to-noise ratio;cepstral-harmonics-to-noise ratio;normalized noise energy,IEE
511,Deepfake Face Detection Using Deep InceptionNet Learning Algorithm,P. Theerthagiri; G. b. Nagaladinne,2023,"Deepfakes is digital manipulation techniques that use deep learning to produce deepfake (misleading) images and videos. Identifying deepfake images is the most difficult part of finding the original. Due to the increasing reputation of deep fakes, identifying original images and videos is more crucial to detect manipulated videos. This paper studies and experiments with different methods that can be used to detect fake and real images and videos. The Convolutional Neural Network (CNN) algorithm named InceptionNet has been used to identify deep fakes. A comparative analysis was performed in this work based on various convolutional Networks. This work uses the dataset from Kaggle with 401 videos of train sample and 3745 images were generated by augmentation process. The results were evaluated with the metrics like accuracy and confusion matrix. The results of the proposed model produces better results in terms of accuracy with 93 % on identifying deep fake images and videos",Deepfake;Inception net;CNN(Convolutional Neural Network);Vision Transformers,IEE
512,Influence of Deepfake Terminology on Content-Emerging Threat Reduction,R. Tripathi; V. K. Mishra; V. Kumar; A. S. Sengar; N. K. Pandey; A. K. Mishra,2023,"A significant development in the rapidly expanding fields of Deep and machine Learning resulted in architectures that can create convincing synthetic content sometimes known as deepfakes. The danger arises when doctored photographs, films, and audios blur the distinction between fake and real content and are employed as weapons to inflict new levels of damage. This work analyzes the effectiveness of Big Data processing on operational parameters and focuses on data-dimensionality factors. It resolves big-data complications using DL and ML for decision-making mechanisms in the enterprise sectors and corporate sectors using in-depth analysis.",Deep Learning;Deep Neural Networks;Big-Data Analysis;Information Integrity,IEE
513,Swapping Face Images Based on Augmented Facial Landmarks and Its Detection,C. Sadu; P. K. Das,2020,"Facial landmark points that are precisely extracted from the face images improve the performance of many applications in the domains of computer vision and graphics. Face swapping is one of such applications. With the availability of sophisticated image editing tools and the use of deep learning models, it is easy to create swapped face images or face swap attacks in images or videos even for non-professionals. Face swapping transfers a face from a source to a destination image, while preserving photo realism. It has potential applications in computer games, privacy protection, etc. However, it could also be used for fraudulent purposes. In this paper, we propose an approach to create face swap attacks and detect them from the original images. The augmented 81-facial landmark points are extracted for creating the face swap attacks. The feature descriptors Weighted Local Magnitude Patterns (WLMP) and Support Vector Machines (SVM) are utilized for the swapped face images detection. The performance of the proposed approach is demonstrated by different types of SVM classifiers on a real-world dataset. Experimental results show that the proposed system effectively does face swapping and detection with an accuracy of 95%.",Face Landmark Points;Face Swap;Face Swap Attack Detection,IEE
514,Identification of Deepfakes using Strategic Models and Architectures,S. R. Nallapati; D. Dommeti; S. Medhalavalasa; K. K. Bonku; P. V. V. S. Srinivas; D. Bhattacharyya,2023,"Deepfake technology has been rapidly evolving and expanding in recent years. It has become increasingly easy to manipulate multimedia content, making it harder to detect what is real and what is manipulated. The research aims to explore how neural networks can be used to detect deepfake in multimedia, helping to protect users from potentially malicious and deceptive content. The aim is to explore what neural networks are, how they can be used to detect deepfakes and the potential implications of this technology. The research also aims to evaluate the advantages and disadvantages of using neural networks for deepfake detection. As the world of deepfake technology continues to evolve, this research will provide an overview of the latest developments in deepfake detection and their potential impact. The goal of this research is to use neural networks to detect deepfakes and to identify suspicious content to alert users. This could help protect users from being exposed to malicious content and help content producers ensure the integrity of their work. As deepfake technology continues to evolve, neural networks may become an essential tool for quickly and accurately detecting deepfakes in multimedia. The research explores topics like, CNN, 3D CNN, GATED RECURRENT UNIT and Architectures like Xception, VGG16, InceptionV3 and ResNet50V2. The outcomes are graphically represented and analyzed. the comparative stratification of the approach is done to analyze and detect deepfakes.",Deepfake Detection;Deep Learning;Convolutional Neural Network;Gated Recurrent Unit;Image Noise Patterns,IEE
515,Transfer Learning Strategies for Detecting Passive and GAN-Generated Image Forgeries with Pretrained Neural Networks,S. Kaman; A. Makandar,2024,"Image forgeries poses significant challenge in the area of digital forensics and security. Detecting forgeries created with more advanced image manipulation techniques especially those generated by Generative Adversarial Networks (GANs) has become critical task. Deep learning powered techniques appears to be most relevant in detecting digital forgeries. Hence, this study is an attempt to investigate the effectiveness of transfer learning using pretrained neural networks such as Alexnet, VGG16, Resnet50, InceptionV3, MobilenetV2 and EfficientNetB4 for detection of both passive and GAN-generated image forgeries. Experiments have been conducted on standard datasets like CASIA2.0 for passive forgeries and 140k real and fake faces for GAN-generated forgeries. Evaluated the efficacy of each pretrained model by considering the impact of fine-tuning and early stopping on overall detection performance. Performance analysis is done with the help of accuracy and loss curves as well as by considering precision, recall, f1 score and accuracy score values. Compared the model�s ability in detecting both passive and GAN-generated image forgeries.",Transfer learning;Image forgery Detection;Deep Learning;Passive forgery;Pretrained neural networks;GANs;Fine-tuning;Early stopping;Deepfake,IEE
516,On the Exploitation of DCT-Traces in the Generative-AI Domain,O. Pontorno; L. Guarnera; S. Battiato,2024,"Deepfakes represent one of the toughest challenges in the world of Cybersecurity and Digital Forensics, especially considering the high-quality results obtained with recent generative AI-based solutions. Almost all generative models leave unique traces in synthetic data that, if analyzed and identified in detail, can be exploited to improve the generalization limitations of existing deepfake detectors. In this paper we analyzed deepfake images in the frequency domain generated by both GAN and Diffusion Model engines, examining in detail the underlying statistical distribution of Discrete Cosine Transform (DCT) coefficients. Recognizing that not all coefficients contribute equally to image detection, we hypothesize the existence of a unique �discriminative fingerprint�, embedded in specific combinations of coefficients. To identify them, Machine Learning classifiers were trained on various combinations of coefficients. In addition, the Explainable AI (XAI) LIME algorithm was used to search for intrinsic discriminative combinations of coefficients. Finally, we performed a robustness test to analyze the persistence of traces by applying JPEG compression. The experimental results reveal the existence of traces left by the generative models that are more discriminative and persistent at JPEG attacks. Code and dataset are available at github/opontorno/dcts_analysis_deepfakes.",Synthetic Traces;Deepfakes;Multimedia Forensics,IEE
517,Coexistence of Deepfake Defenses: Addressing the Poisoning Challenge,J. Park; L. H. Park; H. E. Ahn; T. Kwon,2024,"As Generative Adversarial Networks advance, deepfakes have become increasingly realistic, thereby escalating societal, economic, and political threats. In confronting these heightened risks, the research community has identified two promising defensive strategies: proactive deepfake disruption and reactive deepfake detection. Typically, proactive and reactive defenses coexist, each addressing the shortcomings of the other. However, this paper brings to the fore a critical yet overlooked issue associated with the simultaneous deployment of these deepfake countermeasures. Genuine images gathered from the Internet, already imbued with disrupting perturbations, can lead to data poisoning in the training datasets of deepfake detection models, thereby severely affecting detection accuracy. We propose an improved training framework to address this problem in deepfake detection models. Our approach involves purifying the disrupting perturbations in disruptive images using a backward process of the denoising diffusion probabilistic model (DDPM). Images purified using our DDPM-based technique closely mimic the original, unperturbed images, thereby enabling the successful generation of deepfake images for training purposes. Moreover, our purification process outperforms DiffPure, a prominent adversarial purification method, in terms of speed. While conventional defensive techniques struggle to preserve detection accuracy in the face of a poisoned training dataset, our framework markedly reduces this accuracy drop, thus achieving superior performance across a range of detection models. Our experiments demonstrate that deepfake detection models trained using our framework exhibit an increase in detection accuracy ranging from 11.24%p to 45.72%p when compared to models trained with the DiffPure method. Our implementation is available at https://github.com/seclab-yonsei/Anti-disrupt.",Deepfake;deepfake detection;deepfake disruption;data poisoning;adversarial purification,IEE
518,CSE-ARS: Deep Learning-Based Late Fusion of Multimodal Information for Chat-Based Social Engineering Attack Recognition,N. Tsinganos; P. Fouliras; I. Mavridis; D. Gritzalis,2024,"With the increasing prevalence of chat-based social engineering (CSE) attacks targeting unsuspecting users, the need for robust defenses has never been more critical. In this paper, we introduce Chat-based Social Engineering Attack Recognition System (CSE-ARS), an innovative and effective CSE defense system. CSE-ARS employs a late fusion strategy that integrates the findings of five specialized deep learning models, each focused on detecting distinct CSE attack enablers: critical information leakage recognizer (CRINL-R), personality traits recognizer (PERST-R), dialogue acts recognizer (DIACT-R), persuasion recognizer (PERSU-R), persistence recognizer (PERSI-R). The system harnesses weighted linear aggregation and employs simulated annealing with 10-fold cross-validation, ensuring optimal model performance. CSE-ARS is trained on the CSE-ARS Corpus, a carefully curated dataset tailored to the intricacies of CSE attacks. Extensive evaluation reveals that CSE-ARS achieves satisfactory results in identifying and neutralizing CSE threats, enhancing user security in online interactions.",Corpus;cybersecurity;deep learning;natural language processing;social engineering,IEE
519,Deepfake detection for preventing Audio and Video frauds using Advanced Deep Learning Techniques,R. Bharadwaj; S. Ratnaparkhi; R. Rajpurohit; K. Rahate; R. Pandita; S. Thosar,2023,"Deepfakes, powered by generative adversarial networks (GANs), automate the creation of deceptive videos. To combat this menace, the study assembles an advanced model that fuses ResNeXt, Long Short-Term Memory (LSTM), and ResNet architectures, renowned for their efficacy in handling visual and temporal aspects, for the detection of deepfakes in audio and video content. Pre-processing, facilitated by a Multi-Task Cascaded-Convolutional Neural Network (MTCNN), accurately extracts facial regions. The model undergoes rigorous evaluation across three key datasets which are, FaceForensics++(FF-DF), Celeb-DF, and Facebook Deepfake Detection Challenge (DFDC), affirming its real-world readiness and exceptional accuracy. The combined models consistently deliver highly precise results, maintaining their robustness against evolving deepfake technologies.",Deepfakes;GANs;MTCNN;Facial region extraction;ResNeXt;LSTM;ResNet;FaceForensics++;Celeb-DF;DFDC,IEE
520,DeepfakeUCL: Deepfake Detection via Unsupervised Contrastive Learning,S. Fung; X. Lu; C. Zhang; C. -T. Li,2021,"Face deepfake detection has seen impressive results recently. Nearly all existing deep learning techniques for face deepfake detection are fully supervised and require labels during training. In this paper, we design a novel deepfake detection method via unsupervised contrastive learning. We first generate two different transformed versions of an image and feed them into two sequential sub-networks, i.e., an encoder and a projection head. The unsupervised training is achieved by maximizing the correspondence degree of the outputs of the projection head. To evaluate the detection performance of our unsupervised method, we further use the unsupervised features to train an efficient linear classification network. Extensive experiments show that our unsupervised learning method enables comparable detection performance to state-of-the-art supervised techniques, in both the intra- and inter-dataset settings. We also conduct ablation studies for our method.",,IEE
521,ConTrans-Detect: A Multi-Scale Convolution-Transformer Network for DeepFake Video Detection,W. Sun; Y. Ma; H. Zhang; R. Wang,2023,"With the recent advancement of generative deep learning technologies, DeepFakes are the outcome of the manipulation to generate synthetic images, such as swapping a person's face in a video with another face in another video. Nowadays, deep generative models make it easy to generate fake videos, which is hard to detect. Existing methods have utilized Convolutional Neural Networks (CNNs) to identify manipulated regions for DeepFake video detection. However, these methods might not entirely tackle the difficulties of learning low-level spatial features and capturing temporal variations in temporal information, which are crucial for face forgery detection. Therefore, we propose a Convolution-Transformer Deepfake Detection (ConTrans-Detect) model, comprising a multi-scale CNN module for spatial feature representation and a multi-branch Transformer for temporal feature modeling. The multi-scale CNN module uses 3D Inception block to extract multi-scale low-level features (e.g., edges, corners, and angles) from videos. The multi-branch Transformer module consists of multi-stream Transformer layers, each taking different temporal resolutions and spatial feature dimensions as input to perceive various motion variations. Our model achieves an AUC of 0.929 and 0.920 f1 score, surpassing several state-of-the-art performances on the DeepFake Detection Challenge Datasets (DFDC).",Convolutional neural network;Vision transformer;DeepFake video detection;Security;Privacy,IEE
522,A Survey of Deepfake Detection Methods,B. ?. Yildiz; B. G�kberk,2023,"In this work, we examine recent methods employed for detecting deepfake images and videos, which have become increasingly prevalent in recent times. Deepfake datasets are categorized into generations based on the number of data, quality, and diversity of the data they contain, and a new realistic dataset has been generated to accurately reflect real-world conditions. In this paper, we evaluate the methodologies used for deepfake detection using computer vision and deep learning on currently available datasets and present the results in a comprehensive manner.",deepfake;deep learning;computer vision,IEE
523,Improving Deepfake Detection Generalization by Invariant Risk Minimization,Z. Yin; J. Wang; Y. Xiao; H. Zhao; T. Li; W. Zhou; A. Liu; X. Liu,2024,"The abuse of deepfake techniques has raised serious concerns about social security and ethical problems, which motivates the development of deepfake detection. However, without fully addressing the domain gap issue, existing deepfake detection methods still show weak generalization ability among datasets belonging to different domains with domain-specific characteristics like identities and generation methods, limiting their practical applications. In this article, we propose the Invariant Domain-oriented Deepfake Detection method (ID$_{3}$), which improves the generalization of deepfake detection on multiple domains through invariant risk minimization, a novel learning paradigm that addresses the domain gap problem by jointly training a purified invariant predictor and learning an aligned invariant representation. To train a purified invariant predictor, we design the Domain Refinement Data Augmentation strategy with self-face-swapping and region-erasing approaches, which suppresses domain-specific features and encourages the models to focus on critical domain-invariant characteristics. To learn an aligned invariant representation, we propose the Domain Calibration Batch Normalization approach with multiple BN branches, which normalizes input features from different domains into aligned representations during both training and testing. Extensive experiments on multiple datasets demonstrate that our framework can boost the deepfake detection generalization ability and outperform other baselines by large margins. Our codes can be found here.",Deepfake detection;invariant risk minimization;model generalization,IEE
524,Video Manipulation Detection and Localization Using Deep Learning,H. Mamtora; K. Doshi; S. Gokhale; S. Dholay; C. Gajbhiye,2020,"Nowadays, several low-cost yet productive video editing software tools have been developed due to which it is essential to check the genuineness of digital videos, before they can be used as legal evidences. Thus, detecting and localizing forgery in videos has become an important research field. In this paper we have proposed a solution to detect and localize spatio-temporal manipulation in videos using a deep learning approach involving an architecture based on LSTM or Long short-term memory. Our proposed model is able to perform temporal as well as spatial localization of forgery. The experiments are carried out on the REWIND dataset having 10 original and 10 forged videos. 16 videos are used for training and 4 are used for testing the model. The evaluation of model performance is done at pixel-level, frame-level and video-level for computing the spatial localization, temporal localization and forgery detection accuracy values respectively.",video forgery;convolution;difference layer;LSTM;frame;classification;pixel;neural network;accuracy;sensitivity;specificity;precision,IEE
525,Shallow- and Deep- fake Image Manipulation Localization Using Deep Learning,J. Zhang; H. Tohidypour; Y. Wang; P. Nasiopoulos,2023,"Forged image localization is an important research task, as such images may have a tremendous impact of various aspects of society. Images can be manipulated using image editing tools (known as �shallowfakes�) or, recently, artificial intelligence techniques (�deepfakes�). While there are many existing works that are designed for manipulated areas localization on either shallow- or deep-fake images, there is no single solution that works for both cases. In this paper, we propose the first solution that can perform the localization task on both shallow- and deep-fake images, with high inference accuracy. The dataset and code are available at: https://github.com/zjbthomas/ShallowDeepFakesLocalization.",Image manipulation;Manipulation localization;shallowfakes;deepfakes,IEE
526,Model Attribution of Face-Swap Deepfake Videos,S. Jia; X. Li; S. Lyu,2022,"AI-created face-swap videos, commonly known as Deepfakes, have attracted wide attention as powerful impersonation attacks. Existing research on Deepfakes mostly focuses on binary detection to distinguish between real and fake videos. However, it is also important to determine the specific generation model for a fake video, which can help attribute it to the source for forensic investigation. In this paper, we fill this gap by studying the model attribution problem of Deepfake videos. We first introduce a new dataset with DeepFakes from Different Models (DFDM) based on several Autoencoder models. Specifically, five generation models with variations in encoder, decoder, intermediate layer, input resolution, and compression ratio have been used to generate a total of 6, 450 Deepfake videos based on the same input. Then we take Deepfakes model attribution as a multiclass classification task and propose a spatial and temporal attention based method to explore the differences among Deep-fakes in the new dataset. Experimental evaluation shows that most existing Deepfakes detection methods failed in Deep-fakes model attribution, while the proposed method achieved over 70% accuracy on the high-quality DFDM dataset1.",Face-swap Deepfakes;Model Attribution;Deepfakes Generation,IEE
527,Impact of Video Processing Operations in Deepfake Detection,Y. Lu; T. Ebrahimi,2023,"The detection of digital face manipulation in video has attracted extensive attention due to the increased risk to public trust. To counteract the malicious usage of such techniques, deep learning-based deepfake detection methods have been developed and have shown impressive results. However, the performance of these detectors is often evaluated using benchmarks that hardly reflect real-world situations. For example, the impact of various video processing operations on detection accuracy has not been systematically assessed. To address this gap, this paper first analyzes numerous real-world influencing factors and typical video processing operations. Then, a more systematic assessment methodology is proposed, which allows for a quantitative evaluation of a detector�s robustness under the influence of different processing operations. Moreover, substantial experiments have been carried out on three popular deepfake detectors, which give detailed analyses on the impact of each operation and bring insights to foster future research.",,IEE
528,AI-Generated Images as an Emergent Record Format,J. Bushey,2023,"AI-generated Images are disrupting existing approaches to verifying the trustworthiness of visual media. The application of generative AI in fields in which images are trusted visual evidence of persons, actions and events is drawing the attention of archival scientists and AI researchers. A literature review of AI-generated images as an emergent record format, identified an absence of archival and recordkeeping knowledge. Analysis of the results revealed six thematic categories: authenticity and verifiability; manipulation and misinformation; bias and representation; attribution and intellectual property; transparency and explainability; and ethical considerations. These themes inform the development of research questions and the next phase of the study that includes the application of theory and methods of archival diplomatics and computational archival science.",Generative-AI;AI-generated images;Archives;Recordkeeping;Computational Archival Science;Born-digital images,IEE
529,Contrastive Knowledge Transfer for Deepfake Detection with Limited Data,D. Li; W. Zhuo; W. Wang; J. Dong,2022,"Nowadays forensics methods have shown remarkable progress in detecting maliciously crafted fake images. However, without exception, the training process of deepfake detection models requires a large number of facial images. These models are usually unsuitable for real world applications because of their overlarge size and inferiority in speed. Thus, performing data-efficient deepfake detection is of great importance. In this paper, we propose a contrastive distillation method that maximizes the lower bound of mutual information between the teacher and the student to further improve student�s accuracy in a data-limited setting. We observe that models performing deepfake detection, different from other image classification tasks, have shown high robustness when there is a drop in data amount. The proposed knowledge transfer approach is of superior performance compared with vanilla few samples training baseline and other SOTA knowledge transfer methods. We believe we are the first to perform few-sample knowledge distillation on deepfake detection.",,IEE
530,A Review on Anti-Spoofing : Face Manipulation and Liveness Detection,P. Kittur; A. Pasha; S. Joshi; V. Kulkarni,2023,"The latest developments in deep generative networks have greatly improved the quality of generating life-like fake face videos. Face digital manipulation such as DeepFakes, FaceSwap, and Face2Face are critical issues for automated face recognition systems as it detrimentally affects their performance. To tackle this difficulty, face anti-spoofing is utilized which is a task to prevent unauthorized entry by breaching facial recognition systems using a mask, photo, video or another substitute for a legitimate person's face. The review paper examines the problems and solutions explored in the domain of digital face manipulation, as well as the notion of liveliness detection and numerous aspects and cues that can be used to determine the authenticity of a face. The review is organized into sections, discussing face manipulation techniques, liveness detection using eye blinking, and finally a hybrid system is proposed that considers both face manipulation and liveness detection to strengthen existing solutions. It aims to enhance the security and reliability of facial recognition technology in various applications.",Anti-Spoofing;Face Manipulation;Liveness;Detection;Deep Learning,IEE
531,Multi-Label Deepfake Classification,I. P. Singh; N. Mejri; V. D. Nguyen; E. Ghorbel; D. Aouada,2023,"In this paper, we investigate the suitability of current multi-label classification approaches for deepfake detection. With the recent advances in generative modeling, new deepfake detection methods have been proposed. Nevertheless, they mostly formulate this topic as a binary classification problem, resulting in poor explainability capabilities. Indeed, a forged image might be induced by multi-step manipulations with different properties. For a better interpretability of the results, recognizing the nature of these stacked manipulations is highly relevant. For that reason, we propose to model deepfake detection as a multi-label classification task, where each label corresponds to a specific kind of manipulation. In this context, state-of-the-art multi-label image classification methods are considered. Extensive experiments are performed to assess the practical use case of deepfake detection.",Deepfake detection;Multi-Label Classification;Stacked Manipulations,IEE
532,Detection of AI-Synthesized Speech Using Cepstral & Bispectral Statistics,A. K. Singh; P. Singh,2021,"Digital technology has made possible unimaginable applications come true. It seems exciting to have a handful of tools for easy editing and manipulation, but it raises alarming concerns that can propagate as speech clones, duplicates, or maybe deep fakes. Validating the authenticity of a speech is one of the primary problems of digital audio forensics. We propose an approach to distinguish human speech from AI synthesized speech exploiting the Bi-spectral and Cepstral analysis. Higher-order statistics have less correlation for human speech in comparison to a synthesized speech. Also, Cepstral analysis revealed a durable power component in human speech that is missing for a synthesized speech. We integrate both these analyses and propose a model to detect AI synthesized speech.",AI-synthesized speech;Bi-spectral Analysis;Higher Order Correlations;Cepstral Analysis;MFCC;Multimedia Forensics,IEE
533,Facial Forgery-Based Deepfake Detection Using Fine-Grained Features,A. V. Nadimpalli; A. Rattani,2023,"Facial forgery by deepfakes has caused major se-curity risks and raised severe societal concerns. As a counter-measure, a number of deepfake detection methods have been proposed. Most of them model deepfake detection as a binary classification problem using a backbone convolutional neural network (CNN) architecture pretrained for the task. These CNN-based methods have demonstrated very high efficacy in deepfake detection with the Area under the Curve (AUC) as high as 0.99. However, the performance of these methods degrades signifi-cantly when evaluated across datasets and deepfake manipulation techniques. This draws our attention towards learning more subtle, local, and discriminative features for deepfake detection. In this paper, we formulate deepfake detection as a fine-grained classification problem and propose a new fine-grained solution to it. Specifically, our method is based on learning subtle and generalizable features by effectively suppressing background noise and learning discriminative features at various scales for deepfake detection. Through extensive experimental validation, we demonstrate the superiority of our method over the published research in cross-dataset and cross-manipulation generalization of deepfake detectors for the majority of the experimental scenarios.",Cross-Manipulation Generalization;Deepfakes;Fine-Grained Classification;Facial Manipulations,IEE
534,A Novel Approach to Detect Face Fraud Detection Using Artificial Intelligence,S. Senthil Pandi; M. S. Monesh; B. Lingesh,2024,"The main aim of this research is to identify and prevent fraudulent activities which can be achieved through AI related to facial recognition systems. Nowadays the usage of facial recognition systems is very high, and in the same way the scams by fraudsters are also increased in this research by using AI bots instead of humans. The main motive of this research is to identify the misuse of facial recognition technology. The proposed method using CNN (Convolutional Neural Network) protects the individual privacy of people and their data. It detects whether the character in the image is an AI made or real human. This helps to ensure that only authorized people can use their information. Some of the sectors which use facial recognition systems are security, law enforcement, financial services, education, government services, retail. if unauthorized people access the above-mentioned sectors, the result will be imperiling. This method takes an image as an input and then python is used to process the image, importing a CV library to do this job. Next, we use deep learning models in python to identify whether the character in the image is AI generated or real human. The Computational Intelligence and Photography Lab at Yonsei University assembled a publicly available dataset for this work. Images of both real and fake human faces can be found in the Yonsei University Computational Intelligence and Photography Lab's database. The performance of the proposed system is measured using accuracy, precision and sensitivity. Experimental results shows that CNN based face recognition system outperforms.",Authorization;CNN;Data Protection;Facial recognition,IEE
535,Application of Ensembles of Neural Networks for Deepfake Recognition,M. Yadryshnikova; A. Latipova,2023,"At the moment, the creation of deepfakes for various activities is widespread: sometimes for the sake of humor, and sometimes for malicious purposes. In the second case, such deepfakes can potentially harm a person. Neural networks trained to recognize deepfakes can become an actual tool for combating malicious fakes. This article proposes neural network architectures which can be used in the task of recognizing photo and video deepfakes, describes the datasets that can help in training neural networks for the task, and determines what pre-processing is needed for different datasets. Particular attention is paid to possible options for combining the results of several trained models. The architectures of neural networks Inception-Resnet and Xception were chosen as the basis, the conceptual features of these architectures were described, and their practical testing was carried out in the problem of classifying deepfakes. A method of ensembling models is chosen for better results.",deep learning;artificial intelligence;deepfake;ensemble of neural networks,IEE
536,MINTIME: Multi-Identity Size-Invariant Video Deepfake Detection,D. A. Coccomini; G. K. Zilos; G. Amato; R. Caldelli; F. Falchi; S. Papadopoulos; C. Gennaro,2024,"In this paper, we present MINTIME, a video deepfake detection method that effectively captures spatial and temporal inconsistencies in videos that depict multiple individuals and varying face sizes. Unlike previous approaches that either employ simplistic a-posteriori aggregation schemes, i.e., averaging or max operations, or only focus on the largest face in the video, our proposed method learns to accurately detect spatio-temporal inconsistencies across multiple identities in a video through a Spatio-Temporal Transformer combined with a Convolutional Neural Network backbone. This is achieved through an Identity-aware Attention mechanism that applies a masking operation on the face sequence to process each identity independently, which enables effective video-level aggregation. Furthermore, our system incorporates two novel embedding schemes: (i) the Temporal Coherent Positional Embedding, which encodes the temporal information of the face sequences of each identity, and (ii) the Size Embedding, which captures the relative sizes of the faces to the video frames. MINTIME achieves state-of-the-art performance on the ForgeryNet dataset, with a remarkable improvement of up to 14% AUC in videos containing multiple people. Moreover, it demonstrates very robust generalization capabilities in cross-forgery and cross-dataset settings. The code is publicly available at: https://github.com/davide-coccomini/MINTIME-Multi-Identity-size-iNvariant-TIMEsformer-for-Video-Deepfake-Detection.",Deepfake detection;computer vision;deep learning;vision transformers;convolutional neural networks,IEE
537,ISTVT: Interpretable Spatial-Temporal Video Transformer for Deepfake Detection,C. Zhao; C. Wang; G. Hu; H. Chen; C. Liu; J. Tang,2023,"With the rapid development of Deepfake synthesis technology, our information security and personal privacy have been severely threatened in recent years. To achieve a robust Deepfake detection, researchers attempt to exploit the joint spatial-temporal information in the videos, like using recurrent networks and 3D convolutional networks. However, these spatial-temporal models remain room to improve. Another general challenge for spatial-temporal models is that people do not clearly understand what these spatial-temporal models really learn. To address these two challenges, in this paper, we propose an Interpretable Spatial-Temporal Video Transformer (ISTVT), which consists of a novel decomposed spatial-temporal self-attention and a self-subtract mechanism to capture spatial artifacts and temporal inconsistency for robust Deepfake detection. Thanks to this decomposition, we propose to interpret ISTVT by visualizing the discriminative regions for both spatial and temporal dimensions via the relevance (the pixel-wise importance on the input) propagation algorithm. We conduct extensive experiments on large-scale datasets, including FaceForensics++, FaceShifter, DeeperForensics, Celeb-DF, and DFDC datasets. Our strong performance of intra-dataset and cross-dataset Deepfake detection demonstrates the effectiveness and robustness of our method, and our visualization-based interpretability offers people insights into our model.",Deepfake detection;video transformer;deep learning interpretability,IEE
538,Fake Audio Detection Based On Unsupervised Pretraining Models,Z. Lv; S. Zhang; K. Tang; P. Hu,2022,"This work presents our systems for the ADD2022 challenge. The ADD2022 challenge is the first audio deep synthesis detection challenge, which aims to spot various kinds of fake audios. We have explored using unsupervised pretraining models to build fake audio detection systems. Results indicate that unsupervised pretraining models can achieve excellent performance for fake audio detection. Our final EER results for low-quality fake audio detection and partially fake audio detection are 32.80% and 4.80% relatively. For partially fake audio detection, our results ranked first in the competition. Even trained with totally mismatched data, our method still generalizes well for partially fake audio detection.",Fake audio detection;Unsupervised pre-training models;XLS-R;ECAPA-TDNN,IEE
539,Multiple Image Tampering Detection using Deep Learning Algorithm,N. S. S. Gadiparthi; J. S. Kadha; V. D. R. Palagiri; G. Chadalavada; G. K. Kumba; C. Rajan,2023,"Image manipulation has become a widespread problem with digital photos in recent years. The detection of copy-move picture forgeries, image splicing, and recoloring are the three basic types of image forgeries that are mentioned. The dataset for detection of copy-move images is MICC-220 which involves 220 images with varying lighting conditions and camerasettings. In this paper, Scale-invariant feature transform, DBSCAN algorithm for copy-move image detection, and a deep architecture of a convolutional neural network are some of the approaches and models used to identify recolored images. The dataset used for detection of imagesplicing is CASIA V2 dataset, which contains 4795 photos, to classify altered images and detect different types of image tampering. In addition, image Error Level Analysis, an image compression techniquesareinvolved, along with the convolutional neural network to identify the altered images.",Copy-move;Convolutional Neural Networks (CNN);Recolored image;Image splicing;Scale invariant feature transform(SIFT);Error level Analysis (ELA),IEE
540,A Review of Deep Learning Techniques for Multimodal Fake News and Harmful Languages Detection,E. Festus Ayetiran; �. �zg�bek,2024,"The detection of fake news and harmful languages has become increasingly important in today�s digital age. As the prevalence of fake news and harmful languages continue to increase, so also is the correspondent negative impact on individuals and the society. Researchers are exploring new techniques to identify and combat these issues. Deep neural network (DNN) has found a wide range of applications in diverse problem domains including but not limited to fake news and harmful languages detection. Fake news and harmful languages are currently increasing online and the mode of dissemination of these contents is fast changing from the traditional unimodal to multiple data forms including texts, audios, images and videos. Multimedia contents containing fake news and harmful languages pose more complex challenges than unimodal contents. The choice and efficacy of the fusion methods of the multimedia contents is one of the most challenging. Our area of focus is multimodal techniques based on deep learning that combines diverse data forms to improve detection accuracy. In this review, we delve into the current state of research, the evolution of deep learning techniques that have been proposed for multimodal fake news and harmful languages detection and the state-of-the-art (SOTA) multimedia data fusion methods. In all cases, we discuss the prospects, relationships, breakthroughs and challenges.",Fake news;abusive language;deep learning;hate speech;harmful languages;deepfake;offensive language;toxic language;online trolling;cyberbullying;cyberaggression;extremism;multimedia data fusion,IEE
541,Ensemble Learning Model for Face Swap Detection,K. Samrouth; N. Beuve; O. Deforges; N. Bakir; W. Hamidouche,2024,"Deepfake videos become now one of the top research topics because of their high spreading rate on social media. Faceswap, a particular type of Deepfake, consists in swapping faces of two persons in a video. Hence, face swapping can have malicious uses, such as falsifying privacy, interfering with political campaigns, terrorism, and threatening the social stability of the countries. Thus, early detection of this fake content is a primary task to limit their spread. Multiple approaches for DeepFake detection exist in the literature. The most recent and best ones are Identity-Aware and Mesoscopic features-based approaches. However, each of these approaches presents particular limitations. Therefore, in this paper, we propose to take the best out of these two recent approaches and to optimize the performance and robustness of Deepfake content detection. In particular, we propose an Ensemble Learning model based on combining the best two methods from the two aforementioned most recent approaches of detection. Our experiments show that our proposed ensemble model improved the performance and robustness of Deepfake detection to reach an accuracy of 95%.",Deepfake;Face Swap detection;Deep Learning;Ensemble Learning,IEE
542,A Hybrid approach for Deepfake Detection using CNN-RNN,S. Antad; V. V. Arthamwar; R. K. Deshmukh; A. U. Chame; H. P. Chhangani,2024,"Reliable deepfake detection of falsified videos generated by deep learning is still a pressing challenge with its growing popularity. Deep adversarial neural networks, which educate on film and target faces to ahead facial resources and facial expressions to targets, underneath DF can without difficulty idiot facial recognition structures the usage of revealed, 3-D photos mask, or video recordings from the valid consumer�s face to sensors. We make significant contributions, including building adaptive datasets, comparing primitive and deep models for training, and tunable CNN-RNN tools. The overall evaluation model shows that the results are better than the findings of the most advanced methods. It was acknowledged that Deep faking today greatly impacts our environment; It is done by placing faces on original images/videos using deep neural networks. Together with the sharing of other misinformation via digital social networks, deepfake has formed digital fakery, which has become a real problem of negative social impact and as such there is a great need for successful measures to be taken to examine Deep Fakes [1]. The approach in this research generalizes by capturing physical cues in body shape and size. Our method combines CNN for spatial analysis, capturing facial features and skin texture, and LSTM and RNN for temporal analysis, monitoring expression progress. This method provides stable performance on complex deepfake videos. The modular design allows for future expansion, such as the integration of audio analysis.",CNN-Convolutional Neural Network;LSTMShort Term Neural Network;Recurrent Neural Network (RNN);Hybrid deep learning,IEE
543,Ghost-in-Wave: How Speaker-Irrelative Features Interfere DeepFake Voice Detectors,X. Hai; X. Liu; Z. Chen; Y. Tan; S. Li; W. Niu; G. Liu; R. Zhou; Q. Zhou,2024,"Recent speech synthesis technology can generate high-quality speech indistinguishable from human speech, thus introducing various security and privacy risks. Numerous recent studies have focused on fake voice detection to address these risks, with many claiming to achieve ideal performance. However, is this really the case? A recent research work introduced Speaker-Irrelative-Features (SiFs), unrelated to the information in speech files but capable of influencing fake detectors. This means that existing detectors may rely on SiFs to a certain extent to distinguish real and fake speech. In this paper, we introduce an evaluation framework to evaluate the influence of SiFs in existing fake voice detectors in depth. We evaluate three SiFs which include background noise, the mute parts before and after voice, and the sampling rate on ASVspoof2019 and FoR. Our results confirm the substantial influence of SiFs on fake voice detection performance, and we delve into the analysis of the underlying mechanisms.",Deepfake;AI-Synthesized Speech;Fake Voice Detection,IEE
544,Research on Sitting Posture Recognition Based on Deep Fusion Neural Network,T. Yang; Q. Tao; B. Wu; Z. Zhao,2023,"To address the problems of current sitting recognition methods such as low recognition accuracy, susceptibility to environmental interference, and the inability to adapt to viewpoint changes, a deep fusion neural network model based on VGG, Resnet, and Vision Transformer is proposed. Firstly, the image data are enhanced by using random cropping and random flipping; secondly, shallow features are extracted by the VGG network, and constant mapping is added by the Resnet residual network to extract multi-dimensional features of the image; and finally, the fused feature information is input into the Vision Transformer network for sitting posture recognition. The experimental results show that the accuracy of the fusion model for sitting posture recognition reaches 98.3% and improves to 22.9%, 12.8%, 7.8%, 17.5%, 27.5%, and 20% compared with the traditional VGG, Resnet, Vision Transformer, MobileNet, EfficientNet, and Inception networks, respectively. The fusion model can adapt to viewpoint changes in a range of up to 45 and combines the advantages of individual models; the localization of key feature regions is more complete and accurate, which improves the recognition accuracy.",deep learning;multi-model fusion;posture recognition;accuracy,IEE
545,Self-supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection,L. Chen; Y. Zhang; Y. Song; L. Liu; J. Wang,2022,"Recent studies in deepfake detection have yielded promising results when the training and testing face forgeries are from the same dataset. However, the problem remains challenging when one tries to generalize the detector to forgeries created by unseen methods in the training dataset. This work addresses the generalizable deepfake detection from a simple principle: a generalizable representation should be sensitive to diverse types of forgeries. Following this principle, we propose to enrich the �diversity� of forgeries by synthesizing augmented forgeries with a pool of forgery configurations and strengthen the �sensitivity� to the forgeries by enforcing the model to predict the forgery configurations. To effectively explore the large forgery augmentation space, we further propose to use the adversarial training strategy to dynamically synthesize the most challenging forgeries to the current model. Through extensive experiments, we show that the proposed strategies are surprisingly effective (see Figure 1), and they could achieve superior performance than the current state-of-the-art methods. Code is available at https://github.com/liangchen527/SLADD.",Computer vision for social good; Face and gestures,IEE
546,A Comparative Analysis of Fake Image Detection in Generative Adversarial Networks and Variational Autoencoders,M. Berrahal; M. Boukabous; I. Idrissi,2023,"The rise of deep fake technology has led to growing concerns about its potential misuse for propaganda, disinformation, and even cybercrimes. Deep fake detection has thus become a crucial research area to prevent the spread of fake content and protect digital authenticity. This research investigates the detection of fake human face images using deep learning models. The study utilizes a combination of the CelebA-HQ and FFHQ datasets to create real image labels. Two generative models, a Style-based generator and a Variational Autoencoder, are trained to generate GAN-fake and VAE-fake images, respectively. The deep learning models are then trained and evaluated using both real and fake images. The research focuses on two scenarios: binary net and multi-class net. In the binary net scenario, ResNet50 achieves the highest accuracy of 99.34%, along with excellent precision, recall, and F1-score. VGG16 and VGG19 also perform well in distinguishing between fake and real images. In the multi-class net scenario, ResNet50 again achieves the highest accuracy of 95.25% and balanced F1-score. VGG16 and VGG19 maintain competitive performance, while other models show slightly lower accuracy. These results provide insights into the effectiveness of different deep learning models for detecting fake human face images. ResNet50 consistently performs well in both scenarios, while VGG16 and VGG19 offer reliable alternatives.",Deepfake;Deep Learning;Convolutional Neural Network;Generative Adversarial Net;Variational Autoencoders,IEE
547,A Green Learning Approach to Spoofed Speech Detection,C. Wei; R. Pang; C. . -C. J. Kuo,2024,"A green-learning-based spoofed speech detector that decides whether an input speech sample is bona fide (genuine) or spoofed in an automatic speaker verification (ASV) system, is proposed in this work. The proposed solution, called the green ASVspoof detector (GAD), adopts Wav2vec (version 2.0) speech representations as its front-end model. We partition an input speech sample into temporal segments and adopt the Wav2vec representation for each segment. Then, GAD is a 3-stage decision process comprising one XGBoost classifier in each stage. It offers an interpretable design. It is shown by experimental results that GAD achieves competitive performance in ASVspoof detection. At the same time, it has a smaller model size and significantly lower computational complexity, thus positioning it as an effective and green solution.",ASVspoof;Lightweight Model;Green Learning,IEE
548,Face Swapping Neural Networks Based on Improved Autoencoders,W. -J. Yang; B. -N. Lin; P. -C. Chung; J. -F. Yang,2019,"Traditional face swapping method is manually synthesized through image editing software such that the synthetic results are not only unnatural but also time consuming. This paper proposes a face swapping system mainly based on the improved autoencoders such that the swapped faces can be achieved more natural results and faster speed. In the proposed face swapping system, MTCNN and face recognition are first used to detect and collect the faces of characters A and B from two different video sources. With the collected two facial data sets for characters A and B, we can employ the proposed shared-encoder to extract their facial information and restore their faces by the proposed decoders A and B, respectively. The trained neural networks can swap the faces of character A to the faces of character B if we use shared-encoder with decoder B. Finally, by image fusing process, the swapped faces are pasted to the original video to finish the face swap procedure. The experimental results are exhibited to show the effectiveness of the proposed face swapping neural network system.",autoencoder;neural network;face swapping;face detection;face recognition;image fusion,IEE
549,Implicit Identity Driven Deepfake Face Swapping Detection,B. Huang; Z. Wang; J. Yang; J. Ai; Q. Zou; Q. Wang; D. Ye,2023,"In this paper, we consider the face swapping detection from the perspective of face identity. Face swapping aims to replace the target face with the source face and generate the fake face that the human cannot distinguish between real and fake. We argue that the fake face contains the explicit identity and implicit identity, which respectively corresponds to the identity of the source face and target face during face swapping. Note that the explicit identities of faces can be extracted by regular face recognizers. Particularly, the implicit identity of real face is consistent with the its explicit identity. Thus the difference between explicit and implicit identity of face facilitates face swapping detection. Following this idea, we propose a novel implicit identity driven framework for face swapping detection. Specifically, we design an explicit identity contrast (EIC) loss and an implicit identity exploration (IIE) loss, which supervises a CNN backbone to embed face images into the implicit identity space. Under the guidance of EIC, real samples are pulled closer to their explicit identities, while fake samples are pushed away from their explicit identities. More-over, IIE is derived from the margin-based classification loss function, which encourages the fake faces with known target identities to enjoy intra-class compactness and inter-class diversity. Extensive experiments and visualizations on several datasets demonstrate the generalization of our method against the state-of-the-art counterparts.",Humans: Face;body;pose;gesture;movement,IEE
550,Enhancing General Face Forgery Detection via Vision Transformer with Low-Rank Adaptation,C. Kong; H. Li; S. Wang,2023,"Nowadays, forgery faces pose pressing security concerns over fake news, fraud, impersonation, etc. Despite the demonstrated success in intra-domain face forgery detection, existing detection methods lack generalization capability and tend to suffer from dramatic performance drops when deployed to unforeseen domains. To mitigate this issue, this paper designs a more general fake face detection model based on the vision transformer(ViT) architecture. In the training phase, the pretrained ViT weights are freezed, and only the Low-Rank Adaptation(LoRA) modules are updated. Additionally, the Single Center Loss(SCL) is applied to supervise the training process, further improving the generalization capability of the model. The proposed method achieves state-of-the-arts detection performances in both cross-manipulation and cross-dataset evaluations.",Forgery face detection;generalization,IEE
551,Visually Maintained Image Disturbance Against Deepfake Face Swapping,J. Dong; X. Xie,2021,"As a deep learning-based application, DeepFake can generate malicious images or videos through replacing the face of a source image with the target face, which poses a significant threat to social media. In this paper, we propose a scheme to prevent such tampering by exploring adversarial examples against DeepFake. Specifically, adversarial examples are produced by adding tailored distortion to source images. The added distortion is imperceptible to human vision but can mislead the generation of face-swapped images effectively. We present three novel adversarial attacks against DeepFake autoencoders from perspectives of adversarial transferability and latent representation. Our first method synthesizes universal perturbation, which is image-agnostic. By contrast, the latter two methods directly perform the preciser perturbation specific to a source image. Extensive experiments demonstrate the effectiveness of our adversarial examples against DeepFake in terms of both reference and non-reference image quality assessment.",DeepFake;adversarial examples;adversarial transferability;latent representation;autoencoder,IEE
552,Adaptive Cyber Defense: Leveraging Neuromorphic Computing for Advanced Threat Detection and Response,A. Srivastava; V. Parmar; S. Patel; A. Chaturvedi,2023,"As the complexity of the digital landscape evolves, so does the sophistication of cyber threats, necessitating advanced cybersecurity measures. Despite significant strides in threat detection and response using machine learning and deep learning techniques, these systems grapple with high false positive rates, limited adaptability to evolving threats, and computational inefficiency in real-time data processing. This study proposes to delve into the potential of Neuromorphic Computing (NC) to address these challenges. Inspired by the human brain�s principles, NC offers rapid, efficient information processing through Spiking Neural Networks (SNNs) and other brain-inspired architectures. The study hypothesizes that integrating NC into cyber defence could enhance threat detection, response times, and adaptability, thereby bolstering cybersecurity systems� resilience. However, the implementation of NC in cybersecurity is fraught with challenges, including scalability, compatibility with existing infrastructures, and the creation of secure, robust neuromorphic systems. This study elucidates these challenges, proposes potential solutions, and highlights future research directions in this promising field. With focused research and development, NC could revolutionize cybersecurity, enhancing the defence mechanisms of the digital ecosystems against the relentless onslaught of cyber threats. The study analyses that the incorporation of NC into cybersecurity is not only feasible but also necessary in increasingly digital world.",Adaptive cyber defense;Neuromorphic computing;Threat;Detection and Response,IEE
553,Fake Face2Face Video Detection Using a Novel Scene and Texture Based Feature Set,A. N. Ramkissoon; V. Rajamanickam; W. Goodridge,2023,"The existence of fake videos is a problem that is challenging today's social media-enabled world. There are many classifications for fake videos with one of the most popular being Face2Face. Detecting such fake videos is a challenging issue. This research attempts to comprehend the characteristics that belong to Face2Face videos. In attempting to understand Face2Face videos this work investigates the characteristics of the video that make them unique. As such this research uses scene and texture detection to develop a unique feature set containing 19 data features which is capable of detecting whether a video is a Face2Face or not. This study validates the feature set using a standard dataset of the features relating to the characteristics of the video. These features are analysed using a classification machine learning model. The results of these experiments are examined using four evaluation methodologies. The analysis reveals positive performance with the use of the ML method and the feature set. From these results, it can be ascertained that using the proposed feature set, a video can be predicted as a Face2Face or not and as such prove the hypothesis that there exists a correlation between the characteristics of a video and its genuineness, i.e., whether or not a video is a Face2Face.",Classification;Face2Face;Features;Scene Detection;Texture Detection,IEE
554,"A Continual Deepfake Detection Benchmark: Dataset, Methods, and Essentials",C. Li; Z. Huang; D. P. Paudel; Y. Wang; M. Shahbazi; X. Hong; L. Van Gool,2023,"There have been emerging a number of benchmarks and techniques for the detection of deepfakes. However, very few works study the detection of incrementally appearing deepfakes in the real-world scenarios. To simulate the wild scenes, this paper suggests a continual deepfake detection benchmark (CDDB) over a new collection of deepfakes from both known and unknown generative models. The suggested CDDB designs multiple evaluations on the detection over easy, hard, and long sequence of deepfake tasks, with a set of appropriate measures. In addition, we exploit multiple approaches to adapt multiclass incremental learning methods, commonly used in the continual visual recognition, to the continual deepfake detection problem. We evaluate existing methods, including their adapted ones, on the proposed CDDB. Within the proposed benchmark, we explore some commonly known essentials of standard continual learning. Our study provides new insights on these essentials in the context of continual deepfake detection. The suggested CDDB is clearly more challenging than the existing benchmarks, which thus offers a suitable evaluation avenue to the future research. Both data and code are available at https://github.com/Coral79/CDDB.",Algorithms: Image recognition and understanding (object detection;categorization;segmentation);Computational photography;image and video synthesis;Machine learning architectures;formulations;and algorithms (including transfer;low-shot;semi-;self-;and un-supervised learning),IEE
555,Deep Ensemble Learning with Frame Skipping for Face Anti-Spoofing,U. Muhammad; M. Z. Hoque; M. Oussalah; J. Laaksonen,2023,"Face presentation attacks, also known as spoofing attacks, pose a substantial threat to biometric systems that rely on facial recognition systems, such as access control systems, mobile payments, and identity verification systems. To mitigate the spoofing risk, several video-based methods have been presented in the literature that analyze facial motion in successive video frames. However, estimating the motion between adjacent frames is a challenging task and requires high computational cost. In this paper, we rephrase the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism. In particular, the proposed frame skipping adopts a uniform sampling approach by dividing the original video into video clips of fixed size. By doing so, every nth frame of the clip is selected to ensure that the temporal patterns can easily be perceived during the training of three different recurrent neural networks (RNNs). Motivated by the performance of individual RNNs, a meta-model is developed to improve the overall detection performance by combining the prediction of individual RNNs. Extensive experiments were performed on four datasets, and state-of-the-art performance is reported on MSU-MFSD (3.12%), Replay-Attack (11.19%), and OULU-NPU (12.23%) databases by using half total error rates (HTERs) in the most challenging cross-dataset testing scenario.",Face liveness detection;Ensemble learning;Frame skipping;Recurrent neural network;Face anti-spoofing;Deep learning,IEE
556,Adversarially Robust Deepfake Video Detection,A. Devasthale; S. Sural,2022,"Fake videos have been in circulation on mainstream media since long. However, with increased popularity of online social networks, it is becoming many times easier to spread such videos and achieve virality. Recent advancements in deep learning has further fuelled this menace as the so called deepfake videos are hard to differentiate from the genuine ones. While deepfake video detection techniques attempt to identify the fake videos from real videos, these are now being subjected to adversarial attacks, thus undermining their efficacy. In this paper, we show that accuracy of deepfake detectors can be considerably improved by incorporating an adversarial learning step during model building. We use a recently proposed deep network architecture, namely VGG19, as deepfake detector supplemented with adversarial training using Iterative Fast Gradient Sign Method (I-FGSM). To further improve non-adversarial accuracy ensemble of models were used. Extensive experiments on a large deepfake video corpus under different white box adversarial attacks demonstrate significant adversarial robustness of the proposed method.",Deepfake Video;Adversarial Attack;Deep Learning;Adversarial Training;Face Manipulation,IEE
557,Deepfake Face Extraction and Detection Using MTCNN-Vision Transformers,R. Singh; K. Ashwini; B. Chandu Priya; K. Pavan Kumar,2024,"Deepfake detection is a major problem nowadays. The deepfake detection can be done using face extraction and detection. Strong solutions for face extraction and detection are required in light of the growing prevalence of deepfake technology. This paper combines Vision Transformers with Multi-Task Cascaded Convolutional Networks (MTCNN) to propose a novel method. This approach leverages the real-time face identification skills of MTCNN and the long-range dependency capture ability of Vision Transformers to improve the accuracy of detecting manipulated faces in deepfake footage. We carry out extensive experiments on several deepfake datasets, demonstrating the efficacy of the suggested hybrid strategy. The proposed model findings show that this approach performs better than conventional face identification techniques, particularly when dealing with situations where minor facial alterations are involved. This integration strikes a good compromise between computing efficiency and precision, which makes it a viable option for practical uses. The proposed MT-VIT (Multi-Task Vision Transformer) model provides good accuracy as compared to other state-of-the-art like Residual Networks, Mobile Net, CNN, and Meso-Net.",multitask cascaded convolutional neural network (MTCNN);vision transformer (VIT);deepfake detection,IEE
558,Fused Swish-ReLU Efficient-Net Model for Deepfakes Detection,H. Ilyas; A. Javed; M. M. Aljasem; M. Alhababi,2023,"With the rapid development of sophisticated deepfakes generation methods, the realism of fake content has reached the level where it becomes difficult for human eyes to identify such high-quality fake images/videos, thus increasing the demand for developing deepfakes detection methods. The diversity in deepfakes images/videos in terms of ethnicity, illumination condition, skin tone, age, background setting, and generation algorithms makes the detection task quite difficult. To better address the aforementioned challenges, we present a novel Swish-ReLU Efficient-Net (SRE-Net) that is robust to the identification of deepfakes generated using different face-swap and face-reenactment techniques. More precisely, we fused two EfficienNet-b0 models, one with the ReLU and the other with the Swish activation function along with layer freezing to achieve better detection results. Our SRE-Net attained the average accuracy and precision of 96.5% and 97.07% on the FaceForensics++ dataset, and 88.41% and 91.28% on the DFDC-preview dataset. The high detection results demonstrate the effectiveness of SRE-Net while detecting the deepfakes generated using different manipulation algorithms.",Deepfakes detection;fused Swish-ReLU Efficient-Net;FaceForensics++;DFDC-preview,IEE
559,Fighting Deepfake by Residual Noise Using Convolutional Neural Networks,M. C. El Rai; H. Al Ahmad; O. Gouda; D. Jamal; M. A. Talib; Q. Nasir,2020,"In the last few years, the easy access to images and videos shared online have been continuously increased. The generative adversarial networks using deep learning leads to create very realistic deepfake videos by playing with the digital content of images and videos. The spread of such deepfake videos on social media networks urged the international community to consider seriously its danger and accordingly encouraged the researchers around the world to develop powerful deepfake detection methods. Many approaches are available in the recent literature. In this paper, the proposed approach is based on exploiting the residual noise which is the difference between original image and its denoised version. The study of residual noise has shown effectiveness in deep-fake detection with regards to its distinctive and discriminative features which can be effectively captured by convolutional neural networks with transfer learning. The performance of our approach is evaluated on two datasets: low-resolution video sequences of the FaceForensics++ and high-resolution videos from Kaggle Deepfake Detection challenge (DFDC). The obtained results show relevant accuracy in comparison with other competitive methods.",Deepfake;Authentic Detection;Residual noise;Transfer Learning;Convolutional Neural Networks,IEE
560,Understanding User Perception of Biometric Privacy in the Era of Generative AI,S. Srinivasan,2023,"In the dynamic world of technology, the fusion of biometrics and artificial intelligence has ushered in an unprecedented era marked by convenience, security, and cutting-edge innovation. Biometrics, the science of using unique physical or behavioral attributes for identification and authentication, has seamlessly merged into daily routines. From unlocking smartphones with a fingerprint to clearing airport security with facial recognition, biometrics has transformed the way people interact with technology and the world. Simultaneously, Generative AI, powered by machine learning models, has unlocked new frontiers in generating remarkably realistic synthetic data, including human faces, voices, and fingerprints. This convergence of biometrics and Generative AI lies at the heart of a complex and rapidly evolving landscape, giving rise to profound questions concerning individual privacy and security. This study examines the correlation between demographic factors like age, gender, educational background, technological competence, and the regularity of employing biometric authentication, and their awareness about biometric technologies. Additionally, this research explores concerns regarding the potential misuse of biometric data and the notion that organizations should seek explicit consent before collecting such data. Lastly, it assesses the awareness of potential privacy risks and the belief that individuals should receive education regarding the utilization of their biometric data in AI systems. Descriptive research design has been used in this study. The first section of the questionnaire using Microsoft Forms covers the demographic factors, technological proficiency and frequency of using biometric authentication (e.g., fingerprint, facial recognition). The next section focuses on awareness and usage of biometric technologies, biometric privacy, trust, education, awareness of biometrics, generative AI and deepfakes using the Likert Scale. 53 samples were obtained through Simple Random Sampling from UAE residents. Then, testing of hypothesis using correlation analysis was done using SPSS. The results reveal that demographic variables do not exhibit a statistically significant relationship with privacy concerns. However, there is a statistically significant correlation exists between biometric authentication and awareness & knowledge parameters.",Biometrics;artificial intelligence;generative AI;deepfakes;privacy concerns,IEE
561,Comparison Multi Transfer Learning Models for Deep Fake Image Recognizer,N. A. Rosli; S. N. H. Sheikh Abdullah; A. N. Zamani; A. Ghazvini; N. S. Md Othman; N. A. A. A. Muariff Tajuddin,2021,"The advancement of technologies nowadays cause image digitally to become essential as an official document many available applications used for image editing. Those applications have become a threat to detect image authenticity when dealing with an abundance of digital image evidence in cyber court. Hence, many researchers realize the importance of image authentication fields as deep fake is a powerful weapon for spreading misinformation on the digital platform. Deep learning has known to obtain relevant attributes automatically in placing handcrafted features in a deep network against other single-layer networks. The objective of the research is to compare two models from Convolutional Neural Network (CNN), which are VGG19 dan ResNet50 in deep learning with transfer learning for image fake detector. A total of 1500 random images consisting of 450 forgery images from the IEEE Image Forensics Challenge in 2013 were tested on the splicing technique. From this research, we used two transfer learning techniques to identify tamper images from image splicing. Based on model VGG16 and ResNet50 transfer learning, the accuracy achieved about 94.65% and 95.08%, respectively.",deep learning;neural network;deep fake a transfer learning,IEE
562,A Hybrid CNN-LSTM Approach for Deepfake Audio Detection,M. Chitale; A. Dhawale; M. Dubey; S. Ghane,2024,"As synthetic media techniques advance, the detection of manipulated audio content, known as deepfake audio, has become increasingly important. With the rise of challenges in cybersecurity and misinformation detection posed by deepfake audio, there is a pressing need for detection methods. This research introduces a system for recognizing deepfake audio that combines recurrent and convolutional networks and utilizes Mel Frequency Cepstral Coefficients (MFCC) for extracting features. It also explores feature extraction methods such as spectral contrast, spectral flatness and chromagram. This blended approach merges the effectiveness of MFCC in representing characteristics with CNNs expertise in capturing features and LSTMs capability in capturing temporal dependencies. The system achieves an accuracy rate of 94.73% on a combination of two datasets named �Wave Fake� and Release in the Wild�. By offering an adaptable solution for detecting manipulated audio content this study pushes forward the field of deepfake detection and helps tackle the challenges presented by synthetic media in audio forensics.",Deepfake audio;CNN;RNN;MFCC;LSTM,IEE
563,A Survey on AI-Enabled Attacks and AI-Empowered Countermeasures in Physical Layer,J. Chang; Z. Li; M. Kaveh; Y. Zhang; J. Li; Z. Yan,2023,"As artificial intelligence (AI) continues to integrated into our daily lives, it becomes increasingly crucial to prioritize the security of these systems, particularly at the physical layer. The physical layer is the foundational level of communication systems, responsible for transmitting data over a communication medium. The advent of AI has brought about significant advancements in the field of cybersecurity, introducing new attack methodologies and empowering countermeasures at the physical layer of communication systems. This dual aspect of AI has made it a critical component in maintaining the security and integrity of these systems. However, despite many existing efforts to apply AI into physical layer security, there is still a lack of comprehensive overview of attacks and countermeasures regarding AI-based attacks and countermeasures in this domain. In this article, we provide a general survey on AI -enabled attacks and AI-empowered countermeasures in the physical layer, and analyze its performance using two sets of proposed standards: evaluation criteria for AI -enabled attacks and AI -empowered countermeasures. Through this review, we aim to identify the key challenges that require extensive investigation and propose suggestions for future research directions.",AI-enabled attacks;AI-empowered countermeasures;physical layer security,IEE
564,Hearing and Seeing Abnormality: Self-Supervised Audio-Visual Mutual Learning for Deepfake Detection,C. -S. Sung; J. -C. Chen; C. -S. Chen,2023,"The recent development of deepfakes has resulted in serious threats to society, such as spreading misinformation, defamation, etc. Although recent deepfake detection methods are capable of achieving satisfactory results for seen forgeries, the performance drops significantly for unseen ones. With proper supervised pretraining on auxiliary tasks as prior, the situation can be improved, but the requirement to collect a large number of additional annotations for these tasks may restrict the further development of a generalized deep-fake detector. To address this issue, we propose an Audio-Visual Temporal Synchronization for Deepfake Detection framework for detecting deepfakes that maintains reasonable detection capabilities for unseen ones. The primary objective of our framework is to determine whether there has been a forgery by evaluating the consistency between the sound and the faces in a video clip, together with the relationship between the two features. First, the spatiotemporal feature extraction network is pretrained in a self-supervised manner by exploiting the audio-visual temporal synchronization task to build up a rich representation based on the temporal synchronization relationship between the audio and its corresponding video. For pretraining, we use only real data and carefully selected negative samples with contrastive loss to train the model. A temporal classifier network is used to determine whether or not the video has been manipulated using the representations obtained from the pretrained feature extraction networks. To prevent the model from overfitting to certain manipulation-specific artifacts, we froze the feature extraction networks and only trained the final classifier network on forged data. Extensive experiments on unseen forgery categories and unseen datasets have shown the effectiveness of our method to achieve state-of-the-art results.",Self-supervised Learning;Audio-Visual;Deep-fake Detection,IEE
565,Faster Than Lies: Real-time Deepfake Detection using Binary Neural Networks,R. Lanzino; F. Fontana; A. Diko; M. R. Marini; L. Cinque,2024,"Deepfake detection aims to contrast the spread of deep-generated media that undermines trust in online content. While existing methods focus on large and complex models, the need for real-time detection demands greater efficiency. With this in mind, unlike previous work, we introduce a novel deepfake detection approach on images using Binary Neural Networks (BNNs) for fast inference with minimal accuracy loss. Moreover, our method incorporates Fast Fourier Transform (FFT) and Local Binary Pattern (LBP) as additional channel features to uncover manipulation traces in frequency and texture domains. Evaluations on COCOFake, DFFD, and CIFAKE datasets demonstrate our method�s state-of-the-art performance in most scenarios with a significant efficiency gain of up to a 20� reduction in FLOPs during inference. Finally, by exploring BNNs in deepfake detection to balance accuracy and efficiency, this work paves the way for future research on efficient deepfake detection.",deepfake;binary neural network;deep learning;efficiency;fft;lbp;real-time;flops;bnn;neural network,IEE
566,FAIVconf: Face Enhancement for AI-Based Video Conference with Low Bit-Rate,Z. Li; S. Lin; S. Liu; S. Li; X. Lin; W. Wang; W. Jiang,2022,"Recently, high-quality video conferencing with fewer transmission bits becomes a very hot and challenging problem. We propose FAIVConf, a specially designed video compression framework for video conferencing, based on the effective neural human face generation techniques. FAIVConf brings together several designs to improve the system robustness in real video conference scenarios: face swapping to avoid artifacts in background animation; facial blurring to decrease transmission bit-rate and maintain quality of extracted facial landmarks; and dynamic source update for face view interpolation to accommodate a large range of head poses. Our method achieves significant bit-rate reduction in video conference and gives much better visual quality under the same bit-rate compared with H.264 and H.265 coding schemes.",AI Video Conference;Face Generation;Deep Learning,IEE
567,Real-Time Face Transition using Deepfake Technology (Gan Model),S. Tandon; A. Vig; M. Kartik; H. C. Kumawat,2023,"Many machine learning models require huge datasets to get trained, to make correct predictions, or to increase their accuracy, that's where generative adversarial network (GAN) comes into the picture. GAN is a deep learning model, which can be used to create artificial data. It consists of two neural networks that cooperate in a way that resembles a game: a generator network and a discriminator network. Within the suggested model in this work, a dense motion network-based first-order motion model for image animation is developed. Here a trained GAN extracts the face landmarks from the driving video and develops the embedding model to create the synthesis video using the dedicated module to prepare the Deepfakes, employing key point detectors as a baseline. Lastly, an approach that makes use of dense motion networks to increase the effectiveness of a collection of GAN generators is provided. With the help of the sequel driving combination of driving video with the source image, the given results produce the augmented animation video. Hence, it is tried to implement a lighter model which consists of modules, with the approximate same accuracy when compared with other implementations of GAN. This work has a wide range of applications, including doubling dataset counts with a small number of sources, creating real-time backgrounds and characters for the gaming and animation industries using CG platforms, translating clothes, predicting videos, creating 3D objects, etc.",Artificial Data;Neural Networks;Deepfakes;GAN;Animation,IEE
568,Deepfake Video Detection through Optical Flow Based CNN,I. Amerini; L. Galteri; R. Caldelli; A. Del Bimbo,2019,"Recent advances in visual media technology have led to new tools for processing and, above all, generating multimedia contents. In particular, modern AI-based technologies have provided easy-to-use tools to create extremely realistic manipulated videos. Such synthetic videos, named Deep Fakes, may constitute a serious threat to attack the reputation of public subjects or to address the general opinion on a certain event. According to this, being able to individuate this kind of fake information becomes fundamental. In this work, a new forensic technique able to discern between fake and original video sequences is given; unlike other state-of-the-art methods which resorts at single video frames, we propose the adoption of optical flow fields to exploit possible inter-frame dissimilarities. Such a clue is then used as feature to be learned by CNN classifiers. Preliminary results obtained on FaceForensics++ dataset highlight very promising performances.",Deepfake;Optical flow;Video forensics;CNN,IEE
569,Hacking the AI - the Next Generation of Hijacked Systems,K. Hartmann; C. Steup,2020,"Within the next decade, the need for automation, intelligent data handling and pre-processing is expected to increase in order to cope with the vast amount of information generated by a heavily connected and digitalised world. Over the past decades, modern computer networks, infrastructures and digital devices have grown in both complexity and interconnectivity. Cyber security personnel protecting these assets have been confronted with increasing attack surfaces and advancing attack patterns. In order to manage this, cyber defence methods began to rely on automation and (artificial) intelligence supporting the work of humans. However, machine learning (ML) and artificial intelligence (AI) supported methods have not only been integrated in network monitoring and endpoint security products but are almost omnipresent in any application involving constant monitoring, complex or large volumes of data. Intelligent IDS, automated cyber defence, network monitoring and surveillance as well as secure software development and orchestration are all examples of assets that are reliant on ML and automation. These applications are of considerable interest to malicious actors due to their importance to society. Furthermore, ML and AI methods are also used in audio-visual systems utilised by digital assistants, autonomous vehicles, face-recognition applications and many others. Successful attack vectors targeting the AI of audio-visual systems have already been reported. These attacks range from requiring little technical knowledge to complex attacks hijacking the underlying AI.With the increasing dependence of society on ML and AI, we must prepare for the next generation of cyber attacks being directed against these areas. Attacking a system through its learning and automation methods allows attackers to severely damage the system, while at the same time allowing them to operate covertly. The combination of being inherently hidden through the manipulation made, its devastating impact and the wide unawareness of AI and ML vulnerabilities make attack vectors against AI and ML highly favourable for malicious operators. Furthermore, AI systems tend to be difficult to analyse post-incident as well as to monitor during operations. Discriminating a compromised from an uncompromised AI in real-time is still considered difficult.In this paper, we report on the state of the art of attack patterns directed against AI and ML methods. We derive and discuss the attack surface of prominent learning mechanisms utilised in AI systems. We conclude with an analysis of the implications of AI and ML attacks for the next decade of cyber conflicts as well as mitigations strategies and their limitations.",AI hijacking;artificial intelligence;machine learning;cyber attack;cyber security,IEE
570,Fake face detection based on deep learning and frequency domain processing,M. Wang; P. Fan; T. Yang,2023,"With the rapid development of artificial intelligence, various advanced image generation and processing methods continue to emerge. In terms of fake face images, most are generated by methods based on generative adversarial networks (GANs). The increasing spread of fake face images may cause social problems such as misleading public opinion or damage to personal reputation. In this paper,we proposes a facial synthesis detection method based on deep learning and frequency domain processing. In this method, the Facenet network is used to extract facial features from images and enhance them during the extraction process. Then, fast Fourier transform (FFT) is used to analyze the extracted facial features in the frequency domain, and ResNet50 network is used to extract frequency domain features from the obtained information. Finally, the extracted facial feature vectors and image frequency domain features are fused, and the image is classified based on the obtained fusion features. This method was experimented on a 16-class dataset and achieved good detection results, compared with the optimal facial feature detection model and frequency domain feature detection model.",Deep learning;frequency domain processing;Fast Fourier Transform;feature fusion,IEE
571,Combating Fake News in the Digital Age: A Review of AI-Based Approaches,G. Vishnupriya; A. Jeriel K; A. RNS; G. Ajay; A. G. J,2024,"The increasing spread of false information requires advanced detection methods. This study provides a thorough examination of the various strategies used to identify fake news, ranging from traditional approaches to cutting-edge technologies. The strengths and limitations of artificial intelligence, deep learning, and natural language processing techniques were evaluated. The combination of multimodal analysis, artificial intelligence and graph-based models has been identified as an emerging trend that improves the effectiveness of classification systems. Challenges, such as adversarial attacks and biased training data, highlight the ongoing need for development in this area. Additionally, this paper explores new trends, including user behavior analysis and collaborative cybersecurity strategies, while discussing their potential impact on detecting counterfeit news. A comparative analysis was used to assess the suitability of these methodologies across diverse contexts. The conclusion of the review emphasizes the dynamic nature of detecting false information and underlines the crucial requirement for interdisciplinary cooperation to safeguard against deception in the constantly evolving digital realm.",Fake news detection;Machine learning;Multimedia analysis;Adversarial attacks;Emerging trends,IEE
572,Realtime Deepfake Detection using Video Vision Transformer,A. Doshi; A. Venkatadri; S. Kulkarni; V. Athavale; A. Jagarlapudi; S. Suratkar; F. Kazi,2022,"Practically, Deepfake technology has given people access to generate fake videos that look like real content using neural networks, and can further create misconceptions and deceit about the innocuous elements of society. This technology can prove fatal not only to national security but on an international level. Existing methodologies that apply deep learning to automatically extract salient and discriminative features to detect Deepfakes based on typical CNN-LSTM models tend to have their shortcomings. Having said that, we propose a system that extracts Spatio-Temporal features and achieves Real-Time Deepfake detection using Transformers. For the end user, a web application was developed, which with utmost simplicity allows the uploading of a video that will be further authenticated within the application and, at the same time, features the authentication of live meetings.",Image Processing;Deep Learning;Vision Transformer;Video Vision Transformer,IEE
573,Audio Deepfake Detection and Classification,B. Sarada; T. L. Sudha; M. Domakonda; B. Vasantha,2024,"AI Voice Cloning, also called audio deepfakes is a highly advanced process that utilizes Artificial Intelligence to create a replica of a human voice. There is no doubt that this technology has revolutionized the way we interact with machines and has immense potential for various industries. This technology is used to create new identities or to steal the identities of the original voice owner and spread misinformation using cloned audio. This paper aims to differentiate between cloned voice and original voice using GAN and random forest. A generative adversarial network (GAN) is a deep learning architecture where two neural networks engage in a competitive dynamic within a zero-sum framework, striving to enhance the precision of these predictions. The Synthesized Data contains a lot of disturbances in the background which are generally referred to as Noise. To decrease this noise from the speech signals Spectral Subtraction is used. Feature extraction is done through zero crossing and a Random Forest classifier is used. By this classification, 100% accuracy has been acquired and other metrics such as precision, recall, and F1 score are also approximately equal to 100%. For analysis, a folder of 88 audio is considered.",Deepfakes;GANs;Spectral Subtraction method;Zero Crossing method,IEE
574,Recurrent Convolutional Structures for Audio Spoof and Video Deepfake Detection,A. Chintha; B. Thai; S. J. Sohrawardi; K. Bhatt; A. Hickerson; M. Wright; R. Ptucha,2020,"Deepfakes, or artificially generated audiovisual renderings, can be used to defame a public figure or influence public opinion. With the recent discovery of generative adversarial networks, an attacker using a normal desktop computer fitted with an off-the-shelf graphics processing unit can make renditions realistic enough to easily fool a human observer. Detecting deepfakes is thus becoming important for reporters, social media platforms, and the general public. In this work, we introduce simple, yet surprisingly efficient digital forensic methods for audio spoof and visual deepfake detection. Our methods combine convolutional latent representations with bidirectional recurrent structures and entropy-based cost functions. The latent representations for both audio and video are carefully chosen to extract semantically rich information from the recordings. By feeding these into a recurrent framework, we can detect both spatial and temporal signatures of deepfake renditions. The entropy-based cost functions work well in isolation as well as in context with traditional cost functions. We demonstrate our methods on the FaceForensics++ and Celeb-DF video datasets and the ASVSpoof 2019 Logical Access audio datasets, achieving new benchmarks in all categories. We also perform extensive studies to demonstrate generalization to new domains and gain further insight into the effectiveness of the new architectures.",Convolution;deep learning;deepfake;entropy;spoof,IEE
575,DeepFake Detection using a frame based approach involving CNN,A. Ajoy; C. U. Mahindrakar; D. Gowrish; V. A,2021,"This paper proposes a novel model to detect Deep-Fakes, which are hyper-realistic fake videos generated by advanced AI algorithms involving facial superimposition. With a growing number of DeepFakes involving prominent political figures that hold a lot of social capital, their misuse can lead to drastic repercussions. These videos can not only be used to circulate false information causing harm to reputations of individuals, companies and countries, but also has the potential to cause civil unrest through mass hysteria. Hence it is of utmost importance to detect these DeepFakes and promptly curb their spread. We therefore propose a CNN-based model that learns inherently distinct patterns that change between a DeepFake and a real video. These distinct features include pixel distortion, inconsistencies with facial superimposition, skin colour differences, blurring and other visual artifacts. The proposed model has trained a CNN (Convolutional Neural Network), to effectively distinguish DeepFake videos using a frame-based approach based on aforementioned distinct features. Herein, the proposed work demonstrates the viability of our model in effectively identifying Deepfake faces in a given video source, so as to aid security applications employed by social-media platforms in credibly tackling the ever growing threat of Deepfakes, by effectively gauging the authenticity of videos, so that they may be flagged or ousted before they can cause irreparable harm.",,IEE
576,Leveraging Attention to Achieve Generalization for Image Forgery Detection,M. Atta,2023,"Recently, image forgery has become an alarming trend with the growth of available easy-to-use editing and generation tools. Modern DeepFake methods have achieved extraordinary progress in realistic face manipulation, thus raising concerns among the public about the misuse of such technologies. Unfortunately, with the obnoxiously wide range of possible manipulation and artifact-covering methods, most existing state-of-the-art detection methods lack the generalization capability to handle the output variations. To address this issue, a noticeable shift towards using attention mechanisms has emerged using balanced portions of the latest challenging datasets to detect intra-and inter-spatial relations. Our paper provides a comprehensive analysis of modern deep learning-based methods, showing the benefits of the shift. In addition, we make propositions for future research directions and dataset-building methodology.",Transformer;attention;generative adversarial network;image forgery detection;image forensics;deep learning;DeepFake;computer vision,IEE
577,A Multi-color Spatio-Temporal Approach For Detecting DeepFake,S. Waseem; S. R. Abu-Bakar; Z. Omar; B. A. Ahmed; S. Baloch,2022,"The current surge in hyper-realistic faces created artificially using DeepFakes necessitates media forensics solutions suited to video streams and perform reliably with a low false alarm rate at the video level. The paper proposes a spatial and temporal aware pipeline to detect DeepFake videos automatically. Our method employed a two-stream convolutional neural network to extract local spatial and temporal features independently. These features are then fed to fully connected layers to classify whether a video has been subject to manipulation. The proposed method has been evaluated against FaceForensics++, DFTIMIT, and DFD benchmarks. Our suggested technique demonstrates encouraging performance in this task",DeepFake;Autoencoder;GAN;Face-swap;Face-re-enactment,IEE
578,Hybrid Model for Detecting Deepfake Videos,R. A C; K. P Nihal; K. Mishra; M. Sahithi P; P. A V; H. S Jagadeesh,2023,"Innovations that can produce Deepfake videos are developing quickly. These videos are simple to and leave no obvious signs of alteration. Even though forensic detection in high-quality video datasets has produced fantastic results, there is always a need for more research into the forensics of compressed videos. Compressed videos are common in unofficial forums, such as those on Facebook, WeChat, and Instagram. Therefore, a crucial challenge is how to identify compressed Deepfake videos. In this project, we propose a two-stream method to compute each frame of compressed Deepfake videos. The compressed data has lot of unwanted data which needs to be trimmed, the proposed model performs the filtering to remove the unwanted data on each frame. When combined with scores from the two streams, our proposed technique performs better than the existing techniques in compressed mode.",Deepfake;Mesonet;Resnet;Compressed videos;Face2Face,IEE
579,Eyebrow Recognition for Identifying Deepfake Videos,H. M. Nguyen; R. Derakhshani,2020,"Deepfake imagery that contains altered faces has become a threat to online content. Current anti-deepfake approaches usually do so by detecting image anomalies, such as visible artifacts or inconsistencies. However, with deepfake advances, these visual artifacts are becoming harder to detect. In this paper, we show that one can use biometric eyebrow matching as a tool to detect manipulated faces. Our method could provide an 0.88 AUC and 20.7% EER for deepfake detection when applied to the highest quality deepfake dataset, Celeb-DF.",,IEE
580,A Comprehensive Examination of Biometric ATM Operations Involving Fingerprint and Face Recognition Using Deep Learning,T. S. Burkul; S. Patil,2024,"India's technological advancements have significantly enhanced convenience and reliability, especially in the banking sector, benefiting consumers with notable progress. Automated Teller Machines (ATMs) have revolutionized transaction processes, reducing the chances of errors by human intervention. ATMs facilitate cash withdrawals and deposits 24/7, with seamless integration via bank-issued cards. Despite these advantages, there has been a rise in incidents of card theft and fraudulent transactions, posing challenges to the security and trustworthiness of ATMs. To bolster security measures, a shift from card-based to person-based identification during transactions is imperative. The adoption of a biometric authentication system is crucial for ensuring user verification through a virtual ATM approach. This method involves utilizing face and fingerprint recognition technologies with live streaming, Channel Boosted Convolutional Neural Networks, and One Time Password implementation to establish a highly secure and dependable virtual ATM system. Further research will delve into the details of this proposed strategy.",Biometric ATM;Biometric Identification;Facial Recognition;Fingerprint Authentication;Enhanced Convolutional Neural Networks through Channel Boosting,IEE
581,"Exploring the intricacies of Biometric ATM operations, specifically focusing on the integration of fingerprint and facial recognition using Deep Learning techniques",T. S. Burkul; S. Patil,2024,"India�s technological advancements have significantly enhanced convenience and reliability in the banking sector, benefiting consumers with notable progress. ATMs have revolutionized transaction processes, reducing the chances of errors by human intervention. Despite these advantages, incidents of card theft and fraudulent transactions have been on the rise, posing challenges to the security and trustworthiness of ATMs. Transitioning to person-based identification during transactions is crucial to bolster security measures. The adoption of a biometric authentication system is imperative for ensuring user verification through a virtual ATM approach, utilizing face and fingerprint recognition technologies, live streaming, Channel Boosted Convolutional Neural Networks, and One Time Password implementation to establish a highly secure and dependable virtual ATM system. Further research will delve into the details of this proposed strategy.",Biometric ATM;Biometric Identification;Facial Recognition;Fingerprint Authentication;Enhanced Convolutional Neural Networks through Channel Boosting,IEE
582,LLM-Enhanced Deepfake Detection: Dense CNN and Multi-Modal Fusion Framework for Precise Multimedia Authentication,S. E. VP; C. M. S; R. Dheepthi,2024,"The increasing ubiquity of deepfake technology presents a serious risk to the legitimacy and reliability of multimedia material across a number of sectors, from identity verification to news distribution. Current deepfake detection methods frequently have trouble identifying minor manipulations and are unable to keep up with the latest generation techniques, which creates a serious vulnerability in the defence against the improper use of synthetic media. Using Dense Convolutional Neural Networks (Dense CNN) and Multi-Modal Fusion, this study presents a novel method for deepfake detection. Our Dense CNN architecture which draws inspiration from Dense Net improves sensitivity to complex manipulations while optimizing feature reuse through dense connectivity patterns, thereby mitigating the shortcomings of existing systems. Our suggested approach dynamically combines temporal and visual modalities, enhanced by Multi-Modal Fusion, to offer a comprehensive contextual knowledge that enhances detection accuracy. After thorough tests on several datasets, our method performs exceptionally well and is particularly good at identifying advanced deepfake variations. Our suggested methodology improves the state-of-the-art in deepfake identification by addressing the shortcomings of current systems and providing a reliable response to the urgent problems brought on by the malicious usage of synthetic media in practical applications. Adding Large Language Models (LLMs) is essential to improving the accuracy of the system. To add another level of scrutiny, LLMs are deliberately used to characterize and analyze portions of multimedia information that are vulnerable to manipulation.",Deepfake Detection;Multimedia;Dense CNN;Large Language Model;dense connectivity patterns;Multi-Modal fusion,IEE
583,Towards Intrinsic Common Discriminative Features Learning for Face Forgery Detection Using Adversarial Learning,W. Zhuang; Q. Chu; H. Yuan; C. Miao; B. Liu; N. Yu,2022,"Existing face forgery detection methods usually treat face forgery detection as a binary classification problem and adopt deep convolution neural networks to learn discriminative features. The ideal discriminative features should be only related to the real/fake labels of facial images. However, we observe that the features learned by vanilla classification networks are correlated to unnecessary properties, such as forgery methods and facial identities. Such phenomenon would limit forgery detection performance especially for the generalization ability. Motivated by this, we propose a novel method which utilizes adversarial learning to eliminate the negative effect of different forgery methods and facial identities, which helps classification network to learn intrinsic common discriminative features for face forgery detection. To leverage data lacking ground truth label of facial identities, we design a special identity discriminator based on similarity information derived from off-the-shelf face recognition model. Extensive experiments demonstrate the effectiveness of the proposed method under both intra-dataset and cross-dataset evaluation settings.",Forgery detection;adversarial learning,IEE
584,Interactive Two-Stream Network Across Modalities for Deepfake Detection,J. Wu; B. Zhang; Z. Li; G. Pang; Z. Teng; J. Fan,2023,"As face forgery techniques have become more mature, the proliferation of deepfakes may threaten the security of human society. Although existing deepfake detection methods achieve good performance for in-dataset evaluation, it remains to be improved in the generalization ability, where the representation of the imperceptible artifacts plays a significant role. In this paper, we propose an Interactive Two-Stream Network (ITSNet) to explore the discriminant inconsistency representation from the perspective of cross-modality. In particular, the patch-wise Decomposable Discrete Cosine Transform (DDCT) is adopted to extract fine-grained high-frequency clues, and information from different modalities communicates with each other via a designed interaction module. To perceive the temporal inconsistency, we first develop a Short-term Embedding Module (SEM) to refine subtle local inconsistency representation between adjacent frames, and then a Long-term Embedding Module (LEM) is designed to further refine the erratic temporal inconsistency representation from the long-range perspective. Extensive experimental results conducted on three public datasets show that ITSNet outperforms the state-of-the-art methods both in terms of in-dataset and cross-dataset evaluations.",Deepfake detection;inconsistency representation;cross-modality learning,IEE
585,Deep Fake BERT: Efficient Online Fake News Detection System,M. Kanchana; V. M. Kumar; T. P. Anish.; P. Gopirajan,2023,"The newscast system has shifted from conventional print to online media platforms in the current computing era. As a result, online media platforms enable us to absorb information more quickly and with fewer editorial constraints, and false information is disseminated at an extraordinary rate and on a massive scale. Many practical algorithms for identifying fake News have recently been created, which use unidirectional text sequence analysis. News and social context-level information were encoded using sequential neural networks. As a result, a bidirectional training strategy is capable of enhancing classification. This paper proposed Deep Fake BERT, a new model for identifying bogus News in online media. The model uses a BERT-based deep learning technique by integrating multiple simultaneous modules into a single-layer DCNN with various kernel filter sizes and strides. This combination can handle ambiguity, the most challenging aspect of natural language comprehension. This approach used classification methods such as Naive Bayes, Feed Forward Neural Networks, and LSTM, and prediction results were compared. Based on the comparison, the proposed model yields a classification accuracy is 99.25% to the existing methods.",Deep Fake BERT;DCNN;LSTM;Naive Bases;Deep Learning;BERT;Fake News,IEE
586,A new deep fake method based on background removal,A. Kuznetsov,2021,"The modern digital space is saturated with a huge amount of data in the form of images and videos every day. All information contained is important to users, organizations and other consumers. It should be noted that the speed of information dissemination is so high that sometimes, in order to trace its original source, it is necessary to spend large computing resources. Moreover, during the search for the original source, information can be distorted beyond recognition and acquire new properties in the form of details and additional links. Attackers change information, as a rule, in order to compromise an individual, incite conflicts, undermine the reputation of individuals and legal entities, etc. Among the most modern and popular means is DeepFake technology, with the help of which a person's face can be replaced on an image or video. The paper proposes a new method for generating distorted images, based on removing the background in the image, to improve the visual quality of distortion.",deep fake;forgery;face swap;generative adversarial network;background removal,IEE
587,Analysing the Role of Human-AI Collaboration in Workforce Transformation,V. V. Shenoi; P. Sreeram; C. L. Sai Varma; K. R. Goud; S. N. Afroz,2024,"The rapid advancement of artificial intelligence (AI) and automation technologies has brought forth a confluence of challenges and opportunities in contemporary society. The rapid integration of AI into the workforce landscape has ushered in a transformative era, reshaping industries and challenging traditional work structures. This research paper delves into the critical dimension of Human-AI collaboration mainly and explores AI in the context of workforce transformation. Through a multidisciplinary approach, it explores the evolving relationship between humans and AI, emphasizing the synergy between human intelligence and machine capabilities. The study evaluates the impacts, advantages, and challenges of this collaboration and presents practical insights for fostering a harmonious coexistence between humans and AI. By analyzing the role of Human-AI collaboration in workforce transformation, this paper contributes to a deeper understanding of the future of work and the dynamic interplay between humans and intelligent machines in the digital age.",,IEE
588,Protecting Celebrities from DeepFake with Identity Consistency Transformer,X. Dong; J. Bao; D. Chen; T. Zhang; W. Zhang; N. Yu; D. Chen; F. Wen; B. Guo,2022,"In this work we propose Identity Consistency Transformer, a novel face forgery detection method that focuses on high-level semantics, specifically identity information, and detecting a suspect face by finding identity inconsistency in inner and outer face regions. The Identity Consistency Transformer incorporates a consistency loss for identity consistency determination. We show that Identity Consistency Transformer exhibits superior generalization ability not only across different datasets but also across various types of image degradation forms found in real-world applications including deepfake videos. The Identity Consistency Transformer can be easily enhanced with additional identity information when such information is available, and for this reason it is especially well-suited for detecting face forgeries involving celebrities.11Code will be released at https://github.com/LightDXY/ICT_DeepFake",Recognition: detection;categorization;retrieval; Face and gestures,IEE
589,Facial Privacy Preservation using FGSM and Universal Perturbation attacks,N. Jagadeesha,2022,"Research done in Facial Privacy so far has entrenched the scope of gleaning race, age, and gender from a human�s facial image that are classifiable and compliant biometric attributes. Noticeable distortions, morphing, and face-swapping are some of the techniques that have been researched to restore consumers� privacy. By fooling face recognition models, these techniques cater superficially to the needs of user privacy, however, the presence of visible manipulations negatively affects the aesthetic of the image. The objective of this work is to highlight common adversarial techniques that can be used to introduce granular pixel distortions using white-box and black-box perturbation algorithms that ensure the privacy of users� sensitive or personal data in face images, fooling AI facial recognition models while maintaining the aesthetics of and visual integrity of the image.",Facial Privacy;Facial Aesthetic preservation;Black-Box Attack;White-Box attack;Fast Gradient Sign Method (FGSM);Universal Perturbation;Privacy attributes;Adversarial Machine Learning;DeepFool algorithm,IEE
590,Survey on Vision based Fake News Detection and its Impact Analysis,M. S. Raval; M. Roy; M. Kuribayashi,2022,"Fake news is a post containing multimedia content and misrepresents the event that it is covering. A large number of fake news detection(FND) techniques rely on text analysis and very little attention has been paid to visual content-based detection. Deep learning-based generative models have increased the complexity by creating ultra-realistic phony media content and most detection techniques fail when dealing with such synthesized media. Therefore, the paper surveys the vision-based FND and improves our understanding of the role of visual content in detection. At the same time, it is important to study propagation characteristics and find an impact analysis of fake news. The existing review papers do not combine two parts - detection and impact analysis. Therefore, the proposed survey paper focuses on FND with face manipulation and also performs its impact analysis.",Computer Vision;Deep Fake;Deep Learning;Detection;Fake News;Impact Analysis,IEE
591,Learning Self-Consistency for Deepfake Detection,T. Zhao; X. Xu; M. Xu; H. Ding; Y. Xiong; W. Xia,2021,"We propose a new method to detect deepfake images using the cue of the source feature inconsistency within the forged images. It is based on the hypothesis that images� distinct source features can be preserved and extracted after going through state-of-the-art deepfake generation processes. We introduce a novel representation learning approach, called pair-wise self-consistency learning (PCL), for training ConvNets to extract these source features and detect deepfake images. It is accompanied by a new image synthesis approach, called inconsistency image genera-tor (I2G), to provide richly annotated training data for PCL. Experimental results on seven popular datasets show that our models improve averaged AUC over the state of the art from 96.45% to 98.05% in the in-dataset evaluation and from 86.03% to 92.18% in the cross-dataset evaluation.",Fairness;accountability;transparency;and ethics in vision;Faces,IEE
592,Deepfake Detection with Clustering-based Embedding Regularization,K. Zhu; B. Wu; B. Wang,2020,"In recent months, AI-synthesized face swapping videos referred to as deepfake have become an emerging problem. False video is becoming more and more difficult to distinguish, which brings a series of challenges to social security. Some scholars are devoted to studying how to improve the detection accuracy of deepfake video. At the same time, in order to conduct better research, some datasets for deepfake detection are made. Companies such as Google and Facebook have also spent huge sums of money to produce datasets for deepfake video detection, as well as holding deepfake detection competitions. The continuous advancement of video tampering technology and the improvement of video quality have also brought great challenges to deepfake detection. Some scholars have achieved certain results on existing datasets, while the results on some high-quality datasets are not as good as expected. In this paper, we propose new method with clustering-based embedding regularization for deepfake detection. We use open source algorithms to generate videos which can simulate distinctive artifacts in the deepfake videos. To improve the local smoothness of the representation space, we integrate a clustering-based embedding regularization term into the classification objective, so that the obtained model learns to resist adversarial examples. We evaluate our method on three latest deepfake datasets. Experimental results demonstrate the effectiveness of our method.",face swapping;deepfake detection;clustering-based;regularization,IEE
593,Individualized Emotion Recognition through Dual-representations and Group-established Ground Truth,V. Zhang,2022,"While facial expression is a complex and individualized behavior, all facial emotion recognition (FER) systems known to us rely on a single facial representation and are trained on universal data. We conjecture that: (i) different facial representations can provide different, sometimes complementing views of emotions; (ii) when employed collectively in a discussion group setting, they enable more accurate emotion reading which is highly desirable in autism care and other applications context sensitive to errors. In this paper, we first study FER using pixel-based DL vs semantics-based DL in the context of deepfake videos. Our experiment indicates that while the semantics-trained model performs better with articulated facial feature changes, the pixel-trained model outperforms on subtle or rare facial expressions. Armed with these findings, we have constructed an adaptive FER system learning from both types of models for dyadic or small interacting groups and further leveraging the synthesized group emotions as the ground truth for individualized FER. Using a collection of group conversation videos, we demonstrate that FER accuracy and personalization can benefit from such an approach.",emotion recognition;facial representations;adaptive algorithm;ground truth,IEE
594,Multi-attentional Deepfake Detection,H. Zhao; T. Wei; W. Zhou; W. Zhang; D. Chen; N. Yu,2021,"Face forgery by deepfake is widely spread over the internet and has raised severe societal concerns. Recently, how to detect such forgery contents has become a hot research topic and many deepfake detection methods have been proposed. Most of them model deepfake detection as a vanilla binary classification problem, i.e, first use a backbone network to extract a global feature and then feed it into a binary classifier (real/fake). But since the difference between the real and fake images in this task is often subtle and local, we argue this vanilla solution is not optimal. In this paper, we instead formulate deepfake detection as a fine-grained classification problem and propose a new multi-attentional deepfake detection network. Specifically, it consists of three key components: 1) multiple spatial attention heads to make the network attend to different local parts; 2) textural feature enhancement block to zoom in the subtle artifacts in shallow features; 3) aggregate the low-level textural feature and high-level semantic features guided by the attention maps. Moreover, to address the learning difficulty of this network, we further introduce a new regional independence loss and an attention guided data augmentation strategy. Through extensive experiments on different datasets, we demonstrate the superiority of our method over the vanilla binary classifier counterparts, and achieve state-of-the-art performance. The models will be released recently at https://github.com/yoctta/multiple-attention.",,IEE
595,Exploiting spatiotemporal inconsistencies to detect deepfake videos in the wild,A. Khedkar; A. Peshkar; A. Nagdive; M. Gaikwad; S. Baudha,2022,"Cyberspace is an emerging battlefield and deepfakes are being constantly weaponized by malicious actors. With rapid advancements in media synthesis technologies, detecting deepfakes is becoming increasingly difficult. The following paper presents a unified approach focusing on the fusion of Convolutional Neural Networks and Long Short Term Memory Networks for spatial and temporal analysis of deepfake videos. This study compares the performance of the most prevalent and frequently used deepfake detection methods- convolutional neural networks (CNN) and convolutional neural networks combined with long-short term memory networks (CNN-LSTM) with our architecture on a combined dataset consisting of videos from Face Forensics++ and Deepfake Detection Challenge Dataset, which consists of multiple types of manipulated media- Deepfakes, Faceswaps, Neural Textures, Face Shifter and Face2Face. We find that our architecture provides a 2.5% increase in detection accuracy over the most frequently used current deepfake detection method (CNN-LSTM).",Deepfake Detection;Image Processing;Deep learning;GAN;Generalization;Interpretation,IEE
596,Domain Generalization for Face Forgery Detection by Style Transfer,T. Kim; J. Choi; H. Cho; H. Lim; J. Choi,2024,"Although deep fake detection models have made significant progress, the challenge of performance degradation remains yet for unseen datasets. To address this, we introduce a novel data generalization approach using style transfer to generate images in various domains. Utilizing style transfer, we create a new domain where domain-specific information is eliminated and subsequently train our model on the new domain. Our approach enhances the generalization performance of the detector by adding the style-transferred images to train the deepfake detector. Through the experiments, we confirm that the performance on the trained dataset remains unchanged while achieving an improvement of 8.8% on an unseen dataset. Therefore, We verify the effectiveness of the style-transferred images for generalizing the performance upon unseen datasets.",Deepfake detection;forgery detection;data augmentation;style transfer,IEE
597,DeepFake Face Image Detection based on Improved VGG Convolutional Neural Network,X. Chang; J. Wu; T. Yang; G. Feng,2020,"DeepFake can forge high-quality tampered images and videos that are consistent with the distribution of real data. Its rapid development causes people's panic and reflection. In this paper we presents an improved VGG network named NA-VGG to detect DeepFake face image, which was based on image noise and image augmentation. Firstly, In order to learn the tampering artifacts that may not be seen in RGB channels, SRM filter layer is used to highlight the image noise features; Secondly, the image noise map is augmented to weaken the face features. Finally, the augmented noise images are input into the network to train and judge whether the image is forged. The experimental results using the Celeb-DF dataset have shown that NA-VGG made great improvements than other state-of-the-art fake image detectors.",DeepFake;Image Detection;VGG,IEE
598,Deep Residual Learning for Unmasking DeepFake,T. Bikku; K. Bhargavi; J. Bhavitha; Y. Lalithya; T. Vineetha,2023,"Recently, DeepFake has gained a lot of popularity, any multimedia output created with deep learning technology that appears realistic to viewers is referred to as ""DeepFake."" Despite the positive developments of DeepFake, it has been a significant contributor to threats to an individual's privacy because it allows for the indiscernible swapping of one person's face for another without that person's permission. Additionally, it is simple for hostile actors to influence public events like elections by disseminating false information and harming national security. Therefore, identifying such DeepFake is a critical yet difficult challenge. The separation of DeepFake contents from genuine ones using the human eye has always been a challenging process, but recent research has demonstrated the use of several technologies to provide positive results for the same, but with certain limits. In order to highlight the benefits and drawbacks of the various algorithms utilized for DeepFake production and detection, the paper provides a thorough analysis of the methods employed. The proposed work focuses on using Inception-Resnet V2 to detect deep fakes and packages those advantages of deep learning for this purpose. Here the frames are collected from the uploaded video and divide it into the required number of frames in order to detect deepfakes. The subject's face is then extracted from the video using python face recognition modules. The proposed model, which has been trained on a variety of frame sequences, to determine whether the video is real or a deep fake with 95% accuracy.",Convolutional Neural Networks;Inception network;Residual connections;DeepFake,IEE
599,FAClue: Exploring Frequency Clues by Adaptive Frequency-Attention for Deepfake Detection,W. Liang; Y. Wu; J. Wu; J. Xu,2023,"Detecting fake faces produced by face forgery technologies attracts intensive attention in recent years. Deep learning approaches have shown their effectiveness in deepfake detection task. Some previous deep learning-based methods exploit forgery artifacts in spatial domain but easily overfit the specific forgery patterns. Therefore, some works utilize additional frequency domain information to obtain generalized features. We consider to improve the frequency-based methods in two aspects: 1) extracting discriminative frequency features comprehensively; 2) mining complementary features in different domains sufficiently. In this paper, we propose a dual-stream network named FAClue for deepfake detection, which extracts comprehensive frequency information to complement spatial domain features. Specifically, the FAClue consists of three main components. A Frequency-Attention Extractor (FAE) is proposed to adaptively highlight prominent frequency bands from both global and local perspectives. A RGB-Frequency Complementary Enhancement (RFCE) module is developed to mine complementary information between RGB and frequency domains in an explicit manner. A Frequency Guided Attention (FGA) module is designed to fuse different domain features and generate discriminative features for detection. Extensive experiments on three benchmark datasets demonstrate the FAClue achieves competitive performance compared with state-of-the-art methods.",Deepfake Detection;Frequency Domain;Attention Mechanism;Feature Fusion,IEE
600,DiffSeg: Towards Detecting Diffusion-Based Inpainting Attacks Using Multi-Feature Segmentation,R. A. Frick; M. Steinebach,2024,"With the advancements made in deep learning over the past years, creating convincing media manipulations has become easy and accessible than ever before. In particular, diffusion models such as Stable-Diffusion allow users to synthesize realistic images based on a given text input. Apart from synthesizing entirely new images, diffusion models can also be used to make edits to images using inpainting. To combat the spread of disinformation and illegal content created with diffusion-based inpainting, this paper presents a new detection method based on multi-feature segmentation. Apart from information derived from the raw pixel values, noise, and frequency information are also exploited to detect and localize regions that have been subject to editing. Evaluation results strongly suggest that the proposed method can achieve high mIoU and AUC scores, outperforming state-of-the-art methods, even for syntheses generated by unseen diffusion models, or highly compressed images.",Deepfake Detection;Inpainting Detection;Diffusion Models;Media Forensics,IEE
601,MRE-Net: Multi-Rate Excitation Network for Deepfake Video Detection,G. Pang; B. Zhang; Z. Teng; Z. Qi; J. Fan,2023,"The current social media is flooded with hyper realistic face-synthetic videos due to the explosion of DeepFake technology that has brought a serious impact on human society security, which calls for further exploring on deepfake video detection methods. Existing methods attempt to isolated capture spatial artifacts or extract the homogeneous temporal inconsistency to detect deepfake video, but little attention has been paid to the exploitation of dynamic spatial-temporal inconsistency. To mitigate this issue, in this paper, we propose a novel Multi-Rate Excitation Network (MRE-Net) to effectively excite dynamic spatial-temporal inconsistency from the perspective of multiple rates for deepfake video detection. The proposed MRE-Net is composed of two components: Bipartite Group Sampling (BGS) and multiple rate branches. The BGS draws the entire video into multiple bipartite groups with different rates to cover various face motion dynamic evolution. We further design multiple rate branches to capture both short-term and long-term spatial-temporal inconsistency from corresponding bipartite groups of BGS. Concretely, for the early stages of the multi-rate branches, Momentary Inconsistency Excitation (MIE) module is developed to encode the spatial artifacts and intra-group short-term temporal inconsistency. Meanwhile, for the last stages of the multi-rate branches, Longstanding Inconsistency Excitation (LIE) module is constructed to perceive inter-group long-term temporal dynamics. Extensive experiments and visualizations conducted on four popular datasets demonstrate the effectiveness of the proposed method against state-of-the-art deepfake detection methods.",Deepfake detection;momentary inconsistency;longstanding inconsistency,IEE
602,PUDD: Towards Robust Multi-modal Prototype-based Deepfake Detection,A. L. Pellcier; Y. Li; P. Angelov,2024,"Deepfake techniques generate highly realistic data, making it challenging for humans to discern between actual and artificially generated images. Recent advancements in deep learning-based deepfake detection methods, particularly with diffusion models, have shown remarkable progress. However, there is a growing demand for real-world applications to detect unseen individuals, deepfake techniques, and scenarios. To address this limitation, we propose a Prototype-based Unified Framework for Deepfake Detection (PUDD). PUDD offers a detection system based on similarity, comparing input data against known prototypes for video classification and identifying potential deepfakes or previously unseen classes by analyzing drops in similarity. Our extensive experiments reveal three key findings: (1) PUDD achieves an accuracy of 95.1% on Celeb-DF, outperforming state-of-the-art deepfake detection methods; (2) PUDD leverages image classification as the upstream task during training, demonstrating promising performance in both image classification and deepfake detection tasks during inference; (3) PUDD requires only 2.7 seconds for retraining on new data and emits 105 times less carbon compared to the state-of-the-art model, making it significantly more environmentally friendly.",,IEE
603,Deepfake Detection With Combined Unsupervised-Supervised Contrastive Learning,J. Zheng; Y. Zhou; X. Hu; Z. Tang,2024,"The malicious dissemination of fake images has caused a societal trust crisis, deepfake detection becomes a hot topic now. Through existing detection methods achieve good results in intra-dataset, their performance are poor for unknown manipulations or datasets. To deal with this problem, this paper proposes a new deepfake detection model with combined unsupervised-supervised contrastive learning. By combining unsupervised contrastive learning and supervised contrastive learning with deepfake detection together, the model can discover the essence of fake images from both individual and class features. In addition, a multi-scale attention fusion module is proposed, which helps to enhance the model stability by fusion global and local features of the image. Finally, lots of experiments prove that our method has good performance and generalization ability in intra-dataset, cross-dataset and cross-manipulation scenarios.",deepfake detection;contrastive learning;supervised contrastive learning;combined unsupervised-supervised contrastive learning,IEE
604,Deepfake Detection via Combining Channel and Spatial Attention,A. E. BAYAR; C. TOPAL,2023,"Today, as the widespread use of deepfake technologies weakens the credibility of digital media content, deepfake detection of digital content has become an important issue. Detection of fake content is critical in order to prevent the risk of disinformation that may occur with the rapid spread of manipulated content produced with this technology over the internet. This study proposes a neural network that uses channel and spatial attention mechanisms for the detection of deepfake images. This proposed network is trained with a common dataset by combining DeepfakeTIMIT and VidTIMIT datasets. Compared with models such as InceptionV3, ResNet50 and VGG19, higher accuracy, precision, recall and F1 scores were obtained. This network with attention mechanisms has classified the detection of deepfake images with up to 99% success. The findings of this study will provide an important step in the detection of deep forged images and offer a potential solution for a wider range of applications.",Deepfake;convolutional neural network;channel- wise and spatial attention,IEE
605,Fighting Fake News: Two Stream Network for Deepfake Detection via Learnable SRM,B. Han; X. Han; H. Zhang; J. Li; X. Cao,2021,"Benefitting from the development of deep generative networks, modern fake news generation methods called Deepfake rapidly go viral over the Internet, calling for efficient detection methods. Existing Deepfake detection methods basically use binary classification networks trained on frame-level inputs and lack leveraging temporal information in videos. Besides, the accuracy of these methods will rapidly decrease when processing low-quality data. In this work, we propose a two-stream network to detect Deepfake in video level with the capability of handling low-quality data. The proposed architecture firstly divides the input video into segments and then feeds selected frames of each segment into two streams: The first stream takes RGB information as input and tries to learn the semantic inconsistency. The second stream parallelly leverages noise features extracted by spatial rich model (SRM) filters. Additionally, our experiments found that traditional SRM filters with fixed weights contribute insignificant improvement, we thus design novel learnable SRM filters, which can better fit the noise inconsistency in tampered regions. Segmental fusion and stream fusion are conducted at last to combine the information from segments and streams. We evaluate our algorithm on the existing largest Deepfake dataset FaceForensics++ and the experimental results show that we obtain state-of-the-art performance.",Multimedia forensics;deep learning;fake news;Deepfake;SRM,IEE
606,"Deepfake Characterization, Propagation, and Detection in Social Media - A Synthesis Review",A. Sudarsan; H. N. Chua; M. B. Jasser; R. T. K. Wong,2024,"Deepfake technology, encompassing the creation of hyper-realistic manipulated media, has emerged as a potent force in shaping information dissemination on social media platforms. This synthesis review navigates through existing literature to comprehensively characterize and analyze the propagation dynamics and evaluate the efficacy of detection mechanisms employed in deepfakes within social media environments. Motivated by the escalating concerns surrounding the societal impact of deepfakes, this review critically assesses the current state of research, identifying key trends and challenges. It synthesizes findings on the diverse techniques employed in deepfakes creation, the mechanisms driving their dissemination across social networks, and the evolving landscape of detection strategies. Our synthesis reveals existing research gaps, emphasizing the need for more comprehensive investigations into the characteristics, behavioral, and propagation patterns of different deepfake types. Additionally, we highlight the necessity for standardized datasets and benchmarks to facilitate the development and evaluation of detection methods. Our review aims to guide future research endeavors by providing an overview of the current understanding of deepfake technologies while pinpointing areas that require further exploration and refinement.",deepfake;deep learning;machine learning;characterization;detection mechanisms;propagation dynamics;social media,IEE
607,Detecting Deepfake Videos using Digital Watermarking,A. Qureshi; D. Meg�as; M. Kuribayashi,2021,"Deepfakes constitute fake content -generally in the form of video clips and other media formats such as images or audio- created using deep learning algorithms. With the rapid development of artificial intelligence (AI) technologies, the deepfake content is becoming more sophisticated, with the developed detection techniques proving to be less effective. So far, most of the detection techniques in the literature are based on AI algorithms and can be considered as passive. This paper presents a proof-of-concept deepfake detection system that detects fake news video clips generated using voice impersonation. In the proposed scheme, digital watermarks are embedded in the audio track of a video using a hybrid speech watermarking technique. This is an active approach for deepfake detection. A standalone software application can perform the detection of robust and fragile watermarks. Simulations are performed to evaluate the embedded watermark's robustness against common signal processing and video integrity attacks. As far as we know, this is one of the first few attempts to use digital watermarking for fake content detection.",Digital Watermarking;Deepfake;Authentication;Blockchain,IEE
608,Exposing the Limits of Deepfake Detection using novel Facial mole attack: A Perceptual Black- Box Adversarial Attack Study,Q. U. Ain; A. Javed; K. M. Malik; A. Irtaza,2024,"Recently, we have observed an exponential growth in highly realistic deepfake videos, which are often used to spread disinformation, defame individuals, and even influence political outcomes. To combat these manipulated videos, researchers have proposed various deepfake detection techniques. Recent research has revealed that these detection techniques are vulnerable to different adversarial attacks. This paper examines the vulnerability of deepfake detectors to adversarial black-box attacks in terms of performing penetration testing to expose the existing defense benchmarks of current deepfake detectors. We present a perceptual facial mole black-box adversarial attack on deepfake detectors, where the attacker has limited knowledge of the architecture and settings of the detector. The proposed attack is visually natural and transferable based on the attention distraction mechanism, which distracts the model-shared attention patterns from the region of interest to other regions. We illustrate the efficacy of our attack on multiple cutting-edge deepfake detectors. This attack demonstrates that small perceptible perturbations that are visually natural on the facial face can disrupt and reduce the accuracy of the detectors significantly, up to 40.3%, with the highest success rate of 48.7%. Our findings highlight the necessity for proposing effective deepfake detectors that are resistant to black-box attacks.",Adversarial attack;Black-box attack;Deepfakes detection;Facial Mole attack,IEE
609,Improving Generalization in Facial Manipulation Detection Using Image Noise Residuals and Temporal Features,M. Atamna; I. Tkachenko; S. Miguet,2023,"The high visual quality of modern deepfakes raises significant concerns about the trustworthiness of digital media and makes facial tampering detection more challenging. Although current deep learning-based deepfake detectors achieve excellent results when tested on deepfake images or image sequences generated using known methods, generalization�where a trained model is tasked with detecting deepfakes created with previously unseen manipulation techniques�is still a major challenge. In this paper, we investigate the impact of training spatial and spatio-temporal deep learning network architectures in the image noise residual domain using spatial rich model (SRM) filters on generalization performance. To this end, we conduct a series of tests on the manipulation methods of the FaceForensics++, DeeperForensics-1.0 and Celeb-DF datasets, demonstrating the value of image noise residuals and temporal feature exploitation in tackling the generalization task.",Deepfake detection;video manipulation detection;image forensics;steganalysis features,IEE
610,Electroencephalographic Correlates in Synthetic and Real Emotional Face Stimulation,P. Tarchi; F. Cal�; L. Frassineti; A. Lanat�,2023,"This work reports on physiological electroencephalographic (EEG) correlates in cognitive and emotional processes within the discrimination between synthetic and real faces visual stimuli. Human perception of manipulated data has been addressed in the literature from several perspectives. Researchers have investigated how the use of deep fakes alters people�s ability in face-processing tasks, such as face recognition. Although recent studies showed that humans, on average, are still able to correctly recognize synthetic faces, this study investigates whether those findings still hold considering the latest advancements in AI-based, synthetic image creation. Specifically, 18-channels EEG signals from 21 healthy subjects were analyzed during a visual experiment where synthetic and actual emotional stimuli were administered. According to recent literature, participants were able to discriminate the real faces from the synthetic ones, by correctly classifying about 77% of all images. Preliminary encouraging results showed statistical significant differences in brain activation in both stimuli (synthetic and real) classification and emotional response.",EEG;deep fakes;face recognition,IEE
611,Fusing Global and Local Features for Generalized AI-Synthesized Image Detection,Y. Ju; S. Jia; L. Ke; H. Xue; K. Nagano; S. Lyu,2022,"With the development of the Generative Adversarial Networks (GANs) and DeepFakes, AI-synthesized images are now of such high quality that humans can hardly distinguish them from real images. It is imperative for media forensics to develop detectors to expose them accurately. Existing detection methods have shown high performance in generated images detection, but they tend to generalize poorly in the real-world scenarios, where the synthetic images are usually generated with unseen models using unknown source data. In this work, we emphasize the importance of combining information from the whole image and informative patches in improving the generalization ability of AI-synthesized image detection. Specifically, we design a two-branch model to combine global spatial information from the whole image and local informative features from multiple patches selected by a novel patch selection module. Multi-head attention mechanism is further utilized to fuse the global and local features. We collect a highly diverse dataset synthesized by 19 models with various objects and resolutions to evaluate our model. Experimental results demonstrate the high accuracy and good generalization ability of our method in detecting generated images. Our code is available at https://github.com/littlejuyan/FusingGlobalandLocal.",AI-synthesized Image Detection;Image Forensics;Feature Fusion;Attention Mechanism,IEE
612,A Comprehensive Review on Fake Images/Videos Detection Techniques,R. Chauhan; R. Popli; I. Kansal,2022,"Now that image creation and manipulation have advanced so quickly, there are serious questions about how this may affect society. At best, this leads to loss of trust in digital content. There are many existing algorithms such as Naive Bayes, CNN, RNN, Robust Hashing, GANs, SVM etc. which are being used for the detection of fake videos. Making and classifying deep fakes using Deep Neural Networks (DNN) nowadays have increased the interest of researchers in this field. Deep Fake is the regenerated media that is attained by edging in or replacing some information within the DNN model. In this work, survey withdrawn by various research groups focused the feasibility loopholes that need to be recovered for deep fakes. The use of above-mentioned techniques has been increased by a significant percentage in video game industries and cinema like enhancing visual stuff in pictures. In this paper, different types of datasets used by authors and various contemporary techniques used for fake image/video detection are described. Finally, various research gaps and the possible future directions are highlighted.",Fake image detection;Deep learning;Fake videos;CNNs;GANs,IEE
613,FAMM: Facial Muscle Motions for Detecting Compressed Deepfake Videos Over Social Networks,X. Liao; Y. Wang; T. Wang; J. Hu; X. Wu,2023,"As a face manipulation technique, the misuse of Deepfakes poses potential threats to the state, society, and individuals. Several countermeasures have been proposed to reduce the negative effects produced by Deepfakes. Current detection methods achieve satisfactory performance in dealing with uncompressed videos. However, videos are generally compressed when spread over social networks because of limited bandwidth and storage space, which generates compression artifacts and the detection performance inevitably decreases. Hence, how to effectively identify compressed Deepfake videos over social networks becomes a significant problem in video forensics. In this paper, we propose a facial-muscle-motions-based (FAMM) framework to solve the problem of compressed Deepfake video detection. Specifically, we first locate faces from consecutive frames and extract landmarks from the face images. Then, continuous facial landmarks are utilized to construct facial muscle motion features by modeling the five sensory and face regions. Finally, we fuse the diverse forensic knowledge using Dempster-Shafer theory and provide the final detection results. Furthermore, we demonstrate the effectiveness of FAMM through analyzing mutual information, compression procedure, and facial landmarks for compressed Deepfake videos. Theoretical analyses illustrate that compression does not affect facial muscle motion feature construction and the differences in designed features exist between the real and Deepfake videos. Extensive experimental results conclude that the proposed method outperforms the state-of-the-art methods in detecting compressed Deepfake videos. More importantly, FAMM achieves comparable detection performance on compressed videos that are over real-world social networks.",Multimedia forensics;compressed deepfake videos;facial muscle movements;social networks,IEE
614,Harnessing the Power of ChatGPT to Decimate Mis/Disinformation: Using ChatGPT for Fake News Detection,K. M. Caramancion,2023,"In this paper, the ability of ChatGPT v3.5 to distinguish mis/disinformation against legitimate news content is tested using the current standard fake news test designed for human subject experiments. The test items consist of both news headlines on or before September 2021 in purely textual forms and headlines supported by graphics uploaded as links to an image hosting service. ChatGPT�s response to every test item is then compared with the associated legitimacy of the news headline as fact-checked by independent fact-checking agencies. Results indicate that ChatGPT could predict the legitimacy of every item with a solid 100% accuracy. Furthermore, the yield response time for the prompts is barely a second on average per test item. In the next iteration of this work, newer variants of ChatGPT will be examined to determine if they can detect more sophisticated forms of AI-generated cyber deception, particularly deepfakes.",ChatGPT;Fake News;Misinformation;Disinformation;Information Warfare;Cyber Deception,IEE
615,Deepfakes Examiner: An End-to-End Deep Learning Model for Deepfakes Videos Detection,H. Ilyas; A. Irtaza; A. Javed; K. M. Malik,2022,"Deepfakes generation approaches have made it possible even for less technical users to generate fake videos using only the source and target images. Thus, the threats associated with deepfake video generation such as impersonating public figures, defamation, and spreading disinformation on media platforms have increased exponentially. The significant improvement in the deepfakes generation techniques necessitates the development of effective deepfakes detection methods to counter disinformation threats. Existing techniques do not provide reliable deepfakes detection particularly when the videos are generated using different deepfakes generation techniques and contain variations in illumination conditions and diverse ethnicities. Therefore, this paper proposes a novel hybrid deep learning framework, InceptionResNet-BiLSTM, that is robust to different ethnicities and varied illumination conditions, and able to detect deepfake videos generated using different techniques. The proposed InceptionResNet-BiLSTM consists of two components: customized InceptionResNetV2 and Bidirectional Long-Short Term Memory (BiLSTM). In our proposed framework, faces extracted from the videos are fed to our customized InceptionResNetV2 for extracting frame-level learnable features. The sequences of features are then used to train a temporally aware BiLSTM to classify between the real and fake video. We evaluated our proposed approach on the diverse, standard, and largescale FaceForensics++ (FF++) dataset containing videos manipulated using different techniques (i.e., DeepFakes, FaceSwap, Face2Face, FaceShifter, and NeuralTextures) and the FakeA VCeleb dataset. Our method achieved an accuracy greater than 90% on DeepFakes, FaceSwap, and Face2Face subsets. Performance and generalizability evaluation highlights the effectiveness of our method for detecting deepfake videos generated through different techniques on diverse FF++ and FakeA VCeleb datasets.",Bidirectional LSTM;Deepfakes Detection;FaceForensics++;FakeAVCeleb;InceptionResNetV2;Puppet-master;Face-swap,IEE
616,Improving the Efficiency and Robustness of Deepfakes Detection through Precise Geometric Features,Z. Sun; Y. Han; Z. Hua; N. Ruan; W. Jia,2021,"Deepfakes is a branch of malicious techniques that transplant a target face to the original one in videos, resulting in serious problems such as infringement of copyright, confusion of information, or even public panic. Previous efforts for Deepfakes videos detection mainly focused on appearance features, which have a risk of being bypassed by sophisticated manipulation, also resulting high model complexity and sensitiveness to noise. Besides, how to mine the temporal features of manipulated videos and exploit them is still an open question. We propose an efficient and robust framework named LRNet for detecting Deepfakes videos through temporal modeling on precise geometric features. A novel calibration module is devised to enhance the precision of geometric features, making it more discriminative, and a two-stream Recurrent Neural Network (RNN) is constructed for sufficient exploitation of temporal features. Compared to previous methods, our proposed method is lighter-weighted and easier to train. Moreover, our method has shown robustness in detecting highly compressed or noise corrupted videos. Our model achieved 0.999 AUC on FaceForensics+ + dataset. Meanwhile, it has a graceful decline in performance (-0.042 AUC) when faced with highly compressed videos.1",,IEE
617,DeepVision: Deepfakes Detection Using Human Eye Blinking Pattern,T. Jung; S. Kim; K. Kim,2020,"In this paper, we propose a new approach to detect Deepfakes generated through the generative adversarial network (GANs) model via an algorithm called DeepVision to analyze a significant change in the pattern of blinking, which is a voluntary and spontaneous action that does not require conscious effort. Human eye blinking pattern has been known to significantly change according to the person's overall physical conditions, cognitive activities, biological factors, and information processing level. For example, an individual's gender or age, the time of day, or the person's emotional state or degree of alertness can all influence the pattern. As a result, Deepfakes can be determined through integrity verification by tracking significant changes in the eye blinking patterns in deepfakes by means of a heuristic method based on the results of medicine, biology, and brain engineering research, as well as machine learning and various algorithms based on engineering and statistical knowledge. This means we can perform integrity verification through tracking significant changes in the eye blinking pattern of a subject in a video. The proposed method called DeepVision is implemented as a measure to verify an anomaly based on the period, repeated number, and elapsed eye blink time when eye blinks were continuously repeated within a very short period of time. DeepVision accurately detected Deepfakes in seven out of eight types of videos (87.5% accuracy rate), suggesting we can overcome the limitations of integrity verification algorithms performed only on the basis of pixels.",Cyber security;deep-fake;GANs;deep learning,IEE
618,Privacy and Security Concerns in Generative AI: A Comprehensive Survey,A. Golda; K. Mekonen; A. Pandey; A. Singh; V. Hassija; V. Chamola; B. Sikdar,2024,"Generative Artificial Intelligence (GAI) has sparked a transformative wave across various domains, including machine learning, healthcare, business, and entertainment, owing to its remarkable ability to generate lifelike data. This comprehensive survey offers a meticulous examination of the privacy and security challenges inherent to GAI. It provides five pivotal perspectives essential for a comprehensive understanding of these intricacies. The paper encompasses discussions on GAI architectures, diverse generative model types, practical applications, and recent advancements within the field. In addition, it highlights current security strategies and proposes sustainable solutions, emphasizing user, developer, institutional, and policymaker involvement.",Generative artificial intelligence;privacy concerns;security concerns;deep learning;adversarial attacks;synthetic data;Deepfake;ethical implications;cybersecurity;machine learning;privacy protection;ethical responsibility;misinformation;social engineering;regulatory compliance;artificial intelligence;privacy preservation;data security;threat analysis,IEE
619,Attention-Guided Supervised Contrastive Learning for Deepfake Detection,S. Waseem; S. A. Rahman Bin Syed Abu Bakar; B. A. Ahmed,2024,"Recent advancements in face deepfake detection have shown impressive results. However, prior studies typically used crossentropy loss to approach face manipulation detection as a classification problem. Approaches based on cross-entropy loss prioritize category distinctions over capturing the underlying differences between real and fake faces, which restricts the model's capacity to generalize to unseen datasets. As original image or video can closely resemble the deepfake in terms of appearance, making it challenging to distinguish them, we propose to utilize the differences in the representation space to develop a generalizable detector. In this paper, we present an attention-guided supervised contrastive learning approach for deepfake detection, aiming to leverage differences in the representation space and prioritize disparities between classes rather than focusing solely on categories. By using supervised contrastive learning, the model learns to create a discriminative representation by contrasting between classes, while an attention module directs the model to relevant features for each class and filters out irrelevant features. This method learns features from a wide variety of deepfake images, thus improving the accuracy of deepfake detection in unseen datasets. Experimental results show the effectiveness of our attention-guided supervised contrastive learning deepfake detector on benchmark datasets such as FF++, Celeb-DF, DFD and DFDC-P.",Deepfake;Generalization;Contrastive learning;Attention,IEE
620,Model-Agnostic Method: Exposing Deepfake Using Pixel-Wise Spatial and Temporal Fingerprints,J. Yang; Y. Sun; M. Mao; L. Bai; S. Zhang; F. Wang,2023,"Deepfake poses a serious threat to the reliability of judicial evidence and intellectual property protection. Existing detection methods either blindly utilize deep learning or use biosignal features, but neither considers spatial and temporal relevance of face features. These methods are increasingly unable to resist the growing realism of fake videos and lack generalization. In this paper, we identify a reliable fingerprint through the consistency of AR coefficients and extend the original PPG signal to 3-dimensional fingerprints to effectively detect fake content. Using these reliable fingerprints, we propose a novel model-agnostic method to expose Deepfake by analyzing temporal and spatial faint synthetic signals hidden in portrait videos. Specifically, our method extracts two types of faint information, i.e., PPG features and AR features, which are used as the basis for forensics in temporal and spatial domains, respectively. PPG allows remote estimation of the heart rate in face videos, and irregular heart rate fluctuations expose traces of tampering. AR coefficients reflect pixel-wise correlation and spatial traces of smoothing caused by up-sampling in the process of generating fake faces. Furthermore, we employ two ACBlock-based DenseNets as classifiers. Our method provides state-of-the-art performance on multiple deep forgery datasets and demonstrates better generalization.",Auto-regressive (AR);deep learning;deepfake detection;fingerprint;photoplethysmography (PPG);temporal and spatial,IEE
621,Detectify : Image Tampering Detection using Error Level Analysis (ELA) and Convolutional Neural Network (CNN),T. M. Geethanjali; T. S. Darshan; K. Surya; H. U. Rahul; I. N. Sheety,2024,"In the evolving digital landscape, the proliferation of manipulated images poses a significant challenge to the authenticity and integrity of visual content. This project investigates cutting-edge image manipulation detection techniques, employing a combination of Error Level Analysis (ELA) and Convolutional Neural Networks (CNN) for robust prediction. Focusing on the widely-used CASIA V2.0 dataset, the study provides a comprehensive evaluation of image manipulation methods. Error Level Analysis is utilized as a forensic tool to identify alterations in the compression levels of manipulated images. By scrutinizing variations in error levels, the project aims to enhance the detection accuracy of manipulated regions within visual content. The CNN model is meticulously crafted and trained using preprocessed ELA images to acquire nuanced features essential for discerning tampering- induced alterations. The proposed hybrid approach, integrating ELA and CNN, establishes a robust framework for detecting image manipulation that is adaptable and efficient. Through the meticulous examination of the CASIA V2.0 dataset, this project contributes to ongoing efforts in combating digital image manipulation. This study serves as a valuable resource for forensic analysts, researchers, and practitioners working towards ensuring the veracity of digital images, offering a nuanced understanding of image manipulation techniques in the contemporary digital era.",Image manipulation detection;image tampering detection;CNN and ELA,IEE
622,DeepFake Creation and Detection:A Survey,S. P; S. Sk,2021,"DeepFake has become very popular of late. The term DeepFake refers to any multimedia content generated using deep learning technology appearing realistic to people. Despite the beneficial advances of DeepFake, it has been a major cause of threats to a person's privacy, where one person's face can be swapped with another in an indistinguishable way without consent. Also, it is easy for malicious parties to take over public events like elections by spreading misinformation and leaving a negative impact on national security. Thus, detection of such DeepFake is a crucial yet challenging problem. Human-eye-based segregation of DeepFaked contents from real ones has always been a difficult task; but recent works have shown the use of different technologies recording good results for the same, although with some limitations. The paper thus explores different algorithms used for DeepFake creation and detection; presenting a comprehensive overview of the techniques used and aimed at identifying their pros and cons.",DeepFake Creation and Detection;Face swapping;Encoder-Decoder;Generative adversarial network;LSTM;Convolutional neural network;Recurrent neural network,IEE
623,Beauty Moment Rendering via Face Happiness Scoring,D. -T. Luu; Q. -T. Dong; L. -Q. Nguyen; N. -K. Nguyen; T. -V. Nguyen; M. -T. Tran,2021,"Nowadays, with the rapid development of technology and an energetic lifestyle, people tend to use electronic devices to capture moments. Thus, the need to have a delightful selfie is increasing. This work introduces a Beauty Moment Rendering via Face Happiness Scoring framework, which aims to generate a key-frame that summarizes a short selfie video. Given a set of consecutive photos as input, our approach selects a single image and renders a face for each person at their happiest moment. In order to select a suitable key-frame, we decide to combine the eyes and emotion information as our aggregated score. First, the method detects and tracks the faces in the video frames. Then, the face that has the highest score of each person will be rendered on the result key-frame with the eye gazes being redirected based on a generative model. To the best of our knowledge, we are among the first to address the problem, which comprises video summarization and face beautification.",face happiness scoring;face detection;face tracking;image rendering;GAN,IEE
624,Evading DeepFake Detectors via Adversarial Statistical Consistency,Y. Hou; Q. Guo; Y. Huang; X. Xie; L. Ma; J. Zhao,2023,"In recent years, as various realistic face forgery techniques known as DeepFake improves by leaps and bounds, more and more DeepFake detection techniques have been proposed. These methods typically rely on detecting statistical differences between natural (i.e., real) and DeepFake-generated images in both spatial and frequency domains. In this work, we propose to explicitly minimize the statistical differences to evade state-of-the-art DeepFake detectors. To this end, we propose a statistical consistency attack (StatAttack) against DeepFake detectors, which contains two main parts. First, we select several statistical-sensitive natural degradations (i.e., exposure, blur, and noise) and add them to the fake images in an adversarial way. Second, we find that the statistical differences between natural and DeepFake images are positively associated with the distribution shifting between the two kinds of images, and we propose to use a distribution-aware loss to guide the optimization of different degradations. As a result, the feature distributions of generated adversarial examples is close to the natural images. Furthermore, we extend the StatAttack to a more powerful version, MStatAttack, where we extend the single-layer degradation to multi-layer degradations sequentially and use the loss to tune the combination weights jointly. Comprehensive experimental results on four spatial-based detectors and two frequency-based detectors with four datasets demonstrate the effectiveness of our proposed attack method in both white-box and black-box settings.",Image and video synthesis and generation,IEE
625,DFCP: Few-Shot DeepFake Detection via Contrastive Pretraining,B. Zou; C. Yang; J. Guan; C. Quan; Y. Zhao,2023,"Abuses of forgery techniques have created a considerable problem of misinformation on social media. Although scholars devote many efforts to face forgery detection (a.k.a DeepFake detection) and achieve some results, two issues still hinder the practical application. 1) Most detectors do not generalize well to unseen datasets. 2) In a supervised manner, most previous works require a considerable amount of manually labeled data. To address these problems, we propose a simple contrastive pertaining framework for DeepFake detection (DFCP), which works in a finetuning-after-pretraining manner, and requires only a few labels (5%). Specifically, we design a two-stream framework to simultaneously learn high-frequency texture features and high-level semantics information during pretraining. In addition, a video-based frame sampling strategy is proposed to mitigate potential noise data in the instance-discriminative contrastive learning to achieve better performance. Experimental results on several downstream datasets show the state-of-the-art performance of the proposed DFCP, which works at frame-level (w/o temporal reasoning) with high efficiency but outperforms video-level methods.",Face Forgery Detection;DeepFake;Self-supervised Learning;Contrastive Learning,IEE
626,Exploring the Potential Implications of AI-generated Content in Social Engineering Attacks,Y. Alahmed; R. Abadla; M. J. A. Ansari,2024,"The evolution of artificial intelligence (AI) and machine learning presents both utility and security implications for our digital interactions. This study focuses on the transformative role of generative AI in social engineering attacks, specifically examining three pillars where it significantly amplifies their impact: advanced targeting and personification, genuine content creation, and automated attack infrastructure. The analysis forms a conceptual model named the generative AI social engineering framework. The research delves into human implications and measures to counter social engineering attacks, blending theoretical analysis with practical insights through case studies. Ethical considerations surrounding AI in malicious activities are discussed, emphasizing the importance of safe AI development, and various articles were reviewed to highlight social engineering attacks as a common threat. Two studies were conducted: a user testing study with 48 participants from diverse occupations and social engineering awareness, and an exploratory study collecting qualitative data from 40 social engineering attack victims. The user testing study revealed universal acceptance of the AI-based tool, irrespective of participants� occupations. Victim themes included reasons for falling prey to attacks, methods, prevention advice, and detection. The research concludes by highlighting AI-generated content as a key factor fueling social engineering attacks and bridging the gap between AI development and cybersecurity practices, highlighting the need for interdisciplinary approaches to address evolving challenges.",Machine learning;Chatbot;social engineering;Artificial intelligence;Phishing;ChatGPT,IEE
627,An Analysis of Recent Advances in Deepfake Image Detection in an Evolving Threat Landscape,S. M. Abdullah; A. Cheruvu; S. Kanchi; T. Chung; P. Gao; M. Jadliwala; B. Viswanath,2024,"Deepfake or synthetic images produced using deep generative models pose serious risks to online platforms. This has triggered several research efforts to accurately detect deepfake images, achieving excellent performance on publicly available deepfake datasets. In this work, we study 8 state-of-the-art detectors and argue that they are far from being ready for deployment due to two recent developments. First, the emergence of lightweight methods to customize large generative models, can enable an attacker to create many customized generators (to create deepfakes), thereby substantially increasing the threat surface. We show that existing defenses fail to generalize well to such user-customized generative models that are publicly available today. We discuss new machine learning approaches based on content-agnostic features, and ensemble modeling to improve generalization performance against user-customized models. Second, the emergence of vision foundation models�machine learning models trained on broad data that can be easily adapted to several downstream tasks�can be misused by attackers to craft adversarial deepfakes that can evade existing defenses. We propose a simple adversarial attack that leverages existing foundation models to craft adversarial samples without adding any adversarial noise, through careful semantic manipulation of the image content. We highlight the vulnerabilities of several defenses against our attack, and explore directions leveraging advanced foundation models and adversarial training to defend against this new threat.",deepfake image;foundation models;generative models;deepfake detection,IEE
628,Metamorphic Testing-based Adversarial Attack to Fool Deepfake Detectors,N. T. Lim; M. Yi Kuan; M. Pu; M. K. Lim; C. Yong Chong,2022,"Deepfakes utilise Artificial Intelligence (AI) techniques to create synthetic media where the likeness of one person is replaced with another. There are growing concerns that deepfakes can be maliciously used to create misleading and harmful digital contents. As deepfakes become more common, there is a dire need for deepfake detection technology to help spot deepfake media. Present deepfake detection models are able to achieve outstanding accuracy (>90%). However, most of them are limited to within-dataset scenario. Most models do not generalise well enough in cross-dataset scenario. Furthermore, state-of-the-art deepfake detection models rely on neural network-based classification models that are known to be vulnerable to adversarial attacks. Motivated by the need for a robust deepfake detection model, this study adapts metamorphic testing (MT) principles to help identify potential factors that could influence the robustness of the examined model, while overcoming the test oracle problem in this domain. Metamorphic testing is specifically chosen as the testing technique as it fits our demand to address learning-based system testing with probabilistic outcomes from largely black-box components, based on potentially large input domains. We performed our evaluations on MesoInception-4 and TwoStreamNet models, which are the state-of-the-art deepfake detection models. This study identified makeup application as an adversarial attack that could fool deepfake detectors. Our experimental results demonstrate that both the MesoInception-4 and TwoStreamNet models degrade in their performance by up to 30% when the input data is perturbed with makeup.",,IEE
629,Boosting Deep Feature Fusion-Based Detection Model for Fake Faces Generated by Generative Adversarial Networks for Consumer Space Environment,F. Alrowais; A. Abbas Hassan; W. Sulaiman Almukadi; M. H. Alanazi; R. Marzouk; A. Mahmud,2024,"In the consumer space, deep fakes refer to highly realistic, AI-generated images, audio, or videos that mimic real people generated by cutting-edge technologies such as Generative Adversarial Networks (GANs). In the digital age, recognizing and detecting deepfakes is a critical problem. The most common solutions for deepfake creation are those based on GANs, which can efficiently manipulate multimedia data or create from scratch. GANs comprise two neural networks, a Generator (G) and a Discriminator (D), that concurrently work during competition. The generator generates artificial data, whereas the discriminator calculates the authenticity of generated and real data. This adversarial procedure causes the generator to generate more realistic content. Identifying deep fakes produced by GANs using deep learning (DL) includes leveraging complex neural networks to detect subtle anomalies and artefacts that GANs accidentally introduce. Convolutional Neural Network (CNN) are very effective for these tasks, as they learn to discern inconsistencies and complex features in image textures, lighting, and facial features frequently missed by human eyes. This CNN model is trained on a massive database of fake and authentic images, allowing them to detect minor defects. This study presents a Deep Feature Fusion-based Fake Face Detection Generated by Generative Adversarial Networks (DF4D-GGAN) technique for Consumer Space Environment. The goal of the DF4D-GGAN technique is to detect the presence of real or deepfake images generated by DL. In the DF4D-GGAN technique, the Gaussian filtering (GF) approach is used for preprocessing the input images. Besides, the feature fusion process uses EfficientNet-b4 and ShuffleNet. Moreover, the hyperparameter selection of the DL models is performed by an improved slime mould algorithm (ISMA). Finally, an extreme learning machine (ELM) classifier has been employed to proficiently recognize real and fake images. To validate the results of the DF4D-GGAN technique, a series of simulations were made on benchmark datasets. The results stated that the DF4D-GGAN technique gains improved results over other models.",Consumer space;deepfake image detection;generative adversarial network;slime mould algorithm;image processing;CNN,IEE
630,Faux Reality Detector,S. K. R; S. A; V. R; S. K. M; S. J,2024,"With the advent of a new era in digital content creation, deep learning and generative models have completely changed the way we interact with multimedia. Strong generative adversarial networks (GANs) have been developed, but this has led to grave worries about the potential for malevolent usage. Deep fakes, which are produced by GAN and are hyper-realistic digital forgeries that might be used to spread incorrect information and fool people, pose a serious threat to civilization. As a result, developing reliable and effective deep fake detection algorithms has become an important study area. The major goal of this project is to create and deploy a deep fake detection system that can accurately identify between authentic and false images. Such fake faces can be recognized using a deep learning architecture based on CNNs (Convolutional Neural Networks). Such fake faces can be identified with practically perfect accuracy using a deep learning architecture based on CNNs (Convolutional Neural Networks). based on the fact that the textures of real faces and synthetic ones are very different. The comprehensive research and analysis carried out to understand the fundamental concepts underlying deep fake generation and detection are described in this paper.",Generative A dversa ria I Networks;Fake detection;Deep learning architecture and Convolutional Neural Network,IEE
631,Behavioral Biometrics Authentication Systems: Leveraging Machine Learning for Enhanced Cybersecurity,J. B. Madavarapu; M. Mittal; S. Salagrama; M. M. Adnan; A. Rana; K. Yadav,2024,"This study focuses on behavioral biometrics and machine learning procedure that is employed vigorous in the verification frameworks to improve cybersecurity. Elaborating interesting designs in client behaviour, such as keystroke flow and mouse developments along with advanced machine learning algorithms we propose to generate verification components capable of accurately identifying a person's identity while adapting themselves all the fast live changes associated either. The experiments carried out on real-life datasets demonstrate LSTM models pervasive implementation in contrast to traditional machine learning algorithms (SVM, KNN and Random Forest). Thus, LSTM achieved an accuracy of 95.6%, outperforming SVM (88.7%), KNN (84.5%) and Random Forest (923). Additionally, LSTM proved great flexibility and competitive performance despite longer training times. The abovementioned results have demonstrated that LSTM is effective in learning the complicated real world conditions in sequential data and could be used for improvement of behavioral biometric recognition systems.",Behavioral Biometrics;Machine Learning;Authentication Systems;Cybersecurity;Long Short-Term Memory (LSTM),IEE
632,Virtual Illusions: Unleashing Deepfake Expertise for Enhanced Visual Effects in Film Production,S. Mittal; M. Joshi; P. Vats; G. M. Upadhayay; S. K. Vats; S. Kumar,2024,"As technology continues to evolve, the realm of visual effects in film production has witnessed a significant transformation. Deepfake technology, once associated with controversial uses, has found a legitimate and innovative application within the filmmaking industry. This paper explores the integration of deepfake expertise into film production processes, focusing on its potential to revolutionize visual effects and storytelling. By harnessing deep learning algorithms, filmmakers can create hyper-realistic digital assets, seamlessly blending fiction with reality. This paper delves into the ethical considerations, creative possibilities, and technical challenges associated with the utilization of deepfake technology in filmmaking. Furthermore, it examines case studies and industry trends to provide insights into the current landscape and prospects of incorporating deep fake expertise for enhanced visual effects in film production.",Deepfake;Visual Effects;Film Production;Deep Learning;Digital Assets;Storytelling;Ethics;Technology Integration,IEE
633,An Overview of Affective Speech Synthesis and Conversion in the Deep Learning Era,A. Triantafyllopoulos; B. W. Schuller; G. ?ymen; M. Sezgin; X. He; Z. Yang; P. Tzirakis; S. Liu; S. Mertes; E. Andr�; R. Fu; J. Tao,2023,"Speech is the fundamental mode of human communication, and its synthesis has long been a core priority in human�computer interaction research. In recent years, machines have managed to master the art of generating speech that is understandable by humans. However, the linguistic content of an utterance encompasses only a part of its meaning. Affect, or expressivity, has the capacity to turn speech into a medium capable of conveying intimate thoughts, feelings, and emotions�aspects that are essential for engaging and naturalistic interpersonal communication. While the goal of imparting expressivity to synthesized utterances has so far remained elusive, following recent advances in text-to-speech synthesis, a paradigm shift is well under way in the fields of affective speech synthesis and conversion as well. Deep learning, as the technology that underlies most of the recent advances in artificial intelligence, is spearheading these efforts. In this overview, we outline ongoing trends and summarize state-of-the-art approaches in an attempt to provide a broad overview of this exciting field.",Affective computing;deep learning;emotional voice conversion (EVC);speech synthesis,IEE
634,Towards Spatio-temporal Collaborative Learning: An End-to-End Deepfake Video Detection Framework,W. Guo; S. Du; H. Deng; Z. Yu; L. Feng,2023,"With the rapid development of facial tampering techniques, the deepfake detection task has attracted widespread social concerns. Most existing video-based methods adopt temporal convolution to learn temporal discontinuities directly, where they might neglect to explore both local detail mutation and inconsistent global expression semantics in the temporal dimension. This makes it difficult to learn more discriminative forgery cues. To mitigate this issue, we introduce a novel deepfake video detection framework specifically designed to capture fine-grained traces of tampering. Concretely, we first present a Multi-layered Feature Extraction module (MFE) that constructs comprehensive spatio-temporal representations by stitching different levels of features together. Afterward, we propose a Bidirectional temporal Artifact Enhancement module (BAE), which exploits local differences between adjacent frames to enhance frame-level features. Moreover, we present a Cross temporal Stride Aggregation strategy (CSA) to mine inconsistent global semantics and adaptively obtain multi-timescale representations. Extensive experiments on several benchmarks demonstrate that the proposed method outperforms state-of-the-art performance compared to other competitive approaches.",Deepfake Detection;Spatio-temporal Modeling;Face Forensics;Deep Learning,IEE
635,TruFor: Leveraging All-Round Clues for Trustworthy Image Forgery Detection and Localization,F. Guillaro; D. Cozzolino; A. Sud; N. Dufour; L. Verdoliva,2023,"In this paper we present TruFor, a forensic framework that can be applied to a large variety of image manipulation methods, from classic cheapfakes to more recent manipulations based on deep learning. We rely on the extraction of both high-level and low-level traces through a transformer-based fusion architecture that combines the RGB image and a learned noise-sensitive fingerprint. The latter learns to embed the artifacts related to the camera internal and external processing by training only on real data in a self-supervised manner. Forgeries are detected as deviations from the expected regular pattern that characterizes each pristine image. Looking for anomalies makes the approach able to robustly detect a variety of local manipulations, ensuring generalization. In addition to a pixel-level localization map and a whole-image integrity score, our approach outputs a reliability map that highlights areas where localization predictions may be error-prone. This is particularly important in forensic applications in order to reduce false alarms and allow for a large scale analysis. Extensive experiments on several datasets show that our method is able to reliably detect and localize both cheapfakes and deepfakes manipulations outperforming state-of-the-art works. Code is publicly available at https://grip-unina.github.io/TruFor/",Computer vision for social good,IEE
636,ForgeryNIR: Deep Face Forgery and Detection in Near-Infrared Scenario,Y. Wang; C. Peng; D. Liu; N. Wang; X. Gao,2022,"Deep face forgery and detection is an emerging topic due to the development of GANs. Face forgery detection relies greatly on existing databases for evaluation and adequate training examples for data-hungry machine learning algorithms. However, considering the wide application of face recognition in near-infrared scenarios, there is no publicly available face forgery database that includes near-infrared modality currently. In this paper, we present an attempt at constructing a large-scale dataset for face forgery detection in the near-infrared modality and propose a new forgery detection method based on knowledge distillation named cross-modality knowledge distillation aiming to use a teacher model which is pre-trained on the visible light-based (VIS) big data to guide the student model with a small amount of near-infrared (NIR) data. The proposed near-infrared face forgery dataset, named ForgeryNIR, contains a total of over 50,000 real and fake identities. A number of perturbations are applied to help simulate real-world scenarios. All source images in ForgeryNIR are collected from CASIA NIR-VIS 2.0, and fake images are generated via multiple GAN techniques. The proposed dataset fills the gap of face forgery detection research in the near-infrared modality. A comprehensive study on six representative detection baselines is conducted to evaluate the performance of face forgery detection algorithms in the NIR domain. We further construct a hard testing set, named ForgeryNIR+, which contains forged images that have bypassed existing face forgery detection methods. The proposed datasets will be publicly available and aim to help boost further research on face forgery detection, as well as NIR face detection and recognition.",Near-infrared face;face forgery detection;deepfake,IEE
637,Exposing Deepfake Videos by Tracking Eye Movements,M. Li; B. Liu; Y. Hu; Y. Wang,2021,"It has recently become a major threat to the public media that fake videos are rapidly spreading over the Internet. The advent of Deepfake, a deep-learning based toolkit, has facilitated a massive abuse of improper synthesized videos, which may influence the media credibility and human rights. A worldwide alert has been set off that finding ways to detect such fake videos is not only crucial but also urgent. This paper reports a novel approach to expose deepfake videos. We found that most fake videos are markedly different from the real ones in the way the eyes move. We are thus motivated to define four features that could well capture such differences. The features are then fed to SVM for classification. It is shown to be a promising approach that without high dimensional features and complicated neural networks, we are able to achieve competitive results on several public datasets. Moreover, the proposed features could well participate with other existing methods in the confrontation with deepfakes.",,IEE
638,Efficient Identification of DeepFake Images using CNN,N. C. Gowda; V. H N; D. R. Ramani,2024,"The development of Deepfakes has become more prevalent with the rise of Generative Adversarial Networks (GANs). Deepfakes are synthetically created, modified images that have been made to look real; they pose severe social concerns with privacy an d security issues. To solve these issues, this paper offers a novel method to detect Deepfakes in photographs using a Convolutional Neural Network (CNN) architecture. To detect whether a image has been altered or not, the suggested method examines many aspects of the image. The proposed methods are tested using a sizable benchmark dataset of Deepfakes and non-Deepfakes, and were able to identify modified images with high precision. The strategy is resistant to a variety of manipulations, including those intended to trick cutting-edge detection techniques. It is found that proposed strategy will improve digital media's security and credibility while helping mitigate any possible problems of Deepfake images.",DeepFake;Generative Adversarial Networks (GANs);Deeplearning;Convolutional Neural Network (CNN),IEE
639,GAN Generated Fake Human Face Image Detection,S. Shilaskar; M. Talewar; S. Tak; S. Goud,2024,"In recent years, Generative Adversarial Networks (GANs) have revolutionized the generation of synthetic data that closely mimics real-world distributions. This research paper focuses on detecting fake human face images generated through GANs. The paper provides a thorough analysis of the current state of GAN-generated fake human face detection and proposes a novel method for robust detection. Existing detection methods often struggle with newly emerging GAN architectures, lack generalization capabilities, and are prone to adversarial attacks. In this paper, authors propose an efficient Convolutional Neural Network (CNN) architecture that detects StyleGAN3-generated fake human faces. To enhance the robustness of the model the algorithm employs a series of filters to extract image data, performs grayscale normalization and convolutional operations to find out whether the images are fake or real with more accuracy. The outcomes of the experiments demonstrate that the approach outperforms the current systems in terms of robustly identifying fake images. Authors achieved an accuracy of 99.42%. This system can be integrated into social media platforms to identify fake profile pictures or deepfake images that are often used for impersonation or spreading misinformation.",GANs;Convolutional Neural Network;StyleGAN3;Deep Learning;Fake Human Face Detection,IEE
640,Enhancing Deepfake Image Detection with Deep Convolutional Neural Networks,S. Bhamare; S. Bhamare,2023,"The availability of image editing software such as Adobe Photoshop or GIMP has made picture alteration so widespread these days. Finding these phony photos is a must for exposing image-based cyber crimes. Due to its ubiquity, images produced with a digital camera or smartphone are typically saved in the JPEG format. The 8�8 pixel-sized, independently compressed mage grids used by the JPEG technique are used. Images that haven't been altered have a comparable inaccuracy level. Due to a similar number of faults throughout the whole image, each block should degrade at roughly the same rate during resaving operations. Error Level Analysis was used to determine that the compression ratio of the false image was different from the actual images.",Image Forensics;Image Alteration Detection;Error Level Analysis;Digital Image Manipulation,IEE
641,Action-Independent Generalized Behavioral Identity Descriptors for Look-alike Recognition in Videos,A. Khodabakhsh; H. Loiselle,2020,"There is a long history of exploitation of the visual similarity of look-alikes for fraud and deception. The visual similarity along with the application of physical and digital cosmetics greatly challenges the recognition ability of average humans. Face recognition systems are not an exception in this regard and are vulnerable to such similarities. In contrast to physiological face recognition, behavioral face recognition is often overlooked due to the outstanding success of the former. However, the behavior of a person can provide an additional source of discriminative information with regards to the identity of individuals when physiological attributes are not reliable. In this study, we propose a novel biometric recognition system based only on facial behavior for the differentiation of look-alikes in unconstrained recording conditions. To this end, we organized a dataset of 85, 656 utterances from 1000 look-alike pairs based on videos collected from the wild, large enough for the development of deep learning solutions. Our selection criteria assert that for these collected videos, both state-of-the-art biometric systems and human judgment fail in recognition. Furthermore, to utilize the advantage of large-scale data, we introduce a novel action-independent biometric recognition system that was trained using triplet-loss to create generalized behavioral identity embeddings. We achieve look-alike recognition equal-error-rate of 7.93% with sole reliance on the behavior descriptors extracted from facial landmark movements. The proposed method can have applications in face recognition as well as presentation attack detection and Deepfake detection.",Behavioral Biometrics;Face Recognition;Look-alike face;Facial Motion;Triplet Loss,IEE
642,Fake News Detection: An Effective Content-Based Approach Using Machine Learning Techniques,E. Z. Mathews; N. Preethi,2022,"Fake news is any information fabricated to mislead readers to spread an idea for certain gains (usually political or financial). In today's world, accessing and sharing information is very fast and almost free. Internet users are growing significantly than ever before. Therefore, online platforms are perfect grounds to spread information to a broader section of society. What could circulate between a relative few can now circulate globally overnight. This advantage also marked the increase in the number of fake news attacks by its users, which is unsuitable for a healthy society. Therefore, there is a need for good algorithms to identify and take down fake information as soon as they appear. This paper aims at solving the problem by automating the process of identifying fake news using its content. Evaluation metrics like the accuracy of correct classification, precision, recall and f1-score assess the performance of the approach. The machine learning approach achieved its best performance with 96.7 percentage accuracy, 96.2 percentage precision, 97.5 percentage recall and 96.9 percentage f1 score on the ISOT dataset.",Fake News;Natural Language Processing;Machine Learning;Support Vector Classifier;Passive-Aggressive Classifier;Voting Classifier,IEE
643,Fake Faces Unveiled: A Comprehensive Study on Detecting Generated Facial Images,R. Chauhan; M. Sethi; S. Ahuja,2024,"As a result of AI�s rapid development in recent years, a wide range of tools and methods for editing multimedia have found widespread use. When technology was readily available, it was often misused or exploited illegally instead of being put to good use in areas such as entertainment and education. The term �deep fake� was used relatively recently to characterize digitally altered films and photos that pass muster as legitimate and high-quality productions. The literature review led to the discovery of multiple methods for detecting deep fakes. It is crucial to work on improving fraud detection systems and expanding video and audio forensics studies. In this article, we take a closer look at some of the various deep fake creation and detection algorithms now under study like Xception Network, Long Short Term Memory (LSTM), Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN). The detection of deep fake system will be served using by these techniques. We also used a standardized way to compare various approaches.",Convolutional neural networks;Recurrent neural networks;Deep Fake;Generative adversarial networks;Face recognition,IEE
644,Deepfakes for Histopathology Images: Myth or Reality?,N. Alrasheed; A. Zachariah; S. Prasanna; D. Rao; P. Rao,2020,"Deepfakes have become a major public concern on the Internet as fake images and videos could be used to spread misleading information about a person or an organization. In this paper, we explore if deepfakes can be generated for histopathology images using advances in deep learning. This is because the field of digital pathology is gaining a lot of momentum since the Food and Drug Administration (FDA) approved a few digital pathology systems for primary diagnosis and consultation in the United States. Specifically, we investigate if state-of-the- art generative adversarial networks (GANs) can produce fake histopathology images that can trick an expert pathologist. For our investigation, we used whole slide images (WSIs) hosted by The Cancer Genome Atlas (TCGA). We selected 3 WSIs of colon cancer patients and produced 100,000 patches of 256�256 pixels in size. We trained three popular GANs to generate fake patches of the same size. We then constructed a set of images containing 30 real and 30 fake patches. An expert pathologist reviewed these images and marked them as either real or fake. We observed that the pathologist marked 10 fake patches as real and correctly identified 34 patches (as fake or real). Thirteen patches were incorrectly identified as fake. The pathologist was unsure of 3 fake patches. Interestingly, the fake patches that were correctly identified by the pathologist, had missing morphological features, abrupt background change, pleomorphism, and other incorrect artifacts. Our investigation shows that while certain parts of a histopathology image can be mimicked by existing GANs, the intricacies of the stained tissue and cells cannot be fully captured by them. Unlike radiology, where it is relatively easier to manipulate an image using a GAN, we argue that it is a harder challenge in digital pathology to generate an entire WSI that is fake.",Deepfakes;generative adversarial networks;histopathology images;whole slide imaging;deep learning,IEE
645,Image Animations on Driving Videos with DeepFakes and Detecting DeepFakes Generated Animations,Y. S. Malik; N. Sabahat; M. O. Moazzam,2020,"The concept of image animation is to create a video or animation such that an object from an image is animated as per the motion of driving video. We plan to analyze with minor modifications of an existing framework which does this without any information beforehand about the object which is to be animated. To achieve that, we train our dataset on a set of images and videos for the objects of same category, for example (face, body, street views) etc. Some recent applications of neural networks (CNN) have proved to form realistic human heads. Realistic talking heads can be created by training the dataset of large number of images and videos. A source image of a person can be animated on target poses of a person (driving video), by keeping the appearance and body of the person. However, on the parallel side, there are advancements in the development of systems which are capable of detecting DeepFakes generated videos and animations as it is a crucial security concern. We did experiments on Image Animation to achieve talking heads, Image generations with conditional generative adversarial networks for DeepFakes Generations and the results were realistic. Moreover, we implemented a DeepFake Detector XceptionNet with minor modifications which achieved 95% accuracy on detecting DeepFakes. At last, we implemented a newly introduced technique in which the DeepFake generation is perturbed through which it can easily fool the deepfake detector. XceptionNet was able to achieve less than 30% accuracy on detecting DeepFakes generations when they were perturbed.",DeepFakes;Image Animation;DeepFakes Generations;Detection of DeepFakes;GANS;Adversarial Attacks;Fooling DeepFake Detectors,IEE
646,Forgery Face Image Detection Based on Improved Capsule Network,Y. Liu; Q. Qin; W. Yang; A. Wu; W. Ma; J. Zhang,2022,"Face forgery technologies may have a significant adverse impact on individual privacy and national political security. In this paper, a simple but effective method for detecting forgery face image based on improved capsule network is proposed. More specifically, we first adopt the part of per-trained VGG19 to extract latent features for better classification. Then, the improved capsule network architecture makes use of exponential linear unit (ELU) instead of the traditional rectified linear unit (ReLU) to improve the learning speed and convergence properties. Moreover, the effective attention mechanisms are embedded into the improved capsule network for further improving the detecting accuracy performance. Experimental results on four famous face forgery datasets demonstrate that the proposed framework outperforms other state-of-the-art approaches.",Forgery face detection;VGG-19;Capsule network;ELU;Attention mechanism,IEE
647,Digital Image Forensic Analyzer to Detect AI-generated Fake Images,G. Monkam; J. Yan,2023,"In recent years, the widespread use of smartphones and social media has led to a surge in the amount of digital content available. However, this increase in the use of digital images has also led to a rise in the use of techniques to alter image contents. Therefore, it is essential for both the image forensics field and the general public to be able to differentiate between genuine or authentic images and manipulated or fake imagery. Deep learning has made it easier to create unreal images, which underscores the need to establish a more robust platform to detect real from fake imagery. However, in the image forensics field, researchers often develop very complicated deep learning architectures to train the model. This training process is expensive, and the model size is often huge, which limits the usability of the model. This research focuses on the realism of state-of-the-art image manipulations and how difficult it is to detect them automatically or by humans. We built a machine learning model called G-JOB GAN, based on Generative Adversarial Networks (GAN), that can generate state-of-the-art, realistic-looking images with improved resolution and quality. Our model can detect a realistically generated image with an accuracy of 95.7%. Our near future aim is to implement a system that can detect fake images with a probability of odds of 1- P, where P is the chance of identical fingerprints. To achieve this objective, we have implemented and evaluated various GAN architectures such as Style GAN, Pro GAN, and the Original GAN.",Adversarial Networks;GANs;Classification;CNN;Deep Learning,IEE
648,Abbreviated View of Deepfake Videos Detection Techniques,M. A. Younus; T. M. Hasan,2020,"In the era of technological advances and a qualitative breakthrough in the artificial intelligence field and deep neural networks, a new age of hyper-realistic digital videos forgery called DeepFake has been born, with that new technology, it is difficult to distinguish between real videos and fake ones which are uploaded daily on various websites across the Internet. Many open-source DeepFake creation methods have risen, leading to a growing number of synthesized media clips over the internet. There are many efficient fast methods and techniques which have been designed to detect and spot such phenomenon. Background Comparison, Temporal Pattern Analysis, Eye blinking, Facial Artifacts, Mesoscopic Analysis, and Pose Estimation are some of those techniques. Some of these approaches designed to detect and identify the video forgery without any prior enlightenment concerning the videos under analysis. The primary scope of this study is to provide an abbreviate review of these methodologies of a method-comparison study that has been presented to assist the researcher's evaluation of such studies.",Digital videos forgery;Deepfake Detection techniques;Mesoscopic;Facial Artifacts,IEE
649,Face Morphing Detection in Social Media Content,A. Agarwal; N. Ratha,2024,"Face being an active medium of communication is a significant part of our social media life; however, faces are vulnerable to manipulations. Among various manipulations, face morphing is a well-known tampering technique that aims to generate images containing information from more than one identity. Morphed images are heavily used for various malicious purposes including sarcasm, money laundering, and pornography. For many of the above harmful purposes, these manipulated images are uploaded on social media platforms where they can further go through tampering using social-media filters. Interestingly, the existing morph attack detection works have not addressed social media�s impact on deceiving face morph detectors. In this research, for the first time, we have generated authentic (or real) and face-morphed images impacted by one of the premium features of social media platforms known as filtering. We have used 13 Instagram filters and performed an extensive study on the proposed social-media morphed dataset. It is demonstrated that these filters can radically reduce the morph detection performances of several popular deep-learning classifiers. Therefore, to effectively address the concerns of face morphing and social media filtering, we propose a robust ViT-CNN architecture to advance the morph image detection performance.",Digital Threats;Face Morphing;Social-Media Filters;Robust Morph Detector,IEE
650,Jointly Defending DeepFake Manipulation and Adversarial Attack Using Decoy Mechanism,G. -L. Chen; C. -C. Hsu,2023,"Highly realistic imaging and video synthesis have become possible and relatively simple tasks with the rapid growth of generative adversarial networks (GANs). GAN-related applications, such as DeepFake image and video manipulation and adversarial attacks, have been used to disrupt and confound the truth in images and videos over social media. DeepFake technology aims to synthesize high visual quality image content that can mislead the human vision system, while the adversarial perturbation attempts to mislead the deep neural networks to a wrong prediction. Defense strategy becomes difficult when adversarial perturbation and DeepFake are combined. This study examined a novel deceptive mechanism based on statistical hypothesis testing against DeepFake manipulation and adversarial attacks. First, a deceptive model based on two isolated sub-networks was designed to generate two-dimensional random variables with a specific distribution for detecting the DeepFake image and video. This research proposes a maximum likelihood loss for training the deceptive model with two isolated sub-networks. Afterward, a novel hypothesis was proposed for a testing scheme to detect the DeepFake video and images with a well-trained deceptive model. The comprehensive experiments demonstrated that the proposed decoy mechanism could be generalized to compressed and unseen manipulation methods for both DeepFake and attack detection.",Adversarial attack;adversarial defense;decoy mechanism;DeepFake detection,IEE
651,Exploring Deepfake Detection: A Comparative Study of CNN Models,Raveena; R. Chhikara; P. Punyani,2024,"The rapid advancement of deep learning methodologies has given rise to worries regarding the misuse of hyper-realistic multimedia due to the introduction of deepfake content created by generative adversarial network (GAN) models. Deepfakes, which include altered audio and/or video clips that are nearly identical to real ones, can be used maliciously for things like propaganda, cybercrimes, and political campaigns. To address this challenge, a comparison is conducted involving several CNN models, like EfficientNetB0, VGG-16, DenseNet121, VGG-19, MobileNetV2, ResNet50, InceptionV3, and Xception for deepfake detection. The models are trained using transfer learning technique and by fine-tuning them on the dataset using various hyperparameters. The performance analysis was performed on six cases in which the optimizer, learning rate, batch size, and epochs were adjusted. By exploring this comparative study, a contribution is made to the development of more robust solutions for detecting deepfakes. A thorough analysis of different pre-trained models is conducted and verified, based on the reported outcomes, ResNet50 outperforms the other models. The evaluation of the model's performance involves the comparison of various metrics that have been identified, such as Accuracy, Precision, AUC-ROC curve, and F1-score.",Deepfakes;Deep-Learning;Convolution Neural Networks,IEE
652,Efficient Face-Swap-Verification Using PRNU,A. Hassani; H. Malik,2022,"Facial recognition is becoming the go-to method of identifying users for convenience applications. While great advances have occurred in achieving strong false acceptance and false rejection rates on authentic images, these systems can be vulnerable to face-swap-attacks. This research addresses face-swap-attacks via camera forensics. Whenever an image is modified, there is necessarily an impact to the noise profile (in this case Photo Response Non-Uniformity). Hence, a framework is proposed to enroll the facial recognition camera's �noiseprint� and assess authenticity on future images based on deviation from expected value. This is done using down-sampling compression to improve run time, where images are further segmented into sub-zones to retain local sensitivity. Framework performance is evalu-ated by recording identical facial-images using multiple cameras of the same make. Next, a subset is modified via hand-crafted and AI-tool face-swaps. 100% of images are correctly identified as authentic or tampering when using full-image analysis at full-scale. Efficiency is then optimized by dividing the image into sub-zones and applying compression. Run-time is improved to 4.6 msec on CPU, a 99.1% reduction, by applying quarter-scale down-sampling with 16 sub-zones (this retains 93.5% verification accuracy). These results are validated against three existing state-of-the-art algorithms, which in comparison show over-fitting when compressed. This demonstrates that compressed PRNU can be used to efficiently verify facial-images, including against AI facial manipulation tools.",Digital Cameras;Forensics;Face Recognition;Real-Time Systems;Pattern Recognition;Compressed Sensing,IEE
653,Deep Learning-Based Gender Classification by Training With Fake Data,M. Oulad-Kaddour; H. Haddadou; C. C. Vilda; D. Palacios-Alonso; K. Benatchba; E. Cabello,2023,"Gender classification of human faces is a trending topic and a remarkable biometric task. This research area has useful applications in several fields, such as automated border control (ABC) and forensic work. There are many approaches to gender classification in the literature; the classical approaches usually use real faces. Although good performances have been achieved, data collection remains a problem. Additionally, the privacy of individuals must be included in many existing works. These drawbacks can be overcome by using fake faces. Recently, the creation of a robust fake face corpus using machine learning has become possible. Our main contribution in the present paper is to experimentally investigate the ability of an artificial deepfake corpus to be a substitute for real corpora in facial gender classification tasks. We propose a deep learning-based approach using convolutional neural networks trained with fake faces and tested on real faces. By exploiting artificial faces, data collection obstacles are resolved for the training step, and privacy is highly preserved. Four classifiers based on popular convolutional neural network architectures were implemented. In the test phase, we used faces of real identities extracted from well-known experimental databases such as Face Recognition Technology (FERET), Faculdade de Engenharia Industrial (FEI) faces, Face Recognition and Artificial Vision (FRAV) and Labeled Faces in the Wild (LFW). The results achieved are very promising. We obtained high accuracy rates and low EER scores. They are similar to those of research works using real faces. As a result of this work, we propose a gender-labeled deepfake facial dataset containing more than 200k deepfake corpora that we will make available upon request for research purposes.",Adversarial neural networks;convolutional neural networks;deep learning;fake faces;gender classification,IEE
654,Fake Image Detection Using An Ensemble of CNN Models Specialized For Individual Face Parts,A. Kawabe; R. Haga; Y. Tomioka; Y. Okuyama; J. Shin,2022,"With the rapid increase of deep learning technology, creating human face images with artificial intelligence (AI) is becoming easier. Those generated images are coming up to images that humans cannot distinguish from authentic ones. It is essential to realize an accurate method to detect such fake images to avoid abusing them. In this paper, we propose a fake image detection using an ensemble model of convolutional neural network (CNN) models that focus on deepfake detection of individual face parts. Our results show that a combination of deepfake detection based on different face parts is effective. This idea can be adopted on partially manipulated deepfake images/videos.",deepfake;deep learning;ensemble learning,IEE
655,A Graph Neural Network Model for Live Face Anti-Spoofing Detection Camera Systems,J. Xu; W. Lin; W. Fan; J. Chen; K. Li; X. Liu; G. Xu; S. Yi; J. Gan,2024,"As the demand for the Internet of Things (IoT) grows, it becomes crucial to possess systems capable of detecting any data leakage used for authentication. Within IoT camera systems based on facial bio-metric recognition, there is a risk of deepfake bypassed facial feature authentication due to the widespread use of deepfake video technologies, such as DeepFaceLive and expression manipulation. Traditional face anti-spoofing (FAS) detection techniques may struggle to detect real-time deepfake videos within IoT contexts. Moreover, constrained by the scale of FAS detection data sets, current detection models primarily focus on recognizing the entire face in videos, neglecting the intercomponent correlations of facial features. However, our investigation indicates that different parts of the face have varying impacts on deepfake detection. To address this issue, we segment the face into several regions within video frames and explore the relationships between these regions. Our approach involves constructing feature graphs that represent such correlations, aiming to leverage the relationships between facial regions and the temporal characteristics of real-time facial manipulation videos for use in live facial detection cameras. Initially, features for each facial region are extracted via convolutional neural networks (CNNs). Subsequently, with these features as vertices and their correlations as edges, a feature graph of the entire video is constructed. Ultimately, a graph neural network (GNN) is employed to determine whether the video has been tampered with. Experiments conducted on several publicly accessible data sets demonstrate that our proposed method outperforms other state-of-the-art FAS detection techniques in most scenarios. Thus, the aforementioned advanced GNN model exhibits exceptional performance in real-time deepfake detection tailored for live facial detection cameras.",Camera systems;deep learning;graph neural network (GNN);live face anti-spoofing (FAS) detection,IEE
656,Crime Scene Prediction for Unmanned Aerial Vehicles Investigation via Machine Learning,T. P. Ojo; H. Chi; E. Hilliard; J. Yan,2023,"Unmanned Aerial Vehicles have increased their applicability in evidence gathering for collecting digital evidence. Authenticating this evidence depends on the crime scenario and the type of drones used. With drones, the evidence type could be the GPS location, the communication signal, the flight log, and the multimedia evidence. These are forms of evidence that forensic experts use to finalize crime cases. Analyzing this evidence requires expensive forensic toolsets. This paper will investigate the level of accuracy and performance verification of machine learning algorithms such as Convolutional Neural Networks (CNN), Support Vector Machines (SVM), and Long Short-Term Memory (LSTM) can reach in identifying vehicle information and the details of the people inside the vehicle at the crime scene and starting with the level of identifying the minute details for the investigation. The performance of the machine learning algorithms will analyze the evidence for deepfakes and possible manipulations in the evidence gathered.",Cybersecurity;Digital forensics;SVM;CNN;LSTM;Performance,IEE
657,Cybersecurity Anomaly Detection: AI and Ethereum Blockchain for a Secure and Tamperproof IoHT Data Management,O. P. Olawale; S. Ebadinezhad,2024,"The Internet of Healthcare Things (IoHT) is an emerging critical technology for managing patients� health. They are prone to cybersecurity vulnerabilities because they are connected to the internet, primarily by wireless connections. This is a major concern, considering data privacy and security. Artificial intelligence (AI) models are excellent methods to detect and mitigate cybersecurity vulnerabilities. Since medical Information Technology (IT) is evolving and data privacy is a major concern with sensors generally, in healthcare IoT. The TON_IOT, Edge_IIoT, and UNSW-NB15 datasets were used in this study for assessment and implementation to solve the challenge using the chosen benchmark AI models with the integration of IPFS blockchain technology in order to decentralize and secure the data. Justifiable parameters were used to determine how efficient each technique is in predicting the best outcome. The results show the efficiency of the utilized models, particularly the Support Vector Machines (SVM). The TON_IoT dataset obtained 100% accuracy, the Edge_IIoT dataset obtained 98% accuracy, and the UNSW-NB15 dataset obtained 89% accuracy. The integrated blockchain technology in this model is applied for security purposes. Utilizing these techniques will proffer a secure and safe transmission of medical data. This study will generally provide important insight to other researchers in the healthcare field.",Artificial intelligence;abnormal behavior;healthcare;intrusion detection systems;IoT,IEE
658,Protecting the Privacy of Face by De-Identification Pipeline Based on Deep Learning,A. Parashar; I. Rida; A. Parashar; V. Aski,2022,"In this research, we offer a face de-identification process that is reversible and alters both the face�s geometry and its texture. There are fourteen parameters that are employed for the change of the geometry. The usage of a fixed face texture template is required for texture change. We have explored how the capacity of people and robots to identify faces is affected when different geometrical and surface adjustments are made to components of the face such as the eyes, eyebrows, nose, and lips. The studies using crowdsourcing and machine face recognition were carried out on photographs of well-known persons that were obtained from the internet. The findings collected from both kinds of research indicated that alterations to a person�s facial geometry (form) are less influential on the amount of privacy protection than changes to that person�s face texture.",Face de-identification;Face recognition;Affine transformation;Face geometry modification;Face texture modification;Psychological experiments,IEE
659,Facial Landmarks Detection System with OpenCV Mediapipe and Python using Optical Flow (Active) Approach,N. Kumar Rao B; N. Panini Challa; E. S. P. Krishna; S. S. Chakravarthi,2023,"To achieve positive detection results, a variety of face landmark methods supported by the convolutional neural network have been developed. The instability landmarks thus emerge in video frames as a result of CNNs, on the other hand, are extremely sensitive to input picture noise. This paper provides a light and effective face landmark identification technology based on a lightweight U-Net model based on semantic segmentation and an Optical Flow (Active) Approach (OFA) for solving the problem of landmark shaking. The OFA employs a quick optical flow approach to determine the motion path of the landmark, as well as a route to increasing landmark maintenance. A lightweight U-Net model is used to predict face landmarks with a reduced size of the model and lower computational. To subsume unstable shaking, the predictable face landmarks are given into the OFA technique as well. Finally, various benchmark datasets are used to produce a comparison of many common methodologies as well as the proposed detection process. A lightweight U-Net model is used to model face landmarks in reduced model size and lower computational. To subsume the unstable shaking, the predicted face landmarks are given into the OFA technique as well. Finally, various benchmark datasets are used to produce a comparison of many common methodologies as well as the proposed detection process.",OpenCV;media pipe Facial Landmark;Optical Flow Approach,IEE
660,Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection,Z. Lai; X. Zhang; S. Chen,2024,"Large language models (LLMs) have reached human-like proficiency in generating diverse textual content, underscoring the necessity for effective fake text detection to avoid potential risks such as fake news in social media. Previous research has mostly tested single models on in-distribution datasets, limiting our understanding of how these models perform on different types of data for LLM-generated text detection tasks. We researched this by testing five specialized transformer-based models on both in-distribution and out-of-distribution datasets to better assess their performance and generalizability. Our results revealed that single transformer-based classifiers achieved decent performance on the in-distribution dataset but limited generalization ability on the out-of-distribution dataset. To improve it, we combined the individual classifier models using adaptive ensemble algorithms, which improved the average accuracy significantly from 91.8% to 99.2% on an in-distribution test set and from 62.9% to 72.5% on an out-of-distribution test set. The results indicate the effectiveness, good generalization ability, and great potential of adaptive ensemble algorithms in LLM-generated text detection.",LLM-generated text detection;Adaptive assemble algorithm;Transformer-based classifier;Generalization ability;in-distribution dataset;out-of-distribution dataset,IEE
661,Deepfake video detection using CNN and RNN with OPTICAL FLOW features,E. M. Sathwik Reddy; A. Pavan Kumar; P. Swetha,2024,"Recent developments in machine learning have produced new technologies that make it simple to produce ""deepfake"" videos�videos with convincing face swaps and minimal evidence of editing. It's easy to imagine scenarios in which these realistic fake videos are exploited to cause violent protests, blackmail someone, or fabricate terrorist incidents. Digital content that has been synthesized is used to create extremely realistic-looking fake videos that fool viewers. Generative Adversarial Networks (GAN), a type of deep generative algorithm, are frequently used to do such tasks. By using this technique, realistic contents are synthesized that are highly challenging for conventional detection techniques to identify. Most of the time, discriminators based on convolutional neural networks (CNNs) are used to identify such modified media. Since the technique primarily concentrates on the spatial characteristics of each frame of video and is unable to learn time-related data obtained from inter-frame interactions, we utilized an optical flow-based feature extraction approach to extract time-related features, which are then used for classification. The foundation of this model is the integration of RNN and CNN with optical flow feature architecture.",CNN;Resnet50;RNN;LSTM;Optical flow;support vector machine,IEE
662,Detecting Deepfake Videos using Attribution-Based Confidence Metric,S. Fernandes; S. Raj; R. Ewetz; J. S. Pannu; S. Kumar Jha; E. Ortiz; I. Vintila; M. Salter,2020,"Recent advances in generative adversarial networks have made detecting fake videos a challenging task. In this paper, we propose the application of the state-of-the-art attribution based confidence (ABC) metric for detecting deepfake videos. The ABC metric does not require access to the training data or training the calibration model on the validation data. The ABC metric can be used to draw inferences even when only the trained model is available. Here, we utilize the ABC metric to characterize whether a video is original or fake. The deep learning model is trained only on original videos. The ABC metric uses the trained model to generate confidence values. For, original videos, the confidence values are greater than 0.94.",,IEE
663,Learning Meta Model for Strong Generalization Deepfake Detection,D. Huang; Y. Zhang,2024,"Although deepfake technology is neutral, it can be maliciously used by criminals to cause serious security issues. These deepfake videos generated by deep learning technology are no different from real videos, posing a major threat to personal privacy and information credibility. Existing deepfake detection models face a core challenge: most models have limited generalization capabilities, and often have unsatisfactory detection results in the face of increasingly complex forgery technologies. To solve this problem, we introduce a two-stream deepfake detection model. One stream leverages the Video Swin Transformer to identify inter-frame discontinuities, a common anomaly in deepfakes. While another stream utilizes deep convolutional neural networks to detect facial texture inconsistencies, another telltale sign of a fake face. Furthermore, we use an improved meta-learning method called meta-learning for deepfake detection (MLDD) to train our model, which enhances the model�s adaptability and ability to quickly learn from multiple deepfake styles. Experimental results demonstrate that our model has superior performance and strong generalization compared to state-of-the-art existing techniques.",deepafake detection;meta learning;two-stream network;CDC-Xception;video swin transformer,IEE
664,Multimodaltrace: Deepfake Detection using Audiovisual Representation Learning,M. Anas Raza; K. Mahmood Malik,2023,"By employing generative deep learning techniques, Deepfakes are created with the intent to create mistrust in society, manipulate public opinion and political decisions, and for other malicious purposes such as blackmail, scamming, and even cyberstalking. As realistic deepfake may involve manipulation of either audio or video or both, thus it is important to explore the possibility of detecting deepfakes through the inadequacy of generative algorithms to synchronize audio and visual modalities. Prevailing performant methods, either detect audio or video cues for deepfakes detection while few ensemble the results after predictions on both modalities without inspecting relationship between audio and video cues. Deepfake detection using joint audiovisual representation learning is not explored much. Therefore, this paper proposes a unified multimodal framework, Multimodaltrace, which extracts learned channels from audio and visual modalities, mixes them independently in IntrAmodality Mixer Layer (IAML), processes them jointly in IntErModality Mixer Layers (IEML) from where it is fed to multilabel classification head. Empirical results show the effectiveness of the proposed framework giving state-of-the-art accuracy of 92.9% on the FakeAVCeleb dataset. The cross-dataset evaluation of the proposed framework on World Leaders and Presidential Deepfake Detection Datasets gives an accuracy of 83.61% and 70% respectively. The study also provides insights into how the model focuses on different parts of audio and visual features through integrated gradient analysis.",,IEE
665,Low-Quality Deepfake Detection via Unseen Artifacts,S. Chhabra; K. Thakral; S. Mittal; M. Vatsa; R. Singh,2024,"The proliferation of manipulated media over the Internet has become a major source of concern in recent times. With the wide variety of techniques being used to create fake media, it has become increasingly difficult to identify such occurrences. While existing algorithms perform well on the detection of such media, limited algorithms take the impact of compression into account. Different social media platforms use different compression factors and algorithms before sharing such images and videos, which amplifies the issues in their identification. Therefore, it has become imperative that fake media detection algorithms work well for data compressed at different factors. To this end, the focus of this article is detecting low-quality fake videos in the compressed domain. The proposed algorithm distinguishes real images and videos from altered ones by using a learned visibility matrix, which enforces the model to see unseen imperceptible artifacts in the data. As a result, the learned model is robust to loss of information due to data compression. The performance is evaluated on three publicly available datasets, namely Celeb-DF, FaceForensics, and FaceForensics++, with three manipulation techniques, viz., Deepfakes, Face2Face, and FaceSwap. Experimental results show that the proposed approach is robust under different compression factors and yields state-of-the-art performance on the FaceForensics++ and Celeb-DF datasets with 97.14% classification accuracy and 74.45% area under the curve, respectively.",Artifacts;compression;deepfake,IEE
666,Multilingual Audio-Visual Smartphone Dataset and Evaluation,H. Mandalapu; P. N. A. Reddy; R. Ramachandra; K. S. Rao; P. Mitra; S. R. M. Prasanna; C. Busch,2021,"Smartphones have been employed with biometric-based verification systems to provide security in highly sensitive applications. Audio-visual biometrics are getting popular due to their usability, and also it will be challenging to spoof because of their multimodal nature. In this work, we present an audio-visual smartphone dataset captured in five different recent smartphones. This new dataset contains 103 subjects captured in three different sessions considering the different real-world scenarios. Three different languages are acquired in this dataset to include the problem of language dependency of the speaker recognition systems. These unique characteristics of this dataset will pave the way to implement novel state-of-the-art unimodal or audio-visual speaker recognition systems. We also report the performance of the bench-marked biometric verification systems on our dataset. The robustness of biometric algorithms is evaluated towards multiple dependencies like signal noise, device, language and presentation attacks like replay and synthesized signals with extensive experiments. The obtained results raised many concerns about the generalization properties of state-of-the-art biometrics methods in smartphones.",Smartphone biometrics;audio-visual speaker recognition;presentation attack detection;multilingual,IEE
667,Preliminary Study on Detection of Breasts,M. Pristavnik Vre�njak; A. Peru�i?; �. Emer�i?; P. Peer; B. Batagelj,2024,"In the realm of digital image manipulation, deep fakes, predominantly sourced from pornographic materials, present a significant challenge, especially prevalent in the form of face and body swapping techniques. This emerging issue involves substituting the faces or bodies of individuals in explicit content, using advanced methods like those demonstrated in the DeepNude application. In response, we present an approach which solves the first part of the pipeline � detection of breasts. There has been limited research regarding this biometric modality, with notable exceptions such as breast cancer identification. Due to the lack of research and the absence of open, freely available data, we developed our own dataset. Images with annotations were acquired from pornhub.com and curated by experts. Annotations include name, cup size, possible breast augmentations, ethnicity, among others. To demonstrate that dataset is challenging enough for future research we used images to train in class-agnostic way three CNN-based detection models. The results show the feasibility of not only the proposed detection approaches for the task, but also the dataset and hopefully pave the way for future applications such as supporting court decisions, enhancing virtual clothing fitting techniques, and more.",breast detection;deep fakes;recognition;deep learning;computer vision,IEE
668,UCF: Uncovering Common Features for Generalizable Deepfake Detection,Z. Yan; Y. Zhang; Y. Fan; B. Wu,2023,"Deepfake detection remains a challenging task due to the difficulty of generalizing to new types of forgeries. This problem primarily stems from the overfitting of existing detection methods to forgery-irrelevant features and method-specific patterns. The latter has been rarely studied and not well addressed by previous works. This paper presents a novel approach to address the two types of overfitting issues by uncovering common forgery features. Specifically, we first propose a disentanglement framework that decomposes image information into three distinct components: forgery-irrelevant, method-specific forgery, and common forgery features. To ensure the decoupling of method-specific and common forgery features, a multi-task learning strategy is employed, including a multi-class classification that predicts the category of the forgery method and a binary classification that distinguishes the real from the fake. Additionally, a conditional decoder is designed to utilize forgery features as a condition along with forgery-irrelevant features to generate reconstructed images. Furthermore, a contrastive regularization technique is proposed to encourage the disentanglement of the common and specific forgery features. Ultimately, we only utilize the common forgery features for the purpose of generalizable deepfake detection. Extensive evaluations demonstrate that our framework can perform superior generalization than current state-of-the-art methods.",,IEE
669,Preliminary Forensics Analysis of DeepFake Images,L. Guarnera; O. Giudice; C. Nastasi; S. Battiato,2020,"One of the most terrifying phenomenon nowadays is the Deepfake: the possibility to automatically replace a person's face in images and videos by exploiting algorithms based on deep learning. This paper will present a brief overview of technologies able to produce Deepfake images of faces. A forensics analysis of those images with standard methods will be presented: not surprisingly state of the art techniques are not completely able to detect the fakeness. To solve this, a preliminary idea on how to fight Deepfake images of faces will be presented by analysing anomalies in the frequency domain.",Deepfake;Multimedia Forensics;Generative Adversarial Networks,IEE
670,Defending Deepfakes by Saliency-Aware Attack,Q. Li; M. Gao; G. Zhang; W. Zhai,2024,"With the rapid development of deep learning, especially the generative adversarial network (GAN), face modification has been substantially advanced and enables the generated images to look more realistic. Given an image or a video frame of a person, such a system can create fake images, which manipulates the movement, expression, and even appearance, e.g., hair color, eye color, and age. Such a system is termed Deepfake, which has raised significant ethical issues, especially for celebrities. With the pretrained Deepfake models being widely available on the Internet, its negative applications, such as face manipulation and pornographic generation, have exposed the dark side of the Deepfake technology to the sociocyber world. In this article, we aim to defend a well-trained Deepfake model by manipulating the raw image with unperceived perturbation. To minimize the alterations to the original image while effectively fooling the Deepfake model, we propose to selectively perturb only the foreground person region and maintain the irrelevant background. This is based on the observation that the salient object in a person�s image is always the foreground face region. Such a strategy introduces negligible alterations to the original image, which makes the attack remain effective. We experimentally demonstrate the superiority of the proposed attacking framework over the existing models and show our approach is ready to be applied for out-of-the-box development.",Deepfake;face image;generative adversarial network (GAN);model attack;saliency detection,IEE
671,Survey of Face Liveness Detection for Unsupervised Locations,D. Apgar; M. R. Abid,2021,"Spoofing attacks represent a major threat to facial recognition systems. There are many types of attacks that can be carried out, ranging from 2D photo attacks to 3D mask attacks. Facial recognition systems must defend against such attacks using state-of-the-art anti-spoofing countermeasures. The current Covid-19 outbreak has increased the need for facial recognition, exacerbating the issue of secure facial recognition systems. This paper contains an overview of face liveness detection methods, mainly in the domain of deep learning, and how these methods combat the threat of non-live faces.",Facial recognition;Face liveness;Spoofing,IEE
672,Medical Image Tampering Detection using Deep Learning,B. R. Reddy; M. S. Kumar; P. Neelima; C. Sushama; V. N. Sailaja; D. Ganesh,2024,"The increasing prevalence of cyber-attacks on hospitals and the emergence of advanced photo-editing tools have raised concerns about the potential for medical image falsification. This research focuses on detecting and preventing medical image malpractice, particularly in the context of computed tomography (CT) scans. Building upon previous work with VGG19 and ConnectionNet, this study explores the potential of state-of-the-art deep neural networks, such as ResNet50 and MobileNetV2, for advanced medical image identification and prediction. These models are known for their ability in image classification and can achieve exceptional results when trained on large datasets. By analyzing a diverse dataset of fabricated CT images, this research aims to extract the characteristics of various forgery techniques. The proposed approach seeks to improve accuracy, scalability, and versatility in medical image malpractice detection. This study contributes to preserving the reliability of diagnostic information and ensuring the integrity of medical imaging, safeguarding patient care and preventing misdiagnosis.",Deep learning;Tampered medical images;Computed Tomography (CT) scans;Cyberattacks;ConnectionNet;ResNet50;MobileNetV2;Image tampering detection;Residual connections;Digital threats;Neural networks,IEE
673,Region-Based Steganalysis of Medical Radiographs for Radiographic Machine Identification,F. G. Mohammadi; R. Sebro,2023,"New advances in artificial intelligence (AI) allow us to fake digital images that are difficult for humans to distinguish from real images, including images used in health care like radiographs. Malware creating forged digital radiographs have the potential to have severe negative repercussions for patients' diagnosis and treatment, therefore there is a need to validate the radiographs' source used in health-care. We address this challenge and propose a region-based steganalysis algorithm using a deep learning framework that identified the region of radiographs which has the most informative pixels and patterns for determining the radiographs' source. The deep learning algorithm uses a convolutional neural network (CNN) with four convolutional layers with different filters followed by three layers of fully connected convolutional neural network (FCNN). We used radiographs of the knees (n = 1418), legs (n = 616), ankles (n = 1290) and feet (n = 1074) of patients at Mayo Clinic (01/01/2010 - 12/31/2021) and identified the radiographs' source (manufacturer). The dataset was randomly split by patient into training/validation (n = 3635, 80%) and test (n = 763, 20%), and after tuning evaluated using only one radiograph for each patient in the test dataset. The algorithm yields a model prediction performance for a region of feet radiographs with 98.06% accuracy (Area Under the Curve (AUC) = 98.56%). This novel research is the first in medical forensic imaging that identifies the content-free region of radiographs that is most informative to determine the radiographs' source. These results will be invaluable for detection of fake radiographs and scientific fraud.",Image Authentication;Deep Learning;Forensic Science;Radiology;Steganalysis,IEE
674,Digital Image Forgery Detection Using Deep Learning,B. P. Kumar; V. M. Vinayagam; S. A. Babu; C. Guruparthasarthi; G. Janardhan; M. Deepthi,2024,"Image manipulation, falsification, and deepfake production have become major concerns in the era of digital media. In order to combat false information and online fraud, this project seeks to develop a technology that can identify altered or counterfeit photos. In this work, we present a model for detecting image forgeries based on the Xception architecture, which we have combined with a Flask-based web application. The model undergoes 20 epochs of training, with accuracy and loss metrics tracked throughout. The training process reveals a consistent improvement in accuracy, starting at 55% and reaching an impressive 97.7% by the 20th epoch. Validation accuracy follows a similar trend, beginning at 52.29% and reaching 81.92% at the conclusion of training. Concurrently, both training and validation loss values decrease, indicating the model's learning capacity and ability to generalize. The integration of the model into a Flask web application allows users to interact with the forgery detection system. The TensorFlow optimization, utilizing oneAPI Deep Neural Network Library (oneDNN) with AVX and AVX2 instructions, enhances CPU performance during model execution. The Flask web application provides a user-friendly interface for users to submit images and receive real-time predictions on their authenticity. The model's predictions on a sample set demonstrate its efficacy in distinguishing between real and fake images. The confusion matrix further validates the model's performance, highlighting its capability to make accurate classifications.",Deep Learning;Xception;CNN. Digital image,IEE
675,From Deepfakes to Digital Truths: The Role of Watermarking in AI-Generated Image Verification,J. J. Thakkar; A. Kaur,2024,"The evolution of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) has introduced deepfake technology. Deepfake technology is a form of digital manipulation that alters video, image, and audio content with the help of Generative AI. Those deepfakes have increased concerns in various fields, including education, art, and they also raise ethical and security concerns due to their potential for deceptive content. Reviewing the increasing challenge of identifying high-quality deepfakes, there's a pressing need for robust measures to counter them. This review explores various watermarking techniques and their use to protect content authenticity and origin. Watermarking embeds a subtle watermark and provides a strong defense against deepfake technologies and similar AI-driven tools. The paper discusses current watermarking methods, their strengths and weaknesses, and potential improvements to verify AI-generated content.",Artificial Intelligence;Content Authentication;Deepfake Detection;Digital Media Integrity;Digital Watermarking;Generative AI;Machine Learning,IEE
676,Face Forgery Detection Based On Segmentation Network,Y. Zhou; A. Luo; X. Kang; S. Lyu,2021,"Recent progress in facial manipulation technologies have made it hard to distinguish the sophisticated face swapped images/videos. Due to the diversity of generation software and data sources, it is extremely challenging to devise an efficient generality framework. Instead of regarding the detection process as a vanilla binary classification task, we proposed a detection framework based on pixel-level classification. Considering that the acquisition of real pixel-level ground-truth is somehow expensive or even impractical, we proposed a pseudo ground-truth generation pipeline with prior knowledge of facial manipulation. Besides, we added a new module into the neural network to capture frequency clues, while the ablation experiment verified the effectiveness of this module. The experimental results on several public datasets demonstrated that our proposed framework is effective and superior to other existing similar detection networks.",face swapped images/videos;pixel-level classification;pseudo ground-truth generation;frequency clues,IEE
677,DeepDistAL: Deepfake Dataset Distillation using Active Learning,M. S. Rana; M. Nur Nobi; A. Sung,2024,"In the rapidly evolving landscape of artificial intelligence (AI), particularly in the Deepfake domain, largescale datasets play a pivotal role in ensuring performance, including the model�s accuracy, robustness, trustworthiness, etc. However, the increasing size and intricacy of the datasets impose a growing demand for computational resources and amplify the cost and duration of model building. To mitigate the challenge, dataset distillation provides a solution. For the Deepfake detection problem, noteworthy datasets such as VDFD, FaceForensics++, DFDC, and Celeb-DF underscore the indispensability of extensive data for ensuring model robustness. Nevertheless, the computational requirement associated with these datasets presents significant obstacles. This paper describes a data distillation method utilizing Active Learning to reduce dataset size while retaining essential data qualities. The proposed method facilitates efficient model training selecting representative samples by capturing the most salient features, thereby enabling effective performance in resource-constrained environments. The study encompasses developing a data distillation algorithm tailored for Deepfake detection, rigorous experimentation with a major Deepfake dataset to validate its efficacy, and a comprehensive comparison of the model performance trained on distilled versus original datasets. Through thorough analysis, we demonstrate the practicality and effectiveness of our proposed method in alleviating computational demands without compromising detection accuracy.",Deepfake;Dataset Distillation;Active Learning;DeepDistAL;VDFD,IEE
678,Targeted Data Extraction and Deepfake Detection with Blockchain Technology,M. Taeb; H. Chi; S. Bernadin,2022,"By recording instances of significant forensic relevance, smartphones, which are becoming increasingly crucial for documenting ordinary life events, can produce pieces of evidence in court. Due to privacy or other issues, not everyone is open to having all the data on their phone collected and analyzed. In addition, Law Enforcement Organizations need a lot of memory to keep the information taken from a witness�s phone. Deepfakes which are purposefully utilized as a source of disinformation, manipulation, harassment, and persuasion in court, present another significant problem for law enforcement organizations. Recently, the introduction of blockchain has altered the way we conduct business. Decentralized Applications (Dapps) may be a fantastic way to verify the accuracy of the data, stop the spread of false information, extract specific data with precision, and offer a framework for sharing that takes into account privacy and memory issues. This article outlines the creation of a Dapp that provides users with a secure conduit through distributing evidence that has been verified. By utilizing machine learning (ML) classifiers, this platform not only distinguishes between altered and original material before allowing it, but also uses user-uploaded media to retrain its models to increase prediction accuracy and offer complete transparency. The end outcome of this activity can maintain a clear record (timestamp) of the occurrence, submitted proof, and helpful metadata with the aid of the blockchains� consensus notion.",targeted data extraction systems;deepfake detection;forensic analysis model;blockchain;decentralized applications (Dapps),IEE
679,PhygitalNet: Unified Face Presentation Attack Detection via One-Class Isolation Learning,K. Thakral; S. Mittal; M. Vatsa; R. Singh,2023,"Face biometric systems are shown to be vulnerable to various kinds of presentation attacks including physical and digital attacks. Existing research generally focuses on individual attacks and very few focus on generalizability across digital and physical attacks. In this research, we propose PhygitalNet model that generalizes to both physical and digital presentation attacks on face biometric systems. The proposed model is based on novel one-class iSOLatiOn Learning (SOLO Learning) which is a two-step training process aimed at reducing of the covariate shift between the bonafide samples of the physical as well as digital attack dataset in the pre-training step. In the downstream step, the algorithm introduces a novel single-class iSOLatiOn loss (SOLO loss) function that isolates the samples belonging to the bonafide class away from the samples of the attacked class for both the attack methods. Experimental results show that PhygitalNet achieves a significant performance gain when compared with the baseline techniques, evaluated on a combination of MLFP, MSU-MFSD dataset (for physical attack) and FaceForensics++ (for digital attack) datasets.",,IEE
680,Exposing Fake Faces Through Deep Neural Networks Combining Content and Trace Feature Extractors,E. Kim; S. Cho,2021,"With the breakthrough of computer vision and deep learning, there has been a surge of realistic-looking fake face media manipulated by AI such as DeepFake or Face2Face that manipulate facial identities or expressions. The fake faces were mostly created for fun, but abuse has caused social unrest. For example, some celebrities have become victims of fake pornography made by DeepFake. There are also growing concerns about fake political speech videos created by Face2Face. To maintain individual privacy as well as social, political, and international security, it is imperative to develop models that detect fake faces in media. Previous research can be divided into general-purpose image forensics and face image forensics. While the former has been studied for several decades and focuses on extracting hand-crafted features of traces left in the image after manipulation, the latter is based on convolutional neural networks mainly inspired by object detection models specialized to extract images' content features. This paper proposes a hybrid face forensics framework based on a convolutional neural network combining the two forensics approaches to enhance the manipulation detection performance. To validate the proposed framework, we used a public Face2Face dataset and a custom DeepFake dataset collected on our own. Experimental results using the two datasets showed that the proposed model is more accurate and robust at various video compression rates compared to the previous methods. Throughout class activation map visualization, the proposed framework provided information on which face parts are considered important and revealed the tempering traces invisible to naked eyes.",Convolutional neural networks;DeepFake;Face2Face;fake face detection;fake face image forensics;multi-channel constrained convolution;transfer learning,IEE
681,Transformer Ensemble for Synthesized Speech Detection,E. R. Bartusiak; K. Bhagtani; A. K. Singh Yadav; E. J. Delp,2023,"As voice synthesis systems and deep learning tools continue to improve, so does the possibility that synthesized speech can be used for nefarious purposes. Methods that determine if audio signals contain synthesized or authentic speech are needed. In this paper, we investigate three transformers to detect synthesized speech: Compact Convolutional Transformer (CCT), Patchout faSt Spectrogram Transformer (PaSST), and Self-Supervised Audio Spectrogram Transformer (SSAST). We show that each transformer independently detects synthesized speech well. Then, we propose an ensemble of transformers that can provide even better performance. Finally, we explore how much of an audio signal is needed for high synthesized speech detection. Evaluated on the ASVspoof2019 dataset, we demonstrate that our transformer ensemble detects synthesized speech from shorter segments of audio signals, even on a highly imbalanced dataset.",deep learning;audio forensics;synthesized speech detection;transformers;mel spectrograms,IEE
682,Monocular Identity-Conditioned Facial Reflectance Reconstruction,X. Ren; J. Deng; Y. Cheng; J. Guo; C. Ma; Y. Yan; W. Zhu; X. Yang,2024,"Recent 3D face reconstruction methods have made re-markable advancements, yet there remain huge challenges in monocular high-quality facial reflectance reconstruction. Existing methods rely on a large amount of light-stage captured data to learn facial reflectance models. However, the lack of subject diversity poses challenges in achieving good generalization and widespread applicability. In this paper, we learn the reflectance prior in image space rather than UV space and present a framework named ID2Reflectance. Our framework can directly estimate the reflectance maps of a single image while using limited reflectance data for training. Our key insight is that reflectance data shares facial structures with RGB faces, which enables obtaining expressive facial prior from inexpensive RGB data thus re-ducing the dependency on reflectance data. We first learn a high-quality prior for facial reflectance. Specifically, we pretrain multi-domain facial feature code books and design a codebook fusion method to align the reflectance and RGB domains. Then, we propose an identity-conditioned swapping module that injects facial identity from the target image into the pre-trained autoencoder to modify the identity of the source reflectance image. Finally, we stitch multi-view swapped reflectance images to obtain renderable assets. Extensive experiments demonstrate that our method exhibits excellent generalization capability and achieves state-of-the-art facial reflectance reconstruction results for in-the-wild faces. Our project page is https://xingyuren.github.io/id2reflectance.",3D Face;Reflectance;Face Swapping,IEE
683,Contribution of Timbre and Shimmer Features to Deepfake Speech Detection,A. Chaiwongyen; N. Songsriboonsit; S. Duangpummet; J. Karnjana; W. Kongprawechnon; M. Unoki,2022,"Advanced deep-learning techniques can generate natural and synthetic voices that might be close to someone's voice. Nevertheless, misuse of such technologies is of great concern. Hence, researchers focus on detecting these malicious synthetic voices, called �deepfake speech.� Although many feature extractions and classifications have been proposed, the accuracy of deepfake detection is still unreliable. In addition, most of the current features are computed in the frequency domain. To this end, we conducted experiments to investigate the contribution of two acoustic features and deepfake speech signals. The acoustic features are timbre and shimmer, which represent our auditory perception in the time domain. We point out that eight timbre components and four shimmer components significantly contribute to discriminating deepfake speech from genuine speech. We also propose a method for detecting deepfake speech based on these timbre and shimmer features. The method was evaluated by using a dataset from the Audio Deep Synthesis Detection Challenge (ADD 2022). The results suggest that combining these eight timbre components and four shimmer components with a simple classifier using multilayer perceptron neural networks can enable deepfake speech to be detected potentially effectively.",,IEE
684,A Comprehensive Evaluation of Fake Face Recognition Scheme using Artificial Intelligence Oriented Learning Scheme,S. Subashree; R. Rose S; A. S. Valarmathy; P. Joseph; P. J. Dennis; S. Ravi,2024,"Fake face recognition has emerged as a critical area of research due to the proliferation of synthetic media and its potential misuse in various domains. This study presents a thorough evaluation of a novel Fake Face Recognition Scheme utilizing Artificial Intelligence Oriented Learning Scheme (AIOLS) coupled with Generative Adversarial Network (GAN)-GoogleNet integration. The aim is to discern authentic facial images from synthetic or tampered ones with high accuracy. In this research, we employed a dataset comprising a diverse range of authentic and synthetic facial images. The proposed scheme incorporates the power of GANs for generating synthetic facial images and leverages GoogleNet, a state-of-the-art deep convolutional neural network, for discriminative feature extraction. The integration within the AIOLS framework facilitates efficient learning and adaptation to complex patterns present in fake facial images. The evaluation of our scheme was conducted through rigorous experimentation on the dataset, employing various performance metrics. Notably, the accuracy obtained was measured at an impressive 96.7%, signifying the effectiveness of our approach in distinguishing between real and fake facial images. Additionally, other metrics such as precision, recall, and F1-score were also computed to provide a comprehensive assessment of the scheme's performance.",Fake face recognition;Artificial Intelligence Oriented Learning Scheme (AIOLS);GAN-GoogleNet integration;synthetic media;facial image authentication,IEE
685,Analysis of Spectro-Temporal Modulation Representation for Deep-Fake Speech Detection,H. Cheng; C. O. Mawalim; K. Li; L. Wang; M. Unoki,2023,"Deep-fake speech detection aims to develop effective techniques for identifying fake speech generated using advanced deep-learning methods. It can reduce the negative impact of malicious production or dissemination of fake speech in real-life scenarios. Although humans can relatively easy to distinguish between genuine and fake speech due to human auditory mechanisms, it is difficult for machines to distinguish them correctly. One major reason for this challenge is that machines struggle to effectively separate speech content from human vocal system information. Common features used in speech processing face difficulties in handling this issue, hindering the neural network from learning the discriminative differences between genuine and fake speech. To address this issue, we investigated spectro-temporal modulation representations in genuine and fake speech, which simulate the human auditory perception process. Next, the spectro-temporal modulation was fit to a light convolutional neural network bidirectional long short-term memory for classification. We conducted experiments on the benchmark datasets of the Automatic Speaker Verification and Spoofing Countermeasures Challenge 2019 (ASVspoof2019) and the Audio Deep synthesis Detection Challenge 2023 (ADD2023), achieving an equal-error rate of 8.33% and 42.10%, respectively. The results showed that spectro-temporal modulation representations could distinguish the genuine and deep-fake speech and have adequate performance in both datasets.",,IEE
686,Trustworthy Artificial Intelligence and its use by Law Enforcement Authorities: where do we stand?,S. Roksandi?; N. Protrka; M. Engelhart,2022,"From all kinds of industry, communication, education, banking, government, service, manufacturing, medical, and more, Artificial Intelligence (hereinafter: AI) applications may be found in many sectors of our life. Public safety and criminal justice are gaining advantages thanks to artificial intelligence. For example, traffic safety systems detect infractions and alert authorities. AI is also assisting in the identification of criminals. As a public safety resource, AI is being researched in a number of ways. Face recognition is becoming increasingly popular as an AI application in both the public and private sectors. For law enforcement authorities, AI applications boost efficiency, promote data-driven processes, and extend capabilities. AI technology can help law enforcement agencies make judgments and complete tasks in general. They can strengthen data-driven procedures, increase efficiency, or extend capabilities for specific activities or choices. However, recognized human rights as adjudicated by European Convention of Human Rights are calling for caution in the development and usage of AI within the European Union. Fair Trials and 114 civil society organizations have launched a collective statement to call for an Artificial Intelligence Act which foregrounds fundamental rights in November 2021. This Act is under preparation in the EU. Ethics Guidelines for Trustworthy AI from 2019, by High Level Expert Group on Artificial intelligence set up by the European Commission, (hereinafter: Ethical Guidelines) are underlining how it is necessary to develop, deploy and use trustworthy AI systems in a way that adheres to the ethical principles of: respect for human autonomy, prevention of harm, fairness and explicability. European Parliament Resolution of 6 October 2021 on artificial intelligence in criminal law and its use by the police and judicial authorities in criminal matters (hereinafter: Resolution) underlines that AI, alongside benefits, possesses great risks for fundamental rights and democracies based on the rule of law. AI should not be seen as an end in itself, but as a tool for serving people, with the ultimate aim of increasing human well-being, human capabilities and safety. In this article the authors will analyse some of the concerns taking into accounts principles set in Ethical Guidelines and human rights concerns. As the Regulation on AI is underway in the EU, the authors will stress some of the concerns that should be addressed in its wording.",artificial intelligence;analysis;law enforcement authorities;human rights;ethical guidelines;EU Resolution and Regulation on AI,IEE
687,Fake Video Detection Model Using Hybrid Deep Learning Techniques,O. S. A. Aboosh; A. N. Hassan; D. K. Sheet,2023,"The world is witnessing great developments daily in the field of graphics and computer vision. Now, it�s possible to create fake videos with very realistic faces. Thus, discrimination between original and fake videos has become a major challenge, which caused serious threats to both the individual and society. Usually, the traditional image forensic technicalities are not appropriate to classify videos because of data compression that damages it. Thus, this research focused on the use of hybrid deep learning models that based on convolutional neural networks (CNN) and recurrent neural networks (RNN) methods for fake video detection. The inceptionV3 model was used to extract facial features from the frames, then these features were used to train simpleRNN and Gated Recurrent Unit (GRU) models to classify video. Most deepfake detection works fails when tested on a new dataset, especially those that are real and close to reality. Therefore, the most realistic dataset which produced �in the wild� was chosen in this research. The deepfake detection challenge (DFDC) dataset was used to evaluate the proposed models. Where these models achieved a high detection accuracy, 98.5% for SimpleRNN and 98.9% for GRU. Also, the models achieved 0.979 and 0.986 of AUC respectively.",DeepFake;FaceSwap;Face2Face;Gated Recurrent Unit;InceptionV3;Recurrent Neural Network,IEE
688,End-to-End Reconstruction-Classification Learning for Face Forgery Detection,J. Cao; C. Ma; T. Yao; S. Chen; S. Ding; X. Yang,2022,"Existing face forgery detectors mainly focus on specific forgery patterns like noise characteristics, local textures, or frequency statistics for forgery detection. This causes specialization of learned representations to known forgery patterns presented in the training set, and makes it difficult to detect forgeries with unknown patterns. In this paper, from a new perspective, we propose a forgery detection frame-work emphasizing the common compact representations of genuine faces based on reconstruction-classification learning. Reconstruction learning over real images enhances the learned representations to be aware of forgery patterns that are even unknown, while classification learning takes the charge of mining the essential discrepancy between real and fake images, facilitating the understanding of forgeries. To achieve better representations, instead of only using the encoder in reconstruction learning, we build bipartite graphs over the encoder and decoder features in a multi-scale fashion. We further exploit the reconstruction difference as guidance of forgery traces on the graph output as the final representation, which is fed into the classifier for forgery detection. The reconstruction and classification learning is optimized end-to-end. Extensive experiments on large-scale benchmark datasets demonstrate the superiority of the proposed method over state of the arts.",Face and gestures; Biometrics,IEE
689,A Survey on Video-Based Fake News Detection Techniques,R. Agrawal; D. K. Sharma,2021,"In today's world, fake news identification is a critical problem. Fake news may exist in form of text, images and videos also. There are several techniques exist for fake news detection including forgery detection techniques. This paper discussed the existing forgery techniques used for the fake video detection. In this study, we addressed the existing issues and challenges which make the forgery detection task cumbersome. We have discussed the use of deep neural network, convolutional neural network, biological signal and spatio-temporal neural network for fake video identification. A comparative study of existing techniques, used for forgery detection, is also provided. This exhaustive survey will help the other researchers to combat deep fake problem.",video forgery;fake news;neural networks;deep learning;deep fake,IEE
690,A Hybrid CNN-LSTM model for Video Deepfake Detection by Leveraging Optical Flow Features,P. Saikia; D. Dholaria; P. Yadav; V. Patel; M. Roy,2022,"Deepfakes are the synthesized digital media in order to create ultra-realistic fake videos to trick the spectator. Deep generative algorithms, such as, Generative Adversarial Networks(GAN) are widely used to accomplish such tasks. This approach synthesizes pseudo-realistic contents that are very difficult to distinguish by traditional detection methods. In most cases, Convolutional Neural Network(CNN) based discriminators are being used for detecting such synthesized media. However, it emphasise primarily on the spatial attributes of individual video frames, thereby fail to learn the temporal information from their inter-frame relations. In this paper, we leveraged an optical flow based feature extraction approach to extract the temporal features, which are then fed to a hybrid model for classification. This hybrid model is based on the combination of CNN and recurrent neural network (RNN) architectures. The hybrid model provides effective performance on open source data-sets such as, DFDC, FF++ and Celeb-DF. This proposed method shows an accuracy of 66.26%,91.21% and 79.49% in DFDC, FF++, and Celeb-DF respectively with a very reduced No of sample size of $\leq 100$ samples(frames). This promises early detection of fake contents compared to existing modalities.",,IEE
691,Generalizing Face Forgery Detection with High-frequency Features,Y. Luo; Y. Zhang; J. Yan; W. Liu,2021,"Current face forgery detection methods achieve high accuracy under the within-database scenario where training and testing forgeries are synthesized by the same algorithm. However, few of them gain satisfying performance under the cross-database scenario where training and testing forgeries are synthesized by different algorithms. In this paper, we find that current CNN-based detectors tend to overfit to method-specific color textures and thus fail to generalize. Observing that image noises remove color textures and expose discrepancies between authentic and tampered regions, we propose to utilize the high-frequency noises for face forgery detection. We carefully devise three functional modules to take full advantage of the high-frequency features. The first is the multi-scale high-frequency feature extraction module that extracts high-frequency noises at multiple scales and composes a novel modality. The second is the residual-guided spatial attention module that guides the low-level RGB feature extractor to concentrate more on forgery traces from a new perspective. The last is the cross-modality attention module that leverages the correlation between the two complementary modalities to promote feature learning for each other. Comprehensive evaluations on several benchmark databases corroborate the superior generalization performance of our proposed method.",,IEE
692,Deepfake Video Detection using Neural Networks,M. Jiwtode; A. Asati; S. Kamble; L. Damahe,2022,"Over the past few years, free mobile application tools on Artificial Intelligence and deep learning have made it easy to create reliable face exchanges in a video called �DeepFake� (DF) video that leaves a little hint of traces to check if its fake. Creating a computerized edited video has been demonstrated for quite a long time by actually taking advantage of enhanced visual effects. Recently, Artificial Intelligence has led to a rise in fake content and the ability to access free tools to create it. These purported AI-engineered media are normally called DeepFake(DF). Making a DF with a computerized AI tool is a simple job. However, with regards to identifying this DF, it's a major challenging dispute. Preparing the calculations and training the model to distinguish DF is difficult. The challenge to train an algorithm model to spot the DeepFake (DF) is not simple. We have tried recognizing DF with the use of CNN and RNN. The framework utilizes a CNN for feature extraction at the frame level. The model uses features extracted from the frame level to train the RNN, which then learns to classify videos according to their temporal inconsistencies. Anticipated results, when compared with a large number of hoax videos, were gathered from standard datasets. Using a simple architecture, we will show you how this errand can make your framework accurate.",Artificial Intelligence;RNN;CNN;Hoax Video Detection;DeepFakes,IEE
693,Spoofing Attack Augmentation: Can Differently-Trained Attack Models Improve Generalisation?,W. Ge; X. Wang; J. Yamagishi; M. Todisco; N. Evans,2024,"A reliable deepfake detector or spoofing countermeasure (CM) should be robust in the face of unpredictable spoofing attacks. To encourage the learning of more generaliseable artefacts, rather than those specific only to known attacks, CMs are usually exposed to a broad variety of different attacks during training. Even so, the performance of deeplearning-based CM solutions are known to vary, sometimes substantially, when they are retrained with different initialisations, hyper-parameters or training data partitions. We show in this paper that the potency of spoofing attacks, also deep-learning-based, can similarly vary according to training conditions, sometimes resulting in substantial degradations to detection performance. Nevertheless, while a RawNet2 CM model is vulnerable when only modest adjustments are made to the attack algorithm, those based upon graph attention networks and self-supervised learning are reassuringly robust. The focus upon training data generated with different attack algorithms might not be sufficient on its own to ensure generaliability; some form of spoofing attack augmentation at the algorithm level can be complementary.",anti-spoofing;deepfake detection;countermeasure;text-to-speech;deep learning,IEE
694,Artificial Humans: an Overview of Photorealistic Synthetic Datasets and Possible Applications,D. Nikolova; I. Vladimirov; Z. Terneva,2022,"In this scientific paper, an overview of different photorealistic synthetic human datasets is presented. The creation of more and more artificial data is leading to rapid progress in various fields. Synthetic faces and whole bodies are needed during the processes of training and exploitation of applications in the field. The state of the art synthetic human representations are listed, including their applications.",Artificial Humans;Synthetic Dataset;Photorealistic;Human Face;Human Body;Overview,IEE
695,Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics,S. Jia; R. Lyu; K. Zhao; Y. Chen; Z. Yan; Y. Ju; C. Hu; X. Li; B. Wu; S. Lyu,2024,"DeepFakes, which refer to AI-generated media content, have become an increasing concern due to their use as a means for disinformation. Detecting DeepFakes is currently solved with programmed machine learning algorithms. In this work, we investigate the capabilities of multimodal large language models (LLMs) in DeepFake detection. We conducted qualitative and quantitative experiments to demonstrate multimodal LLMs and show that they can expose AI-generated images through careful experimental design and prompt engineering. This is interesting, considering that LLMs are not inherently tailored for media forensic tasks, and the process does not require programming. We discuss the limitations of multimodal LLMs for these tasks and suggest possible improvements.",Deepfake Detection;Multimodal Large Language Models;Media Forensics;GPT4V,IEE
696,Deepfake Detection by Exploiting Surface Anomalies: The Surfake Approach,A. Ciamarra; R. Caldelli; F. Becattini; L. Seidenari; A. Del Bimbo,2024,"The ever-increasing use of synthetically generated content in different sectors of our everyday life, one for all media information, poses a strong need for deepfake detection tools in order to avoid the proliferation of altered messages. The process to identify manipulated content, in particular images and videos, is basically performed by looking for the presence of some inconsistencies and/or anomalies specifically due to the fake generation process. Different techniques exist in the scientific literature that exploit diverse ad-hoc features in order to highlight possible modifications. In this paper, we propose to investigate how deepfake creation can impact on the characteristics that the whole scene had at the time of the acquisition. In particular, when an image (video) is captured the overall geometry of the scene (e.g. surfaces) and the acquisition process (e.g. illumination) determine a univocal environment that is directly represented by the image pixel values; all these intrinsic relations are possibly changed by the deepfake generation process. By resorting to the analysis of the characteristics of the surfaces depicted in the image it is possible to obtain a descriptor usable to train a CNN for deepfake detection: we refer to such an approach as SurFake. Experimental results carried out on the FF + + dataset for different kinds of deep-fake forgeries and diverse deep learning models confirm that such a feature can be adopted to discriminate between pristine and altered images; furthermore, experiments witness that it can also be combined with visual data to provide a certain improvement in terms of detection accuracy.",,IEE
697,A video is worth more than 1000 lies. Comparing 3DCNN approaches for detecting deepfakes,Y. Wang; A. Dantcheva,2020,"Manipulated images and videos have become increasingly realistic due to the tremendous progress of deep convolutional neural networks (CNNs). While technically intriguing, such progress raises a number of social concerns related to the advent and spread of fake information and fake news. Such concerns necessitate the introduction of robust and reliable methods for fake image and video detection. Towards this in this work, we study the ability of state of the art video CNNs including 3D ResNet, 3D ResNeXt, and I3D in detecting manipulated videos. We present related experimental results on videos tampered by four manipulation techniques, as included in the FaceForensics++ dataset. We investigate three scenarios, where the networks are trained to detect (a) all manipulated videos, as well as (b) separately each manipulation technique individually. Finally and deviating from previous works, we conduct cross-manipulation results, where we (c) detect the veracity of videos pertaining to manipulation-techniques not included in the train set. Our findings clearly indicate the need for a better understanding of manipulation methods and the importance of designing algorithms that can successfully generalize onto unknown manipulations.",,IEE
698,Benchmarking Joint Face Spoofing and Forgery Detection With Visual and Physiological Cues,Z. Yu; R. Cai; Z. Li; W. Yang; J. Shi; A. C. Kot,2024,"Face anti-spoofing (FAS) and face forgery detection play vital roles in securing face biometric systems from presentation attacks (PAs) and vicious digital manipulation (e.g., deepfakes). Despite satisfactory performance upon large-scale data and powerful deep models, recent advances in face spoofing and forgery detection approaches usually focus on 1) unimodal visual appearance or physiological (i.e., remote photoplethysmography (rPPG)) cues; and 2) separated feature representation for FAS or face forgery detection. On one side, unimodal appearance and rPPG features are respectively vulnerable to high-fidelity face 3D mask and video replay attacks, inspiring us to design reliable multi-modal fusion mechanisms for generalized FAS. On the other side, there are rich common features across FAS and face forgery detection tasks (e.g., periodic rPPG rhythms and vanilla appearance for bonafides), providing solid evidence to design a joint FAS and face forgery detection system in a multi-task learning fashion. In this paper, we establish the first joint face spoofing and forgery detection benchmark using both visual appearance and physiological rPPG cues. To enhance the rPPG periodicity discrimination, we design a two-branch physiological network using both facial spatio-temporal rPPG signal map and its continuous wavelet transformed counterpart as inputs. To mitigate the modality bias and improve the fusion efficacy, we conduct a weighted batch and layer normalization for both appearance and rPPG features before multi-modal fusion. We also investigate prevalent deep models, feature fusion strategies and multi-task learning configurations for joint face spoofing and forgery detection. We find that the generalization capacities of both unimodal (appearance or rPPG) and multi-modal (appearance+rPPG) models can be obviously improved via joint training on these two tasks. We hope this new benchmark will facilitate the future research of both FAS and deepfake detection communities.",Face anti-spoofing;face forgery detection;deepfake;rPPG;fusion;joint training;multi-task learning,IEE
699,GPT-4 versus Bard and Bing: LLMs for Fake Image Detection,O. M. Al-Janabi; O. M. Alyasiri; E. A. Jebur,2023,"The recent emergence of sophisticated Large Language Models (LLMs) such as GPT-4, Bard, and Bing has revolutionized the domain of scientific inquiry, particularly in the realm of large pre-trained vision-language models. This pivotal transformation is driving new frontiers in various fields, including image processing and digital media verification. In the heart of this evolution, our research focuses on the rapidly growing area of image authenticity verification, a field gaining immense relevance in the digital era. The study is specifically geared towards addressing the emerging challenge of distinguishing between authentic images and deepfakes � a task that has become critically important in a world increasingly reliant on digital media. Our investigation rigorously assesses the capabilities of these advanced LLMs in identifying and differentiating manipulated imagery. We explore how these models process visual data, their effectiveness in recognizing subtle alterations, and their potential in safeguarding against misleading representations. The implications of our findings are far-reaching, impacting areas such as security, media integrity, and the trustworthiness of information in digital platforms. Moreover, the study sheds light on the limitations and strengths of current LLMs in handling complex tasks like image verification, thereby contributing valuable insights to the ongoing discourse on AI ethics and digital media reliability.",deepfake detection;large language models (LLMs);GPT-4;bard;bing chat,IEE
700,Generative AI: Impactful Considerations to Responsible Data Practices in Business Execution,T. Osm�ni; M. Ali,2023,"AI is shaping our society and changing what it means to be human. The future is getting frenetic since the adoption of Generative AI (GenAI) in our everyday life. Humanity is slowly transcending from a society of consumers to creators. We first began with Siri and Alexa; now it is ChatGPT, DALL-E, Stable Diffusion and several other tools powered by Artificial Intelligence (AI) and Machine Learning (ML). Audi as well has started the use of Generative Adversarial Networks (GANs) to get inspiration on wheel design. This paper will focus on: the advantages; the social and cultural impact that GenAI opposes; use cases on how GenAI can enhance innovation and drive business value from the technical prospect; the potential risks that might arise if GenAI is abused and conclude with how technology teams alongside the C-Suite and Board of Directors should take action. These risks include deepfakes, legal confusion, hiring biases and inaccurate chatbots. AI is in the service of humanity and it is a responsibility of ours to treat(/train) it with dignity and fairness.",bias;chatbots;deepfakes;GANs;GenAI;Operator 4.0,IEE
701,Lost in Translation: Lip-Sync Deepfake Detection from Audio-Video Mismatch,M. Bohacek; H. Farid,2024,"Highly realistic voice cloning combined with AI-powered video manipulation allows for the creation of compelling lip-sync deepfakes where anyone can be made to say things they never did. The resulting fakes are being used to entertain, but also for everything from election related disinformation to small- and large-scale fraud. Lip-sync deepfakes can be particularly difficult to detect because only the mouth and jaw of the person talking is modified. We describe a robust and general-purpose technique to detect these fakes. This technique begins by independently translating the audio (using audio-to-text transcription) and video (using automated lip-reading). We then show that the resulting transcriptions are significantly mismatched for lip-sync deepfakes as compared to authentic videos. The robustness of this technique is evaluated against a controlled dataset of our creation and in-the-wild fakes, all of varying length and resolution.",deepfakes;media forensics,IEE
702,OpenForensics: Large-Scale Challenging Dataset For Multi-Face Forgery Detection And Segmentation In-The-Wild,T. -N. Le; H. H. Nguyen; J. Yamagishi; I. Echizen,2021,"The proliferation of deepfake media is raising concerns among the public and relevant authorities. It has become essential to develop countermeasures against forged faces in social media. This paper presents a comprehensive study on two new countermeasure tasks: multi-face forgery detection and segmentation in-the-wild. Localizing forged faces among multiple human faces in unrestricted natural scenes is far more challenging than the traditional deepfake recognition task. To promote these new tasks, we have created the first large-scale dataset posing a high level of challenges that is designed with face-wise rich annotations explicitly for face forgery detection and segmentation, namely Open-Forensics. With its rich annotations, our OpenForensics dataset has great potentials for research in both deepfake prevention and general human face detection. We have also developed a suite of benchmarks for these tasks by conducting an extensive evaluation of state-of-the-art instance detection and segmentation methods on our newly constructed dataset in various scenarios.",Datasets and evaluation;Faces;Image and video manipulation detection and integrity methods,IEE
703,Deepfake: A Survey on Facial Forgery Technique Using Generative Adversarial Network,D. Yadav; S. Salmani,2019,"""Deepfake"" it is an incipiently emerging face video forgery technique predicated on AI technology which is used for creating the fake video. It takes images and video as source and it coalesces these to make a new video using the generative adversarial network and the output is very convincing. This technique is utilized for generating the unauthentic spurious video and it is capable of making it possible to generate an unauthentic spurious video of authentic people verbally expressing and doing things that they never did by swapping the face of the person in the video. Deepfake can create disputes in countries by influencing their election process by defaming the character of the politician. This technique is now being used for character defamation of celebrities and high-profile politician just by swapping the face with someone else. If it is utilized in unethical ways, this could lead to a serious problem. Someone can use this technique for taking revenge from the person by swapping face in video and then posting it to a social media platform. In this paper, working of Deepfake technique along with how it can swap faces with maximum precision in the video has been presented. Further explained are the different ways through which we can identify if the video is generated by Deepfake and its advantages and drawback have been listed.",Deepfake;Machine Learning;Deep Learning;Generative Adversarial Network;Neural Network,IEE
704,"What makes you, you? Analyzing Recognition by Swapping Face Parts",C. Ferrari; M. Serpentoni; S. Berretti; A. Del Bimbo,2022,"Deep learning advanced face recognition to an unprecedented accuracy. However, understanding how local parts of the face affect the overall recognition performance is still mostly unclear. Among others, face swap has been experimented to this end, but just for the entire face. In this paper, we propose to swap facial parts as a way to disentangle the recognition relevance of different face parts, like eyes, nose and mouth. In our method, swapping parts from a source face to a target one is performed by fitting a 3D prior, which establishes dense pixels correspondence between parts, while also handling pose differences. Seamless cloning is then used to obtain smooth transitions between the mapped source regions and the shape and skin tone of the target face. We devised an experimental protocol that allowed us to draw some preliminary conclusions when the swapped images are classified by deep networks, indicating a prominence of the eyes and eyebrows region. Code available at https://github.com/clferrari/FacePartsSwap",,IEE
705,AI-Enhanced Photo Authenticity: A User-Focused Approach to Detecting and Analyzing Manipulated Images,M. -T. Tran; B. -T. Nguyen; V. -L. Nguyen; T. -S. Nguyen; M. -K. Tran; T. -L. Do,2024,"In the digital age, the authenticity of photographs is increasingly questioned due to the rise of sophisticated AI and human manipulation techniques. This paper presents the development of an AI-assisted system designed to aid users in identifying and verifying the genuineness of photos. Unlike fully automated solutions, our approach emphasizes user empowerment, providing tools to enhance human expertise in photo authentication. The system integrates advanced algorithms to detect potential manipulations and localize regions of interest, directing users� attention to specific areas that warrant closer examination. Users can conduct more efficient and effective authenticity checks without scrutinizing the entire image by focusing on these targeted regions. Our goal is to augment, not replace, the critical role of human judgment in verifying photo authenticity. The system�s design and implementation are discussed, along with case studies demonstrating its practical application in various scenarios. This research aims to contribute to the growing field of digital forensics by providing a robust, user-friendly tool that bridges the gap between AI capabilities and human expertise in photo verification.",Photo Authenticity;AI-Assisted Verification;Manipulation Detection;Digital Forensics;Region Localization,IEE
706,"Multimodal Cognitive Learning for Media Forgery Detection: A Comprehensive Framework Combining Random Forest and Deep Ensemble Architectures (Xception, ResNeXt) across Image, Video, and Audio Modalities",A. Abirami; S. Bhuvaneswari; K. Krithika; I. Nithyasree; B. Prashithaa Abhirami,2023,"Deepfake content has become more prevalent in the age of quickly evolving technology, which has significantly undermined the reliability and integrity of digital media. An integrated multimodal deepfake detection system is presented in this study as a response to the ubiquitous threat posed by altered photos, videos, and audio recordings. The image deepfake detection module examines visual data for telltale signs of manipulation using Convolutional Neural Networks (CNNs), Xception, and ResNeXT. This module successfully distinguishes between real and fake photos by carefully examining pixel-level attributes and contextual data. With the use of spatiotemporal CNNs (Xception & ResNeXT), it parses video frames to find minute discrepancies, making it possible to accurately identify deepfake films. This multi-modal system is finished with the addition of deepfake audio detection. This module excels in differentiating between authentic and faked audio recordings using Mel spectrograms and Convolutional Neural Networks, adding to a thorough protection against audio deepfakes. Additionally, a unifying framework has been provided that effectively unifies these three detection modules, boosting the system�s effectiveness and performance as a whole. The solution has been thoroughly assessed using measures like accuracy, F1 score, ROC curve, and AUC, and the model structures for in-depth comprehension. This multi-modal deepfake detection technology acts as a crucial precaution in a time when false information is widely disseminated, enabling consumers to distinguish fact from fiction across numerous media types. This study highlights the importance of integrated solution in maintaining the legitimacy of digital content in today�s information-driven world while also showcasing its technological capability.",Deepfake detection;Multi-modal system;Image manipulation;Video forgery;Audio spoofing;Convolutional Neural Networks (CNNs);Xception;ResNeXT;Spatiotemporal analysis;Mel spectrograms;F1 score;ROC curve;AUC,IEE
707,Detecting Deepfakes using CNN and LSTM,R. Chinchalkar; R. Sinha; M. Kumar; N. Chauhan; S. Deokar; S. Gonge,2023,"Deepfake, a face-swapping method that has been abused recently, has caused a great deal of public worry. Effective countermeasures are required because several deepfake videos, sometimes known as ""deepfakes,"" have already been created and posted online. Therefore, Deepfake detection is going to be a promising defense against deep fakes. It is quite easy to imagine cases in which these convincing tampered videos are exploited to foment political unrest, extort money, or stage terrorist attacks. In this study, a pipeline is suggested for identifying and classifying deepfake videos. Our system uses convolutional neural networks (CNNs) to retrieve frame-level characteristics. Then, a recurrent neural network (RNN-LSTM) is built using these features to determine if a video has been altered or not. We study, analyze and compare various methodologies and ours on a vast cluster of deep fake videos from various video sources. We present how our system can complete this task effectively with comparative results while utilizing a straight forward architecture.",deepfakes;facial manipulation;deep learning,IEE
708,Detecting Deepfakes: using CNN to Identify Manipulated Visual Media,N. Sunanda; K. Shailaja; J. S. Babu; K. Vamsi Krishna; N. LakshmanPratap; R. Kanth Motupalli,2024,"Deepfake detection is a rapidly evolving field with significant implications for the integrity of visual media. This review explores techniques, challenges, and future directions in deepfake detection. Traditional image forensics techniques, deep learning models, and multi-modal fusion approaches are employed to differentiate real content from deepfakes. Addressing the challenges of evolving deepfake algorithms and the need for real-time detection, future research should focus on novel architectures, training strategies, temporal and contextual information, and ethical considerations. By advancing deepfake detection methods, researchers can contribute to combating the proliferation of synthetic content and preserving the authenticity of visual media in the digital age.",Res-Next Convolution Neural Network;long short-term memory (LSTM);PyTorch,IEE
709,Exploring Frequency Adversarial Attacks for Face Forgery Detection,S. Jia; C. Ma; T. Yao; B. Yin; S. Ding; X. Yang,2022,"Various facial manipulation techniques have drawn seri-ous public concerns in morality, security, and privacy. Al- though existing face forgery classifiers achieve promising performance on detecting fake images, these methods are vulnerable to adversarial examples with injected impercep- tible perturbations on the pixels. Meanwhile, many face forgery detectors always utilize the frequency diversity be-tween real and fake faces as a crucial clue. In this paper, in- stead of injecting adversarial perturbations into the spatial domain, we propose a frequency adversarial attack method against face forgery detectors. Concretely, we apply dis-crete cosine transform (DCT) on the input images and in-troduce a fusion module to capture the salient region of ad-versary in the frequency domain. Compared with existing adversarial attacks (e.g. FGSM, PGD) in the spatial do-main, our method is more imperceptible to human observers and does not degrade the visual quality of the original images. Moreover, inspired by the idea of meta-learning, we also propose a hybrid adversarial attack that performs at-tacks in both the spatial and frequency domains. Exten-sive experiments indicate that the proposed method fools not only the spatial-based detectors but also the state-of- the-art frequency-based detectors effectively. In addition, the proposed frequency attack enhances the transferability across face forgery detectors as black-box attacks.",Face and gestures,IEE
710,Convolutional Neural Network Based on Diverse Gabor Filters for Deepfake Recognition,A. H. Khalifa; N. A. Zaher; A. S. Abdallah; M. W. Fakhr,2022,"Media synthesis and manipulation has reached unprecedented levels of realism owing to the proliferation of deep learning. Deepfake has been the de-facto tool for media manipulation. Although this technology has potential in the entertainment industry, its threats include political manipulation and bypassing biometric security systems. As a result, deepfake detection has garnered widespread attention among research communities. The intuition is to use deep learning to fix the problems created by deep learning. Although convolutional neural networks have shown their dominance in the filed of pattern recognition, the receptive field-model size dilemma still persists along with the lack of interpretation for such models. While the traditional Gabor function was proposed to fix these problems, it can only generate limited linear Gabor filters which makes it optimal for limited data and applications. The contribution of this paper is quadruple: (i) proposing a unified Gabor function capable of generating linear, elliptical, and circular Gabor filters. (ii) leveraging the back-propagation learning framework to incorporate the proposed function in convolutional neural networks and generate adaptive Gabor filters. (iii) presenting a dual scale large receptive field network for deepfake image recognition. (iv) demonstrating where the proposed model stands in terms of performance and architecture size compared to state-of-the-art models. The proposed model is evaluated on four benchmark datasets: Celeb-DF (v2), DeepFake Detection Challenge Preview, FaceForensics++ and Wilddeepfake. Experimental results show that the proposed adaptive Gabor filters reduce the model size by 64.9% compared to adaptive weighted filters without performance reduction.",Compact neural networks;image classification;image forensics;learnable filters;pattern recognition,IEE
711,PhoneyTalker: An Out-of-the-Box Toolkit for Adversarial Example Attack on Speaker Recognition,M. Chen; L. Lu; Z. Ba; K. Ren,2022,"Voice has become a fundamental method for human-computer interactions and person identification these days. Benefit from the rapid development of deep learning, speaker recognition exploiting voice biometrics has achieved great success in various applications. However, the shadow of adversarial example attacks on deep neural network-based speaker recognition recently raised extensive public concerns and enormous research interests. Although existing studies propose to generate adversarial examples by iterative optimization to deceive speaker recognition, these methods require multiple iterations to construct specific perturbations for a single voice, which is input-specific, time-consuming, and non-transferable, hindering the deployment and application for non-professional adversaries. In this paper, we propose PhoneyTalker, an out-of-the-box toolkit for any adversary to generate universal and transferable adversarial examples with low complexity, releasing the requirement for professional background and specialized equipment. PhoneyTalker decomposes an arbitrary voice into phone combinations and generates phone-level perturbations using a generative model, which are reusable for voices from different persons with various texts. Experiments on mainstream speaker recognition systems with large-scale corpus show that PhoneyTalker outperforms state-of-the-art methods with overall attack success rates of 99.9% and 84.0% under white-box and black-box settings respectively.",Adversarial example attack;universal adversarial perturbation;generative model;speaker recognition,IEE
712,Classification of Deepfake Videos Using Pre-trained Convolutional Neural Networks,M. Masood; M. Nawaz; A. Javed; T. Nazir; A. Mehmood; R. Mahum,2021,"The advancement of Artificial Intelligence (AI) has brought a revolution in the field of information technology. Furthermore, AI has empowered the new applications to run with minimum resources and computational cost. One of such applications is Deepfakes, which produces extensively altered and modified multimedia content. However, such manipulated visual data imposed a severe threat to the security and privacy of people and can cause massive sect, religious, political, and communal stress around the globe. Now, the face-swapped base visual content is difficult to recognizable by humans through their naked eyes due to the advancement of Generative adversarial networks (GANs). Therefore, identifying such forgeries is a challenging task for the research community. In this paper, we have introduced a pipeline for identifying and detecting person faces from input visual samples. In the second step, several deep learning (DL) based approaches are employed to compute the deep features from extracted faces. Lastly, a classifier namely SVM is trained over these features to classify the data as real or manipulated. We have performed the performance comparison of various feature extractors and confirmed from reported results that DenseNet-169 along with SVM classifier outperforms the rest of the methods.",deepfakes;deep-learning;visual manipulations;convolutional neural networks,IEE
713,Efficient Video Privacy Protection Against Malicious Face Recognition Models,E. Guo; P. Li; S. Yu; H. Wang,2022,"The proliferation of powerful facial recognition systems poses a serious threat to user privacy. Attackers could train highly accurate facial recognition models using public data on social platforms. Therefore, recent works have proposed image pre-processing techniques to protect user privacy. Without affecting people's normal viewing, these techniques add special noises into images, so that it would be difficult for attackers to train models with high accuracy. However, existing protection techniques are mainly designed for image data protection, and they cannot be directly applied for video data because of high computational overhead. In this paper, we propose an efficient protection method for video privacy that exploits unique features of video protection to eliminate computation redundancy for computational acceleration. The evaluation results under various benchmarks demonstrate that our method significantly outperforms the traditional methods by reducing computation overhead by 35.5%.",Computation reuse;deep learning;video privacy,IEE
714,Analysis of Fake News Detection using Graph Neural Network (GNN) and Deep Learning,P. Hiremath; S. S. Kalagi; Mohana,2023,"The rise of fake news in social networks has become a significant concern, necessitating innovative strategies to combat misinformation. One such approach is the use of graph neural networks (GNNs) to trace and analyze false information dissemination. GNNs are specialized DL model capable of processing graph-structured data, making them ideal for capturing intricate dependencies and relationships in the spread of fake news. Proposed implementation starting with data preparation, where a carefully curated dataset is essential. The news stories are processed, tokenized, and transformed into a graph representation to better understand the relationships between words or entities. Graph construction enables the formulation of ML problems as graph classification tasks. Graph embedding, achieved through methods like word2vec or GNNs, plays a crucial role in representing each node as a low-dimensional vector, capturing its semantic significance within the network. This technique facilitates ML activities, such as node classification and link prediction. Combining graph embeddings and GNNs for classification allows for a more precise identification of true and false news, considering the structure and content of news propagation graphs. Finally, evaluating false news detection involves performance metrics such as accuracy. Proposed implementation obtained detection accuracy of 94%. Striking a balance between minimizing false positives and false negatives is crucial to combat misinformation effectively. By employing this approach, society can create a more trustworthy information environment, enabling individuals to make informed decisions and reducing the negative impact of fake news.",Graphical Neural Network(GNN);Deep Learning;Fake News Detection;Natural Language Processing(NLP),IEE
715,Gotcha: Real-Time Video Deepfake Detection via Challenge-Response,G. Mittal; C. Hegde; N. Memon,2024,"With the rise of AI-enabled Real-Time Deepfakes (RTDFs), the integrity of online video interactions has become a growing concern. RTDFs have now made it feasible to replace an imposter's face with their victim in live video interactions. Such advancement in deepfakes also coaxes detection to rise to the same standard. However, existing deepfake detection techniques are asynchronous and hence ill-suited for RTDFs. To bridge this gap, we propose a challenge-response approach that establishes authenticity in live settings. We focus on talking-head style video interaction and present a taxonomy of challenges that specifically target inherent limitations of RTDF generation pipelines. We evaluate representative examples from the taxonomy by collecting a unique dataset comprising eight challenges, which consistently and visibly degrades the quality of state-of-the-art deepfake generators. These results are corroborated both by humans and a new automated scoring function, leading to 88.6% and 80.1% AUC, respectively. The findings under-score the promising potential of challenge-response systems for explainable and scalable real-time deepfake detection in practical scenarios. We provide access to data and code at https://github.com/mittalgovind/GOTCHA-Deepfakes.",Deepfakes;Video Calls;Real-time Deepfakes;Challenge-Response;Authentication,IEE
716,"Deepfake: Classifiers, Fairness, and Demographically Robust Algorithm",A. Agarwal; N. Ratha,2024,"Deepfake detection research has seen tremendous success and has achieved remarkably high performance on a few existing datasets. However, the significant drawback of the existing works is the generalizability of the detection algorithms under cross-datasets and cross-attack/manipulation settings. On top of that, another critical bottleneck of deepfake detection literature is the understanding of the fairness quotient of these algorithms. One big reason for such a less explored domain is the unavailability of deep fake datasets covering multiple ethnicities and genders with proper annotations. For example, the popular deepfake detection datasets such as FaceForensics++ and Celeb-DF are highly biased toward Caucasian ethnicity. Recently, a multi-ethnicity multi-modal dataset namely FakeAVCeleb has been released which can fulfill this gap. Henceforth by utilizing the potential of this dataset, we have performed the fairness study of deepfake detection algorithms. For that, several image classifiers are selected which range from deep convolutional neural networks to handcrafted image feature extraction to vision transformers. The experiments performed using such a wide variety of classifiers reveal that the deepfake detectors are not fair and can detect one ethnicity with high accuracy but fail miserably on others. For instance, the performance of one of the popular deepfake detection networks namely XceptionNet shows a reduction of more than 30% when dealing with different ethnicities and genders. Not only ethnicity or gender but also the type of classifiers have a huge impact on the performance. We assert that the proposed study can help in building a fair, robust, and accurate deepfake classifier utilizing insightful findings that can help in the selection of an effective and robust backbone architecture.",,IEE
717,Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection,A. Haliassos; R. Mira; S. Petridis; M. Pantic,2022,"One of the most pressing challenges for the detection of face-manipulated videos is generalising to forgery methods not seen during training while remaining effective under common corruptions such as compression. In this paper, we examine whether we can tackle this issue by harnessing videos of real talking faces, which contain rich information on natural facial appearance and behaviour and are readily available in large quantities online. Our method, termed RealForensics, consists of two stages. First, we exploit the natural correspondence between the visual and auditory modalities in real videos to learn, in a self-supervised cross-modal manner, temporally dense video representations that capture factors such as facial movements, expression, and identity. Second, we use these learned representations as targets to be predicted by our forgery detector along with the usual binary forgery classification task; this encourages it to base its real/fake decision on said factors. We show that our method achieves state-of-the-art performance on cross-manipulation generalisation and robustness experiments, and examine the factors that contribute to its per-formance. Our results suggest that leveraging natural and unlabelled videos is a promising direction for the development of more robust face forgery detectors.",Computer vision for social good; Face and gestures; Representation learning; Self-& semi-& meta- Video analysis and understanding,IEE
718,A Deepfake Face Video Authentication Method Based on Spatio-temporal Fusion Features,B. Li; S. Zhou; Z. Zhang; J. Yin,2023,"With the wide spread of deepfake face videos, it has brought huge hidden dangers of trust to national security and social stability. In this paper, the authentication model framework of deepfake face video with spatio-temporal fusion features is proposed. Through three improvements including collecting mixed training samples, training two 2D deep convolutional neural networks with face center clipping images and using 3D deep convolutional neural networks to utilize the inter-frame consistency information, the authentication success rate of deepfake face video is improved. In the experiment two video forgery methods FaceSwap and Deepfakes were selected in the Faceforences ++ dataset to identify the deepfake video of facial feature area and facial edge area, which obtained certain results. Further breakthroughs are expected in the future through the integration of multi-modal data features and the use of large-scale pre-trained models.",deepfakes;face video authentication;spatio-temporal fusion;mixed training samples,IEE
719,BiHPF: Bilateral High-Pass Filters for Robust Deepfake Detection,Y. Jeong; D. Kim; S. Min; S. Joe; Y. Gwon; J. Choi,2022,"The advancement in numerous generative models has a two-fold effect: a simple and easy generation of realistic synthesized images, but also an increased risk of malicious abuse of those images. Thus, it is important to develop a generalized detector for synthesized images of any GAN model or object category, including those unseen during the training phase. However, the conventional methods heavily depend on the training settings, which cause a dramatic decline in performance when tested with unknown domains. To resolve the issue and obtain a generalized detection ability, we propose Bilateral High-Pass Filters (BiHPF), which amplify the effect of the frequency-level artifacts that are generally found in the synthesized images of generative models. Also, to find the properties of the general frequency-level artifacts, we develop an additional method to adversarially extract the artifact compression map. Numerous experimental results validate that our method outperforms other state-of-the-art methods, even when tested with unseen domains.",Vision Systems and Applications Deep Learning -> Adversarial Learning; Adversarial Attack and Defense Methods; Deep Learning -> Neural Generative Models; Autoencoders; GANs; Security/Surveillance,IEE
720,Detecting and Mitigating the Dissemination of Fake News: Challenges and Future Research Opportunities,W. Shahid; B. Jamshidi; S. Hakak; H. Isah; W. Z. Khan; M. K. Khan; K. -K. R. Choo,2024,"Fake news is a major threat to democracy (e.g., influencing public opinion), and its impact cannot be understated particularly in our current socially and digitally connected society. Researchers from different disciplines (e.g., computer science, political science, information science, and linguistics) have also studied the dissemination, detection, and mitigation of fake news; however, it remains challenging to detect and prevent the dissemination of fake news in practice. In addition, we emphasize the importance of designing artificial intelligence (AI)-powered systems that are capable of providing detailed, yet user-friendly, explanations of the classification / detection of fake news. Hence, in this article, we systematically survey existing state-of-the-art approaches designed to detect and mitigate the dissemination of fake news, and based on the analysis, we discuss several key challenges and present a potential future research agenda, especially incorporating AI explainable fake news credibility system.",Artificial intelligence (AI) explainability;blockchain-based detection;deceptive content;deep fakes;fake news;misinformation;news propaganda;social bots;social media,IEE
721,Identifying Deepfake Faces with ResNet50-Keras using Amazon EC2 DL1 Instances powered by Gaudi Accelerators from Habana Labs,S. Pradhan; R. Shah; R. Shah; A. Goenka,2022,"With the emergence of deepfake technology, it has become exponentially more difficult to identify real content from the artificially generated on social media. To counter the ill-effects of online deepfake content, we propose an application to predict if a given facial image is real or generated virtually via deepfake technology. We train a custom ResNet50-Keras model on the new AWS EC2 DL1 Instances powered by Gaudi accelerators developed by Habana Labs (an Intel company) and integrate the instance with Amazon's S3 bucket. With the model saved as an h5 file, we make a RestAPI using FastAPI. The API takes an input image, converts it into a JSON request, and passes it to the backend. Faces extracted from these images are passed through various pre-processing methods and finally to the model that classifies them to be either a deepfake or not and generates a face mesh accordingly. The model combines the processed faces into a single image sent back as a response to the client that changes the stateHooks to display the desired result. Further, we have summarized the results obtained when detecting such manipulated images.",habana;gaudi;aws ec2 dl1;resnet50;faceforensics;tensorflow;keras;deepfake;mediapipe;facial landmark;react;fastapi;restful api,IEE
722,Celeb-DF: A Large-Scale Challenging Dataset for DeepFake Forensics,Y. Li; X. Yang; P. Sun; H. Qi; S. Lyu,2020,"AI-synthesized face-swapping videos, commonly known as DeepFakes, is an emerging problem threatening the trustworthiness of online information. The need to develop and evaluate DeepFake detection algorithms calls for datasets of DeepFake videos. However, current DeepFake datasets suffer from low visual quality and do not resemble DeepFake videos circulated on the Internet. We present a new large-scale challenging DeepFake video dataset, Celeb-DF, which contains 5,639 high-quality DeepFake videos of celebrities generated using improved synthesis process. We conduct a comprehensive evaluation of DeepFake detection methods and datasets to demonstrate the escalated level of challenges posed by Celeb-DF.",,IEE
723,ABC-CapsNet: Attention based Cascaded Capsule Network for Audio Deepfake Detection,T. M. Wani; R. Gulzar; I. Amerini,2024,"In response to the escalating challenge of audio deepfake detection, this study introduces ABC-CapsNet (Attention-Based Cascaded Capsule Network), a novel architecture that merges the perceptual strengths of Mel spectrograms with the robust feature extraction capabilities of VGG18, enhanced by a strategically placed attention mechanism. This architecture pioneers the use of cascaded capsule networks to delve deeper into complex audio data patterns, setting a new standard in the precision of identifying manipulated audio content. Distinctively, ABC-CapsNet not only addresses the inherent limitations found in traditional CNN models but also showcases remarkable effectiveness across diverse datasets. The proposed method achieved an equal error rate EER of 0.06% on the ASVspoof2019 dataset and an EER of 0.04% on the FoR dataset, underscoring the superior accuracy and reliability of the proposed system in combating the sophisticated threat of audio deepfakes.",Audio Deepfakes;Cascaded Networks;Capsule Networks;ASVspoof 2019;FoR,IEE
724,A comprehensive study on multimedia DeepFakes,A. Boutadjine; F. Harrag; K. Shaalan; S. Karboua,2023,"Since the entry of so-called DeepFakes in the development of fake multimedia, this late has marked a turning point and emerged as a major issue, although visual and aural media manipulations date back to the beginning of media itself. Thanks to this technology, the detection of altered and generated material has recently received more attention since the human ability to identify DeepFakes has significantly been far less effective than that of deep learning models. organizations need to be ready as there are countless ways to deceive using convincingly altered photos, videos, and audio, such as perpetrating fraud, damaging reputations, extorting money or influencing public opinion during elections, which undoubtedly impacts society. In this regard, there is a critical need for automated solutions that can identify fake multimedia material and prevent the spread of dangerous misinformation. This article aims to give a comprehensive review of DeepFakes and a summary of the technology that underpins it. We provide information on various DeepFake detection algorithms, identify potential dangers of this frightening modern phenomenon, and highlight future research challenges.",DeepFake;artificial intelligence;deep learning;DeepFake detection.,IEE
725,Fine-Grained Face Swapping Via Regional GAN Inversion,Z. Liu; M. Li; Y. Zhang; C. Wang; Q. Zhang; J. Wang; Y. Nie,2023,"We present a novel paradigm for high-fidelity face swapping that faithfully preserves the desired subtle geometry and texture details. We rethink face swapping from the perspective of fine-grained face editing, i.e., �editing for swapping� (E4S), and propose a framework that is based on the explicit disentanglement of the shape and texture of facial components. Following the E4S principle, our framework enables both global and local swapping of facial features, as well as controlling the amount of partial swapping specified by the user. Furthermore, the E4S paradigm is in-herently capable of handling facial occlusions by means of facial masks. At the core of our system lies a novel Regional GAN Inversion (RGI) method, which allows the explicit disentanglement of shape and texture. It also allows face swapping to be performed in the latent space of Style-GAN. Specifically, we design a multi-scale mask-guided encoder to project the texture of each facial component into regional style codes. We also design a mask-guided injection module to manipulate the feature maps with the style codes. Based on the disentanglement, face swapping is re-formulated as a simplified problem of style and mask swapping. Extensive experiments and comparisons with current state-of-the-art methods demonstrate the superiority of our approach in preserving texture and shape details, as well as working with high resolution images. The project page is https://e4s2022.github.io",Image and video synthesis and generation,IEE
726,Faceswap Deepfakes Detection using Novel Multi-directional Hexadecimal Feature Descriptor,Qurat-ul-ain; A. Javed; K. Mahmood Malik,2022,"With the growing number of sophisticated deep learning algorithms and fake video generation applications, it is now possible to create highly realistic deepfake videos. Faceswap is the most commonly employed deepfakes approach, which is challenging to detect due to variations in the facial skin tone, illumination conditions, presence of accessories like glasses on the face, compression artifacts, etc. Existing local texture descriptors have achieved better performance on face recognition applications; however, they compute only the limited directional information while ignoring the magnitude details. This motivated us to develop a robust local texture descriptor to extract more directional and magnitude details from the adjacent pixels to effectively represent the video frames. For this purpose, we proposed a robust multi-directional hexadecimal feature descriptor (MDHFD) by combining the local hexadecimal pattern (LHeXDP) and Local Adjacent Neighborhood Magnitude Pattern (LANMP). LHeXDP calculates the orientation-based pattern by computing 1st- and 2nd-order derivatives at 0�, 45�, 90�, and 135� angles from each center pixel. LANMP computes the magnitude information from each central pixel to its adjacent pixels in horizontal, vertical, diagonal, and diagonal-back directions. Histograms of both the LHeXDP and LANMP are fused to compute a multi-directional feature vector, which is used to train a support vector machine to classify between the original or faceswap deepfakes video. We measured the performance of our system on the challenging faceswap subset of a diverse and large-scale Face Forensic++ and World Leaders datasets. Experimental results illustrate that the proposed method outperforms state-of-art methods for the detection of faceswap deepfakes.",Deepfakes;faceswap;LHeXDP;LANMP;magnitude-based patterns;orientation-based patterns;SVM,IEE
727,Detection Enhancement for Various Deepfake Types Based on Residual Noise and Manipulation Traces,J. Kang; S. -K. Ji; S. Lee; D. Jang; J. -U. Hou,2022,"As deepfake techniques become more sophisticated, the demand for fake facial image detection continues to increase. Various deepfake detection techniques have been introduced but detecting all types of deepfake images with a single model remains challenging. We propose a technique for detecting various types of deepfake images using three common traces generated by deepfakes: residual noise, warping artifacts, and blur effects. We adopted a network designed for steganalysis to detect pixel-wise residual-noise traces. We also consider landmarks, which are the primary parts of the face where unnatural deformations often occur in deepfake images, to capture high-level features. Finally, because the effect of a deepfake is similar to that of blurring, we apply features from various image quality measurement tools that can capture traces of blurring. The results demonstrate that each detection strategy is efficient, and that the performance of the proposed network is stable and superior to that of existing detection networks on datasets of various deepfake types.",Deepfake forensics;image forensics;residual noise;warping artifact;image quality measurement,IEE
728,Face2Face Manipulation Detection Based on Histogram of Oriented Gradients,A. Megahed; Q. Han,2020,"Nowadays with rapid advances in computer vision and deep learning, it is possible to create highly realistic synthetic faces in digital videos. This situation increases anxiety and suspicion in the video content. It can be a big challenge for humans and machines to differentiate between real and fake faces in a video, especially when the video is compressed or has low resolution. In this paper, an efficient method is proposed for detecting Face2Face manipulations. With the analysis of manipulated videos, we found that there are some visual artifacts that can be exploited to detect fake faces. The proposed method utilizes the histogram of oriented gradients for feature extraction that can be effective in exposing Face2Face manipulations. Experimental results clarify that our method effectively detects the manipulated faces with a high-performance accuracy under various compression quality levels.",Face forensics;Video manipulation detection;Facial reenactment;HOG features;SVM classifier,IEE
729,Fake-image detection with Robust Hashing,M. Tanaka; H. Kiya,2021,"In this paper, we investigate whether robust hashing has a possibility to robustly detect fake-images even when multiple manipulation techniques such as JPEG compression are applied to images for the first time. In an experiment, the proposed fake detection with robust hashing is demonstrated to outperform state-of-the-art one under the use of various datasets including fake images generated with GANs.",fake images;GAN,IEE
730,Fake News Detection on COVID-19 Tweeter Data Using Machine Learning Models,A. Chabukswar; S. J; S. G; L. S R; P. D. Shenoy; V. K R,2022,"People can access the news easily from various channels like social media (twitter, Facebook etc.,), social bots due to which the Fake news is propagated at a faster rate. To avoid this, Machine Learning models can be used to categorize the news into different classes like Fake and Real so that people will be aware of the real news. An ensemble model is proposed to classify the Tweets which are collected from the Kaggle consisting of twitter posts, data pre-processing, extracting features using NLTK toolkit and training and testing the data using various Machine Learning (ML) models such as Support Vector Machine, Naive Bayes, Logistic Regression and Random Forest. An accuracy of 70% is achieved on LIAR dataset. Datasets based on COVID-19 Tweets, achieved an accuracy of 90% by Ensemble approach.",Fake news;Natural Language Processing (NLP);Twitter;Machine Learning,IEE
731,Evaluating Effectiveness of Using Multi-Features to Differentiate Real from Fake Facial Images,S. Saif; S. Tehseen,2022,"Face analysis is one of the key research areas in the field of computer vision with applications in numerous areas. Face recognition, emotion recognition, and more recently deepfake detection have greatly benefited from the advancements in the field of face analysis. Our research attempts to identify useful facial features for analysis. We first analyze the effectiveness of geometric facial features for the purpose of emotion recognition. In later experiments, a fusion scheme was created based on the preliminary analysis,which tested the performance of these selected features for the identification of real and fake images. We include local image features in combination with geometric facial features to measure their effectiveness in fake image detection tasks. The promising results produced in this study can be used to perform a more in-depth analysis of face geometry and its result in facial analysis.",Face Analysis;Face Feature Extraction;Emotion Recognition Features;Fake Image Detection,IEE
732,Adversarial Identity Injection for Semantic Face Image Synthesis,G. Tarollo; T. Fontanini; C. Ferrari; G. Borghi; A. Prati,2024,"Nowadays, deep learning models have reached incredible performance in the task of image generation. Plenty of literature works address the task of face generation and editing, with human and automatic systems that struggle to distinguish what�s real from generated. Whereas most systems reached excellent visual generation quality, they still face difficulties in preserving the identity of the starting input subject. Among all the explored techniques, Semantic Image Synthesis (SIS) methods, whose goal is to generate an image conditioned on a semantic segmentation mask, are the most promising, even though preserving the perceived identity of the input subject is not their main concern. Therefore, in this paper, we investigate the problem of identity preservation in face image generation and present an SIS architecture that exploits a cross-attention mechanism to merge identity, style, and semantic features to generate faces whose identities are as similar as possible to the input ones. Experimental results reveal that the proposed method is not only suitable for preserving the identity but is also effective in the face recognition adversarial attack, i.e. hiding a second identity in the generated faces.",Face Editing;Semantic Image Synthesis;Adversarial Attacks,IEE
733,CYBORG: Blending Human Saliency Into the Loss Improves Deep Learning-Based Synthetic Face Detection,A. Boyd; P. Tinsley; K. Bowyer; A. Czajka,2023,"Can deep learning models achieve greater generalization if their training is guided by reference to human perceptual abilities? And how can we implement this in a practical manner? This paper proposes a training strategy to ConveY Brain Oversight to Raise Generalization (CYBORG). This new approach incorporates human-annotated saliency maps into a loss function that guides the model�s learning to focus on image regions that humans deem salient for the task. The Class Activation Mapping (CAM) mechanism is used to probe the model�s current saliency in each training batch, juxtapose this model saliency with human saliency, and penalize large differences. Results on the task of synthetic face detection, selected to illustrate the effectiveness of the approach, show that CYBORG leads to significant improvement in accuracy on unseen samples consisting of face images generated from six Generative Adversarial Networks across multiple classification network architectures. We also show that scaling to even seven times the training data, or using non-human-saliency auxiliary information, such as segmentation masks, and standard loss cannot beat the performance of CYBORG-trained models. As a side effect of this work, we observe that the addition of explicit region annotation to the task of synthetic face detection increased human classification accuracy. This work opens a new area of research on how to incorporate human visual saliency into loss functions in practice. All data, code and trained models used in this work are offered with this paper.",Algorithms: Biometrics;face;gesture;body pose;Machine learning architectures;formulations;and algorithms (including transfer;low-shot;semi-;self-;and un-supervised learning);Psychology and cognitive science,IEE
734,Demystifying deepfakes using deep learning,R. K. Singh; P. V. Sarda; S. Aggarwal; D. K. Vishwakarma,2021,"Manipulation of images, videos and audios using face edit apps and web services have long been in use, since decades but recent advances in deep learning has led to rising AI generated fake images and videos with swapped faces, lip synced audios and puppet masters, popularly known as Deepfakes. Generated primarily using one of the following two approaches namely, Autoencoders and Generator Adversarial Networks which rests on trained deep neural networks, deepfakes offer unprecedented challenges. The degree of realism achieved by deep learning powered deepfakes increases with increasing amounts of data i.e, fake images and videos readily available on the internet at disposal to train GANs. Deepfake algorithms create media leaving a bare margin of difference between the authentic or original source and the forged or deepfaked targets. Thus, new mechanisms and techniques to detect and filter out such deepfakes is the need of the hour.This paper exploits two powerful deep learning based CNN architectures namely, Inception-Resnet-v2 and XceptionNet for detecting the deepfakes. The proposed approach not only outshines the existing approaches in terms of efficiency and accuracy but also offers the best in terms of the given space and time complexity.",Auto-encoders;DFDC;FaceForensics++;GAN;Inception-ResNet-v2;MesoNet;XceptionNet,IEE
735,IIN-FFD: Intra-Inter Network for Face Forgery Detection,Q. Zhou; Z. Zhou; Z. Bao; W. Niu; Y. Liu,2024,"Since different kinds of face forgeries leave similar forgery traces in videos, learning the common features from different kinds of forged faces would achieve promising generalization ability of forgery detection. Therefore, to accurately detect known forgeries while ensuring high generalization ability of detecting unknown forgeries, we propose an intra-inter network (IIN) for face forgery detection (FFD) in videos with continual learning. The proposed IIN mainly consists of three modules, i.e., intra-module, inter-module, and forged trace masking module (FTMM). Specifically, the intra-module is trained for each kind of face forgeries by supervised learning to extract special features, while the inter-module is trained by self-supervised learning to extract the common features. As a result, the common and special features of the different forgeries are decoupled by the two feature learning modules, and then the decoupled common features can be utlized to achieve high generalization ability for FFD. Moreover, the FTMM is deployed for contrastive learning to further improve detection accuracy. The experimental results on FaceForensic++ dataset demonstrate that the proposed IIN outperforms the state-of-the-arts in FFD. Also, the generalization ability of the IIN verified on DFDC and Celeb-DF datasets demonstrates that the proposed IIN significantly improves the generalization ability for FFD.",deep learning;information security;image classfication;neural networks;face forgery;face forgery detection,IEE
736,Deep Learning model-based Multimedia forgery detection,Y. Shah; P. Shah; M. Patel; C. Khamkar; P. Kanani,2020,Images and videos can be spread very conveniently using social media platforms like WhatsApp and Facebook. The authenticity of this information cannot be verified easily but it spreads swiftly. Fake images or videos are a new threat for people as they spread false information and rumors. Advances in technology have given rise to several techniques that can easily generate fake images or videos. Deepfakes and spliced images are some of the results of such advances. They pose a great menace to the internet Tackling and detecting such an entity is a tricky task. Our paper portrays a technique to detect such entities. It will assist people in detecting bogus content and have confidence on the legitimacy of the content on the internet We present a description of CNN based approach and evaluate its results. The drawbacks of the traditional approach have been minimized using Inception Residual Network architecture based CNNs.,Deepfake;Convolutional Neural Networks;error level analysis;fake images;Inception Networks;Residual Networks,IEE
737,Analysis and Comparison of Deepfakes Detection Methods for Cross-Library Generalisation,C. Wang; H. Sharifzadeh; S. Varastehpour; I. Ardekani,2023,"The rise of generative artificial intelligence (GenAI) has made it increasingly possible to use Deepfakes technology to generate fake pictures and videos. While this technology has benefits, it also has downsides such as spreading misinformation and endangering public interests. To address this issue, researchers have proposed various deep forgery detection algorithms and have achieved remarkable results. However, a common problem regarding these detection methods is that while in-library detection can usually achieve high accuracy, their performance is significantly degraded in cross-library detection. This indicates a severe problem of insufficient generalisation ability.To better compare the performance differences between various detection methods, this paper analyses the detection performance of the six established models of Two-stream, MesoNet, HeadPose, FWA, VA, and Multi-task. To ensure consistency, we employ a uniform evaluation framework as a benchmark for comparison. We conduct extensive intra-library and cross-library tests to evaluate these methods� generalisation ability by utilising accuracy and error rate as key evaluation criteria for our experiments. Additionally, we further explore areas for improvement by analysing the impact of data augmentation, dataset partitioning, and threshold selection on the performance of these detection methods. Our comparative experiments are conducted on three existing fake face video datasets, including FaceForensics++, DeepfakeTIMIT, and Celeb-DF.Our research findings indicate the database partitioning method has a direct impact on the detector�s performance, and to enhance generalisation performance, the database should be divided person-based manually. The effectiveness of data augmentation techniques in improving cross-library performance is generally limited, and setting the threshold directly using source domain data often leads to a high error rate in the target domain. The findings of this paper provide insights into the development of more effective detection methods to combat the harmful effects of Deepfakes.",Deepfakes;Detection Methods;Generalisation;Cross-Library,IEE
738,How Do the Hearts of Deep Fakes Beat? Deep Fake Source Detection via Interpreting Residuals with Biological Signals,U. A. Ciftci; ?. Demir; L. Yin,2020,"Fake portrait video generation techniques have been posing a new threat to the society with photorealistic deep fakes for political propaganda, celebrity imitation, forged evidences, and other identity related manipulations. Following these generation techniques, some detection approaches have also been proved useful due to their high classification accuracy. Nevertheless, almost no effort was spent to track down the source of deep fakes. We propose an approach not only to separate deep fakes from real videos, but also to discover the specific generative model behind a deep fake. Some pure deep learning based approaches try to classify deep fakes using CNNs where they actually learn the residuals of the generator. We believe that these residuals contain more information and we can reveal these manipulation artifacts by disentangling them with biological signals. Our key observation yields that the spatiotemporal patterns in biological signals can be conceived as a representative projection of residuals. To justify this observation, we extract PPG cells from real and fake videos and feed these to a state-of-the-art classification network for detecting the generative model per video. Our results indicate that our approach can detect fake videos with 97.29% accuracy, and the source model with 93.39% accuracy.",,IEE
739,Learning Patch-Channel Correspondence for Interpretable Face Forgery Detection,Y. Hua; R. Shi; P. Wang; S. Ge,2023,"Beyond high accuracy, good interpretability is very critical to deploy a face forgery detection model for visual content analysis. In this paper, we propose learning patch-channel correspondence to facilitate interpretable face forgery detection. Patch-channel correspondence aims to transform the latent features of a facial image into multi-channel interpretable features where each channel mainly encoders a corresponding facial patch. Towards this end, our approach embeds a feature reorganization layer into a deep neural network and simultaneously optimizes classification task and correspondence task via alternate optimization. The correspondence task accepts multiple zero-padding facial patch images and represents them into channel-aware interpretable representations. The task is solved by step-wisely learning channel-wise decorrelation and patch-channel alignment. Channel-wise decorrelation decouples latent features for class-specific discriminative channels to reduce feature complexity and channel correlation, while patch-channel alignment then models the pairwise correspondence between feature channels and facial patches. In this way, the learned model can automatically discover corresponding salient features associated to potential forgery regions during inference, providing discriminative localization of visualized evidences for face forgery detection while maintaining high detection accuracy. Extensive experiments on popular benchmarks clearly demonstrate the effectiveness of the proposed approach in interpreting face forgery detection without sacrificing accuracy. The source code is available at https://github.com/Jae35/IFFD.",Face forgery detection;interpretable representation learning;patch-channel correspondence,IEE
740,Detecting Manipulated Facial Videos: A Time Series Solution,Z. Zhang; C. Mal; B. Ding; M. Gao,2021,"We propose a new method to expose fake videos based on a time series solution. The method is based on bidirectional long short-term memory (Bi-LSTM) backbone architecture with two different types of features: Face-Alignment and Dense-Face-Alignment, in which both of them are physiological signals that can be distinguished between fake and original videos. We choose 68 landmark points as the feature of Face-Alignment and Pose Adaptive Feature (PAF) for Dense-Face-Alignment. Based on these two facial features, we designed two deep networks. In addition, we optimize our network by adding an attention mechanism that improves detection precision. Our method is tested over benchmarks of Face Forensics/Face Forensics++ dataset and show a promising performance on inference speed while maintaining accuracy with state-of art solutions that deal against DeepFake.",face manipulation detection;image/video analysis;deep learning;pattern recognization,IEE
741,An Overview of Video Tampering Detection Techniques: State-of-the-Art and Future Directions,S. K. Pandey; L. Kumar; G. Kumar; A. Kumar; K. U. Singh; T. Singh,2023,"In the realm of video processing and forensics, finding video tampering is a critical challenge. The purposeful change or manipulation of video material to conceal or falsely depict the original information is referred to as �video tampering.� A significant demand for efficient video tampering detection methods has emerged in recent years as a result of the rise in false news, cyberbullying, and other types of criminal behavior. Modern approaches for detecting video manipulation may be generally divided into two categories: passive methods and aggressive methods. Whereas active methods entail putting digital watermarks or other identifiers on the video clip to aid tampering detection, passive methods rely on evaluating the video content for inconsistencies or artifacts generated during tampering. Techniques like sensor noise analysis, splicing detection, and forgery detection based on compression artifacts are examples of passive approaches. To find any discrepancies produced by manipulation, sensor noise analysis examines the noise patterns in the video. Splicing detection entails identifying the borders between several video segments and inspecting the content of each segment for irregularities. Analyzing the compressed video stream for irregularities caused during tampering is required for detecting forgeries based on compression artifacts. Techniques like digital watermarking, digital signatures, and fingerprinting are examples of active procedures. To detect any manipulation efforts, digital watermarking entails putting a digital watermark into the video clip. To confirm the legitimacy of the video clip, a digital signature is applied to it. To do fingerprinting, special characteristics from the video footage are extracted and saved in a database. In addition to the aforementioned methods, machine learning-based systems have also demonstrated promising outcomes in the identification of video manipulation. Using these methods, any tampering attempts in fresh movies are detected by training a machine learning model on a dataset of tampered and untampered recordings. Many issues still need to be resolved despite the improvements in video manipulation detection methods. They include the detection of tampering in live video broadcasts as well as the identification of deep fake movies, which are incredibly lifelike and challenging to spot. The creation of increasingly complex machine learning models, the fusion of several detection methods, and the investigation of novel methods for detecting tampering in live video feeds are some of the future goals for study in this area.",Video criminology;Video phony;Video altering;Video joining;Video Compositing;Video fraud discovery,IEE
742,DSVAE: Disentangled Representation Learning for Synthetic Speech Detection,A. K. Singh Yadav; K. Bhagtani; Z. Xiang; P. Bestagini; S. Tubaro; E. J. Delp,2023,"Tools to generate high quality synthetic speech that is perceptually indistinguishable from speech recorded from hu-man speakers are easily available. Many incidents report misuse of synthetic speech for spreading misinformation and committing financial fraud. Several approaches have been proposed for detecting synthetic speech. Many of these approaches use deep learning methods without providing reasoning for the decisions they make. This limits the explainability of these approaches. In this paper, we use disentangled representation learning for developing a synthetic speech detector. We propose Disentangled Spectrogram Variational Auto Encoder (DSVAE) which is a two stage trained variational autoencoder that processes spectrograms of speech to generate features that disentangle synthetic and bona fide speech. We evaluated DSVAE using the ASVspoof2019 dataset. Our experimental results show high accuracy (> 98%) on detecting synthetic speech from 6 known and 10 unknown speech synthesizers. Further, the visualization of disentangled features obtained from DSVAE provides rea-soning behind the working principle of DSVAE, improving its explainability. DSVAE performs well compared to several existing methods. Additionally, DSVAE works in practical scenarios such as detecting synthetic speech uploaded on social platforms and against simple attacks such as removing silence regions.",disentangled representation learning;synthetic speech detection;explainable AI;autoencoder,IEE
743,Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to Adversarial Examples,S. Hussain; P. Neekhara; M. Jere; F. Koushanfar; J. McAuley,2021,"Recent advances in video manipulation techniques have made the generation of fake videos more accessible than ever before. Manipulated videos can fuel disinformation and reduce trust in media. Therefore detection of fake videos has garnered immense interest in academia and industry. Recently developed Deepfake detection methods rely on Deep Neural Networks (DNNs) to distinguish AI-generated fake videos from real videos. In this work, we demonstrate that it is possible to bypass such detectors by adversarially modifying fake videos synthesized using existing Deepfake generation methods. We further demonstrate that our adversarial perturbations are robust to image and video compression codecs, making them a real-world threat. We present pipelines in both white-box and black-box attack scenarios that can fool DNN based Deepfake detectors into classifying fake videos as real.",,IEE
744,Transformer And Node-Compressed Dnn Based Dual-Path System For Manipulated Face Detection,Z. Luo; S. -I. Kamata; Z. Sun,2021,"Deep neural networks (DNNs) have extensively promoted data generation development; the quality of these generated content has achieved an impressive new level. Therefore, manipulated content, especially facial manipulation, is a growing concern for online information legitimacy. Most current deep learning-based methods depend on local features sampled by convolutional kernels and lack knowledge globally. To address the problem, we propose a dual-path pipeline using Neural Ordinary Differential Equations (NODE) based neural network and facial-feature biased transformer to deal with the visual content from a different view. The transformer path could link these landmarks in a long-range, moreover, we adopt an attention guided augmentation based self-ensemble for more robust performance. Extensive experiments show that our system could surpass several commonly used approaches in terms of video-level accuracy and AUC with better interpretability.",Image forensics;DeepFake detection;neural network;face manipulation,IEE
745,Lips Don't Lie: A Generalisable and Robust Approach to Face Forgery Detection,A. Haliassos; K. Vougioukas; S. Petridis; M. Pantic,2021,"Although current deep learning-based face forgery detectors achieve impressive performance in constrained scenarios, they are vulnerable to samples created by unseen manipulation methods. Some recent works show improvements in generalisation but rely on cues that are easily corrupted by common post-processing operations such as compression. In this paper, we propose LipForensics, a detection approach capable of both generalising to novel manipulations and withstanding various distortions. LipForensics targets high-level semantic irregularities in mouth movements, which are common in many generated videos. It consists in first pretraining a spatio-temporal network to perform visual speech recognition (lipreading), thus learning rich internal representations related to natural mouth motion. A temporal network is subsequently finetuned on fixed mouth embeddings of real and forged data in order to detect fake videos based on mouth movements without overfitting to low-level, manipulation-specific artefacts. Extensive experiments show that this simple approach significantly surpasses the state-of-the-art in terms of generalisation to unseen manipulations and robustness to perturbations, as well as shed light on the factors responsible for its performance.",,IEE
746,DeepFake Image Detection Using Adaptive Discriminator Augmentation (ADA),D. A. Talib; A. A. Abed,2023,"The proliferation of Deepfake technology, driven by artificial intelligence (AI), poses a growing threat as it facilitates the dissemination of hate speech and misinformation through convincingly fabricated images. Deepfakes, a subdomain of AI, manipulate and superimpose one person's face onto another's, exploiting the power of machine learning to create deceptive content at an unprecedented pace and affordability. Despite the controversial nature of Deepfakes, their use is expanding both commercially and collectively. This paper offers an in-depth investigation into the effectiveness of StyleGAN2-ADA in identifying fake images, with a particular focus on detecting Deepfakes. We propose a novel GAN Discriminator model designed to enhance the accuracy of this detection process. Our model's training dataset comprises an extensive collection of 76,400 images from the FFHQ dataset. In our experimental evaluation, we subjected our model to 100 fake images, achieving an impressive detection rate of 95.71 %. This remarkable outcome underscores the efficacy of our approach in identifying Deepfakes. Furthermore, our technique demonstrates exceptional precision in distinguishing between real and fake images, promising a robust defense against the harmful impact of AI-generated fake content.",DeepFake images;Detection Fake;Image datasets;StyleGAN2-ADA;Adaptive Discriminator Augmentation,IEE
747,AI-Synthesized Voice Detection Using Neural Vocoder Artifacts,C. Sun; S. Jia; S. Hou; S. Lyu,2023,"Advancements in AI-synthesized human voices have created a growing threat of impersonation and disinformation, making it crucial to develop methods to detect synthetic human voices. This study proposes a new approach to identifying synthetic human voices by detecting artifacts of vocoders in audio signals. Most DeepFake audio synthesis models use a neural vocoder, a neural network that generates waveforms from temporal-frequency representations like mel-spectrograms. By identifying neural vocoder processing in audio, we can determine if a sample is synthesized. To detect synthetic human voices, we introduce a multi-task learning framework for a binaryclass RawNet2 model that shares the feature extractor with a vocoder identification module. By treating vocoder identification as a pretext task, we constrain the feature extractor to focus on vocoder artifacts and provide discriminative features for the final binary classifier. Our experiments show that the improved RawNet2 model based on vocoder identification achieves high classification performance on the binary task overall. Codes and data can be found at https://github.com/csun22/Synthetic-Voice-Detection-Vocoder-Artifacts.",,IEE
748,Towards the Detection of AI-Synthesized Human Face Images,Y. Lu; T. Ebrahimi,2024,"Over the past years, image generation and manipulation have achieved remarkable progress due to the rapid development of generative AI based on deep learning. Recent studies have devoted significant efforts to address the problem of face image manipulation caused by deepfake techniques. However, the problem of detecting purely synthesized face images has been explored to a lesser extent. In particular, the recent popular Diffusion Models (DMs) have shown remarkable success in image synthesis. Existing detectors struggle to generalize between synthesized images created by different generative models. In this work, a comprehensive benchmark including human face images produced by Generative Adversarial Networks (GANs) and a variety of DMs has been established to evaluate both the generalization ability and robustness of state-of-the-art detectors. Then, the forgery traces introduced by different generative models have been analyzed in the frequency domain to draw various insights. The paper further demonstrates that a detector trained with frequency representation can generalize well to other unseen generative models.",Synthetic face image;detection;GANs;diffusion models;frequency analysis,IEE
749,AI vs. Human Vision: A Comparative Analysis for Distinguishing AI-Generated and Natural Images,R. Purohit; Y. Sane; D. Vaishampayan; S. Vedantam; M. Singh,2024,"Today�s data-driven generation has led to remarkable advancements in technology. However, as there are two sides to a coin, technology too has both its advantages and disadvantages. The expansion of AI has given rise to �Deepfake� which involves skillful superimposing of person�s face with another person�s face which is very dangerous and it is used to produce morphed images and disseminate fake videos which has led to cyberbullying, financial fraud and cybersecurity risks. Our goal is to correctly determine authentic images by classifying them into AI generated v/s real images.We have used �PyGoogle� image library for creation of dataset for AI images and for the real image dataset we have used our own camera to capture real images. We have used CNN model on both the dataset and observed that accuracy of Google images dataset is 88 percent and that of the own dataset is 81 percent. For evaluating the performance of our model we have created Confusion Matrix for the same.",AI images;Image Classification;CNN,IEE
750,Paste You Into Game: Towards Expression and Identity Consistency Face Swapping,H. Zeng; W. Zhang; K. Chen; Z. Zhang; L. Li; Y. Ding,2022,"Customizing game characters for individual players has been a long-standing attractive feature in the game industry. However, traditional solutions like manual editing within a game engine are always time-consuming and unsatisfying. Our work proposes a novel automatic face swapping method for arbitrary users and game characters, addressing three challenges including style gap between human and game faces, identity preservation, and expression consistency. A game face dataset is collected to handle the cross-style gap; an identity compound embedding is proposed to ease the bias existing in the commonly-used ID identifiers and it provides a more robust identity representation; a novel expression embedding loss is proposed to enforce the expression consistency between the swapped and target faces and it achieves better expression consistency than the previous methods, especially when the expression is very subtle. The visualized results, as well as the qualitative and quantitative comparisons, reveal the significance and effectiveness of our proposed solutions.",Game CG;Face Swapping;Identity;Expression;Image Synthesizing,IEE
751,Deep Neural Networks Based Error Level Analysis for Lossless Image Compression Based Forgery Detection,C. G. Sri; S. Bano; T. Deepika; N. Kola; Y. L. Pranathi,2021,"The proposed model is implemented in deep learning based on counterfeit feature extraction and Error Level Analysis (ELA) techniques. Error level analysis is used to improve the efficiency of distinguishing copy-move images produced by Deep Fake from the real ones. Error Level Analysis is used on images in-depth for identifying whether the photograph has long passed through changing. This Model uses CNN on the dataset of images for training and to test the dataset for identifying the forged image. Convolution neural network (CNN) can extract the counterfeit attribute and detect if images are false. In the proposed approach after the tests were carried out, it is displayed with the pie chart representation based on percentage the image is detected. It also detects different image compression ratios using the ELA process. The results of the assessments display the effectiveness of the proposed method.",Error level analysis (ELA);Convolution neural network (CNN);Deep Learning,IEE
752,Detection of Synthesized Videos using CNN,R. V. Saraswathi; M. Gadwalkar; S. S. Midhun; G. N. Goud; A. Vidavaluri,2022,"Deepfake refers to changing a person's face or their facial emotions. Many fake videos are being overused and going viral in a matter of seconds. Deep learning is used to generate fake videos and images. Deepfakes are synthetic media in which the people who appear there are not real. Increasingly sophisticated technology makes it difficult to distinguish between real and fake videos and images. This will make both men and women more concerned about their safety. It is essential to create a model that can distinguish between real and fake videos in order to maintain and respect everyone's right to privacy. In this research, a Deep Learning Approach is used to offer a framework to identify these Deepfake's, a convolutional neural network architecture will be trained using a database of faces that were taken out of a mixed dataset.",Deepfake;ResNext;Long Short-Term Memory;Convolutional Neural Network,IEE
753,Artificial Intelligence into Multimedia Deepfakes Creation and Detection,M. A. Khder; S. Shorman; D. T. Aldoseri; M. M. Saeed,2023,"Artificial intelligence has enabled deepfakes, or fake videos that closely resemble real ones, commercially viable (AI). As according to our research, people are less likely to believe social media news, but they are also more likely to be dubious than to be fooled by deepfakes. This finding combines ideas about how effective visual communication is and how uncertainty weakens public discourse confidence. The methodology for this article will based on reviewing the related articles to explore the main components and solutions in the deepfakes. In this article will study and review the deepfakes and it impacts in different multimedia with AI tools. Therefore, that conclude that deepfakes may increase already existing hazards to countries and online civic cultures by increasing general mistrust and doubt in the most of online resources.",Artificial intelligence;deepfakes;Photo deepfakes;Audio deepfakes;video deepfakes,IEE
754,SDHF: Spotting DeepFakes with Hierarchical Features,T. Liang; P. Chen; G. Zhou; H. Gao; J. Liu; Z. Li; J. Dai,2020,"DeepFake videos are widely distributed on social media platforms, which has seriously affected the authenticity of digital media content, calling for robust DeepFake detection methods. Although numerous detection methods are formulated as frame-based binary classification, less attention has been paid to aggregate the features over individual frames to get a video-based judgement. We observed that for the detection of DeepFake videos, three different level forgery features from frame, clip and video can complement each other. We also found that discrete, large interval sampling strategy is more suitable for DeepFake detection, which can sample more complex video scenes, including multiple subjects, diverse facial expressions and head poses. In this work, we propose a hierarchical framework, using 2D convolutional neural networks for frame-level features extraction followed by a 1D convolutional aggregator to extract clip-level and video-level features, which can comprehensively exploit three different levels of features to make decisions. Evaluation was performed on four datasets, including DFDC, Celeb-DF, FaceForensics++ and UADFV, which provides competitive results compared to other methods. Experimental results of cross-test demonstrate that our hierarchical framework has excellent generalization performance in the face of unknown datasets.",DeepFake detection;Hierarchical features,IEE
755,Unmasking the Illusions: A Comprehensive Study on Deepfake Videos and Images,R. Ranout; C. Kumar,2024,"This research paper delves into the complex world of deepfakes, investigating recent advances in the creation and identification of synthetic content. It is becoming more important to comprehend the complex threats that deepfake technology presents to the credibility of digital media. This study deep dives into deepfake creation methods. We examine the toolbox of content manipulators, starting with early image-based alterations and moving on to more modern audio and video synthesis. The research sheds light on the technologies that allow for the misleading creation of synthetic material that seems very genuine.The survey investigates the developments in deepfake detection tactics which complements the investigation of production methods. It delves at the history of forensic methods and how they have been augmented by machine learning algorithms that can differentiate between real and fake content. Given the never-ending back-and-forth between creators and detectors, the study takes a close look at the strengths, weaknesses, opportunities and threats of existing detection methods. The possible consequences for privacy, disinformation and society trust are illuminated as well as the ethical problems underlying deepfake technology. As the globe becomes more saturated with synthetic media our discussion moves on to examine the social and legal ramifications.This study seeks to provide a thorough overview of the synthetic reality world by combining the two viewpoints of deepfake creation and detection. Researchers, legislators and tech developers dealing with the serious consequences of deepfake technologies on digital content integrity and the information ecosystem as a whole will find this survey helpful because it outlines the present state-of-the-art as well as emerging trends.",synthetic;GANs;autoencoders;ecosystem;video manipulation,IEE
756,LIED: A Lightweight and Ensemble learning approach for fake face Detection,R. Budhiraja; M. Kumar; M. K. Das; A. S. Bafila; S. Singh,2023,"For many years, machine learning problems have primarily been driven by the availability and quality of data. Being the key, data has been equally vulnerable and got a savior in the form of generative adversarial networks (GANs) which opened the floodgates for generating almost any type of real, yet synthetic data. Human face became one of the initial victims to this superior technology, where in highly realistic and convincing fake content is generated using deep learning technologies or ��DeepFakes��. Taking a giant leap forward from manipulating facial attributes, to be now able to swap expressions seamlessly and even generate new (non-existent) synthetic faces poses a grave threat not only to chosen few, but for the entire society. This upshoot has been reciprocated with significant efforts and investments for its detection, but the techniques are often marred with either lower accuracies, or, higher computation costs. This is where convolutional reservoir networks (CoRN) come to rescue owing to their lightweight nature, able to do ensemble feature extraction and its generalization ability. This paper investigates, implements and demonstrates the application of CoRN based architectures to the task of human fake face detection. The steep performance improvements as evident from our results further ratify the effectiveness of this approach, which is also shown to perform exceedingly well against smaller datasets.",DeepFake Detection;Fake Face Detection;Convolutional Reservoir Networks;Convolution Neural Networks;Reservoir Computing;Ensemble Feature Extraction,IEE
757,On the Vulnerability of Deepfake Detectors to Attacks Generated by Denoising Diffusion Models,M. Ivanovska; V. �truc,2024,"The detection of malicious deepfakes is a constantly evolving problem that requires continuous monitoring of de-tectors to ensure they can detect image manipulations gen-erated by the latest emerging models. In this paper, we in-vestigate the vulnerability of single-image deepfake detec-tors to black-box attacks created by the newest generation of generative methods, namely Denoising Diffusion Models (DDMs). Our experiments are run on FaceForensics++, a widely used deepfake benchmark consisting of manipulated images generated with various techniques for face iden-tity swapping and face reenactment. Attacks are crafted through guided reconstruction of existing deepfakes with a proposed DDM approach for face restoration. Our findings indicate that employing just a single denoising diffusion step in the reconstruction process of a deepfake can signif-icantly reduce the likelihood of detection, all without intro-ducing any perceptible image modifications. While training detectors using attack examples demonstrated some effectiveness, it was observed that discriminators trained on fully diffusion-based deepfakes exhibited limited generalizability when presented with our attacks.",,IEE
758,Revealing Image Deepfakes: A Convolutional Neural Network Approach Leveraging VGG-16 Mode,V. Ajay Kumar; S. Birudu; K. Sirisha; B. Chaitanya Mouli; K. Hemanth; P. Adesh,2024,"Digital image forgery has become a prevalent issue in modern technology-driven sphere, where sophisticated editing tools allow malicious users to create misleading and deceptive visual content. To deal with this growing problem, deep learning techniques have emerged as a powerful tool for both preventing and detecting digital image manipulation. In the proposed project focussing on developing deep learningbased forgery detection methods that can accurately identify manipulated images and to localize the forged part in the image using different methodologies, including VGG-16 which is a standard deep Convolutional Neural Networks (CNN),U-net, to build robust detection models capable of detecting a wide range of forgery techniques. Evaluating the effectiveness of our proposed forgery detection model, then building a comprehensive dataset consisting of authentic and forged images with diverse manipulation techniques. Furthermore, the proposed project addresses the challenge of detecting forged images that are altered to bypass existing detection mechanisms.",Deep Learning;CNN (Convolutional neural network);VGG-16 (Visual Geometry Group) model;U-net;Image Forgery,IEE
759,Real-Time Deep Learning Platforms,,2022,"Summary form only. Real-time deep learning is the process of training a deep convolutional neural network CNN model by running custom-created dataset through it, to continuously improve the model. This contrasts with �traditional� machine learning, in which a data scientist builds the model with a batch of historical testing data in an offline mode. Real-time deep learning is useful in scenarios when there is not enough data available upfront for training, and in cases where data needs to adapt to new patterns. In this speech, principle of computer vision is summarized along with definitions for deep learning and CNN. The lecture is then forwarded to the introduction for object detection, face-mask detection, face recognition. Many deep learning platforms are outlined with a focus on YOLO platforms. Some applications for face and face mask recognition are given. Personal re-identification, which is very important and recent topic, is explained with some obtained real-time results. Deep fake algorithms are also discussed with some obtained experimental results. All platforms are invoked on a Jetson Nano development kit to get real-time industry-like applications ready for marketing.",,IEE
760,Image Manipulation Detection Using Man Tra-Net,V. R. R; T. R; G. Geetha,2023,"We've created ManTraNet., a unified deep neural architecture, to battle real-world picture forgeries., which commonly entail several types and coupled modifications. ManTra-Net., in contrast to numerous other current systems., which performs both localization and detection without any further preprocessing., is an end-to-end network. ManTra-Net supports images of any resolution and a wide range of common forgery techniques., such as splices., copy-moves., deletions., and additions., as well as previously unrecognised types may be a completely convolutional network. In order to distinguish reliable picture forgery traces from other types of forgeries., we tend to design a simplistic yet efficient self-supervised learning task. Additionally., we provide a Z-score feature for native anomaly detection., frame the forgery localization disadvantage as an area anomaly detection drawback., and suggest a special memory resolution for native anomaly analysis.",forgery;deepneural;ManTra-Net;localization,IEE
761,Artificial Intelligence and Art: A University Curriculum Course for Undergraduates,Garvey; G. Patrick,2023,"This paper describes a new course entitled �Al & Art� offered at Quinnipiac University in the spring of 2023. In this course students used text-to-image AI generators to create artwork, learned to write prompts using ChatGPT, and wrote short essays on critical issues and topics implicated by the rise of AI image-generation software. This course fosters essential learning outcomes such as critical thinking, creativity and hands-on experience with cutting-edge AI technology preparing them for 21st-century careers and citizenship.",Artificial Intelligence;AI;text-to-image generation;ChatGPT;AI Detection;Critical Thinking;Art;DALL*E2;Midjourney;Open AI;Stable Diffusion,IEE
762,A Face Forgery Video Detection Model Based on Knowledge Distillation,H. Liang; Y. Leng; J. Luo; J. Chen; X. Guo,2024,"With the rapid evolution of artificial intelligence (AI), face forgery videos have proliferated, posing significant societal challenges. Traditional detection methods struggle with poor generalization and cross-database accuracy, unable to address subtle features and variations in face images across scales and compression levels. This paper reviews current face forgery detection methods, identifying key limitations. It introduces a novel model enhancing features through knowledge distillation, optimizing generalization and robustness via a unique loss function and temperature adjustment strategy. Additionally, a Discrete Cosine Transform with multi-scale and multi-compression capabilities (DCTMS) is integrated, enriching texture and detail capture. Experimental results on deepfake datasets demonstrate the efficacy of the proposed methods, achieving high detection accuracy and robustness across diverse scenarios, including cross-database experiments. This study contributes valuable insights and techniques to advance the field of face forgery detection, addressing risks associated with manipulated video content.",face forgery detection;deep learning;knowledge distillation;discrete cosine transform,IEE
763,A Review of Spam Detection in Social Media,?. Yurtseven; S. Bagriyanik; S. Ayvaz,2021,"With significant usage of social media to socialize in virtual environments, bad actors are now able to use these platforms to spread their malicious activities such as hate speech, spam, and even phishing to very large crowds. Especially, Twitter is suitable for these types of activities because it is one of the most common social media platforms for microblogging with millions of active users. Moreover, since the end of 2019, Covid-19 has changed the lives of individuals in many ways. While it increased social media usage due to free time, the number of cyber-attacks soared too. To prevent these activities, detection is a very crucial phase. Thus, the main goal of this study is to review the state-of-art in the detection of malicious content and the contribution of AI algorithms for detecting spam and scams effectively in social media.",social media;phishing;spam;machine learning;deep learning;NLP,IEE
764,DeepFake Video Detection,A. M. Saber; M. T. Hassan; M. S. Mohamed; R. ELHusseiny; Y. M. Eltaher; M. Abdelrazek; Y. M. Kamal Omar,2022,"Recently, deepfake face-swapping techniques are widely used, which allow to easily create buinesslike fake videos. Determining the rightfulness of a video is becoming increasingly important due to the potential distructive impact it can have on the world. we used more than technique and compared between them to detect fake videos. we applied different techniques like YOLO-CRNN, LSTM and in this paper, we compared between them in some techniques EfficientNet-B5 is used to pluck out the spatial options of those faces they are fed as a batch of input series into a two-way long- and short-term memory (BiLSTM) to extract temporal characteristics. The scheme is then tested on a a huge new dataset in; CelebDFFaceForencics++ (c23), based on a mash-up of two well-known records; FaceForencies++ (c23) and CelebDF. Achieved Area Under Receiver Operating Characteristic (AUROC) curve 89.35% result, 89.38 accuracy, 83.13% recovery, 85.54% accuracy and 84.23 F1-measure to insert data focus.",CNN;Deepfake;RNN;YOLO-CRNN;RELU;CelebDF;FaceForenciscs++,IEE
765,DeepReversion: Reversely Inferring the Original Face from the DeepFake Face,J. Ai; Z. Wang; B. Huang; Z. Han,2023,"Deepfake techniques can generate realistic fake images and videos. Malicious fake facial images quickly spread through the Internet, posing a potential threat to personal privacy and judicial forensics. However, the defense methods against deepfake proposed so far mainly focus on the discrimination of authenticity, but cannot identify the true source of the forged face, i.e., the original genuine face corresponding to the face-swapped fake face. This paper poses an interesting issue for face deepfake, which is the proactive forensics of �knowing what and knowing how�. In view of the fact that the fake face exhibits high similarity with the original face, especially the facial expression and pose, we argue that the original face can be approximately estimated from the deepfake counterpart. Accordingly, we advocate a deep-learning-based face inversion approach, so-called DeepReversion, which learns the inverse mapping from the deepfake face to the original face. Based on UNet, we design a specific end-to-end DeepReversion network, and conduct comprehensive experiments on public deepfake datasets. The experimental results show that the speculated face is highly consistent with the original face in terms of visual effects, PSNR, SSIM and similarity given by face recognizers.",,IEE
766,MMGANGuard: A Robust Approach for Detecting Fake Images Generated by GANs Using Multi-Model Techniques,S. Ali Raza; U. Habib; M. Usman; A. Ashraf Cheema; M. Sajid Khan,2024,"Recent advances in Generative Adversarial Networks (GANs) have produced synthetic images with high visual fidelity, making them nearly indistinguishable from human-created images. These synthetic images referred to as deepfakes, have become a major source of misinformation due to social media. Technology is advancing rapidly, so reliable methods for distinguishing real from fake images are needed. The current detection mechanisms require image forensics tools such as error level analysis (ELA), and clone detection to detect manipulated images. These approaches are limited because they require forensics expertise to use, are manual in application nature, and are unscalable, creating a need for a framework for a scalable tool that experts and non-experts can use to combat the spread of manipulated images and preserve digital visual information authenticity. We approach this problem with a multi-model ensemble framework using the transfer learning method to effectively detect fake images. The proposed approach named Multi-Model GAN Guard (MMGANGuard)integrates four models into an ensemble framework to identify GAN-generated image characteristics to improve deepfake detection. The Gram-Net architecture, ResNet50V2, and DenseNet201 models are used with co-occurrence matrices using transfer learning for MMGANGuard. Through comprehensive experiments, the proposed model demonstrates promising results in detecting the deepfake with high accuracy on the StyleGAN dataset. For automated detection of deepfake-generated images, the proposed model exceeded 97% accuracy, 98.5% TPR, 98.4% TPR, and 95.6% TPR in these evaluations, eliminating the need for manual assessment which is promising for future research in this domain.",Deep fake;data analytics;deep learning;GANs;StyleGAN;detection;multi-model,IEE
767,Trans-DF: A Transfer Learning-based end-to-end Deepfake Detector,M. Patel; A. Gupta; S. Tanwar; M. S. Obaidat,2020,"With the advent of information and communication technologies, there have been breakthrough developments in the field of Artificial Intelligence (AI). Moreover, increasing computation power and decreasing processing times, new applications are being developed at great speeds. One such application is Deepfakes, which tackles the increased manipulated and forged media content. But these fake images and videos hamper the security and privacy of individuals and can have large-scale religious, communal, or political implications that may prove to be catastrophic for a nation. The face swapped content at times can be identified by human observation, but with the use of Generative adversarial networks (GANs), such forged content can be developed with is hard to be identified even by humans. Hence, detecting such videos and images is a challenging task for researchers. Motivated from these gaps, in this paper, we propose a pipeline for detecting and extracting human faces from videos, process them to extract features from them, and then classify them as real or fake. The results of the proposed model achieved an accuracy of 90.2% for classifying fake images from real ones.",Deepfakes;Classification;Feature Extraction;Random Forest;VGG;ResNet;Inception;MobileNet;DenseNet,IEE
768,DeePhy: On Deepfake Phylogeny,K. Narayan; H. Agarwal; K. Thakral; S. Mittal; M. Vatsa; R. Singh,2022,"Deepfake refers to tailored and synthetically generated videos which are now prevalent and spreading on a large scale, threatening the trustworthiness of the information available online. While existing datasets contain different kinds of deepfakes which vary in their generation technique, they do not consider progression of deepfakes in a �phylogenetic� manner. It is possible that an existing deepfake face is swapped with another face. This process of face swapping can be performed multiple times and the resultant deepfake can be evolved to confuse the deepfake detection algorithms. Further, many databases do not provide the employed generative model as target labels. Model attribution helps in enhancing the explainability of the detection results by providing information on the generative model employed. In order to enable the research community to address these questions, this paper proposes DeePhy, a novel Deepfake Phylogeny dataset which consists of 5040 deep-fake videos generated using three different generation techniques. There are 840 videos of one-time swapped deep-fakes, 2520 videos of two-times swapped deepfakes and 1680 videos of three-times swapped deepfakes. With over 30 GBs in size, the database is prepared in over 1100 hours using 18 GPUs of 1,352 GB cumulative memory. We also present the benchmark on DeePhy dataset using six deep-fake detection algorithms. The results highlight the need to evolve the research of model attribution of deepfakes and generalize the process over a variety of deepfake generation techniques. The database is available at: http://iab-rubric.org/deephy-database",,IEE
769,Verifiable Facial De-Identification in Video Surveillance,S. Park; H. Na; D. Choi,2024,"With the advancement of facial recognition technology, concerns over facial privacy breaches owing to data leaks and external attacks have been escalating. Existing de-identification methods face challenges with compatibility with facial recognition models and difficulties in verifying de-identified images. To address these issues, this study introduces a novel framework that combines face verification-enabled de-identification techniques with face-swapping methods, tailored for video surveillance environments. This framework employs StyleGAN, Pixel2Style2Pixel (PSP), HopSkipJumpAttack (HSJA), and FaceNet512 to achieve face verification-capable de-identification, and uses the dlib library for face swapping. Experimental results demonstrate that this method maintains high face recognition performance (98.37%) across various facial recognition models while achieving effective de-identification. Additionally, human tests have validated its sufficient de-identification capabilities, and image quality assessments have shown its excellence across various metrics. Moreover, real-time de-identification feasibility was evaluated using Nvidia Jetson AGX Xavier, achieving a processing speed of up to 9.68 fps. These results mark a significant advancement in demonstrating the practicality of high-quality de-identification techniques and facial privacy protection in the field of video surveillance.",Face de-identification;face privacy;face verification;face verifiable de-identification;privacy protection;StyleGAN,IEE
770,Effect of Text Augmentation and Adversarial Training on Fake News Detection,H. Ahmed; I. Traore; S. Saad; M. Mamun,2024,"The action of spreading false information through fake news articles presents a significant danger to society because it has the ability to shape public opinion with inaccurate facts. This can lead to negative effects, such as reduced trust in institutions and the promotion of conflict, division, and even violence. In this article, a text augmentation technique is introduced as a means of generating new data from preexisting fake news datasets. This approach has the potential to enhance classifier performance by a range of 3%�11%. It can also be utilized to launch a successful attack on trained classifiers, with up to a 90% success rate. However, the success rate of these attacks decreased to less than 28% when the model was retrained with the generated adversarial examples. These results demonstrate the effectiveness of text augmentation as a viable method for detecting fake news and increasing classifier accuracy and performance, as well as its ability to be utilized to perform adversarial machine learning (ML) and improve the resilience of ML algorithms.",Abstract meaning representation (AMR);adversarial training;clonal selection algorithm;cyberattack;fake news;graph representation;text generation,IEE
771,Enhancing Interpretability in AI-Generated Image Detection with Genetic Programming,M. Lin; L. Shang; X. Gao,2023,"IGC can produce realistic AI-generated images that challenge human perception. Detecting AI-generated content is critical, which has prompted the technology to tell apart real images from the generated ones. However, the existing methods, such as CNND, LGrad, lack interpretability. Unlike traditional image classification, it is crucial to know why the image can be considered as AI-generated. We introduce a novel AI-generated image detector based on genetic programming (GP), prioritizing both interpretability and classification accuracy. This application of GP in this context emphasizes the need for interpretability in AI-generated content identification. Our GP-based approach not only achieves competitive classification accuracy but also provides transparent decision-making processes, bridging the interpretability gap. This method enhances trust and understanding in the AI-generated image detection process. Through extensive experiments, we highlight the potential of GP-based detectors for this unique task. This research contributes to improving the transparency and reliability of AI-generated image detection, holding implications for computer vision and image forensics. Our work emphasizes the pivotal role of interpretability in distinguishing AI-generated content and offers insights into the inner workings of such models and also achieves a good generation ability.",AI-generated image detection;Genetic Programming;Interpretability;Transparency,IEE
772,MaLP: Manipulation Localization Using a Proactive Scheme,V. Asnani; X. Yin; T. Hassner; X. Liu,2023,"Advancements in the generation quality of various Generative Models (GMs) has made it necessary to not only perform binary manipulation detection but also localize the modified pixels in an image. However, prior works termed as passive for manipulation localization exhibit poor generalization performance over unseen GMs and attribute modifications. To combat this issue, we propose a proactive scheme for manipulation localization, termed MaLP. We encrypt the real images by adding a learned template. If the image is manipulated by any GM, this added protection from the template not only aids binary detection but also helps in identifying the pixels modified by the GM. The template is learned by leveraging local and global-level features estimated by a two-branch architecture. We show that MaLP performs better than prior passive works. We also show the generalizability of MaLP by testing on 22 different GMs, providing a benchmark for future research on manipulation localization. Finally, we show that MaLP can be used as a discriminator for improving the generation quality of GMs. Our models/codes are available at www.github.com/vishal3477/pro_loc.",Adversarial attack and defense,IEE
773,Detecting Deepfakes Using GAN Manipulation Defects in Human Eyes,E. Tchaptchet; E. F. Tagne; J. Acosta; R. Danda; C. Kamhoua,2024,"The Deepfake phenomenon is very important nowadays because there are possibilities to create very real images that can fool anyone, thanks to deep learning tools based on generative adversarial networks (GAN). These images are used as profile images on social media, aimed here at creating discord and scams internationally. In this work, we show that these images can be detected by a multitude of imperfections present in the synthetized eyes such as the irregular shape of the pupil and the difference between the corneal reflections of the two eyes. These imperfections are caused by the absence of physical/physiological constraints in most GAN models. We are developing a two tier architecture able of detecting these deepfake images. It starts with an automatic segmentation method of the eye pupil to check the shape. Then, for pupils of non-standard shape, the whole image is taken, transformed into gray level and then passed into an architecture that extracts and compares the corneal specular reflections of two eyes. Experimenting with a large set of real image data from the Flickr-Faces-HQ dataset and fake styleGAN2 images demonstrates the effectiveness of our method. Our method has good stability for physiological properties during deep learning; therefore, it is robust as some of the single-class deepfake detection methods. The results of the experiments on the selected datasets demonstrate greater precision compared to other methods.",Adversarial machine learning;Deepfake;face generation;GAN,IEE
774,"Unmasking Deepfakes: Understanding the Technology, Risks, and Countermeasures",P. Rathi; S. K. Budhani; G. Murari Upadhyay; P. Vats; R. Kaur; A. K. Saini,2024,"This research explores the transformative role of deepfake technology as a cutting-edge tool in the realm of Visual Effects (VFX) filmmaking. Deepfake, an artificial intelligence-driven technique, has evolved beyond its controversial origins to become an invaluable asset in creating hyper-realistic digital content. This paper delves into the intricacies of deepfake applications, focusing on its utilization as a powerful tool for seamlessly integrating computer-generated imagery (CGI) into live-action sequences. The study investigates the advancements in deepfake algorithms, emphasizing their ability to convincingly replicate human expressions, gestures, and voices. Through a comprehensive analysis of case studies and industry practices, we examine how deepfake technology has transcended traditional limitations, providing filmmakers with a versatile and efficient means of enhancing visual storytelling. Furthermore, the ethical considerations and challenges associated with the use of deepfake in filmmaking are discussed. As technology blurs the lines between reality and fiction, concerns regarding misinformation and the potential for misuse are addressed.",Deepfake;Synthetic media;Artificial intelligence;Machine learning;Neural networks;Generative adversarial networks (GANs);Audio-visual manipulation,IEE
775,On the use of Stable Diffusion for creating realistic faces: from generation to detection,L. Papa; L. Faiella; L. Corvitto; L. Maiano; I. Amerini,2023,"The mass adoption of diffusion models has shown that artificial intelligence (AI) systems can be used to easily generate realistic images. The spread of these technologies paves the way to previously unimaginable creative uses while also raising the possibility of malicious applications. In this work, we propose a critical analysis of the overall pipeline, i.e., from creating realistic human faces with Stable Diffusion v1.5 [1] to recognizing fake ones. We first propose an analysis of the prompts that allow the generation of extremely realistic faces with a human-in-the-loop approach. Our objective is to identify the text prompts that drive the image generation process to obtain realistic photos that resemble everyday portraits captured with any camera. Next, we study how complex it is to recognize these fake contents for both AI-based models and non-expert humans. We conclude that similar to other deepzfake creation techniques, despite some limitations in generalization across different datasets, it is possible to use AI to recognize these contents more accurately than non-expert humans would.",Computer vision;Deepfake detection;Diffusion models;Prompt engineering;Security,IEE
776,Exposing Lip-syncing Deepfakes from Mouth Inconsistencies,S. K. Datta; S. Jia; S. Lyu,2024,"A lip-syncing deepfake is a digitally manipulated video in which a person�s lip movements are created convincingly using AI models to match altered or entirely new audio. Lipsyncing deepfakes are a dangerous type of deepfakes as the artifacts are limited to the lip region and more difficult to discern. In this paper, we describe a novel approach, LIP-syncing detection based on mouth INConsistency (LIPINC), for lip-syncing deepfake detection by identifying temporal inconsistencies in the mouth region. These inconsistencies are seen in the adjacent frames and throughout the video. Our model can successfully capture these irregularities and outperforms the state-of-the-art methods on several benchmark deepfake datasets. Code is available at https://github.com/skrantidatta/LIPINC.",DeepFake detection;Lip-syncing deepfakes;Spatial-temporal inconsistency,IEE
777,Audio-Visual Temporal Forgery Detection Using Embedding-Level Fusion and Multi-Dimensional Contrastive Loss,M. Liu; J. Wang; X. Qian; H. Li,2024,"Audio-visual deepfake detection is the process of identifying and detecting deepfakes that have been generated using both audio and visual content with AI algorithms. Most existing methods primarily focus on the overall authenticity while neglecting the position of forgeries in time. This can be particularly problematic, as even a small alteration in a clip can significantly impact its meaning. Such brand new attacks are dangerous and how to tackle such attacks remains an open question. In this paper, we present a novel neural network-based model to tackle the temporal forgery detection (TFD) problem. It consists of new audio and visual encoders with cross-modal attention for embedding extraction, and an embedding-level fusion mechanism with self-attention for forgery localization. Besides, a multi-dimensional contrastive loss is proposed which helps the model not only to capture audio-visual inconsistency for deepfake detection but also to exploit temporal inconsistency by coherently constraining the extracted embeddings. Extensive experiments on the LAV-DF dataset show that the presented method outperforms several state-of-the-art temporal forgery localization methods by up to 23.4% on AP@0.5 and 13.8% on AR@100. In addition, we also show the effectiveness of the proposed model on deepfake detection.",Audio-visual deepfake detection;temporal forgery localization;embedding-level fusion;multi-dimensional contrastive;audio-visual inconsistency,IEE
778,Challenges of Face Image Authentication and Suggested Solutions,Z. A. Salih; R. Thabit; K. A. Zidan; B. E. Khoo,2022,"The rapid development of face image manipulation algorithms and the distribution of their easy-to-use applications bring an urgent need to manipulation detection techniques that can reveal the modification in face image and prove its authenticity. Recently, the term �DeepFakes� and their detection techniques have attracted the attention of the research community. To current date, there is no universal detection technique and each one has its own limitations. In this paper, a brief review of face image manipulation techniques and their detection is presented followed by a summary of the limitations and challenges that can face the manipulation detection techniques. Then, the paper presents some suggestions which can be considered for future researches in this attracted and interesting research topic. The review in this paper can be considered as a starting point for the researchers who are concerned about this research field.",DeepFakes;face image authentication;face image manipulation;image tamper detection,IEE
779,The PartialSpoof Database and Countermeasures for the Detection of Short Fake Speech Segments Embedded in an Utterance,L. Zhang; X. Wang; E. Cooper; N. Evans; J. Yamagishi,2023,"Automatic speaker verification is susceptible to various manipulations and spoofing, such as text-to-speech synthesis, voice conversion, replay, tampering, adversarial attacks, and so on. We consider a new spoofing scenario called �Partial Spoof� (PS) in which synthesized or transformed speech segments are embedded into a bona fide utterance. While existing countermeasures (CMs) can detect fully spoofed utterances, there is a need for their adaptation or extension to the PS scenario. We propose various improvements to construct a significantly more accurate CM that can detect and locate short-generated spoofed speech segments at finer temporal resolutions. First, we introduce newly developed self-supervised pre-trained models as enhanced feature extractors. Second, we extend our PartialSpoof database by adding segment labels for various temporal resolutions. Since the short spoofed speech segments to be embedded by attackers are of variable length, six different temporal resolutions are considered, ranging from as short as 20 ms to as large as 640 ms. Third, we propose a new CM that enables the simultaneous use of the segment-level labels at different temporal resolutions as well as utterance-level labels to execute utterance- and segment-level detection at the same time. We also show that the proposed CM is capable of detecting spoofing at the utterance level with low error rates in the PS scenario as well as in a related logical access (LA) scenario. The equal error rates of utterance-level detection on the PartialSpoof database and ASVspoof 2019 LA database were 0.77 and 0.90%, respectively.",Anti-spoofing;deepfake;PartialSpoof;self-supervised learning;spoof localization;countermeasure,IEE
780,TIMIT-TTS: A Text-to-Speech Dataset for Multimodal Synthetic Media Detection,D. Salvi; B. Hosler; P. Bestagini; M. C. Stamm; S. Tubaro,2023,"With the rapid development of deep learning techniques, the generation and counterfeiting of multimedia material has become increasingly simple. Current technology enables the creation of videos where both the visual and audio contents are falsified. While the multimedia forensics community has begun to address this threat by developing fake media detectors. However, the vast majority existing forensic techniques only analyze one modality at a time. This is an important limitation when authenticating manipulated videos, because sophisticated forgeries may be difficult to detect without exploiting cross-modal inconsistencies (e.g., across the audio and visual tracks). One important reason for the lack of multimodal detectors is a similar lack of research datasets containing multimodal forgeries. Existing datasets typically contain only one falsified modality, such as deepfaked videos with authentic audio tracks, or synthetic audio with no associated video. Currently, datasets are needed that can be used to develop, train, and test these forensic algorithms. In this paper, we propose a new audio-visual deepfake dataset containing multimodal video forgeries. We present a general pipeline for synthesizing deepfake speech content from a given video, facilitating the creation of counterfeit multimodal material. The proposed method uses Text-to-Speech (TTS) and Dynamic Time Warping (DTW) techniques to achieve realistic speech tracks. We use this pipeline to generate and release TIMIT-TTS, a synthetic speech dataset containing the most cutting-edge methods in the TTS field. This can be used as a standalone audio dataset, or combined with DeepfakeTIMIT and VidTIMIT video datasets to perform multimodal research. Finally, we present numerous experiments to benchmark the proposed dataset in both monomodal (i.e., audio) and multimodal (i.e., audio and video) conditions. This highlights the need for multimodal forensic detectors and more multimodal deepfake data.",Audio;multimodal;deepfake;forensics;synthetic speech;text-to-speech;TIMIT,IEE
781,Evaluating the Effectiveness of Hybrid Features in Fake News Detection on Social Media,M. G. Yigezu; M. A. Mehamed; O. Kolesnikova; T. K. Guge; A. Gelbukh; G. Sidorov,2023,"This research focuses on the detection of fake news on social media, specifically in Amharic language posts. The study highlights the importance of utilizing hybrid features, which include both news content and social content features, to improve the accuracy of fake news detection. We evaluated the effectiveness of these hybrid features using state-of-the-art methodologies and explored methods that optimize detection accuracy and reduce latency. Our research revealed that we achieved an impressive Fl-score of 0.99 by utilizing a BERT-based uncased model. This outcome was obtained by incorporating a combination of textual content, publication dates, and page creation dates as hybrid features.",fake news;hybrid features;pre-trained model;social context;news content,IEE
782,Hierarchical Frequency-Assisted Interactive Networks for Face Manipulation Detection,C. Miao; Z. Tan; Q. Chu; N. Yu; G. Guo,2022,"Recently, face manipulation techniques have caused increasing trust concerns in our society. Although current face manipulation detection methods achieve impressive performance regarding intra-dataset evaluation, they are struggling to improve the generalization and robustness ability. To address this issue, we propose a novel Hierarchical Frequency-assisted Interactive Networks (HFI-Net) to explore comprehensive frequency-related forgery cues for face manipulation detection. At first, we formulate HFI-Net as a dual-branch network to take full advantage of both CNN and transformer for capturing local details and global context information, respectively. Considering the forged faces are easy to show flaws in the frequency domain, a novel Frequency-based Feature Refinement (FFR) module is proposed to learn frequency-based attention from RGB features. FFR module emphasizes forgery cues and suppresses the pristine semantics information by keeping middle-high frequency features while discarding the low-frequency ones. Based on FFR, we further develop a co- sharing Global-Local Interaction (GLI) module to conduct frequency-assisted interactions while capturing complementarity among dual branches. Lastly, we further implement the GLI module in each stage of the network to effectively explore multi-level frequency artifacts. Extensive experiments are conducted on several popular benchmarks including FaceForensics++, Celeb-DF, DeepFake-TIMIT, DFDC, UADFV, and DeeperForensics-1.0, which shows that our model outperforms the state-of-the-art, especially in unseen datasets, manipulations, and perturbations evaluation.",Face manipulation detection;frequency;transformer;CNN,IEE
783,Evaluating Quality of Visual Explanations of Deep Learning Models for Vision Tasks,Y. Yang; S. Mahmoudpour; P. Schelkens; N. Deligiannis,2023,"Explainable artificial intelligence (XAI) has gained considerable attention in recent years as it aims to help humans better understand machine learning decisions, making complex black-box systems more trustworthy. Visual explanation algorithms have been designed to generate heatmaps highlighting image regions that a deep neural network focuses on to make decisions. While convolutional neural network (CNN) models typically follow similar processing operations for feature encoding, the emergence of vision transformer (ViT) has introduced a new approach to machine vision decision-making. Therefore, an important question is which architecture provides more human-understandable explanations. This paper examines the explain-ability of deep architectures, including CNN and ViT models under different vision tasks. To this end, we first performed a subjective experiment asking humans to highlight the key visual features in images that helped them to make decisions in two different vision tasks. Next, using the human-annotated images, ground-truth heatmaps were generated that were compared against heatmaps generated by explanation methods for the deep architectures. Moreover, perturbation tests were performed for objective evaluation of the deep models' explanation heatmaps. According to the results, the explanations generated from ViT are deemed more trustworthy than those produced by other CNNs, and as the features of the input image are more dispersed, the advantage of the model becomes more evident.",Explainable artificial intelligence;Vision Transformer;heatmaps;subjective evaluation,IEE
784,Deep Reinforcement Learning for Cyber Security,T. T. Nguyen; V. J. Reddi,2023,"The scale of Internet-connected systems has increased considerably, and these systems are being exposed to cyberattacks more than ever. The complexity and dynamics of cyberattacks require protecting mechanisms to be responsive, adaptive, and scalable. Machine learning, or more specifically deep reinforcement learning (DRL), methods have been proposed widely to address these issues. By incorporating deep learning into traditional RL, DRL is highly capable of solving complex, dynamic, and especially high-dimensional cyber defense problems. This article presents a survey of DRL approaches developed for cyber security. We touch on different vital aspects, including DRL-based security methods for cyber�physical systems, autonomous intrusion detection techniques, and multiagent DRL-based game theory simulations for defense strategies against cyberattacks. Extensive discussions and future research directions on DRL-based cyber security are also given. We expect that this comprehensive review provides the foundations for and facilitates future studies on exploring the potential of emerging DRL to cope with increasingly complex cyber security problems.",Cyber defense;cyber security;cyberattacks;deep learning;deep reinforcement learning (DRL);Internet of Things (IoT);IoT;review;survey,IEE
785,Towards a Simultaneous and Granular Identity-Expression Control in Personalized Face Generation,R. Liu; B. Ma; W. Zhang; Z. Hu; C. Fan; T. Lv; Y. Ding; X. Cheng,2024,"In human-centric content generation, the pre-trained text-to-image models struggle to produce user-wanted por-trait images, which retain the identity of individuals while exhibiting diverse expressions. This paper introduces our efforts towards personalized face generation. To this end, we propose a novel multi-modal face generation frame-work, capable of simultaneous identity-expression control and more fine-grained expression synthesis. Our expression control is so sophisticated that it can be specialized by the fine-grained emotional vocabulary. We devise a novel dif-fusion model that can undertake the task of simultaneously face swapping and reenactment. Due to the entanglement of identity and expression, separately and precisely control-ling them within one framework is a nontrivial task, thus has not been explored yet. To overcome this, we propose sev-eral innovative designs in the conditional diffusion model, including balancing identity and expression encoder, improved midpoint sampling, and explicitly background con-ditioning. Extensive experiments have demonstrated the controllability and scalability of the proposed framework, in comparison with state-of-the-art text-to-image, face swap-ping, and face reenactment methods.",Personalized Face Generation;Face Swapping;Face Reenactment;Text-to-Image,IEE
786,A Novel Facial Manipulation Detection Method Based on Contrastive Learning,Z. Ma; P. Xu; X. Mei; J. Shen,2022,"Nowadays, numerous synthesized face-swapping videos generated by face forgery algorithms have become an emerging problem, which promotes facial manipulation detection to be a significant topic. With the development of face forgery algorithms, some fake face images or videos generated by those strong forgery algorithms are very realistic, which have brought much difficulty to facial manipulation detection. In this paper, we present a novel facial manipulation detection method based on contrastive learning. We analyze the texture features of manipulated facial images and propose to compare and learn the features of the whole face and the center face in order to get more general features. We calculate the similarity and distribution distance between the whole face and the center face. The experiments implemented on FaceForensics++ dataset demonstrate that the proposed method achieves outstanding results and can learn the general features.",Facial Manipulation Detection;Face Forgery Detection;Contrastive Learning;Siamese Network;Deep learning,IEE
787,TruceNet: A CNN-Based Model for Accurate Classification of DeepFake Images,D. Rao; K. Utturwar; T. Shelke; A. Patil; E. Sarda,2023,"With the rise of GANs, the prevalence of Deepfakes has increased, resulting in significant privacy, security, and social concerns. To tackle this issue, we propose TruceNet, a novel approach that utilizes a CNN architecture to detect Deepfakes in images. Our method analyzes various image features to determine if manipulation has occurred. Through experiments on a comprehensive dataset of Deepfakes and non-Deepfakes, we evaluate TruceNet's effectiveness. Our CNN architecture achieves high detection accuracy, outperforming state-of-the-art methods. TruceNet exhibits robustness against common Deepfake manipulations such as face swapping, expression modification, and Neural Texture Synthesis. It consistently achieves an average accuracy of 94.2% in correctly classifying manipulated images, maintaining a precision of 95% across different manipulation scenarios. The research findings highlight TruceNet's significant contribution in mitigating Deepfake risks and enhancing digital media security and trustworthiness. By accurately detecting Deepfakes, TruceNet offers a reliable solution to combat the growing threat posed by manipulated images.",CNN;DeepFake;TruceNet;Classification;ResNet,IEE
788,A Multi-Modal Framework for Fake News Analysis for Detection to Deconstruction,S. E. Vadakkethil Somanathan Pillai; H. S. Parveen,2024,"The research discusses a multimodal framework for analyzing and detecting fake news and understanding its impact on society. This framework employs diverse strategies, including linguistic analysis, social network monitoring, and visual assessment, to capture various aspects of fabricated information and its dissemination. The first component of the framework focuses on linguistic analysis, examining the language and textual content used in fake news articles to identify misleading information, biased language, and sensationalized headlines. The second component analyzes the role of social networks in spreading fake news, tracking its propagation through platforms like social media and identifying key actors and influencers involved in its dissemination. The third component involves visual assessment, examining the images and videos used in fake news to manipulate public perceptions and emotions, including the detection of doctored images and misleading illustrations.",Fake News Detection;NLP;Machine Learning,IEE
789,Deepfake Forensics via an Adversarial Game,Z. Wang; Y. Guo; W. Zuo,2022,"With the progress in AI-based facial forgery (i.e., deepfake), people are concerned about its abuse. Albeit effort has been made for training models to recognize such forgeries, existing models suffer from poor generalization to unseen forgery technologies and high sensitivity to changes in image/video quality. In this paper, we advocate robust training for improving the generalization ability. We believe training with samples that are adversarially crafted to attack the classification models improves the generalization ability considerably. Considering that AI-based face manipulation often leads to high-frequency artifacts that can be easily spotted (by models) yet difficult to generalize, we further propose a new adversarial training method that attempts to blur out these artifacts, by introducing pixel-wise Gaussian blurring. Plenty of empirical evidence show that, with adversarial training, models are forced to learn more discriminative and generalizable features. Our code: https://github.com/ah651/deepfake_adv.",Deepfake forensics;adversarial training;data augmentation;generalization ability,IEE
790,Learning to Listen and Listening to Learn: Spoofed Audio Detection Through Linguistic Data Augmentation,Z. Khanjani; L. Davis; A. Tuz; K. Nwosu; C. Mallinson; V. P. Janeja,2023,"Spoofed audio, both human or machine generated, causes deception and disinformation and as such is a societal challenge. This study advances the detection of spoofed audio through a novel approach that augments knowledge about audio data by incorporating linguistic information. Using perceptual methods, for English audio samples, experts in sociolinguistics listened for audio cues, and used binary labels to indicate the perceived authenticity of a set of speech samples, based on phonetic and phonological features that occur frequently in spoken English. These Expert Defined Linguistic Features (EDLFs) were then used in supervised spoofed audio detection methods to augment AI models. An ensemble method based on multi-domain features both from the audio data itself and the EDLFs was also created to evaluate the spoofed audio detection, and to demonstrate how EDLFs can improve traditional methods of spoofed audio detection. We found that augmenting the audio data with expertinformed linguistic annotation increased the accuracy of spoofed audio detection significantly in both the training and testing datasets across the evaluated single and ensemble models. Our findings indicate the promising avenue of augmenting audio data with perceptual linguistic techniques, as a method of human discernment, to enhance AI-based approaches for spoofed audio detection. These features also establish a foundation for direct linguistic annotations on new audio clips for robust spoofed audio detection.",audio deepfake;spoofed audio detection;Artificial Intelligence;linguistics;sociolinguistics;linguistic perception,IEE
791,Jekyll: Attacking Medical Image Diagnostics using Deep Generative Models,N. Mangaokar; J. Pu; P. Bhattacharya; C. K. Reddy; B. Viswanath,2020,"Advances in deep neural networks (DNNs) have shown tremendous promise in the medical domain. However, the deep learning tools that are helping the domain, can also be used against it. Given the prevalence of fraud in the healthcare domain, it is important to consider the adversarial use of DNNs in manipulating sensitive data that is crucial to patient healthcare. In this work, we present the design and implementation of a DNN-based image translation attack on biomedical imagery. More specifically, we propose Jekyll, a neural style transfer framework that takes as input a biomedical image of a patient and translates it to a new image that indicates an attacker-chosen disease condition. The potential for fraudulent claims based on such generated �fake� medical images is significant, and we demonstrate successful attacks on both X-rays and retinal fundus image modalities. We show that these attacks manage to mislead both medical professionals and algorithmic detection schemes. Lastly, we also investigate defensive measures based on machine learning to detect images generated by Jekyll.","deep learning, generative models, medical image diagnostics, attacks, defenses",IEE
792,Temporal Localization of Deepfake Audio Based on Self-Supervised Pretraining Models and Transformer Classifier,Z. Yan; H. Wang; M. Du; R. Zhang,2024,"With the development of deep learning technology, the ability of deepfake audio is getting stronger and stronger, and localized audio tampering may bring huge semantic changes, posing a great threat to social security. Unlike the true-false binary classification for tampered audio detection, locating the regional location of tampered audio is more challenging. In order to improve the accuracy of localization, the framework proposed in this paper integrates an audio feature extractor based on a self-supervised pretraining model and a transformer-based back-end classifier. First, a large-scale self-supervised pretraining model is used to train the speech representations, such as BYOL-A or WavLM, and then the learned speech representations are fed into the transformer back-end classifier for the temporal localization and regression tasks, which classify each frame and estimate the audio tampering boundaries in order to detect audio tampering segments. Experiments demonstrate that our framework shows good performance for partial forgery detection and localization in challenging environments.",audio deepfake detection;manipulation region location;patially fake;self-supervised pretraining models;transformer,IEE
793,Obscenity Detection in Videos Through a Sequential ConvNet Pipeline Classifier,N. Gautam; D. K. Vishwakarma,2023,"The amount of pornographic material available on the Web is staggering. This content is available freely on the Internet and without any restrictions which pose a threat to minors as they might be introduced to such content, which is harmful to their mental health for the long term and also there is huge threats of pornographic content generation to the celebrities, known figures due to invention of deep fakes. There are many software that blocks access to the visually disturbing sites that contains obscene, child pornography, or material �harmful� to minors but only a few software analysis motion content of the videos and mostly only image features are analyzed. To tackle this problem, we propose a frame sequence ConvNet pipeline using ResNet-18 for features extraction and analyzing  ${N}$  frame feature map using the proposed ConvNet for the frame sequence classification, therefore implicitly encapsulating the motion information by encoding changes in the ResNet output feature vector, which achieves a state-of-the-art accuracy of 98.25% in classifying pornographic videos of the Pornography-800 data set and state-of-the-art accuracy of 97.15% in classifying videos of the Pornography-2k data set.",Convolution neural networks;end-to-end trainable network;human detection model;porn detection,IEE
794,Statistics-Aware Audio-Visual Deepfake Detector,M. Astrid; E. Ghorbel; D. Aouada,2024,"In this paper, we propose an enhanced audio-visual deep detection method. Recent methods in audio-visual deepfake detection mostly assess the synchronization between audio and visual features. Although they have shown promising results, they are based on the maximization/minimization of isolated feature distances without considering feature statistics. Moreover, they rely on cumbersome deep learning architectures and are heavily dependent on empirically fixed hyperparameters. Herein, to overcome these limitations, we propose: (1) a statistical feature loss to enhance the discrimination capability of the model, instead of relying solely on feature distances; (2) using the waveform for describing the audio as a replacement of frequency-based representations; (3) a post-processing normalization of the fakeness score; (4) the use of shallower network for reducing the computational complexity. Experiments on the DFDC and FakeAVCeleb datasets demonstrate the relevance of the proposed method.",deepfake detector;multi-modal;audiovisual;distribution;similarity,IEE
795,PS3DT: Synthetic Speech Detection Using Patched Spectrogram Transformer,A. K. Singh Yadav; Z. Xiang; K. Bhagtani; P. Bestagini; S. Tubaro; E. J. Delp,2023,"Many deep learning synthetic speech generation tools are readily available. The use of synthetic speech has caused financial fraud, impersonation of people, and misinformation to spread. For this reason forensic methods that can detect synthetic speech have been proposed. Existing methods often overfit on one dataset and their performance reduces substantially in practical scenarios such as detecting synthetic speech shared on social platforms. In this paper we propose, Patched Spectrogram Synthetic Speech Detection Transformer (PS3DT), a synthetic speech detector that converts a time domain speech signal to a mel-spectrogram and processes it in patches using a trans-former neural network. We evaluate the detection performance of PS3DT on ASVspoof2019 dataset. Our experiments show that PS3DT performs well on ASVspoof2019 dataset compared to other approaches using spectrogram for synthetic speech detection. We also investigate generalization performance of PS3DT on In-the-Wild dataset. PS3DT generalizes well than several existing methods on detecting synthetic speech from an out-of-distribution dataset. We also evaluate robustness of PS3DT to detect telephone quality synthetic speech and synthetic speech shared on social platforms (compressed speech). PS3DT is robust to compression and can detect telephone quality synthetic speech better than several existing methods.",synthetic speech detection;deep learning;signal processing;ASVspoof2019;transformer networks,IEE
796,End-to-End Anti-Forensics Network of Single and Double JPEG Detection,D. Kim; W. Ahn; H. -K. Lee,2021,"JPEG compression is one of the major image compression methods and is widely used on the Internet. In addition, identifying traces of JPEG compression and double JPEG compression (DJPEG) is crucial in the image forensics field. Therefore, JPEG compression detection and DJPEG compression detection are two of the popular image authentication methods. Many feature-based JPEG detection methods have been proposed for that purpose, and there have been outstanding improvements in DJPEG detection with the development of deep learning. A number of anti-forensics of JPEG detection that counter feature-based detectors have been proposed but only a few techniques that counter DJPEG have been researched. This paper explores whether JPEG reconstruction methods, including restoration and anti-forensics of JPEG detection, can deceive JPEG and DJPEG detectors. We demonstrate that existing anti-forensics of JPEG detection can deceive both JPEG and DJPEG detectors well but perform poorly in non-aligned cases and degrade the image quality. We propose a convolutional neural network (CNN) based anti-forensics method to improve the performance of anti-forensics so that they can proficiently deceive JPEG and DJPEG detectors with higher image quality. Moreover, we explore the generalization algorithm to handle the real scenario.",Anti-forensics;CNN;DJPEG detection;image forensics;JPEG detection;JPEG restoration,IEE
797,Controllable Guide-Space for Generalizable Face Forgery Detection,Y. Guo; C. Zhen; P. Yan,2023,"Recent studies on face forgery detection have shown satisfactory performance for methods involved in training datasets, but are not ideal enough for unknown domains. This motivates many works to improve the generalization, but forgery-irrelevant information, such as image background and identity, still exists in different domain features and causes unexpected clustering, limiting the generalization. In this paper, we propose a controllable guide-space (GS) method to enhance the discrimination of different forgery domains, so as to increase the forgery relevance of features and thereby improve the generalization. The well-designed guide-space can simultaneously achieve both the proper separation of forgery domains and the large distance between real-forgery domains in an explicit and controllable manner. Moreover, for better discrimination, we use a decoupling module to weaken the interference of forgery-irrelevant correlations between domains. Furthermore, we make adjustments to the decision boundary manifold according to the clustering degree of the same domain features within the neighborhood. Extensive experiments in multiple in-domain and cross-domain settings confirm that our method can achieve state-of-the-art generalization.",,IEE
798,Face Poison: Obstructing DeepFakes by Disrupting Face Detection,Y. Li; J. Zhou; S. Lyu,2023,"Recent years have seen fast development in synthesizing realistic human faces using AI-based forgery technique called DeepFake, which can be weaponized to cause negative personal and social impacts. In this work, we develop a defense method, namely FacePosion, to prevent individuals from becoming victims of DeepFake videos by sabotaging would-be training data. This is achieved by disrupting face detection, a prerequisite step to prepare victim faces for training DeepFake model. Once the training faces are wrongly extracted, the DeepFake model can not be well trained. Specifically, we propose a multi-scale feature-level adversarial attack to disrupt the intermediate features of face detectors using different scales. Extensive experiments are conducted on seven various DeepFake models using six face detection methods, empirically showing that disrupting face detectors using our method can effectively obstruct DeepFakes.",DeepFake defense;video forensics;adversarial perturbation;face detection,IEE
799,Detection of Authenticity - of Content for Forensics Using Forenshield,P. Govindarajan; A. S. P; S. K. S; A. Tesfahun,2023,"The rampant spread of deepfake videos, a significant threat to media integrity, occurs widely on social media and news platforms. Detecting Deepfakes is a formidable challenge. The proposed study involves a novel algorithm to detect the deepfake. The model comprises of various pre-existing classifiers and a novel algorithm named ForenShield � which detects the deepfakes with an accuracy of 97%. The proposed novel technique works on voting strategy and it outperforms all the pre-existing classifiers, exhibiting the models excellence through the same.",Deepfake;ForenShield;Voting Strategy;Classifiers,IEE
800,Cross-Dataset Face Manipulation Detection,B. Bekci; Z. Akhtar; H. K. Ekenel,2020,"Easily available recent face image/video manipulation techniques and tools are now being utilized to generate highly realistic manipulated videos known as DeepFakes, which can fool face recognition systems and humans. Thus, it is vital to devise precise manipulation detection methods. Despite the progress, existing mechanisms are limited to the datasets or manipulation types. In this paper, to increase the performance under unseen data and manipulations, a DeepFakes detection framework using metric learning and steganalysis rich models is presented. Extensive empirical analysis on three publicly available datasets, namely, FaceForensics++, CelebDF, and DeepFakeTIMIT, were carried out to evaluate the generalization capability of the proposed approach. The framework attained 5% to 15% accuracy gains under unseen manipulations.",Deep Learning;Metric Learning;DeepFake;Generalization;Face Manipulation,IEE
801,"Real, Fake and Synthetic Faces - Does the Coin Have Three Sides?",S. Naeem; R. Al-Sharawi; M. R. Khan; U. Tariq; A. Dhall; H. Al Nashash,2024,"With the ever-growing power of generative artificial intelligence, deepfake and artificially generated (synthetic) media have continued to spread online, which creates various ethical and moral concerns regarding their usage. To tackle this, we thus present a novel exploration of the trends and patterns observed in real, deepfake and synthetic facial images. The proposed analysis is done in two parts: firstly, we incorporate eight deep learning models and analyze their performances in distinguishing between the three classes of images. Next, we look to further delve into the similarities and differences between these three sets of images by investigating their image properties both in the context of the entire image as well as in the context of specific regions within the image. ANOVA test was also performed and provided further clarity amongst the patterns associated between the images of the three classes. From our findings, we observe that the investigated deep-learning models found it easier to detect synthetic facial images, with the ViT Patch-16 model performing best on this task with a class-averaged sensitivity, specificity, precision, and accuracy of 97.37%, 98.69%, 97.48%, and 98.25%, respectively. This observation was supported by further analysis of various image properties. We saw noticeable differences across the three category of images. This analysis can help us build better algorithms for facial image generation, and also shows that synthetic, deepfake and real face images are indeed three different classes.",,IEE
802,Media Forensics and DeepFakes: An Overview,L. Verdoliva,2020,"With the rapid progress in recent years, techniques that generate and manipulate multimedia content can now provide a very advanced level of realism. The boundary between real and synthetic media has become very thin. On the one hand, this opens the door to a series of exciting applications in different fields such as creative arts, advertising, film production, and video games. On the other hand, it poses enormous security threats. Software packages freely available on the web allow any individual, without special skills, to create very realistic fake images and videos. These can be used to manipulate public opinion during elections, commit fraud, discredit or blackmail people. Therefore, there is an urgent need for automated tools capable of detecting false multimedia content and avoiding the spread of dangerous false information. This review paper aims to present an analysis of the methods for visual media integrity verification, that is, the detection of manipulated images and videos. Special emphasis will be placed on the emerging phenomenon of deepfakes, fake media created through deep learning tools, and on modern data-driven forensic methods to fight them. The analysis will help highlight the limits of current forensic tools, the most relevant issues, the upcoming challenges, and suggest future directions for research.",Deep learning;deepfakes;digital image forensics;video forensics,IEE
803,Improving Generalization by Commonality Learning in Face Forgery Detection,P. Yu; J. Fei; Z. Xia; Z. Zhou; J. Weng,2022,"This paper proposes a commonality learning strategy for face video forgery detection to improve the generalization. Considering various face forgery methods could leave certain similar forgery traces in videos, we attempt to learn the common forgery features from different forgery databases, so as to achieve better generalization in the detection of unknown forgery methods. Firstly, the Specific Forgery Feature Extractors (SFFExtractors) are trained separately for each of given forgery methods. We utilize the U-net structure and consider the triplet loss, location loss, classification loss, and automatic weighted loss to ensure the detection ability of SFFExtractors on the corresponding forgery methods. Next, the Common Forgery Feature Extractor (CFFExtractor) is trained under the supervision of SFFExtractors to explore the commonality of the forgery traces caused by different forgery methods. The extracted common forgery feature is expected to have a good generalization. The experimental results on FaceForensic++ show that the SFFExtractors outperform many state-of-the-arts in face forgery detection. The generalization performance of the CFFExtractor is verified on FaceForensic++, DFDC, and CelebDF. It is proved that commonality learning can be an effective strategy to improve generalization.",Deep learning;deepfake;face swapping;video forensics;generalization ability,IEE
804,Keeping Children Safe Online With Limited Resources: Analyzing What is Seen and Heard,A. Jevremovic; M. Veinovic; M. Cabarkapa; M. Krstic; I. Chorbev; I. Dimitrovski; N. Garcia; N. Pombo; M. Stojmenovic,2021,"It is every parent�s wish to protect their children from online pornography, cyber bullying and cyber predators. Several existing approaches analyze a limited amount of information stemming from the interactions of the child with the corresponding online party. Some restrict access to websites based on a blacklist of known forbidden URLs, others attempt to parse and analyze the exchanged multimedia content between the two parties. However, new URLs can be used to circumvent a blacklist, and images, video, and text can individually appear to be safe, but need to be judged jointly. We propose a highly modular framework of analyzing content in its final form at the user interface, or Human Computer Interaction (HCI) layer, as it appears before the child: on the screen and through the speakers. Our approach is to produce Children�s Agents for Secure and Privacy Enhanced Reaction (CASPER), which analyzes screen captures and audio signals in real time in order to make a decision based on all of the information at its disposal, with limited hardware capabilities. We employ a collection of deep learning techniques for image, audio and text processing in order to categorize visual content as pornographic or neutral, and textual content as cyberbullying or neutral. We additionally contribute a custom dataset that offers a wide spectrum of objectionable content for evaluation and training purposes. CASPER demonstrates an average accuracy of 88% and an F1 score of 0.85 when classifying text, and an accuracy of 95% when classifying pornography.",Cyber-bullying;cyber-grooming;online safety;pornography filter;real time agent,IEE
805,Deepfake Catcher: Can a Simple Fusion be Effective and Outperform Complex DNNs?,A. Agarwal; N. Ratha,2024,"Despite having completely different configurations, deep learning architectures learn a specific set of features that are common across architectures. For example, the initial few layers learn the low-level edge features from the images. Based on this fact, in this research, we have showcased the potential of deep neural network fusion for simple and effective deepfake detection. The advantage of building an architecture in such a manner is to build a low-power-consuming and accurate defense that can be deployed on mobile devices. To utilize the pre-trained knowledge and obtain downstream task-specific knowledge, we have identified a breakpoint in different networks and divided the obtained knowledge of a network into fixed and adaptive information. We have kept the fixed knowledge intact while modifying the adaptive knowledge along with entirely new knowledge for the deepfake detection task. In the end, the decision of multiple deep architectures trained based on their breakpoint are combined for improved performance. Extensive comparisons performed with existing state-of-the-art architectures demonstrate the effectiveness of the proposed deepfake detection algorithm. The proposed algorithm not only surpasses the existing state-of-the-art (SOTA) algorithms but also needs low computational power. We have further challenged the proposed algorithm by evaluating it by collecting real-world deepfake images.",,IEE
806,Enhancing Gender Privacy with Photo-Realistic Fusion of Disentangled Spatial Segments,P. Rot; J. Kri�aj; P. Peer; V. �truc,2024,"Soft-biometric privacy enhancing techniques (SB-PETs) transform facial images to preserve identity while preventing the automatic extraction of soft-biometrics by confusing machines through noise injections or attribute obfuscation. However, existing SB-PETs often sacrifice image quality for privacy enhancement, limiting practical usage, especially in applications that allow for human inspection. To address these issues, we introduce a novel SB-PET that (i) generates photo-realistic images with obscured gender information, which makes attribute extraction challenging for machine-learning models, but also human observers, and (ii) preserves identity to a significant extent. The proposed approach, abbreviated PriDSS, operates in the latent space of the StyleGANv2 model and aims to (i) preserve the appearance of facial parts from the input image carrying identity information, and (ii) incorporate global context from images of the opposite gender, thus, obscuring the original gender information. PriDSS shows promising results when compared to state-of-the-art techniques from the literature, and leads to competitive gender-privacy and face-verification performance, while ensuring superior photo-realism.",soft�biometrics;privacy;verification,IEE
807,3D-Aware Face Swapping,Y. Li; C. Ma; Y. Yan; W. Zhu; X. Yang,2023,"Face swapping is an important research topic in computer vision with wide applications in entertainment and privacy protection. Existing methods directly learn to swap 2D facial images, taking no account of the geometric information of human faces. In the presence of large pose variance between the source and the target faces, there always exist undesirable artifacts on the swapped face. In this paper, we present a novel 3D-aware face swapping method that generates high-fidelity and multi-view-consistent swapped faces from single-view source and target images. To achieve this, we take advantage of the strong geometry and texture prior of 3D human faces, where the 2D faces are projected into the latent space of a 3D generative model. By disentangling the identity and attribute features in the latent space, we succeed in swapping faces in a 3D-aware manner, being robust to pose variations while transferring fine-grained facial details. Extensive experiments demonstrate the superiority of our 3D-aware face swapping framework in terms of visual quality, identity similarity, and multi-view consistency. Code is available at https://lyx0208.github.io/3dSwap.",Humans: Face;body;pose;gesture;movement,IEE
808,Generative Adversarial Networks for Mitigating Bias in Disinformation,R. Walambe; P. Chaudhary; A. Bajaj; A. S. Rathore; V. Jain; K. Kotecha,2023,"The increasing use of social platforms has led to the rampant spread of disinformation in a number of domains and hampered the credibility of these sources. Disinformation is a type of information disorder wherein fake information is generated with the intent to harm. Machine learning and deep learning can be used to detect such auto-generated information. The conventional method includes gathering vast volumes of text data in terms of both true and fake news stories, headlines, or any other sources and then labeling the data. This leaves us with the issues of human bias within these existing systems, the quality of the aggregated data from different sources and their accurate labeling. In this paper, we propose and demonstrate a textual deep fake detection and generation framework based on Generative Adversarial Network (GAN). The methods are demonstrated on three separate domains namely, political data, sports-related data, and medical data pertaining to COVID 19. Cosine similarity-based evaluation metric is employed for analyzing the classification accuracy of the discriminator and the performance of the Generator in generating near-true fake articles which are very similar in the style and context to the real datasets. The contribution of this work is threefold; firstly, we have demonstrated the generator network which generates the synthetic textual deep-fakes which are extremely similar to the actual instances of disinformation. Secondly, the development of a discriminator network that detects the system-generated data with the real data and lastly, the composite GAN model which can be used in various applications such as automated labeling and annotation is shown. Additionally, this approach can help in generating balanced datasets required for machine learning tasks and alleviate the problem of bias in AI systems, especially for disinformation detection tasks where the disinformation class instances are typically lesser as compared to the true information instances.",GAN;Discriminator;Generator;Real;Fake;Textual;data bias;cosine similarity,IEE
809,Generative Adversarial Ensemble Learning for Face Forensics,J. -Y. Baek; Y. -S. Yoo; S. -H. Bae,2020,"The recent advance of synthetic image generation and manipulation methods allows us to generate synthetic face images close to real images. On the other hand, the importance of identifying the synthetic face images increases more and more to protect personal privacy from those. Although some deep learning-based image forensic methods have been developed recently, it is still challenging to distinguish synthetic images generated by recent image generation and manipulation methods such as the deep fake, face2face, and face swap. To resolve this challenge, we propose a novel generative adversarial ensemble learning method. We train multiple discriminative and generative networks based on the adversarial learning. Compared to the conventional adversarial learning, our method is however more focused on improving the discrimination ability rather than image generation one. To this end, we improve the discriminabilty by ensembling outputs from different two discriminators. In addition, we train two generators in order to generate general and hard synthetic images. By ensemble learning of all the generators and discriminators, we improve the discriminators by using the generated synthetic face images, and improve the generators by passing the combined feedback of the discriminators. On the FaceForensics benchmark challenge, we thoroughly evaluate our methods by comparing the recent methods. We also provide the ablation study to prove the effectiveness and usefulness of our method.",Digital image forensics;generative adversarial ensemble learning;deep learning;synthetic image detection;face image,IEE
810,Multi-scale Feature Learning with Graph Attention Network for Face Forgery Detection,Y. Su; W. Lin; J. Xu; X. Liu,2024,"Face forgery videos, known as Deepfakes, are widely spread on social media with great potential threat, making the detection of forged face videos is crucial. Commonly, forgery video detection methods are based on Convolutional Neural Networks or Transformer, which treats images as grid or sequence structures for binary classification discrimination. Since face objects are usually not regularly shaped quadrilaterals, treating them as grid or sequence structures is redundant and inflexible, thus losing useful information. Based on this, we propose a new perspective to represent facial images as graph structures, which are fed into Graph Neural Network to learn the intrinsic relationships of facial regions for deep forgery detection. In addition, we propose a feature fusion module to learn artifact information in the frequency domain for a more comprehensive facial feature representation to further improve the reliability of our model. Extensive experiments on several benchmark databases demonstrate the effectiveness and robust generalization ability of our method compared with many state-of-the-art methods.",Face Forgery Detection;Multi-attention;GNN;Deep Learning,IEE
811,Live Face De-Identification in Video,O. Gafni; L. Wolf; Y. Taigman,2019,"We propose a method for face de-identification that enables fully automatic video modification at high frame rates. The goal is to maximally decorrelate the identity, while having the perception (pose, illumination and expression) fixed. We achieve this by a novel feed-forward encoder-decoder network architecture that is conditioned on the high-level representation of a person's facial image. The network is global, in the sense that it does not need to be retrained for a given video or for a given identity, and it creates natural looking image sequences with little distortion in time.",,IEE
812,Exploiting Modality-Specific Features for Multi-Modal Manipulation Detection and Grounding,J. Wang; B. Liu; C. Miao; Z. Zhao; W. Zhuang; Q. Chu; N. Yu,2024,"AI-synthesized text and images have gained significant attention, particularly due to the widespread dissemination of multi-modal manipulations on the internet, which has resulted in numerous negative impacts on society. Existing methods for multi-modal manipulation detection and grounding primarily focus on fusing vision-language features to make predictions, while overlooking the importance of modality-specific features, leading to sub-optimal results. In this paper, we construct a simple and novel transformer-based framework for multi-modal manipulation detection and grounding tasks. Our framework simultaneously explores modality-specific features while preserving the capability for multi-modal alignment. To achieve this, we introduce visual/language pre-trained encoders and dual-branch cross-attention (DCA) to extract and fuse modality-unique features. Furthermore, we design decoupled fine-grained classifiers (DFC) to enhance modality-specific feature mining and mitigate modality competition. Moreover, we propose an implicit manipulation query (IMQ) that adaptively aggregates global contextual cues within each modality using learnable queries, thereby improving the discovery of forged details. Extensive experiments on the DGM4 dataset demonstrate the superior performance of our proposed model compared to state-of-the-art approaches.",multi-modal;media manipulation;transformer;modality-specific,IEE
813,Deep-Learning-Based Lithium Battery Defect Detection via Cross-Domain Generalization,X. Chen; M. Liu; Y. Niu; X. Wang; Y. Cheng Wu,2024,"This research addresses the critical challenge of classifying surface defects in lithium electronic components, crucial for ensuring the reliability and safety of lithium batteries. With a scarcity of specific defect data, we introduce an innovative Cross-Domain Generalization (CDG) approach, incorporating Cross-domain Augmentation, Multi-task Learning, and Iteration Learning. Leveraging a steel surface defect dataset as foundational knowledge, our approach compensates for the limited lithium-specific data and enhances model generalization. We also introduce the Lithium Electronic Surface Defect Classification (IESDC) dataset, demonstrating significant accuracy improvements over baseline methods. Our comprehensive evaluation covers model interpretability, robustness, and adaptability. Beyond battery technology, this methodology offers a framework for data scarcity challenges in various industries, emphasizing the importance of adaptable learning methods.",Lithium electronic surface defect classification;cross-domain generalization;multi-task learning;iteration learning,IEE
814,Video Face Manipulation Detection Through Ensemble of CNNs,N. Bonettini; E. D. Cannas; S. Mandelli; L. Bondi; P. Bestagini; S. Tubaro,2021,"In the last few years, several techniques for facial manipulation in videos have been successfully developed and made available to the masses (i.e., FaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in video sequences with incredibly realistic results and a very little effort. Despite the usefulness of these tools in many fields, if used maliciously, they can have a significantly bad impact on society (e.g., fake news spreading, cyber bullying through fake revenge porn). The ability of objectively detecting whether a face has been manipulated in a video sequence is then a task of utmost importance. In this paper, we tackle the problem of face manipulation detection in video sequences targeting modern facial manipulation techniques. In particular, we study the ensembling of different trained Convolutional Neural Network (CNN) models. In the proposed solution, different models are obtained starting from a base network (i.e., EfficientNetB4) making use of two different concepts: (i) attention layers; (ii) siamese training. We show that combining these networks leads to promising face manipulation detection results on two publicly available datasets with more than 119000 videos.",deepfake;video forensics;deep learning;attention,IEE
815,Synthetic Speech Classification using Bidirectional LSTM Networks,A. S. G S; G. V; V. C. Thirumavalavan; V. P. Sivabalan; M. N. Suresh; T. S. Jayaraman,2022,"With the invention of generative adversarial networks, synthetic man-made manipulation of speech has been exponentially increasing. The detection of synthetic or bonafide speech is a challenging problem due to the availability of plenty of algorithms generating synthetic speech signals, This becomes more challenging if we want to know the algorithm used to generate the synthetic speech. In this work, a set of synthetic speech signals generated by five different commonly known algorithms and an another set belonging to unknown algorithm class are used for classification. The objective is to classify the algorithms used to generate synthetic speech. Recurrent neural network based bidirectional long short term memory (B-LSTM) sequence to label classifier is employed for training and evaluation. Eight different feature sets are used for analyzing the performance of classification accuracy. It is observed that the feature set produced from dynamic time warping and spectral characteristics provide the best classification accuracy.",Speech;Deepfake;Feature extraction;B-LSTM;Synthetic Speech,IEE
816,Exploiting temporal information to prevent the transferability of adversarial examples against deep fake detectors,D. Lin; B. Tondi; B. Li; M. Barni,2022,"The diffusion of AI tools capable of generating realistic DeepFakes (DF) videos raises serious threats to face-based biometric recognition systems. For this reason, several detectors based on Deep Neural Networks (DNNs) have been developed to distinguish between real and DF videos. Despite their good performance, these methods suffer from vulnerability to adversarial attacks. In this paper, we argue that it is possible to increase the resilience of DNN-based DF detectors against black-box adversarial attacks by exploiting the temporal information contained in the video. By using such information, in fact, the transferability of adversarial examples from a source to a target model is significantly decreased, making it difficult to launch an attack without accessing the target network. To back this claim, we trained two convolutional neural networks (CNNs) to detect DF videos, and measured their robustness against black-box, transfer-based, attacks. We also trained two detectors by adding to the CNNs a long short-term memory (LSTM) layer to extract temporal information. Then, we measured the transferability of adversarial examples to-wards the LSTM-networks. The results we got suggest that the methods based on temporal information are less prone to black-box attacks.",,IEE
817,Dual Attention Network Approaches to Face Forgery Video Detection,Y. -X. Luo; J. -L. Chen,2022,"Forged videos are commonly spread online. Most have malicious content and cause serious information security problems. The most critical issue in deepfake detection is the identification of traces of tampering in fake videos. This study designs a Dual Attention Forgery Detection Network (DAFDN), which embeds a spatial reduction attention block (SRAB) and a forgery feature attention module (FFAM) to the backbone network. DAFDN embeds the two proposed attention mechanisms and enables the convolution neural network to extract peculiar traces left by images� warping. This study uses two benchmark datasets, DFDC and FaceForensics++, to compare the performance of the proposed DAFDN with other methods. The results show that the proposed DAFDN mechanism achieves AUC scores of 0.911 and 0.945 in the datasets DFDC and FaceForensics++, respectively. These results are better than those of previously developed methods, such as XceptionNet and EfficientNet-related methods.",Deepfake;forgery video detection;dual attention neural network;convolutional neural network;information security,IEE
818,Reinforced Disentanglement for Face Swapping without Skip Connection,X. Ren; X. Chen; P. Yao; H. -Y. Shum; B. Wang,2023,"The SOTA face swap models still suffer the problem of either target identity (i.e., shape) being leaked or the target non-identity attributes (i.e., background, hair) failing to be fully preserved in the final results. We show that this insufficient disentanglement is caused by two flawed designs that were commonly adopted in prior models: (1) counting on only one compressed encoder to represent both the semantic-level non-identity facial attributes(i.e., pose) and the pixel-level non-facial region details, which is contradictory to satisfy at the same time; (2) highly relying on long skip-connections [50] between the encoder and the final generator, leaking a certain amount of target face identity into the result. To fix them, we introduce a new face swap framework called ""WSC-swap"" that gets rid of skip connections and uses two target encoders to respectively capture the pixel-level non-facial region attributes and the semantic non-identity attributes in the face region. To further reinforce the disentanglement learning for the target encoder, we employ both identity removal loss via adversarial training (i.e., GAN [18]) and the non-identity preservation loss via prior 3DMM models like [11]. Extensive experiments on both FaceForensics++ and CelebA-HQ show that our results significantly outperform previous works on a rich set of metrics, including one novel metric for measuring identity consistency that was completely neglected before.",,IEE
819,Towards a Domain-Agnostic Knowledge Graph-as-a-Service Infrastructure for Active Cyber Defense with Intelligent Agents,P. Calyam; M. Kejriwal; P. Rao; J. Cheng; W. Wang; L. Bai; V. S. Siddhardh Nadendla; S. Madria; S. K. Das; R. Chadha; K. A. Hoque; K. Palaniappan; K. Neupane; R. L. Neupane; S. Gandhari; M. Singhal; L. Othmane; M. Yu; V. Anand; B. Bhargava; B. Robertson; K. Kee; P. Buzzanell; N. Bolton; H. Taneja,2023,"Active cyber defense mechanisms are necessary to perform automated, and even autonomous operations using intelligent agents that defend against modern/sophisticated AI-inspired cyber threats (e.g., ransomware, cryptojacking, deep-fakes). These intelligent agents need to rely on deep learning using mature knowledge and should have the ability to apply this knowledge in a situational and timely manner for a given AI-inspired cyber threat. In this paper, we describe a �domain-agnostic knowledge graph-as-a-service� infrastructure that can support the ability to create/store domain-specific knowledge graphs for intelligent agent Apps to deploy active cyber defense solutions defending real-world applications impacted by AI-inspired cyber threats. Specifically, we present a reference architecture, describe graph infrastructure tools, and intuitive user interfaces required to construct and maintain large-scale knowledge graphs for the use in knowledge curation, inference, and interaction, across multiple domains (e.g., healthcare, power grids, manufacturing). Moreover, we present a case study to demonstrate how to configure custom sets of knowledge curation pipelines using custom data importers and semantic extract, transform, and load scripts for active cyber defense in a power grid system. Additionally, we show fast querying methods to reach decisions regarding cyberattack detection to deploy pertinent defense to outsmart adversaries.",knowledge graph;active cyber defense;cyber-security;power grid systems,IEE
820,AI-Generated Image Detection With Wasserstein Distance Compression and Dynamic Aggregation,Z. Lyu; J. Xiao; C. Zhang; K. -M. Lam,2024,"With the rapid advancement of generative models, image detectors for AI-generated content have become an increasingly necessary technology in computer vision, attracting significant attention from researchers. This technology aims to detect whether an image is naturally generated by imaging systems (e.g., digital cameras) or generated by advanced AI techniques. Despite the promising performance achieved by recent fake detection methods, they are typically trained on millions of redundant images with similar characteristics, leading to inefficient training. Furthermore, the performances of existing detectors often deteriorate when the training datasets are imbalanced. To address these challenges, we propose a novel AI-generated image detector based on dynamic aggregation and information compression with the Wasserstein distance. Experimental results show that our proposed method significantly outperforms state-of-the-art models that generalize across different generative models, with an increase of $\mathbf{+ 1. 8 6 \%}$ average accuracy and $\mathbf{+ 0. 1 4 \%}$ average precision, while substantially reducing the training time. On imbalanced datasets, our proposed method leads to a $\mathbf{+ 1 4. 4 6 \%}$ accuracy improvement, clearly demonstrating its robustness on imbalanced datasets.",Fake Image Detection;Efficient Training,IEE
821,WaterLo: Protect Images from Deepfakes Using Localized Semi-Fragile Watermark,N. Beuve; W. Hamidouche; O. D�forges,2023,"Most existing contributions in the field of Deepfake detection focus on passive detection methods, where the detector only analyzes the doctored image. However, this approach often lacks the ability to generalize to unseen data and struggles to detect Deepfakes generated using new deepfake models. To address this limitation, our paper proposes an active detection approach, where we have access to the image before the Deepfake is generated. Our solution involves applying a watermark that disappears in modified regions, allowing our detector to identify image modifications and localize them accurately. Additionally, we incorporate a compression module into our training pipeline to enhance the watermark�s robustness against JPEG compression. Experimental results demonstrate the effectiveness of our proposed solution, achieving a remarkable detection accuracy of 97.83% while maintaining significantly higher image quality compared to previous works. Furthermore, by incorporating the compression module in the training pipeline, we improve the detection accuracy on compressed samples, albeit with a slight decrease in accuracy for non-compressed samples. This contribution also provides a valuable tool for video owners to verify if their videos have been tampered with and safeguard them against unauthorized use. The code of the proposed framework is available at https://github.com/beuve/waterlo.",deepfake detection;deep learning;watermarking,IEE
822,Development of a Privacy-Preserving UAV System With Deep Learning-Based Face Anonymization,H. Lee; M. U. Kim; Y. Kim; H. Lyu; H. J. Yang,2021,"In this paper, we develop a privacy-preserving UAV system that does not infringe on the privacy of people in the videos taken by UAVs. Instead of blurring or masking the face parts of the videos, we want to exquisitely modify only the face parts so that the people in the modified videos still look like humans, but they become anonymous. Doing so, the semantic information of the videos can be preserved even with the anonymization. Specifically, based on the latest generative adversarial network architecture, we propose a deep learning-based face-anonymization scheme so that each modified face part looks like the face of a person who does not actually exist. The trained face-anonymizer is then mounted on the UAV system we have implemented. Through experiments, we confirm that the developed privacy-preserving UAV system anonymizes UAV�s first-person videos so that the people in the video are not recognized as anyone in the dataset used. In addition, we show that even with such anonymized videos, the perception performance required for performing UAV�s essential functions such as simultaneous localization and mapping is not degraded.",Privacy infringement;privacy-preserving vision;deep learning;security robot;UAV patrol system,IEE
823,Reverse Engineering of Generative Models: Inferring Model Hyperparameters From Generated Images,V. Asnani; X. Yin; T. Hassner; X. Liu,2023,"State-of-the-art (SOTA) Generative Models (GMs) can synthesize photo-realistic images that are hard for humans to distinguish from genuine photos. Identifying and understanding manipulated media are crucial to mitigate the social concerns on the potential misuse of GMs. We propose to perform reverse engineering of GMs to infer model hyperparameters from the images generated by these models. We define a novel problem, �model parsing�, as estimating GM network architectures and training loss functions by examining their generated images � a task seemingly impossible for human beings. To tackle this problem, we propose a framework with two components: a Fingerprint Estimation Network (FEN), which estimates a GM fingerprint from a generated image by training with four constraints to encourage the fingerprint to have desired properties, and a Parsing Network (PN), which predicts network architecture and loss functions from the estimated fingerprints. To evaluate our approach, we collect a fake image dataset with 100 K images generated by 116 different GMs. Extensive experiments show encouraging results in parsing the hyperparameters of the unseen models. Finally, our fingerprint estimation can be leveraged for deepfake detection and image attribution, as we show by reporting SOTA results on both the deepfake detection (Celeb-DF) and image attribution benchmarks.",Reverse engineering;fingerprint estimation;generative models;deepfake detection;image attribution,IEE
824,My Face My Choice: Privacy Enhancing Deepfakes for Social Media Anonymization,U. A. �ift�i; G. Yuksek; ?. Demir,2023,"Recently, productization of face recognition and identification algorithms have become the most controversial topic about ethical AI. As new policies around digital identities are formed [22], we introduce three face access models in a hypothetical social network, where the user has the power to only appear in photos they approve. Our approach eclipses current tagging systems and replaces unapproved faces with quantitatively dissimilar deepfakes. In addition, we propose new metrics specific for this task, where the deepfake is generated at random with a guaranteed dissimilarity. We explain access models based on strictness of the data flow, and discuss impact of each model on privacy, usability, and performance. We evaluate our system on Facial Descriptor Dataset [61] as the real dataset, and two synthetic datasets with random and equal class distributions. Running seven SOTA face recognizers on our results, MFMC reduces the average accuracy by 61%. Lastly, we extensively analyze similarity metrics, deepfake generators, and datasets in structural, visual, and generative spaces; supporting the design choices and verifying the quality.",Applications: Social good;Biometrics;face;gesture;body pose;Explainable;fair;accountable;privacy-preserving;ethical computer vision,IEE
825,Detecting DeepFakes: A Deep Convolutional Neural Network Approach with Depth Wise Separable Convolutions,R. V. Reddy; A. Nethi; S. Sukhija; Y. Gupta,2023,"This paper presents a deep learning based approach for detecting deepfake images and videos. With the rise of free and easily accessible software tools, such as GANs, creating deep-fakes has become effortless. However, detecting these deepfakes has proven to be a significant challenge. Our method uses a deep convolutional neural network architecture that involves depth-wise separable convolutions to classify whether an image or video is real or fake. We trained and evaluated our model on the CelebDF V2 dataset, achieving high accuracy rates of 98.8% and 97.4% for image and video classification, respectively. Our work is a significant contribution towards mitigating the spread of deepfakes, and we plan to expand our research to detect AI-generated audio in future work. We also propose the development of an online browser extension to make our detection method accessible to the general public and to integrate it into various social media and messaging platforms to prevent the spread of deepfakes.",deepfakes;generative adversarial networks (GANs);computer vision;machine learning;artificial intelligence;image and video manipulation;misinformation and disinformation;social media,IEE
826,COM-PRESS: Dashboard to Detect (AI-Based) Image Manipulations,H. Mareen; S. D'haeseleer; K. Van Damme; T. Evens; P. Lambert; G. Van Wallendael,2024,The COM-PRESS dashboard enables image manipulation analysis for fact checkers.,Multimedia Forensics;Image Forgery Detection;Deepfake Detection,IEE
827,Finding Facial Forgery Artifacts with Parts-Based Detectors,S. Schwarcz; R. Chellappa,2021,"Manipulated videos, especially those where the identity of an individual has been modified using deep neural networks, are becoming an increasingly relevant threat in the modern day. In this paper, we seek to develop a generalizable, explainable solution to detecting these manipulated videos. To achieve this, we design a series of forgery detection systems that each focus on one individual part of the face. These parts-based detection systems, which can be combined and used together in a single architecture, meet all of our desired criteria - they generalize effectively between datasets and give us valuable insights into what the network is looking at when making its decision. We thus use these detectors to perform detailed empirical analysis on the FaceForensics++, Celeb-DF, and Facebook Deep-fake Detection Challenge datasets, examining not just what the detectors find but also collecting and analyzing useful related statistics on the datasets themselves.",,IEE
828,Artificial Intelligence as a Driver of Strategic Communications in the Period of Deep Mediatization,D. P. Gavra; E. V. Bykova; I. A. Baikova,2024,"The article is devoted to the transformation of the processes of deep mediatization of social relations in a ratified digital society, due to the intensive introduction of self-learning neural networks and, more broadly, generative artificial intelligence. The characteristic of the current stage of mediatization is given, and an overview of the relevant theoretical approaches is proposed. The influence of artificial intelligence technologies on mediatization processes is considered, positive and negative effects are identified, and the most significant risks are analyzed. Special attention is paid to such phenomena with negative potential as the deepening of the digital divide, manipulation of public opinion and its exploitation with the use of deep fakes, preservation of bubbles and echo chambers, algorithmic bias and cultural homogenization.",Artificial Intelligence;strategic communications;big data;deep mediatization,IEE
829,Improved Accuracy in Image Tampering Detection using MobileNet,V. V. S. Tallapragada; V. M. L. Prakash; U. V. Reddy; V. H. S. Reddy; C. Praneeth,2023,"Recent developments in the technology and the exponential increase in accessing the digital networks have increased over the past few years. With this expansion, the data that is being accessed by the remote devices have also increased. This scenario is more pertinent over the images or image-based data which are used by unauthenticated users. It is relatively simple for unscrupulous intruders to subtly alter these digital photographs for illegal transactions. Therefore, preventing the modification of images have become a significant concern. This study mainly concentrates on the development of novel technique for the protection of medical images from tampering. It is proposed to use MobileNet for classification. Like the inception towers, MobileNets use depth-wise separable convolutions. These cut down the latency by decreasing the number of a parameters. Moreover, MobileNets have convenient model-shrinking parameters that can be called before training to achieve the desired precise size. Results show that the accuracy of the proposed technique has increased twice when compared to the existing ResNet based architecture.",Image Tampering;ResNet;MobileNet;Medical Images;Classification,IEE
830,Dense 3D Coordinate Code Prior Guidance for High-Fidelity Face Swapping and Face Reenactment,A. Tang; H. Xue; J. Ling; R. Xie; L. Sang,2021,"In face synthesis tasks, commonly used 2D face representations (e.g. 2D landmarks, segmentation maps, etc.) are usually sparse and discontinuous. To combat these shortcomings, we utilize a dense and continuous representation, named Projected Normalized Coordinate Code (PNCC), as the guidance and develop a PNCC-Spatio-Normalization (PSN) method to achieve face synthesis regarding arbitrary head poses and expressions. Based on PSN, we provide an effective framework for face reenactment and face swapping task. To ensure a harmonious and seamless face swapping, a simple yet effective Appearance-Blending Module (ABM) is proposed to fit the synthesized face to the target face. Our method is subject-agnostic and can be applied to any pair of faces without extra fine-tuning. Both qualitative and quantitative experiments are conducted to demonstrate the superiority of the proposed method in comparisons to existing state-of-the-art systems.",,IEE
831,Robustness of Electrical Network Frequency Signals as a Fingerprint for Digital Media Authentication,N. Poredi; D. Nagothu; Y. Chen; X. Li; A. Aved; E. Ardiles-Cruz; E. Blasch,2022,"Leveraging modern Artificial Intelligence (AI) technology, Deepfake attacks manipulate audio/video streams (AVS) to mimic any targeted person or scenario. Deepfake attacks are highly disturbing, and the misinformation can mislead the public, raising further challenges in policy, technical, social, and legal aspects. Electrical Network Frequency (ENF) signals embedded in AVS data are promising to be utilized as fingerprints to authenticate digital media and timely detect deepfaked audio or video. Meanwhile, the success of ENF-based deepfake detection approaches will be forfeited if attackers can create false ENF fingerprints to fool the detector. In this paper, a thorough experimental study validates the robustness of ENF signals as a fingerprint for digital media authentication. Taking statistical, supervised learning, and deep learning approaches, this work shows that it is infeasible to forecast the future ENF signals based on historical records. While strict theoretical proof is yet to be done, this work experimentally verifies ENF signals as a reliable fingerprint to authenticate digital media.",Electrical Network Frequency (ENF) Signals;Embedded Fingerprints;Digital Media Authentication,IEE
832,A reliable solution to detect deepfakes using Deep Learning,H. K. Vedamurthy; R. V; G. S P,2022,"Recently, it has become simple to produce trustworthy face video exchanges that leave a few signs of deception thanks to in-depth free reading software tools (DF). Despite decades of effective use of visual effects in digital video deception, recent developments in in-depth learning have significantly improved the genuine nature of misleading content and the accessibility that can be achieved with it. This is referred to as AI-synthesized media or DF in short. Making DF is a simple task that uses practical tools. However, it is a significant difficulty if these DFs are discovered, because it is hard to train the algorithm for identifying DF. CNNs and RNNs have helped us come closer to DF. The Convolutional Neural Network (CNN) is used by the system to extract features at the individual level. The continuous neural network (RNN) states learn to recognize whether or not a video is being deceived and be able to spot temporary anomalies among the frames given by DF's creative tools thanks to these capabilities. An extensive collection of pseudo-videos gathered from a common data source is the anticipated outcome. We demonstrate how our method can produce a competitive outcome in this work that is simple to utilize.",Deep fake;ResNext;CNN;RNN;GAN;LSTM,IEE
833,Landmark Breaker: Obstructing DeepFake By Disturbing Landmark Extraction,P. Sun; Y. Li; H. Qi; S. Lyu,2020,"The recent development of Deep Neural Networks (DNN) has significantly increased the realism of AI-synthesized faces, with the most notable examples being the DeepFakes. The DeepFake technology can synthesize a face of target subject from a face of another subject, while retains the same face attributes. With the rapidly increased social media portals (Facebook, Instagram, etc), these realistic fake faces rapidly spread though the Internet, causing a broad negative impact to the society. In this paper, we describe Landmark Breaker, the first dedicated method to disrupt facial landmark extraction, and apply it to the obstruction of the generation of DeepFake videos. Our motivation is that disrupting the facial landmark extraction can affect the alignment of input face so as to degrade the DeepFake quality. Our method is achieved using adversarial perturbations. Compared to the detection methods that only work after DeepFake generation, Landmark Breaker goes one step ahead to prevent DeepFake generation. The experiments are conducted on three state-of-the-art facial landmark extractors using the recent Celeb-DF dataset.",,IEE
834,"Detection of Morphed Face, Body, Audio signals using Deep Neural Networks",D. Gharde; M. P. A; S. N; S. K. S,2022,"Deepfakes have been a hot topic in the field of deep learning. It is typically used to alter the face or body of a person to create a fake image or video. With the rise of internet, the number of fake content especially deepfakes have increased exponentially. There have already been cases of these causing conflict and hatred among people. To keep this misinformation regulated, there needs to be a way to distinguish deepfakes from the rest. We therefore have come up with a model to classify deepfakes from pristine, accurately and quickly, so that anyone can upload an image/video to know whether it is genuine or not. The parameters taken into consideration for classifying deepfakes are face, audio and body language. The model for face consists of MMOD-CNN Face detector for pre-processing the input, which is then passed on to a Temporal Convolutional Network (TCN) to predict. For audio deepfake detection, audio converted into a spectrogram is passed to a ResNet50V2 followed by a TCN to predict. The Body Language model uses a vanilla TCN to predict if its a deepfake video or not.",TCN;MMOD;ResNet50V2;CNN;Conditional GAN;deepfakes;deep-learning;temporal convolution,IEE
835,Techniques to Detect Fake Profiles on Social Media Using the New Age Algorithms - A Survey,A. K. M. Rubaiyat Reza Habib; E. Elijah Akpan; B. Ghosh; I. K. Dutta,2024,"This research explores the growing issue of fake accounts in Online Social Networks [OSNs]. While platforms like Twitter, Instagram, and Facebook foster connections, their lax authentication measures have attracted many scammers and cybercriminals. Fake profiles conduct malicious activities, such as phishing, spreading misinformation, and inciting social discord. The consequences range from cyberbullying to deceptive commercial practices. Detecting fake profiles manually is often challenging and causes considerable stress and trust issues for the users. Typically, a social media user scrutinizes various elements like the profile picture, bio, and shared posts to identify fake profiles. These evaluations sometimes lead users to conclude that a profile is indeed fake. Many ongoing research endeavors focus on new-age machine learning algorithms identifying fake profiles by examining elements such as the profile picture, and the content shared, including fake news or reviews, and distinguishing whether the profile is operated by a social bot or a real person. Our paper aims to comprehensively discuss and compile these diverse methods, providing an understanding of existing techniques for future studies.",Online Social Network (OSN);Generative Adversarial Networks (GAN);Support Vector Machine (SVM);Convolutional Neural Network (CNN);Extreme Gradient Boosting (XGBoost),IEE
836,ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis,Y. He; B. Gan; S. Chen; Y. Zhou; G. Yin; L. Song; L. Sheng; J. Shao; Z. Liu,2021,"The rapid progress of photorealistic synthesis techniques have reached at a critical point where the boundary between real and manipulated images starts to blur. Thus, benchmarking and advancing digital forgery analysis have become a pressing issue. However, existing face forgery datasets either have limited diversity or only support coarse-grained analysis.To counter this emerging threat, we construct the ForgeryNet dataset, an extremely large face forgery dataset with unified annotations in image- and video-level data across four tasks: 1) Image Forgery Classification, including two-way (real/fake), three-way (real/fake with identity-replaced forgery approaches/fake with identity-remained forgery approaches), and n-way (real and 15 respective forgery approaches) classification. 2) Spatial Forgery Localization, which segments the manipulated area of fake images compared to their corresponding real images. 3) Video Forgery Classification, which re-defines the video-level forgery classification with manipulated frames in random positions. This task is important because attackers in real world are free to manipulate any target frame. and 4) Temporal Forgery Localization, to localize the temporal segments which are manipulated. ForgeryNet is by far the largest publicly available deep face forgery dataset in terms of data-scale (2.9 million images, 221,247 videos), manipulations (7 image-level approaches, 8 video-level approaches), perturbations (36 independent and more mixed perturbations) and annotations (6.3 million classification labels, 2.9 million manipulated area annotations and 221,247 temporal forgery segment labels). We perform extensive benchmarking and studies of existing face forensics methods and obtain several valuable observations. We hope that the scale, quality, and variety of our ForgeryNet dataset will foster further research and innovation in the area of face forgery classification, as well as spatial and temporal forgery localization etc.",,IEE
837,An Architecture for the detection of GAN-generated Flood Images with Localization Capabilities,J. Wang; O. Alamayreh; B. Tondi; M. Barni,2022,"In this paper, we address a new image forensics task, namely the detection of fake flood images generated by ClimateGAN architecture. We do so by proposing a hybrid deep learning architecture including both a detection and a localization branch, the latter being devoted to the identification of the image regions manipulated by ClimateGAN. Even if our goal is the detection of fake flood images, in fact, we found that adding a localization branch helps the network to focus on the most relevant image regions with significant improvements in terms of generalization capabilities and robustness against image processing operations. The good performance of the proposed architecture is validated on two datasets of pristine flood images downloaded from the internet and three datasets of fake flood images generated by ClimateGAN starting from a large set of diverse street images.",,IEE
838,Crafting A Panoptic Face Presentation Attack Detector,S. Mehta; A. Uberoi; A. Agarwal; M. Vatsa; R. Singh,2019,"With the advancements in technology and growing popularity of facial photo editing in the social media landscape, tools such as face swapping and face morphing have become increasingly accessible to the general public. It opens up the possibilities for different kinds of face presentation attacks, which can be taken advantage of by impostors to gain unauthorized access of a biometric system. Moreover, the wide availability of 3D printers has caused a shift from print attacks to 3D mask attacks. With increasing types of attacks, it is necessary to come up with a generic and ubiquitous algorithm with a panoptic view of these attacks, and can detect a spoofed image irrespective of the method used. The key contribution of this paper is designing a deep learning based panoptic algorithm for detection of both digital and physical presentation attacks using Cross Asymmetric Loss Function (CALF). The performance is evaluated for digital and physical attacks in three scenarios: ubiquitous environment, individual databases, and cross-attack/cross-database. Experimental results showcase the superior performance of the proposed presentation attack detection algorithm.",,IEE
839,Online Banking User Authentication Methods: A Systematic Literature Review,N. A. Karim; O. A. Khashan; H. Kanaker; W. K. Abdulraheem; M. Alshinwan; A. -K. Al-Banna,2024,"Online banking has become increasingly popular in recent years, making it a target for cyberattacks. Banks have implemented various user authentication methods to protect their customers� online accounts. This paper reviews the state-of-the-art user authentication methods used in online banking and potential cyber threats. This paper starts by exploring different user authentication methods, such as knowledge-based authentication (KBA), biometrics-based authentication (BBA), possession-based authentication (PBA), and other methods. The advantages and disadvantages of each user authentication method are then discussed. Furthermore, the paper discusses the various cyber threats that can compromise user authentication for online banking systems, such as malware attacks, social engineering, phishing attacks, man-in-the-middle (MiTM) attacks, denial of service (DoS) attacks, session hijacking, weak passwords, keyloggers, SQL injection, and replay attacks. Also, the paper explores the user authentication methods used by popular banks, which can provide insights into best practices for safeguarding online banking accounts and future user authentication methods in online banking and cyber threats. It states that the increasing use of BBA, two-factor authentication (2FA), and multi-factor authentication (MFA) will help improve the security of online banking systems. However, the paper also warns that new cyber challenges will emerge, and banks need to be vigilant in protecting their customers� online banking accounts.",User authentication;online banking;cyber threats;2FA;MFA;cyber challenges,IEE
840,Fusion Transformer with Object Mask Guidance for Image Forgery Analysis,D. Karageorgiou; G. Kordopatis-Zilos; S. Papadopoulos,2024,"In this work, we introduce OMG-Fuser, a fusion transformer-based network designed to extract information from various forensic signals to enable robust image forgery detection and localization. Our approach can operate with an arbitrary number of forensic signals and leverages object information for their analysis � unlike previous methods that rely on fusion schemes with few signals and often disregard image semantics. To this end, we design a forensic signal stream composed of a transformer guided by an object attention mechanism, associating patches that depict the same objects. In that way, we incorporate object-level information from the image. Each forensic signal is processed by a different stream that adapts to its peculiarities. A token fusion transformer efficiently aggregates the outputs of an arbitrary number of network streams and generates a fused representation for each image patch. We assess two fusion variants on top of the proposed approach: (i) score-level fusion that fuses the outputs of multiple image forensics algorithms and (ii) feature-level fusion that fuses low-level forensic traces directly. Both variants exceed state-of-the-art performance on seven datasets for image forgery detection and localization, with a relative average improvement of 12.1% and 20.4% in terms of F1. Our model is robust against traditional and novel forgery attacks and can be expanded with new signals without training from scratch. Our code is publicly available at: https://github.com/mever-team/omgfuser",image forensics;forgery detection;forgery localization;deepfake detection;signal fusion,IEE
841,Exposing Deep Fakes Using Inconsistent Head Poses,X. Yang; Y. Li; S. Lyu,2019,"In this paper, we propose a new method to expose AI-generated fake face images or videos (commonly known as the Deep Fakes). Our method is based on the observations that Deep Fakes are created by splicing synthesized face region into the original image, and in doing so, introducing errors that can be revealed when 3D head poses are estimated from the face images. We perform experiments to demonstrate this phenomenon and further develop a classification method based on this cue. Using features based on this cue, an SVM classifier is evaluated using a set of real face images and Deep Fakes.",Media Forensics;DeepFake Detection;Head Pose Estimation,IEE
842,Detection of GAN-Synthesized street videos,O. Alamayreh; M. Barni,2021,"Research on the detection of AI-generated videos has focused almost exclusively on face videos, usually referred to as deepfakes. Manipulations like face swapping, face reenactment and expression manipulation have been the subject of an intense research with the development of a number of efficient tools to distinguish artificial videos from genuine ones. Much less attention has been paid to the detection of artificial non-facial videos. Yet, new tools for the generation of such kind of videos are being developed at a fast pace and will soon reach the quality level of deepfake videos. The goal of this paper is to investigate the detectability of a new kind of AI-generated videos framing driving street sequences (here referred to as DeepStreets videos), which, by their nature, can not be analysed with the same tools used for facial deepfakes. Specifically, we present a simple frame-based detector, achieving very good performance on state-of-the-art DeepStreets videos generated by the Vid2vid architecture. Noticeably, the detector retains very good performance on compressed videos, even when the compression level used during training does not match that used for the test videos.",DeepStreets;DeepFake;GANs;XceptionNet;Vid2vid;Video Forensics,IEE
843,Deepfakes � Reality Under Threat?,M. S. Rana; M. Solaiman; C. Gudla; M. F. Sohan,2024,"In recent years, advances in technology, specifically in machine learning, artificial intelligence, and deep learning, have made it possible to create highly convincing fake videos known as Deepfakes. These videos are produced by training computer models on extensive datasets of faces and then seamlessly blending one person�s facial expressions onto another�s, resulting in videos that are nearly indistinguishable from reality. The widespread use of Deepfakes presents several concerns, including the creation of political distress, the occurrence of fake terrorism events, the undermining of trust in digital media, etc. Therefore, there is an urgent need to continually advance Deepfake detection and prevention methodologies to safeguard against their malevolent use and maintain the integrity of digital content. This paper conducts a meticulous analysis of the current landscape of Deepfake research, surveys the most effective detection solutions, and introduces a real-time Deepfake detection and prevention model within a rigorous testing framework. This model integrates innovative Blockchain and Steganalysis technologies to provide a robust solution to combat the explosion of Deepfakes. Our holistic framework offers a systematic and statistically rigorous approach to distinguishing genuine content from its manipulated counterparts, Deepfakes. By employing the principles of hypothesis testing, and a robust test statistic, our research equips us with the analytical tools necessary to make well-informed and precise classifications, significantly contributing to the ongoing battle against Deepfakes.",Deepfakes;GANs;Hypothesis;Blockchain;Steganalysis,IEE
844,Deepfake Classification For Human Faces using Custom CNN,A. M. Kalemullah; P. P; S. V,2024,"This paper emphasizes the urgent need for effective deepfake classification methods, particularly for human faces, due to the escalating threat of this technology. The research proposes a comprehensive approach using a Convolutional Neural Network (CNN) model and two Transfer Learning models (ResNet-50 and EfficientNet B7) to address this challenge. It investigates the synthesis of realistic-looking facial manipulations and their societal impacts, highlighting the importance of accurate classification in mitigating these effects. The study evaluates and compares the proposed models' accuracy in detecting manipulated facial content, analyzing their strengths and limitations. Overall, the paper provides a timely exploration of deepfake classification, offering practical solutions to enhance digital security and trustworthiness.",Deepfake;Facial Manipulation;Convolution Neural Network;Transfer Learning;Resnet-50 and EfficientNet B7,IEE
845,Cyberattacks Using ChatGPT: Exploring Malicious Content Generation Through Prompt Engineering,L. Alotaibi; S. Seher; N. Mohammad,2024,"The emergence of ChatGPT within the realm of computing has provided considerable advantages to a diverse array of individuals. However, it has also become a tool employed by adversaries to execute cyberattacks. This research paper examines the implementation of prompt engineering as a means to coerce ChatGPT into generating malicious content that deviates from its ethical boundaries. By leveraging these techniques, cybercriminals can effortlessly create a range of attacks, including phishing attempts, creating and propagating malware, backdoor attacks, and impersonation schemes, often in conjunction with deep fakes. To substantiate these cases, we successfully present concrete evidence by prompt engineering, which enabled the production of convincing phishing emails and code snippets for malware generation such as keyloggers. Additionally, we address the pressing concern of defending against these malicious activities, exploring effective approaches such as AI-generated text detection and system vulnerability detection.",AI-Powered Attacks;Backdoor Attacks;ChatGPT;Cyberattacks;Cybercrime;Malware;Prompt Engineering;Phishing Attacks,IEE
846,GAN Latent Space Manipulation Based Augmentation for Unbalanced Emotion Datasets,Y. Xiong; J. You; L. Shen,2023,"Learning with small or highly unbalanced datasets have long been an important area of research in computer vision. Extracting features from these datasets is more difficult and the training process of deep learning models could be hindered. In order to solve this problem many approaches have been proposed, among which data augmentation is widely used since it can balance the dataset by generating new samples for small classes. Current data augmentation methods like image manipulation can only generate samples with low diversity, generative model based methods can not guarantee the quality and distribution of generated images. This paper proposes an offline data augmentation method based on generative adversarial network (GAN) latent space manipulation to create new samples for small classes in unbalanced image datasets. This method helps fill the sparse data manifold of small classes with new samples and can guarantee data quantity, quality, diversity and distribution at the same time. More specifically, we choose the facial expression recognition (FER) task as an example where linear interpolation, combination and concatenation of StyleGAN latent codes are used to generate new samples. We further apply latent space vector arithmetic to perform inter-class translation for different facial expressions. The proposed methods are evaluated through extensive experiments on two different FER databases.",,IEE
847,Detection of AI-Generated Images From Various Generators Using Gated Expert Convolutional Neural Network,R. Ahmad Fattah Saskoro; N. Yudistira; T. Noor Fatyanosa,2024,"The rapid advancement of artificial intelligence (AI), particularly in text-to-image generative models, has led to a proliferation of synthetic images. This progress, while remarkable, raises concerns about misuse in fraudulent activities. To address this issue, we propose a Convolutional Neural Network (CNN)-based approach for classifying AI-generated images from multiple generators. We introduce a gated CNN model that leverages mixed datasets for improved training efficiency and performance. This approach eliminates the need for extensive tuning with each new dataset and mitigates the risk of catastrophic forgetting. Our experiments demonstrate that the gated CNN model slightly outperforms traditional single CNN models, providing a more robust solution for identifying AI-generated images. This paper presents a comprehensive comparison of methods and offers insights into enhancing the classification of AI-generated images.",AI-generated images;CNN;gated network;image classification,IEE
848,A Honey-imprint enabled Approach for Resisting Social Engineering Attacks,Z. Zhong; W. Fan,2023,"In the Reconnaissance step of the Cyber Kill Chain (CKC) model, social engineering (SE) techniques are often used to obtain sensitive/private data. This paper proposes a ""honey-imprint"" enabled approach which takes advantage of Natural Language Processing (NLP) for detecting SE attacks, Generative Adversarial Networks (GAN) for generating decoys from original sensitive information, and steganography for imprinting the honey watermark. The purpose of honey-imprint is to protect the sensitive information in the original file while leaving a covert imprint on the honey file to identify the malicious user. With this, we can further capture malicious interactions (using honey-imprinted data) by the honeypot system. We implement a prototype to verify the design, and the experimental results show that the method is valid and effective.",Social Engineering;NLP;GAN;Steganography;Honeypot;Deceptive Defense,IEE
849,On the Detection of Digital Face Manipulation,H. Dang; F. Liu; J. Stehouwer; X. Liu; A. K. Jain,2020,"Detecting manipulated facial images and videos is an increasingly important topic in digital media forensics. As advanced face synthesis and manipulation methods are made available, new types of fake face representations are being created which have raised significant concerns for their use in social media. Hence, it is crucial to detect manipulated face images and localize manipulated regions. Instead of simply using multi-task learning to simultaneously detect manipulated images and predict the manipulated mask (regions), we propose to utilize an attention mechanism to process and improve the feature maps for the classification task. The learned attention maps highlight the informative regions to further improve the binary classification (genuine face v. fake face), and also visualize the manipulated regions. To enable our study of manipulated face detection and localization, we collect a large-scale database that contains numerous types of facial forgeries. With this dataset, we perform a thorough analysis of data-driven fake face detection. We show that the use of an attention mechanism improves facial forgery detection and manipulated region localization.",,IEE
850,A Quantitative Evaluation Framework of Video De-Identification Methods,S. Bursic; A. D'Amelio; M. Granato; G. Grossi; R. Lanzarotti,2021,"We live in an era of privacy concerns, motivating a large research effort in face de-identification. As in other fields, we are observing a general movement from hand-crafted to deep learning methods, mainly involving generative models. Although these methods produce more natural de-identified images or videos, we claim that the mere evaluation of the de-identification is not sufficient, especially when it comes to processing the images/videos further. In this note, we take into account the issue of preserving privacy, facial expressions, and photo-reality simultaneously, proposing a general testing framework. The quantitative evaluation is applied to four open-source tools, producing a baseline for future de-identification methods.",,IEE
851,Deepfakes Signatures Detection in the Handcrafted Features Space,A. Hamadene; A. Ouahabi; A. Hadid,2023,"In the Handwritten Signature Verification (HSV) literature, several synthetic databases have been developed for data-augmentation purposes, where new specimens and new identities were generated using bio-inspired algorithms, neuromotor synthesizers, Generative Adversarial Networks (GANs) as well as several deep learning methods. These synthetic databases contain synthetic genuine and forgeries specimens which are used to train and build signature verification systems. Researches on generative data assume that synthetic data are as close as possible to real data, this is why, they are either used for training systems when used for data augmentation tasks or are used to fake systems as synthetic attacks. It is worth, however, to point out the existence of a relationship between the handwritten signature authenticity and human behavior and brain. Indeed, a genuine signature is characterised by specific features that are related to the owner�s personality. The fact which makes signature verification and authentication achievable. Handcrafted features had demonstrated a high capacity to capture personal traits for authenticating real static signatures. We, therefore, Propose in this paper, a handcrafted feature based Writer-Independent (WI) signature verification system to detect synthetic writers and signatures through handcrafted features. We also aim to assess how realistic are synthetic signatures as well as their impact on HSV system�s performances. Obtained results using 4000 synthetic writers of GPDS synthetic database show that the proposed handcrafted features have considerable ability to detect synthetic signatures vs. two widely used real individuals signatures databases, namely CEDAR and GPDS-300, which reach 98.67% and 94.05% of successful synthetic detection rates respectively.",,IEE
852,Multimodal Forgery Detection Using Ensemble Learning,A. Hashmi; S. A. Shahzad; W. Ahmad; C. W. Lin; Y. Tsao; H. -M. Wang,2022,"The recent rapid revolution in Artificial Intelligence (AI) technology has enabled the creation of hyper-realistic deepfakes, and detecting deepfake videos (also known as AI-synthesized videos) has become a critical task. The existing systems generally do not fully consider the unified processing of audio and video data, so there is still room for further improvement. In this paper, we focus on the multimodal forgery detection task and propose a deep forgery detection method based on audiovisual ensemble learning. The proposed method consists of four parts, namely a Video Network, an Audio Network, an Audiovisual Network, and a Voting Module. Given a video, the proposed multimodal and ensemble learning system can identify whether it is fake or real. Experimental results on a recently released multimodal FakeAVCeleb dataset show that the proposed method achieves 89% accuracy, significantly outperforming existing models.",,IEE
853,De-identifying Face Image Datasets While Retaining Facial Expressions,A. Leibl; A. Mei�ner; S. Altmann; A. Attenberger; H. Mayer,2023,"Progress in computer vision, particularly based on machine learning, depends heavily on the availability of appropriate datasets. However, for applications like face recognition or emotion detection, this requires the collection of face images, which comprise especially privacy-sensitive biometric data. The corresponding valid ethical concerns and legal regulations regarding privacy rights limit the creation of new datasets. To reconcile the need for detailed facial image datasets with the right to privacy protection, appropriate anonymization techniques are needed. To this end, we suggest a pipeline to repurpose a face swapping tool for de-identification by combining it with synthetic image generation and a novel procedure to select source images to improve the trade-off between data utility retention and privacy enhancement. A quantitative comparison of our results to other de-identification approaches shows that our method leads to better retention of facial expressions while providing adequate privacy protection. Thus, applying this procedure to face image datasets before publication could help mitigate privacy concerns.",,IEE
854,Spoof Trace Disentanglement for Generic Face Anti-Spoofing,Y. Liu; X. Liu,2023,"Prior studies show that the key to face anti-spoofing lies in the subtle image patterns, termed �spoof trace,� e.g., color distortion, 3D mask edge, and Moir� pattern. Spoof detection rooted on those spoof traces can improve not only the model's generalization but also the interpretability. Yet, it is a challenging task due to the diversity of spoof attacks and the lack of ground truth for spoof traces. In this work, we propose a novel adversarial learning framework to explicitly estimate the spoof related patterns for face anti-spoofing. Inspired by the physical process, spoof faces are disentangled into spoof traces and the live counterparts in two steps: additive step and inpainting step. This two-step modeling can effectively narrow down the searching space for adversarial learning of spoof trace. Based on the trace modeling, the disentangled spoof traces can be utilized to reversely construct new spoof faces, which is used as data augmentation to effectively tackle long-tail spoof types. In addition, we apply frequency-based image decomposition in both the input and disentangled traces to better reflect the low-level vision cues. Our approach demonstrates superior spoof detection performance on 3 testing scenarios: known attacks, unknown attacks, and open-set attacks. Meanwhile, it provides a visually-convincing estimation of the spoof traces. Source code and pre-trained models will be publicly available upon publication.",Deep learning;face anti-spoofing;low-level vision;spoof traces;synthesis;weak supervision,IEE
855,Classifying Genuine Face images from Disguised Face Images,J. Kim; S. Han; S. S.Woo,2019,"Detecting fake or disguised face images become much more challenging due to the significant advancements made in machine learning, computer vision, and image processing techniques. In addition, due to the rise of various DeepFakes, fake images can be maliciously used to attack individuals and deter true information. Therefore, it is crucial to building a classifier that accurately distinguishes an individual from different or similar persons. In this preliminary work, we aim to detect a target person's face from different similar individuals, Doppelgangers, leveraging the dataset from Disguised Faces in the Wild (DFW) 2018. We use well-known off-the-shelf face detection classifiers, such as ShallowNet, VGG-16, and Xception to evaluate the classification performance. In order to further improve the detection performance, we apply data augmentation. Our preliminary result shows that the Xception model can classify one from different individuals with a 62% accuracy.",DeepFakes;Fake Image Detection;Doppelganger;Disguised Face in the Wild (DFW),IEE
856,The societal impact of Deepfakes: Advances in Detection and Mitigation,A. Kaushal; A. Mina; A. Meena; T. H. Babu,2023,"This comprehensive survey paper examines the current state of deepfake detection techniques, analyzing their strengths, weaknesses, and limitations, as well as their effectiveness in detecting different types of deepfakes. We also analyze the evolution of deepfake detection techniques over time and discuss future research directions. By providing a thorough examination of the existing literature, this paper aims to assist researchers, practitioners, and policymakers in understanding the current landscape of deepfake detection and identifying areas for future development.",Deepfakes;Media Manipulation;Artificial Intelligence;Machine Learning;Cybersecurity,IEE
857,Exposing Deepfake Frames through Spectral Analysis of Color Channels in Frequency Domain,M. A. Amin; Y. Hu; H. She; J. Li; Y. Guan; M. Z. Amin,2023,"Highly realistic deepfakes are generated by employing generative neural networks, even to the point that it is difficult for humans to tell them apart from the real ones. Nowadays they are one of the causes of misrepresentation or misinformation regarding different subjects. The detection of deepfake content is very important. It can be analyzed in different domains, such as spatial domain and frequency domain, or by employing combinations of them. In this work, we first took inspiration from traditional image forensics and performed a comprehensive frequency spectrum analysis on the deepfake frames and their context color channels to detect spectral anomalies and statistical features. We then use the frequency spectrum statistical features to distinguish between pristine and deepfake content using both unsupervised and supervised learning approaches. Finally, we scrutinize the trained deepfake detection models� generalization capability from the perspective of suggested statistical features across different deepfake datasets and methods. Our analysis demonstrated the effectiveness of statistical features by identifying real and deepfake content with high accuracy, surpassing the performance of several state-of-the-art methods.",Deepfakes;Statistical Features;Spectrum Analysis;Image Forensics;Generalization Capability,IEE
858,IID-Net: Image Inpainting Detection Network via Neural Architecture Search and Attention,H. Wu; J. Zhou,2022,"Deep learning (DL) has demonstrated its powerful capabilities in the field of image inpainting, which could produce visually plausible results. Meanwhile, the malicious use of advanced image inpainting tools (e.g. removing key objects to report fake news, erasing visible copyright watermarks, etc.) has led to increasing threats to the reliability of image data. To fight against the inpainting forgeries (not only DL-based but also traditional ones), in this work, we propose a novel end-to-end Image Inpainting Detection Network (IID-Net), to detect the inpainted regions at pixel accuracy. The proposed IID-Net consists of three sub-blocks: the enhancement block, the extraction block and the decision block. Specifically, the enhancement block aims to enhance the inpainting traces by using hierarchically combined special layers. The extraction block, automatically designed by Neural Architecture Search (NAS) algorithm, is targeted to extract features for the actual inpainting detection tasks. To further optimize the extracted latent features, we integrate global and local attention modules in the decision block, where the global attention reduces the intra-class differences by measuring the similarity of global features, while the local attention strengthens the consistency of local features. Furthermore, we thoroughly study the generalizability of our IID-Net, and find that different training data could result in vastly different generalization capability. By carefully examining 10 popular inpainting methods, we identify that the IID-Net trained on only one specific deep inpainting method exhibits desirable generalizability; namely, the obtained IID-Net can accurately detect and localize inpainting manipulations for various unseen inpainting methods as well. Extensive experimental results are presented to validate the superiority of the proposed IID-Net, compared with the state-of-the-art competitors. Our results would suggest that common artifacts are shared across diverse image inpainting methods. Finally, we build a public inpainting dataset of 10K image pairs for future research in this area.",Inpainting forensics;generalizability;deep neural networks,IEE
859,Neural Emotion Director: Speech-preserving semantic control of facial expressions in �in-the-wild� videos,F. P. Papantoniou; P. P. Filntisis; P. Maragos; A. Roussos,2022,"In this paper, we introduce a novel deep learning method for photo-realistic manipulation of the emotional state of actors in �in-the-wild� videos. The proposed method is based on a parametric 3D face representation of the actor in the input scene that offers a reliable disentanglement of the facial identity from the head pose and facial expressions. It then uses a novel deep domain translation framework that alters the facial expressions in a consistent and plausible manner, taking into account their dynamics. Finally, the altered facial expressions are used to photo-realistically manipulate the facial region in the input scene based on an especially-designed neural face renderer. To the best of our knowledge, our method is the first to be capable of controlling the actor's facial expressions by even using as a sole input the semantic labels of the manipulated emotions, while at the same time preserving the speech-related lip movements. We conduct extensive qualitative and quantitative evaluations and comparisons, which demonstrate the effectiveness of our approach and the especially promising results that we obtain. Our method opens a plethora of new possibilities for useful applications of neural rendering technologies, ranging from movie post-production and video games to photo-realistic affective avatars.",Image and video synthesis and generation; Face and gestures; Vision + graphics,IEE
860,ManTra-Net: Manipulation Tracing Network for Detection and Localization of Image Forgeries With Anomalous Features,Y. Wu; W. AbdAlmageed; P. Natarajan,2019,"To fight against real-life image forgery, which commonly involves different types and combined manipulations, we propose a unified deep neural architecture called ManTraNet. Unlike many existing solutions, ManTra-Net is an end-to-end network that performs both detection and localization without extra preprocessing and postprocessing. ManTra-Net is a fully convolutional network and handles images of arbitrary sizes and many known forgery types such splicing, copy-move, removal, enhancement, and even unknown types. This paper has three salient contributions. We design a simple yet effective self-supervised learning task to learn robust image manipulation traces from classifying 385 image manipulation types. Further, we formulate the forgery localization problem as a local anomaly detection problem, design a Z-score feature to capture local anomaly, and propose a novel long short-term memory solution to assess local anomalies. Finally, we carefully conduct ablation experiments to systematically optimize the proposed network design. Our extensive experimental results demonstrate the generalizability, robustness and superiority of ManTra-Net, not only in single types of manipulations/forgeries, but also in their complicated combinations.",Segmentation;Grouping and Shape;Computational Photography; Deep Learning ; Image and Video Synthesis; Statistical Learning; Vision A,IEE
861,Detect and Locate: Exposing Face Manipulation by Semantic- and Noise-Level Telltales,C. Kong; B. Chen; H. Li; S. Wang; A. Rocha; S. Kwong,2022,"The technological advancements of deep learning have enabled sophisticated face manipulation schemes, raising severe trust issues and security concerns in modern society. Generally speaking, detecting manipulated faces and locating the potentially altered regions are challenging tasks. Herein, we propose a conceptually simple but effective method to efficiently detect forged faces in an image while simultaneously locating the manipulated regions. The proposed scheme relies on a segmentation map that delivers meaningful high-level semantic information clues about the image. Furthermore, a noise map is estimated, playing a complementary role in capturing low-level clues and subsequently empowering decision-making. Finally, the features from these two modules are combined to distinguish fake faces. Extensive experiments show that the proposed model achieves state-of-the-art detection accuracy and remarkable localization performance.",Face forensics;face forgery detection;face manipulation localization,IEE
862,AUNet: Learning Relations Between Action Units for Face Forgery Detection,W. Bai; Y. Liu; Z. Zhang; B. Li; W. Hu,2023,"Face forgery detection becomes increasingly crucial due to the serious security issues caused by face manipulation techniques. Recent studies in deepfake detection have yielded promising results when the training and testing face forgeries are from the same domain. However, the problem remains challenging when one tries to generalize the detector to forgeries created by unseen methods during training. Observing that face manipulation may alter the relation between different facial action units (AU), we propose the Action-Units Relation Learning framework to improve the generality of forgery detection. In specific, it consists of the Action Units Relation Transformer (ART) and the Tampered AU Prediction (TAP). The ART constructs the relation between different AUs with AU-agnostic Branch and AU-specific Branch, which complement each other and work together to exploit forgery clues. In the Tampered AU Prediction, we tamper AU-related regions at the image level and develop challenging pseudo samples at the feature level. The model is then trained to predict the tampered AU regions with the generated location-specific supervision. Experimental results demonstrate that our method can achieve state-of-the-art performance in both the in-dataset and cross-dataset evaluations.",Humans: Face;body;pose;gesture;movement,IEE
863,Defending against GAN-based DeepFake Attacks via Transformation-aware Adversarial Faces,C. Yang; L. Ding; Y. Chen; H. Li,2021,"DeepFake represents a category of face-swapping attacks that leverage machine learning models such as autoen-coders or generative adversarial networks. Although the concept of the face-swapping is not new, its recent technical advances make fake content (e.g., images, videos) imperceptible to Humans. Various detection techniques for DeepFake attacks have been explored. These methods, however, are passive measures against DeepFakes as they are mitigation strategies after the high-quality fake content is generated. This work aims to take an offensive measure to impede the generation of high-quality fake images or videos. Specifically, we propose to use novel transformation-aware adversarially perturbed faces as a defense against GAN-based DeepFake attacks, which leverages differentiable random image transformations during the generation. We also propose an ensemble-based approach to enhance the defense robustness against GAN-based DeepFake variants under the black-box setting. We show that training a DeepFake model with adversarial faces can lead to a significant degradation in the quality of synthesized faces.",,IEE
864,A Multimodal Misinformation Detector for COVID-19 Short Videos on TikTok,L. Shang; Z. Kou; Y. Zhang; D. Wang,2021,"This paper studies an emerging and important problem of identifying misleading COVID-19 short videos where the misleading content is jointly expressed in the visual, audio, and textual content of videos. Existing solutions for misleading video detection mainly focus on the authenticity of videos or audios against AI algorithms (e.g., deepfake) or video manipulation, and are insufficient to address our problem where most videos are user-generated and intentionally edited. Two critical challenges exist in solving our problem: i) how to effectively extract information from the distractive and manipulated visual content in TikTok videos? ii) How to efficiently aggregate heterogeneous information across different modalities in short videos? To address the above challenges, we develop TikTec, a multimodal misinformation detection framework that explicitly exploits the captions to accurately capture the key information from the distractive video content, and effectively learns the composed misinformation that is jointly conveyed by the visual and audio content. We evaluate TikTec on a real-world COVID- 19 video dataset collected from TikTok. Evaluation results show that TikTec achieves significant performance gains compared to state-of-the-art baselines in accurately detecting misleading COVID-19 short videos.",,IEE
865,MirageNet - Towards a GAN-based Framework for Synthetic Network Traffic Generation,S. K. Nukavarapu; M. Ayyat; T. Nadeem,2022,"With the emergence of machine learning technology that supports the development of synthetic models, many new use cases and challenges are emerging in the fields of computer vision and security. The main model behind this technology is Generative Adversarial Networks (GANs), with their ability to model unknown distributions accurately and perform well in generating synthetic data such as images and videos. However, the application of this technology by the networking community has been lacking. Given this motivation, we introduce MirageNet; our vision for a GAN-based synthetic network traffic generation framework, which can automatically create synthetic network models of protocols, applications, and devices. With the potential to build many applications for privacy, security, and network optimization. In this paper, we present MiragePkt; the first component of MirageNet. It is a GAN-based model to synthetically generate network packets. We describe the different challenges, limitations, and solutions for generating synthetic network packets. Finally, we validate and evaluate the performance of our framework with the synthesizing DNS packets.",,IEE
866,Real-Time Face Swapping System using OpenCV,A. Datta; O. K. Yadav; Y. Singh; S. S; K. M; S. E,2021,"Face swapping has been a thriving genre of work which primarily is associated with the replacement or substitution of one referral face on the face of the other person, be it by means of still images or in real time. This paper exhibits the research on Real-Time Face Swapping algorithm, using the reference image of the user and henceforth considering it as our input image instead of using a data set thereby working on a real time model by the use of the python open-source model of Computer Vision i.e., OpenCV. The input image facial features and attributes are extracted and are replaced to make the final resulting output through our model. The training of the model starts with learning the facial alignments and features to be able to recognize a face and extract its features before swapping it. Now, heading over to the process of image warping by the dissociation and partitioning of the user's face and its background. To increase the precision of the model, in the second part of parsing the face is performed to cancel out other features of the live image, hence the output is obtained. In this research, it was tried to bring accuracy and precision to the model by improving the condition of the image, editing out borders, and training it to a bunch of data for face recognition and correction. On analyzing it delivers the most subtle outputs alongside performing the tasks with the process including the analysis of our image and its output too. The model delivered is to improve the conditions of security, privacy, image capture, and entertainment purposes.",Face Swapping;Real time system;Computer Vision;Face arrangement;Face substitution;Masking;Warping,IEE
867,Voice Reenactment with F0 and timing constraints and adversarial learning of conversions,F. Bous; L. Benaroya; N. Obin; A. Roebel,2022,"This paper introduces voice reenactement as the task of voice conversion (VC) in which the expressivity of the source speaker is preserved during conversion while the identity of a target speaker is transferred. To do so, an original neural-VC architecture is proposed based on sequence-to-sequence voice conversion (S2S-VC) in which the speech prosody of the source speaker is preserved during conversion. First, the S2S-VC architecture is modified to synchronize the converted speech with the source speech by phonetic duration encoding; second, the decoder is conditioned on the desired sequence of F0- values and an explicit F0-loss is formulated between the F0 of the source speaker and the F0 of the converted speech. Finally, adversarial learning of conversion is integrated within the S2S-VC architecture to exploit advantages of both reconstruction of original speech with ground truth and converted speech with manipulated attributes. An experimental evaluation on the VCTK speech database shows that the speech prosody can be efficiently preserved during conversion, and that the proposed adversarial learning consistently improves the conversion and the naturalness of the reenacted speech.",Voice conversion;voice reenactement;prosody preservation,IEE
868,Detection of Diffusion Model-Generated Faces by Assessing Smoothness and Noise Tolerance,B. Liu; B. Liu; M. Ding; T. Zhu,2024,"The fast growth of artificial intelligence (AI) raises much concern about the misinformation brought by AI-generated content (AIGC), especially Deepfake techniques that generate fake human faces. The recent development of Diffusion Models (DMs) moves another critical step forward to generate high-resolution and realistic human faces, which has become a challenge for existing Deepfake detectors. In this paper, we propose a DM-generated image detector by looking into the generation pipeline of DMs and the details of DM-generated images. The detector is based on the observation that DM-generated human faces show over-smooth textures and do not contain details as real human faces. Through a comprehensive analysis of DM-generated faces in spatial and frequency domains, we noticed that the over-smoothness improves the tolerance of Gaussian noise since excessive smoothness mitigates some of the impact of noise. Inspired by the observations, we propose a Deepfake detector capable of recognizing challenging DM-generated faces. We mainly propose the Noise Residual Unit (NRD) in our framework to collect the frequency response of images to Gaussian noise as distinctive features for classification. In detail, for an input face image, we add Gaussian noise to it and get the noise-degraded image. Then, the NRU generates the Noise Residual Image (NRI) by calculating the residual of the high-pass-filtered original image and the high-pass-filtered degraded image. The NRI indicates the high-frequency impact brought by the Gaussian noise and, therefore, suggests the tolerance of the original image to noise degradation. The original image and NRI are encoded and fused to obtain the joint representation, which is then fed to a classifier to predict the binary label. We conducted comprehensive experiments to evaluate the effectiveness of the proposed detector. The results indicate that our proposed detector achieves state-of-the-art detection performance on DM-generated faces and generalizes well to unseen DM-generated and GAN-generated face datasets.",Deepfake detection;diffusion models;frequency analysis,IEE
869,Leveraging Knowledge Graphs for CheapFakes Detection: Beyond Dataset Evaluation,M. -S. Dao; K. Zettsu,2023,"The proliferation of the internet and the availability of vast amounts of information have given rise to a critical and pressing issue of fake news. Among the various forms of fake news, cheapfakes are particularly prominent in deceiving people. Existing research on cheapfakes detection has primarily focused on analyzing the context and correlation between textual and visual information, but has largely overlooked the significance of external knowledge. As a result, most previous approaches, apart from the baseline of ICME�23 Grand Challenge on Detecting Cheapfakes, have heavily relied on evaluating the dataset itself to improve performance. However, despite achieving impressive results on public test datasets, these approaches often suffer from poor performance in real-world scenarios due to their overreliance on the given dataset. In this study, we propose a novel approach that utilizes knowledge graphs to address the issue of insufficient information from external knowledge. Unlike previous approaches, our proposal does not directly alter or participate in the public test dataset to enhance performance, which can potentially result in significant overfitting. Our proposed approach achieved an accuracy score of 83.52% on Task 1, surpassing the baseline by 1.7%, and an accuracy score of 84% on Task 2, outperforming the best result from the previous challenge by 8%.",Deep Learning;Computer Vision;Natural Language Processing;Knowledge Graph;Cheapfakes;Misinformation;News,IEE
870,A Multi-Factor Combinations Enhanced Reversible Privacy Protection System for Facial Images,Y. -L. Pan; J. -C. Chen; J. -L. Wu,2021,"With the abuse of deepfake and other deep learning technologies, anonymization and deanonymization for face images have become one of the essential tasks for privacy protection. Thus, we propose a novel reversible privacy protection framework for facial images based on conditional encoder and de-coder framework. For the purpose to increase the diversity and controllability over the anonymized faces, we also introduce facial attributes and a style vector from a reference back-ground face dataset and pretrained face recognition model and thus name the proposed framework as the Multi-factor Modifier (MfM) to achieve multi-factor facial de/re-identification. Specifically, with the correct password, our method produces near-original reconstructed images. Otherwise, it can generate photo-realistic and diverse anonymized images. With extensive experiments, it shows that the proposed approach can successfully anonymize face images in high fidelity according to the given conditions as compared with other methods and deanonymize without altering the facial data distributions.",Privacy protection;Generative Adversarial Network;and de/re-identification,IEE
871,A Representative Study on Human Detection of Artificially Generated Media Across Countries,J. Frank; F. Herbert; J. Ricker; L. Sch�nherr; T. Eisenhofer; A. Fischer; M. D�rmuth; T. Holz,2024,"AI-generated media has become a threat to our digital society as we know it. Forgeries can be created automatically and on a large scale based on publicly available technologies. Recognizing this challenge, academics and practitioners have proposed a multitude of automatic detection strategies to detect such artificial media. However, in contrast to these technological advances, the human perception of generated media has not been thoroughly studied yet.In this paper, we aim to close this research gap. We conduct the first comprehensive survey on people�s ability to detect generated media, spanning three countries (USA, Germany, and China), with 3,002 participants covering audio, image, and text media. Our results indicate that state-of-the-art forgeries are almost indistinguishable from ""real"" media, with the majority of participants simply guessing when asked to rate them as human- or machine-generated. In addition, AI-generated media is rated as more likely to be human-generated across all media types and all countries. To further understand which factors influence people�s ability to detect AI-generated media, we include personal variables, chosen based on a literature review in the domains of deepfake and fake news research. In a regression analysis, we found that generalized trust, cognitive reflection, and self-reported familiarity with deepfakes significantly influence participants� decisions across all media categories.",,IEE
872,Enhanced Generation of Gastrointestinal Images for Data Augmentation Using a Modified BlobGAN,A. Ayubi; N. P. Utama,2024,"The advent of artificial intelligence (AI) and deep learning has revolutionized healthcare, particularly in the realm of medical imaging, patient care, and personalized treatments. However, the emergence of deepfake technology, while offering promising opportunities, also presents unique challenges. Generative adversarial networks (GANs) can produce highly realistic synthetic medical images (deepfakes) with potential applications in tasks like segmentation and detection. This study leverages a modified BlobGAN architecture, incorporating a self-attention block, to generate enhanced gastrointestinal images. We trained and validated our model on the Kvasir dataset, a comprehensive repository of endoscopic images. Our modifications aim to address the limitations of current deep learning models by producing synthetic images of exceptional quality that closely resemble real gastrointestinal images. Results demonstrate a lowest Fr�chet Inception Distance (FID) of 15.552 and a highest Inception Score (IS) of 6.951, indicating the high fidelity of our generated images. By generating synthetic data that mirrors actual medical images, this research contributes to overcoming challenges of limited data availability and privacy concerns in the field of AI for healthcare. Ultimately, our approach has the potential to expand training datasets and improve the performance of automated classification systems.",Generative Adversarial Networks;BlobGAN;Gastrointestinal Imaging;Synthetic Images;Data Augmentation;Kvasir Dataset;Self-Attention Block,IEE
873,A Multi-Layer Capsule-based Forensics Model for Fake Detection of Digital Visual Media,S. S. Khalil; S. M. Youssef; S. N. Saleh,2021,"The dangers generated from synthesized multimedia are increasing every day. The creation of the so-called Deepfakes multimedia is vastly evolving, making the detection task harder every day. Researchers and corporations are interested in exploring the technology limits and are coming up with new tools every year to create more robust fake media. In this paper, a new enhanced fake video detection model is introduced addressing many of the face-swapping threats and the low generalization problem. A preprocessing stage is proposed to minimize the noise in the data to enhance their quality. The proposed architecture uses a modified application of capsule neural networks (CapsNet) with an enhanced routing technique. It does not require a lot of training data and generates a small number of training parameters making it fast to build. The model was trained and tested using the DFDC-P dataset and the results have proven that it outperformed other detectors in terms of detection recall, weighted precision, and F1 score.",deepfake detection;capsule network;capsnet,IEE
874,Detecting Synthetic Speech Manipulation in Real Audio Recordings,M. Hafizur Rahman; M. Graciarena; D. Castan; C. Cobo-Kroenke; M. McLaren; A. Lawson,2022,"Recent advances in artificial speech and audio technologies have improved the abilities of deep-fake operators to falsify media and spread malicious misinformation. Anyone with limited coding skills can use freely available speech synthesis tools to create convincing simulations of influential speakers� voices with the malicious intent to distort the original message. With the latest technology, malicious operators do not have to generate an entire audio clip; instead, they can insert a partial manipulation or a segment of synthetic speech into a genuine audio recording to change the entire context and meaning of the original message. Detecting these insertions is especially challenging because partially manipulated audio can more easily avoid synthetic speech detectors than entirely fake messages can. This paper describes a potential synthetic speech detection system based on the x-ResNet architecture with a probabilistic linear discriminant analysis (PLDA) backend. Experimental results suggest that the PLDA backend results in a 25% average error reduction among partially synthesized datasets over a non-PLDA baseline.",partial synthetic speech;synthetic speech detection;anti-spoof;x-ResNet;PLDA,IEE
875,"Deepfakes: A Review on Technologies, Applications and Strategies",K. S. Kaswan; K. Malik; J. S. Dhatterwal; M. S. Naruka; D. Govardhan,2023,"Deepfakes are artificial intelligence-generated multimedia, primarily videos or audio, that effectively edit or invent information by superimposing one person's likeness or voice onto that of another. They use deep learning techniques such as GAN s to generate hyper-realistic simulations that blur the line between reality and fiction. Deepfakes encompass everything from political satire to possible concerns in the fields of disinformation, privacy invasion, and cybersecurity. Understanding deepfakes is critical in an age when manipulated media may influence public opinion and undermine confidence. The primary objective of this paper is to provide a holistic overview of deepfake technology, shedding light on both its creative potential and inherent risks. Through a systematic exploration of the evolution, applications, techniques, and detection strategies, we aim to equip readers with an informed perspective on this ever-evolving field. By synthesizing existing knowledge and insights, this paper intends to contribute to the ongoing discourse surrounding deepfakes, enabling stakeholders to make informed decisions, develop effective countermeasures, and anticipate the future trajectory of this technology. Ultimately, our work strives to foster awareness and preparedness in an age where discerning the truth has never been more vital.",Deepfakes;GAN;RNN;CNN;Machine Learning;AI,IEE
876,Technological Innovations for Tackling Domestic Violence,A. Z. Kouzani,2023,"Domestic violence is an issue of great importance that exceeds socioeconomic backgrounds and cultural boundaries. It stems from factors such as power struggle, mental health issue, financial hardship, substance abuse, among others. Technology can play a vital role in not only detecting and mitigating instances of domestic violence, but also providing essential support and resources to its victims. This review paper examines the latest technological innovations for tackling domestic violence. It describes a range of technology platforms and tools, and discusses their capabilities and shortcomings. Firstly, the review methodology is given including the aims and objectives of the review, the search strategy, and the selection of sources. Next, the technological innovations in the context of domestic violence are defined. Then, the paper presents the technological approaches developed to tackle domestic violence through: (i) analysis of data shared through digital platforms, (ii) analysis of data captured by ambient sensors, (iii) analysis of data collected by smartphones, (iv) analysis of data obtained by wearable sensors, (v) protection of online activities, (vi) prevention of non-contact harassment, (vii) deployment of anti-stalking and anti-monitoring measures, and (viii) use of virtual reality techniques. Next, discussions on the capabilities and applications of these technological innovations across different aspects of domestic violence are presented. The paper also addresses the challenges and limitations associated with these innovations, and gives future directions and recommendations for further research and development.",Artificial intelligence;audio;detection;digital platforms;domestic violence;image;intervention;intimate partner violence;mobile applications;prevention;sensors;technology;video;virtual reality;wearable devices,IEE
877,An End to End Solution For Automated Hiring,Y. Chaudhari; P. Jadhav; Y. Gupta,2022,"Automation enables organizations to manage complicated workloads and processes with ease which increases efficiency and saves time. One such tool is automated hiring which accelerates the process by eliminating the requirement for the recruiter to be present in person. This study proposes an innovative approach that includes all steps of a standard interview with proper monitoring, providing the candidate with an experience similar to a true face-to-face interview while ensuring no cheating occurs. The resume short lister uses natural language processing (NLP) to rate resumes based on job requirements and stores candidate data in a database for future communication. The interview bot uses deepfake technology to provide the user with a realistic experience. Using similarity metrics, questions are asked based on data retrieved from the resume as well as user responses to prior questions. The software would finally analyze the data collected to determine the right choice for the position offered. The entire procedure is monitored by extracting information from the camera during the interview to prevent cheating, and the candidate is disqualified in case of any malpractice.",Natural language processing;recommendation systems;similarity;resume analysis;automated hiring;computer vision;deepfakes,IEE
878,A Dataless FaceSwap Detection Approach Using Synthetic Images,A. Jain; N. Memon; J. Togelius,2022,"Face swapping technology used to create �Deepfakes� has advanced significantly over the past few years and now enables us to create realistic facial manipulations. Current deep learning algorithms to detect deepfakes have shown promising results, however, they require large amounts of training data, and as we show they are biased towards a particular ethnicity. We propose a deepfake detection methodology that eliminates the need for any real data by making use of synthetically generated data using Style-GAN3. This not only performs at par with the traditional training methodology of using real data but it shows better generalization capabilities when finetuned with a small amount of real data. Furthermore, this also reduces biases created by facial image datasets that might have sparse data from particular ethnicities. To promote reproducibility the code base has been made publicly available 11https://github.com/anubhav1997/youneednodataset",,IEE
879,Exploring Adversarial Fake Images on Face Manifold,D. Li; W. Wang; H. Fan; J. Dong,2021,"Images synthesized by powerful generative adversarial network (GAN) based methods have drawn moral and privacy concerns. Although image forensic models have reached great performance in detecting fake images from real ones, these models can be easily fooled with a simple adversarial attack. But, the noise adding adversarial samples are also arousing suspicion. In this paper, instead of adding adversarial noise, we optimally search adversarial points on face manifold to generate anti-forensic fake face images. We iteratively do a gradient-descent with each small step in the latent space of a generative model, e.g. Style-GAN, to find an adversarial latent vector, which is similar to norm-based adversarial attack but in latent space. Then, the generated fake images driven by the adversarial latent vectors with the help of GANs can defeat main-stream forensic models. For examples, they make the accuracy of deepfake detection models based on Xception or EfficientNet drop from over 90% to nearly 0%, mean-while maintaining high visual quality. In addition, we find manipulating noise vectors n at different levels have different impacts on attack success rate, and the generated adversarial images mainly have changes on facial texture or face attributes.",,IEE
880,DFP-Net: An explainable and trustworthy framework for detecting deepfakes using interpretable prototypes,F. Khalid; A. Javed; K. M. Malik; A. Irtaza,2023,"The rise of deepfake videos poses a serious threat to the authenticity of visual media, as they have a potential to manipulate public opinion, mislead individuals or groups, harm reputation, etc. Traditional methods for detecting deepfakes rely on deep learning models, which lack transparency and interpretability. To gain the confidence of forensic experts in AI-based deepfakes detector, we present a novel DFP-Net for detecting deepfakes using interpretable and explainable prototypes. Our method makes use of the power of prototype-based learning to generate a set of representative images that capture the essential features of genuine and deepfake images. These prototypes are then used to explain our model�s decision-making process and to provide insights into the features most relevant for deepfake detection. We then use these prototypes to train a classification model that can detect deepfakes accurately and with high interpretability. To further improve the interpretability of our method, we also utilize the Grad-CAM technique to generate heatmaps that highlight the regions of the image that contribute the most towards the decision of the model. These heatmaps can be used to explain the reasoning behind the model�s decision and provide insights into the visual cues that distinguish deepfakes from real images. Experimental results on a large-scale FaceForensics++, Celeb-DF and DFDC-P datasets demonstrate that our method achieves state-of-the-art performance in deepfakes detection. Moreover, the interpretability and explainability of our method make it more trustworthy to forensic experts by allowing them to understand how the model works and makes predictions.",Deepfakes detection;DFP-Net;Interpretable prototypes;Explainable AI;FaceForensics++,IEE
881,A Study on Analyzing Deepfake through various Facial Regions- A Review,A. Khatri; N. Gupta,2023,"In today's scenario, Deepfakes images and videos are being spread globally in social media websites like facebook, twitter and instagram to divert the mindset of people and frame the particular opinion. Many android applications like Faceapp are using Generative Adversarial Network (GAN) to imitate realistic images. Moreover, some free deepfake android app such as Zao, The Chinese app that help users to interchange faces in an easy manner with well-known personalities of the film industry so they can look as if they are being casted for the role in the movie, There are great requirements for detecting deepfakes due to the holistic misuse. Although many deepfakes detection algorithms are already existing in this aspect, very little work has been done to detect deepfake on the basis of analyzing normal eye blink rate. This paper presents a review on detecting deepfake through analyzing various facial regions like normal eye blink rate of a human being because it is not generally feasible to detect eye blink rate of a person at normal rate due to the deficiency of closed eye images.",Face-swap deepfakes;Fake images;Fake Videos;Generative Adversarial Networks;Autoencoder,IEE
882,Making Sense of Blockchain for AI Deepfakes Technology,A. Yazdinejad; R. M. Parizi; G. Srivastava; A. Dehghantanha,2020,"Deepfakes generally refers to a new breed of adversarial deep learning technology to create non-consensual contents (mostly videos) for nefarious purposes. Most researches focus on the `detection' of deepfakes using AI-assisted approaches to take on this problem. This has been the common method operandi used by researchers thus far. However, there is one missing aspect of the deepfake problem, which is `authentication'. Instead of attempting to detect what content is fake, in this paper, we focus on techniques to provide tamper-proof evidence of what content is real. Blockchain has been advocated to be helpful with the authentication aspect of many real-world scenarios. Despite the scattered efforts around such solutions, there are no studies that can shed light on where it makes sense to adopt blockchain technology to better take on the deepfake problem. This paper aims to provide a one-stop guide to using blockchain to navigate deepfake artificial intelligence. We discuss potential use cases and solutions to tackle deepfakes technology via blockchain functionalities and features.",Blockchain;Deepfakes;AI-generated video;Fake content;Distributed ledger;Security;Privacy,IEE
883,Perception vs. Reality: Understanding and Evaluating the Impact of Synthetic Image Deepfakes over College Students,E. Preu; M. Jackson; N. Choudhury,2022,"Artificial Intelligence (AI)-powered Deepfakes are responsible for new challenges in consumers� visual experience, and pose a wide range of negative consequences (i.e., non-consensual intimate imagery, political dis/misinformation, financial fraud, and cybersecurity issues) for individuals, societies, and organizations. Research suggested legislation, corporate policies, anti-Deepfake technology, education, and training to combat Deepfakes including the usage of synthetic media to raise awareness so that people can become more critical in detection when evaluating these contents in the future. To educate and raise awareness among the college-going students, this pilot survey study utilized both synthetic and real images over undergraduate students (N=19) to understand the human cognition and perception demonstrated by the literate population in detecting Deepfake media with their bare eyes. The results showed that human cognition and perception are insufficient in detecting synthetic media with their inexperienced eyes and even the intelligent population is vulnerable to this technology. While Deepfakes are becoming sophisticated and imperceptible, it was observed that this kind of survey study can be beneficial in raising awareness among the population about the societal impact of the technology and may also improve their detection ability for future encounters.",Deepfake;human detection;survey;cognitive;synthetic media;perception;fake news,IEE
884,Active Defense Against Voice Conversion Through Generative Adversarial Network,S. Dong; B. Chen; K. Ma; G. Zhao,2024,"Active defense is an important approach to counter speech deepfakes that threaten individuals� privacy, property, and reputation. However, the existing works in this field suffer from issues such as time-consuming and ordinary defense effectiveness. This letter proposes a Generative Adversarial Network (GAN) framework for adversarial attacks as a defense against malicious voice conversion. The proposed method uses a generator to produce adversarial perturbations and adds them to the mel-spectrogram of the target audio to craft adversarial example. In addition, in order to enhance the defense effectiveness, a spectrogram waveform conversion simulation module (SWCSM) is designed to simulate the process of reconstructing waveform from the adversarial mel-spectrogram example and re-extracting mel-spectrogram from the reconstructed waveform. Experiments on four state-of-the-art voice conversion models show that our method achieves the overall best performance among five compared methods in both white-box and black-box scenarios in terms of defense effectiveness and generation time.",Active defense;adversarial attack;deepfake;generative adversarial network;voice conversion,IEE
885,Contrastive Pseudo Learning for Open-World DeepFake Attribution,Z. Sun; S. Chen; T. Yao; B. Yin; R. Yi; S. Ding; L. Ma,2023,"The challenge in sourcing attribution for forgery faces has gained widespread attention due to the rapid development of generative techniques. While many recent works have taken essential steps on GAN-generated faces, more threatening attacks related to identity swapping or expression transferring are still overlooked. And the forgery traces hidden in unknown attacks from the open-world unlabeled faces still remain under-explored. To push the related frontier research, we introduce a new benchmark called Open-World DeepFake Attribution (OW-DFA), which aims to evaluate attribution performance against various types of fake faces under open-world scenarios. Meanwhile, we propose a novel framework named Contrastive Pseudo Learning (CPL) for the OW-DFA task through 1) introducing a Global-Local Voting module to guide the feature alignment of forged faces with different manipulated regions, 2) designing a Confidence-based Soft Pseudo-label strategy to mitigate the pseudo-noise caused by similar methods in unlabeled set. In addition, we extend the CPL framework with a multi-stage paradigm that leverages pre-train technique and iterative learning to further enhance traceability performance. Extensive experiments verify the superiority of our proposed method on the OW-DFA and also demonstrate the interpretability of deepfake attribution task and its impact on improving the security of deepfake detection area.",,IEE
886,Artificial Intelligence as Enabler for Sustainable Development,R. Walshe; A. Koene; S. Baumann; M. Panella; L. Maglaras; F. Medeiros,2021,"When the UN published the 17 Sustainable Development Goals (SDGs) in 2015, emerging technologies like Artificial Intelligence (AI) were not yet mature. However, through its deployment across industry sectors and verticals, issues related to sustainability, fairness, inclusiveness, efficiency, and usability of these technologies are now priorities for global consumers and producers. This paper discusses what needs to be considered by both policy makers and �managers� in order to exploit the use of AI for SDG achievement. AI can act as a real and meaningful enabler to achieve sustainability goals; however, it may also have negative impacts. Therefore, a carefully balanced approach is required to ensure that Artificial Intelligence systems are employed to help solve sustainability issues without inadvertently affecting other goals.",artificial intelligence;sustainability;SDGs cybersecurity;standardization;green computing;data governance;Internet of Things (IoT),IEE
887,PROVES: Establishing Image Provenance using Semantic Signatures,M. Xie; M. Kulshrestha; S. Wang; J. Yang; A. Chakrabarti; N. Zhang; Y. Vorobeychik,2022,"Modern AI tools, such as generative adversarial networks, have transformed our ability to create and modify visual data with photorealistic results. However, one of the deleterious side-effects of these advances is the emergence of nefarious uses in manipulating information in visual data, such as through the use of deep fakes. We propose a novel architecture for preserving the provenance of semantic information in images to make them less susceptible to deep fake attacks. Our architecture includes semantic signing and verification steps. We apply this architecture to verifying two types of semantic information: individual identities (faces) and whether the photo was taken indoors or outdoors. Verification accounts for a collection of common image transformation, such as translation, scaling, cropping, and small rotations, and rejects adversarial transformations, such as adversarially perturbed or, in the case of face verification, swapped faces. Experiments demonstrate that in the case of provenance of faces in an image, our approach is robust to black-box adversarial transformations (which are rejected) as well as benign transformations (which are accepted), with few false negatives and false positives. Background verification, on the other hand, is susceptible to black-box adversarial examples, but be-comes significantly more robust after adversarial training.",Security/Surveillance Deep Learning -> Adversarial Learning;Adversarial Attack and Defense Methods,IEE
888,Extracting Deep Local Features to Detect Manipulated Images of Human Faces,M. Tarasiou; S. Zafeiriou,2020,"Recent developments in computer vision and machine learning have made it possible to create realistic manipulated videos of human faces, raising the issue of ensuring adequate protection against the malevolent effects unlocked by such capabilities. In this paper we propose local image features which are shared across manipulated regions as a key element for the automatic detection of manipulated face images. We also design a lightweight architecture with the correct structural biases for extracting such features and derive a multitask training scheme that consistently outperforms image class supervision alone. The trained networks achieve state-of-the-art results in the FaceForensics++ dataset using significantly reduced number of parameters and are shown to work well in detecting fully generated face images.",,IEE
889,G�Face: High-Fidelity Reversible Face Anonymization via Generative and Geometric Priors,H. Yang; X. Xu; C. Xu; H. Zhang; J. Qin; Y. Wang; P. -A. Heng; S. He,2024,"Reversible face anonymization, unlike traditional face pixelization, seeks to replace sensitive identity information in facial images with synthesized alternatives, preserving privacy without sacrificing image clarity. Traditional methods, such as encoder-decoder networks, often result in significant loss of facial details due to their limited learning capacity. Additionally, relying on latent manipulation in pre-trained GANs can lead to changes in ID-irrelevant attributes, adversely affecting data utility due to GAN inversion inaccuracies. This paper introduces G2Face, which leverages both generative and geometric priors to enhance identity manipulation, achieving high-quality reversible face anonymization without compromising data utility. We utilize a 3D face model to extract geometric information from the input face, integrating it with a pre-trained GAN-based decoder. This synergy of generative and geometric priors allows the decoder to produce realistic anonymized faces with consistent geometry. Moreover, multi-scale facial features are extracted from the original face and combined with the decoder using our novel identity-aware feature fusion blocks (IFF). This integration enables precise blending of the generated facial patterns with the original ID-irrelevant features, resulting in accurate identity manipulation. Extensive experiments demonstrate that our method outperforms existing state-of-the-art techniques in face anonymization and recovery, while preserving high data utility. Code is available at https://github.com/Harxis/G2Face.",Reversible face anonymization;generative prior;geometric prior;identity-aware feature fusion,IEE
890,MFAAN: Unveiling Audio Deepfakes with a Multi-Feature Authenticity Network,K. S. Krishnan; K. S. Krishnan,2023,"In the contemporary digital age, the proliferation of deepfakes presents a formidable challenge to the sanctity of information dissemination. Audio deepfakes, in particular, can be deceptively realistic, posing significant risks in misinformation campaigns. To address this threat, we introduce the Multi-Feature Audio Authenticity Network (MFAAN)�an advanced architecture tailored for the detection of fabricated audio content. MFAAN incorporates multiple parallel paths designed to harness the strengths of different audio representations, including Mel-frequency cepstral coefficients (MFCC) [1], linear-frequency cepstral coefficients (LFCC) [1], and Chroma Short Time Fourier Transform (Chroma-STFT). By synergistically fusing these features, MFAAN achieves a nuanced understanding of audio content, facilitating robust differentiation between genuine and manipulated recordings. Preliminary evaluations of MFAAN on two benchmark datasets, �In-the-Wild� Audio Deepfake Data [2] and The Fake-or-Real Dataset [3], demonstrate its superior performance, achieving accuracies of 98.93% and 94.47% respectively. Such results not only underscore the efficacy of MFAAN but also highlight its potential as a pivotal tool in the ongoing battle against deepfake audio content.",Audio deep fakes;Mel-frequency cepstral co-efficients (MFCC);Deep Learning;linear-frequency cepstral coefficients (LFCC);Chroma Short Time Fourier Transform (Chroma-STFT);Privacy,IEE
891,FakeLocator: Robust Localization of GAN-Based Face Manipulations,Y. Huang; F. Juefei-Xu; Q. Guo; Y. Liu; G. Pu,2022,"Full face synthesis and partial face manipulation by virtue of the generative adversarial networks (GANs) and its variants have raised wide public concerns. In the multi-media forensics area, detecting and ultimately locating the image forgery has become an imperative task. In this work, we investigate the architecture of existing GAN-based face manipulation methods and observe that the imperfection of upsampling methods therewithin could be served as an important asset for GAN-synthesized fake image detection and forgery localization. Based on this basic observation, we have proposed a novel approach, termed FakeLocator, to obtain high localization accuracy, at full resolution, on manipulated facial images. To the best of our knowledge, this is the very first attempt to solve the GAN-based fake localization problem with a gray-scale fakeness map that preserves more information of fake regions. To improve the universality of FakeLocator across multifarious facial attributes, we introduce an attention mechanism to guide the training of the model. To improve the universality of FakeLocator across different DeepFake methods, we propose partial data augmentation and single sample clustering on the training images. Experimental results on popular FaceForensics++, DFFD datasets and seven different state-of-the-art GAN-based face generation methods have shown the effectiveness of our method. Compared with the baselines, our method performs better on various metrics. Moreover, the proposed method is robust against various real-world facial image degradations such as JPEG compression, low-resolution, noise, and blur.",DeepFake;face manipulation;DeepFake detection and localization,IEE
892,Exposing DeepFakes Using Convolutional Neural Networks and Transfer Learning Approaches,S. Suratkar; F. Kazi; M. Sakhalkar; N. Abhyankar; M. Kshirsagar,2020,Advancements in Artificial Intelligence - oriented computing power and the ever-growing reach of social media have proven to be catalysts in emergence and spread of a new vein of AI generated fake videos known as 'DeepFake' videos. Such videos are synthesized using generative machine learning models like Generative Adversarial Networks or Variational AutoEncoders and they can achieve high degrees of realism. Spread of sensitive political or obscene content in form of such videos may lead to social distress to the target entity(s). This paper presents a study pertinent to the detection of DeepFake videos using Convolutional Neural Networks (CNNs) with transfer learning. A comparative study of the performance of various models in the detection of tampered videos has been presented. These models are trained (fine-tuned) and tested on a custom dataset encompassing randomly selected labelled frames from videos in the DeepFake Detection Dataset by Google AI and FaceForensics++ dataset.,Convolutional Neural Networks;Generative Adversarial Networks;Transfer Learning;Visual Geometry Group;DenseNet;Xception;Inception V3,IEE
893,Deepfake Algorithm Using Multiple Noise Modalities with Two-Branch Prediction Network,H. -W. Hsu; J. -J. Ding,2021,"In this paper, we propose a facial manipulation detection method based on multiple image noise analysis modalities and a two-branch prediction network to separation different types of forgery artifacts. The proposed architecture reveals whether the input image can be decomposed into a blending of two images from different sources, and checks whether some patches of the input image are generated from a deep learning networks at the same time. We observe that most of the existing forgery detection work] only focuses on finding one of the blending or manipulation artifacts in the input image. As a result, this method provides an effective way for forgery detection by simultaneously checking the manipulation and blending artifacts. In addition, for use with different types of image noise analysis modalities, our method can find more robust detection features in the high-frequency domain compared with traditionally detection in the RGB domain, thereby obtaining better performance. Extensive experiments show that our method outperforms other existing forgery detection methods on detecting synthesized face image, no matter on detecting training dataset or on detecting unseen face manipulation techniques.",,IEE
894,Recent advancements in Image Steganography using Generative Adversarial Networks methods,S. I. Fatima; Y. Garapati,2024,"Generative Adversarial Networks are employed by GAN-based models in image steganography to efficiently conceal information from images while preserving their visual integrity. These models are made up of two primary parts: the discriminator which determines if an image is a real image or a stego-image, and the generator which embeds the hidden data into images. The generator learns how to embed data in a way that minimizes obvious distortions through adversarial training, where the discriminator and generator fight to make the hidden data less noticeable to detection algorithms and human observers. High data capacity and versatility are strengths of GAN-based steganography models, which enable efficient data concealment across a variety of image formats and steganographic techniques. They dynamically adjust the embedding procedure to strike a compromise between image quality and data capacity. They do, however, come with certain drawbacks such as the need for sophisticated model training, high processing overhead and hyperparameter sensitivity. Notwithstanding these drawbacks, GAN-based techniques mark a substantial breakthrough in the development of delicate and reliable image steganography techniques.",GAN;image steganography;data hiding;generator;discriminator,IEE
895,Self-Supervised Distilled Learning for Multi-modal Misinformation Identification,M. Mu; S. Das Bhattacharjee; J. Yuan,2023,"Rapid dissemination of misinformation is a major societal problem receiving increasing attention. Unlike Deep-fake, Out-of-Context misinformation, in which the unaltered unimode contents (e.g. image, text) of a multi-modal news sample are combined in an out-of-context manner to generate deception, requires limited technical expertise to create. Therefore, it is more prevalent a means to confuse readers. Most existing approaches extract features from its uni-mode counterparts to concatenate and train a model for the misinformation classification task. In this paper, we design a self-supervised feature representation learning strategy that aims to attain the multi-task objectives: (1) task-agnostic, which evaluates the intra- and inter-mode representational consistencies for improved alignments across related models; (2) task-specific, which estimates the category-specific multi-modal knowledge to enable the classifier to derive more discriminative predictive distributions. To compensate for the dearth of annotated data representing varied types of misinformation, the proposed Self-Supervised Distilled Learner (SSDL) utilizes a Teacher network to weakly guide a Student network to mimic a similar decision pattern as the teacher. The two-phased learning of SSDL can be summarized as: initial pretraining of the Student model using a combination of contrastive self-supervised task-agnostic objective and supervised task-specific adjustment in parallel; finetuning the Student model via self-supervised knowledge distillation blended with the supervised objective of decision alignment. In addition to the consistent out-performances over the existing baselines that demonstrate the feasibility of our approach, the explainability capacity of the proposed SSDL also helps users visualize the reasoning behind a specific prediction made by the model.",Applications: Social good;Image recognition and understanding (object detection;categorization;segmentation;scene modeling;visual reasoning);Vision + language and/or other modalities,IEE
896,StyleIPSB: Identity-Preserving Semantic Basis of StyleGAN for High Fidelity Face Swapping,D. Jiang; D. Song; R. Tong; M. Tang,2023,"Recent researches reveal that StyleGAN can generate highly realistic images, inspiring researchers to use pretrained StyleGAN to generate high-fidelity swapped faces. However, existing methods fail to meet the expectations in two essential aspects of high-fidelity face swapping. Their results are blurry without pore-level details and fail to preserve identity for challenging cases. To overcome the above artifacts, we innovatively construct a series of identity-preserving semantic bases of StyleGAN (called StyleIPSB) in respect of pose, expression, and illumination. Each basis of StyleIPSB controls one specific semantic attribute and disentangles with the others. The StyleIPSB constrains style code in the subspace of W+ space to preserve pore-level details and gives us a novel tool for high-fidelity face swapping, and we propose a three-stage framework for face swapping with StyleIPSB. Firstly, we transform the target facial images' attributes to the source image. We learn the mapping from 3D Morphable Model (3DMM) parameters, which capture the prominent semantic variance, to the coordinates of StyleIPSB that show higher identity-preserving and fidelity. Secondly, to transform detailed attributes which 3DMM does not capture, we learn the residual attribute between the reenacted face and the target face. Finally, the face is blended into the background of the target image. Extensive results and comparisons demonstrate that StyleIPSB can effectively preserve identity and pore-level details. The results of face swapping can achieve state-of-the-art performance. We will release our code at https://github.com/a686432/StyleIPSB",Humans: Face;body;pose;gesture;movement,IEE
897,A New Dataset for Forged Smartphone Videos Detection: Description and Analysis,Y. Akbari; A. A. Najeeb; S. Al Maadeed; O. Elharrouss; F. Khelifi; A. Lawgaly,2023,"The advancement of Internet technology has significantly impacted daily life, which is influenced by digital videos taken with smartphones as the most popular type of multimedia. These digital videos are extensively sent through various social media websites such as WhatsApp, Instagram, Facebook, Twitter, and YouTube. The development of intelligent and simple editing tools has favoured the transformation of multimedia content on the Internet. As a result, these digital videos� credibility, reliability, and integrity have become critical concerns. This paper presents a video forgery (Copy-move forgery) dataset in which 250 original videos are manipulated mainly by two forgery techniques: Insertion and Deletion. Inserting transparent objects into the original video without raising suspicion is one type of manipulation performed. Another type of forgery presented on the dataset is the removal of objects from the original video without notifying the viewers. The videos were collected from five different mobile devices, namely, IPhone 8 Plus, Nokia 5.4, Samsung A50, Xiomi Redmi Note 9 Pro and Huawei Y9-1. The forged videos were created using a popular video editing software called Adobe After Effects as well as usage of other software such as Adobe Photoshop and AfterCodecs. Since the source of the videos is known, PRNU-based methods can be suitable for applying to the dataset. Experiments were performed using classical and deep learning methods. The results are recorded and discussed in detail, showing that improvements are essential for the dataset. Furthermore, the forged videos of this dataset are comparatively large when compared to other datasets that performed copy-move forgery.",Dataset;video;mobile devices;copy-move forgery;deep learning,IEE
898,FakeTransformer: Exposing Face Forgery From Spatial-Temporal Representation Modeled By Facial Pixel Variations,Y. Sun; Z. Zhang; C. Qiu; L. Wang; L. Sun; Z. Wang,2022,"With the rapid development of generation model, AI-based face manipulation technology, which called DeepFakes, has become more and more realistic. This means of face forgery can attack any target, which poses a new threat to personal privacy and property security. Moreover, the misuse of synthetic video shows potential dangers in many areas, such as identity harassment, pornography and news rumors. Inspired by the fact that the spatial coherence and temporal consistency of physiological signal are destroyed in the generated content, we attempt to find inconsistent patterns that can distinguish between real videos and synthetic videos from the variations of facial pixels, which are highly related to physiological information. Our approach first applies Eulerian Video Magnification (EVM) at multiple Gaussian scales to the original video to enlarge the physiological variations caused by the change of facial blood volume, and then transform the original video and magnified videos into a Multi-Scale Eulerian Magnified Spatial-Temporal map (MEMSTmap), which can represent time-varying physiological enhancement sequences on different octaves. Then, these maps are reshaped into frame patches in column units and sent to the vision Transformer to learn the spatio-time descriptors of frame levels. Finally, we sort out the feature embedding and output the probability of judging whether the video is real or fake. We validate our method on the FaceForensics++ and DeepFake Detection datasets. The results show that our model achieves excellent performance in forgery detection, and also show outstanding generalization capability in cross-data domain.",Digital Face Manipulation;DeepFakes;Face Swap;Image Forensics,IEE
899,Anti-Forensics for Face Swapping Videos via Adversarial Training,F. Ding; G. Zhu; Y. Li; X. Zhang; P. K. Atrey; S. Lyu,2022,"Generating falsified faces by artificial intelligence, widely known as DeepFake, has attracted attention worldwide since 2017. Given the potential threat brought by this novel technique, forensics researchers dedicated themselves to detect the video forgery. Except for exposing falsified faces, there could be extended research directions for DeepFake such as anti-forensics. It can disclose the vulnerability of current DeepFake forensics methods. Besides, it could also enable DeepFake videos as tactical weapons if the falsified faces are more subtle to be detected. In this paper, we propose a GAN model to behave as an anti-forensics tool. It features a novel architecture with additional supervising modules for enhancing image visual quality. Besides, a loss function is designed to improve the efficiency of the proposed model. After experimental evaluations, we show that the DeepFake forensics detectors are susceptible to attacks launched by the proposed method. Besides, the proposed method can efficiently produce anti-forensics videos in satisfying visual quality without noticeable artifacts. Compared with the other anti-forensics approaches, this is tremendous progress achieved for DeepFake anti-forensics. The attack launched by our proposed method can be truly regarded as DeepFake anti-forensics as it can fool detecting algorithms and human eyes simultaneously.",Digital forensics;anti-forensics;DeepFake;generative adversarial network,IEE
900,Art of Detection: Custom CNN and VGG19 for Accurate Real Vs Fake Image Identification,H. V; K. P; M. A,2023,"In the current digital age, the ability to distinguish between real and manipulated images has become crucial due to the proliferation of doctored images. This research aims to address this challenge by employing two distinct neural network architectures: a custom Convolutional Neural Network (CNN) and the pre-trained VGG19 model for the classification of real versus fake images. Experimental results reveal that the custom CNN achieved a noteworthy accuracy of 94.46%, outperforming the VGG19 model, which secured an accuracy of 84.24%. Such findings suggest that while pre-trained models like VGG19 bring significant value to image classification tasks, a tailored CNN can offer superior performance for specialized tasks such as detecting image authenticity. This study provides a foundation for further exploration in image forensics, emphasizing the importance of model selection and optimization in combating digital image manipulations.",Detecting image authenticity;Convolutional Neural Network (CNN);VGG19 Model;Image Classification,IEE
901,Recent Advancement in 3D Biometrics using Monocular Camera,A. Mukherjee; A. Das,2023,"Recent literature has witnessed significant interest towards 3D biometrics employing monocular vision for robust authentication methods. Motivated by this, in this work we seek to provide insight on recent development in the area of 3D biometrics employing monocular vision. We present the similarity and dissimilarity of 3D monocular biometrics and classical biometrics, listing the strengths and challenges. Further, we provide an overview of recent techniques in 3D biometrics with monocular vision, as well as application systems adopted by the industry. Finally, we discuss open research problems in this area of research.",,IEE
902,Face Swapping for Low-Resolution and Occluded Images In-the-Wild,J. Park; W. Kang; H. I. Koo; N. I. Cho,2024,"Safeguarding personal identity in various surveillance videos, dashcams, and on-street videos is crucial. One way to do this is to detect faces and blur them, but a better solution is to replace them with non-existent ones to maintain the naturalness of the videos. While face swapping methods have already been used in the media industry with high-quality faces, it is challenging to apply them for identity protection to faces in-the-wild where faces are often occluded and of low-resolution. Therefore, we propose a new framework for face swapping specifically designed to work with face images taken in real-world scenarios, making it useful as a privacy protection method. To tackle the issue of low-resolution images, we introduce a Cross-Resolution Contrastive Loss (CRCL) technique, which allows our neural network model to be trained using triplets of varying resolutions. This enables the model to learn and use identity information across different resolutions, thereby improving its accuracy. We also propose a plug-and-play framework that can be easily applied to existing face swapping models to handle occlusions. By explicit swapping of facial features and filling of occluded regions, our framework provides a more seamless blend. To demonstrate the effectiveness of our method in handling faces in-the-wild, we create an occluded VGGFace2 dataset consisting of face images augmented with various facial masks and hand occlusions. Through quantitative and qualitative assessments on this dataset, our proposed method demonstrates robust performance under low-resolution or occluded scenarios. Significant improvements are made in the quality of swapped faces while preserving their identity and attributes, highlighting the effectiveness of our framework in advancing face swapping as a reliable privacy protection measure.",Deep learning;de-identification;face swapping;in-the-wild;low-resolution;occlusion;privacy protection,IEE
903,Pose-Aware Speech Driven Facial Landmark Animation Pipeline for Automated Dubbing,D. Bigioi; H. Jordan; R. Jain; R. McDonnell; P. Corcoran,2022,"A novel neural pipeline allowing one to generate pose aware 3D animated facial landmarks synchronised to a target speech signal is proposed for the task of automatic dubbing. The goal is to automatically synchronize a target actors� lips and facial motion to an unseen speech sequence, while maintaining the quality of the original performance. Given a 3D facial key point sequence extracted from any reference video, and a target audio clip, the neural pipeline learns how to generate head pose aware, identity aware landmarks and outputs accurate 3D lip motion directly at the inference stage. These generated landmarks can be used to render a photo-realistic video via an additional image to image conversion stage. In this paper, a novel data augmentation technique is introduced that increases the size of the training dataset from N audio/visual pairs up to NxN unique pairs for the task of automatic dubbing. The trained inference pipeline employs a LSTM-based network that takes Mel-coefficients as input from an unseen speech sequence, combined with head pose, and identity parameters extracted from a reference video to generate a new set of pose aware 3D landmarks that are synchronized with the unseen speech.",Machine learning;computer vision;lip synchronization;talking head generation;automatic dubbing;audio driven deep fakes;artificial intelligence,IEE
904,Wish You Were Here: Context-Aware Human Generation,O. Gafni; L. Wolf,2020,"We present a novel method for inserting objects, specifically humans, into existing images, such that they blend in a photorealistic manner, while respecting the semantic context of the scene. Our method involves three subnetworks: the first generates the semantic map of the new person, given the pose of the other persons in the scene and an optional bounding box specification. The second network renders the pixels of the novel person and its blending mask, based on specifications in the form of multiple appearance components. A third network refines the generated face in order to match those of the target person. Our experiments present convincing high-resolution outputs in this novel and challenging application domain. In addition, the three networks are evaluated individually, demonstrating for example, state of the art results in pose transfer benchmarks.",,IEE
905,Lip Sync Matters: A Novel Multimodal Forgery Detector,S. A. Shahzad; A. Hashmi; S. Khan; Y. -T. Peng; Y. Tsao; H. -M. Wang,2022,"Deepfake technology has advanced a lot, but it is a double-sided sword for the community. One can use it for beneficial purposes, such as restoring vintage content in old movies, or for nefarious purposes, such as creating fake footage to manipulate the public and distribute non-consensual pornography. A lot of work has been done to combat its improper use by detecting fake footage with good performance thanks to the availability of numerous public datasets and unimodal deep learning-based models. However, these methods are insufficient to detect multimodal manipulations, such as both visual and acoustic. This work proposes a novel lip-reading-based multi-modal Deepfake detection method called �Lip Sync Matters.� It targets high-level semantic features to exploit the mismatch between the lip sequence extracted from the video and the synthetic lip sequence generated from the audio by the Wav2lip model to detect forged videos. Experimental results show that the proposed method outperforms several existing unimodal, ensemble, and multimodal methods on the publicly available multimodal FakeAVCeleb dataset.",,IEE
906,Low Bandwidth Video-Chat Compression using Deep Generative Models,M. Oquab; P. Stock; O. Gafni; D. Haziza; T. Xu; P. Zhang; O. Celebi; Y. Hasson; P. Labatut; B. Bose-Kolanu; T. Peyronel; C. Couprie,2021,"To unlock video chat for hundreds of millions of people hindered by poor connectivity or unaffordable data costs, we propose to authentically reconstruct faces on the receiver�s device using facial landmarks extracted at the sender�s side and transmitted over the network. In this context, we discuss and evaluate the benefits and disadvantages of several deep adversarial approaches. In particular, we explore quality and bandwidth trade-offs for approaches based on static landmarks, dynamic landmarks or segmentation maps. We design a mobile-compatible architecture based on the first order animation model of Siarohin et al. In addition, we leverage SPADE blocks to refine results in important areas such as the eyes and lips. We compress the networks down to about 3 MB, allowing models to run in real time on iPhone 8 (CPU). This approach enables video calling at a few kbits per second, an order of magnitude lower than currently available alternatives.",,IEE
907,The Stable Signature: Rooting Watermarks in Latent Diffusion Models,P. Fernandez; G. Couairon; H. J�gou; M. Douze; T. Furon,2023,"Generative image modeling enables a wide range of applications but raises ethical concerns about responsible deployment. We introduce an active content tracing method combining image watermarking and Latent Diffusion Models. The goal is for all generated images to conceal an invisible watermark allowing for future detection and/or identification. The method quickly fine-tunes the latent decoder of the image generator, conditioned on a binary signature. A pre-trained watermark extractor recovers the hidden signature from any generated image and a statistical test then determines whether it comes from the generative model. We evaluate the invisibility and robustness of the watermarks on a variety of generation tasks, showing that the Stable Signature is robust to image modifications. For instance, it detects the origin of an image generated from a text prompt, then cropped to keep 10% of the content, with 90+% accuracy at a false positive rate below 10?6.",,IEE
908,Analyzing the Methods for Detecting Deepfakes,M. Khichi; R. K. Yadav,2021,"Progress in the field of deep counterfeiting is equally impressive and worrisome on the upside. We can change the fidelity of the media that will undoubtedly lead to some world memes, but in the hands of the bad guys. Deepfake technology can be used to spread misinformation and destroy public trust in. It is almost like science fiction identity theft. You can allow anyone to tell what they want, but the reverse is true. In this paper, Detailed study has been carried out that proposed different deepfake detection models, this document finds DEFAKEHOP as the best method in , which uses spatial dimensionality reduction and soft classification to obtain a more concise description of the face for each detection channel. This article finally looks at �s research direction in this field, as well as the development of more powerful technologies to deal with the growing threat surrounding Deepfake technology.",Deepfakes;Autoencoders;Deep Learning;Convolutional Neural Network;Transfer Learning;Generative Adversarial Network,IEE
909,Detecting and Preventing Faked Mixed Reality,F. Kilger; A. Kabil; V. Tippmann; G. Klinker; M. -O. Pahl,2021,"Virtualized collaboration can significantly increase remote management of critical infrastructures. Crises such as the current COVID-19 pandemic push the technology: they require remote management to keep our infrastructures running. Mixed Reality (MR) prototypes enable remote management in diverse fields such as medicine, industry 4.0, energy systems, education, or cyber awareness. However, the evolution of virtualized collaboration is still in the beginning. By design, MR is fake: its reality is generated from models. This makes detecting attacks very difficult. Many MR-attacks result from well-known cybersecurity threats. This paper identifies classic attack surfaces, vectors, and concrete threats that are relevant for MR. It presents mitigation methods that can help to secure the underlying data exchanges. However, distributed systems are often heterogeneous and under different management authorities, making securing the entire virtualized remote management stack difficult. The paper therefore also introduces considerations towards an MR-client-based attack detection, i.e., MR-forensics, including relevant features and the use of machine learning.",Cybersecurity;Mixed Reality;Remote Management;Deepfake;MR forensics,IEE
910,Face Generation and Editing With StyleGAN: A Survey,A. Melnik; M. Miasayedzenkau; D. Makaravets; D. Pirshtuk; E. Akbulut; D. Holzmann; T. Renusch; G. Reichert; H. Ritter,2024,"Our goal with this survey is to provide an overview of the state of the art deep learning methods for face generation and editing using StyleGAN. The survey covers the evolution of StyleGAN, from PGGAN to StyleGAN3, and explores relevant topics such as suitable metrics for training, different latent representations, GAN inversion to latent spaces of StyleGAN, face image editing, cross-domain face stylization, face restoration, and even Deepfake applications. We aim to provide an entry point into the field for readers that have basic knowledge about the field of deep learning and are looking for an accessible introduction and overview.",Deep learning;deepfakes;face generation;face restoration;GAN;GAN inversion;latent space;StyleGAN,IEE
911,Countering Deepfakes using an Improved Advanced CNN and its Ensemble with Pretrained Models,A. Mathur; M. Tejpal; K. Bhargava; K. Natarajan; M. Singh,2024,"The extensive spread of DeepFake images on the internet has emerged as a significant challenge, with applications ranging from harmless entertainment to harmful acts like blackmail, misinformation, and spreading false propaganda. To tackle this issue, this paper introduces a sophisticated DeepFake detection model designed to identify and mitigate the increase of these deceptive images. The model architecture integrates an ensemble approach, combining the strengths of two pre-trained Convolutional Neural Network (CNN) models�MobileNet and Xception�with a novel CNN architecture, the Advanced CNN (ACNN). This rigorous validation process enabled the model to achieve a high accuracy rate of 97.89% in detecting DeepFakes. The successful implementation of this ensemble CNN approach demonstrates its effectiveness in distinguishing between real and fabricated imagery with high precision. This research makes a substantial contribution to the field of digital image forensics, offering a reliable tool for stakeholders across various sectors to identify and counteract the spread of DeepFake images online.",DeepFake Detection;Convolutional Neural Networks (CNN);MobileNet;Xception;Advanced CNN (ACNN);Ensemble Learning;Generative Adversarial Networks (GANs),IEE
912,Robust CLIP-Based Detector for Exposing Diffusion Model-Generated Images,Santosh; L. Lin; I. Amerini; X. Wang; S. Hu,2024,"Diffusion models (DMs) have revolutionized image generation, producing high-quality images with applications spanning various fields. However, their ability to create hyper-realistic images poses significant challenges in distinguishing between real and synthetic content, raising concerns about digital authenticity and potential misuse in creating deepfakes. This work introduces a robust detection framework that integrates image and text features extracted by CLIP model with a Multilayer Perceptron (MLP) classifier. We propose a novel loss that can improve the detector�s robustness and handle imbalanced datasets. Additionally, we flatten the loss landscape during the model training to improve the detector�s generalization capabilities. The effectiveness of our method, which outperforms traditional detection techniques, is demonstrated through extensive experiments, underscoring its potential to set a new state-of-the-art approach in DM-generated image detection. The code is available at https://github.com/Purdue-M2/RobustDM_Generated_Image_Detection.",Diffusion models;CLIP;Robust;AI images,IEE
913,MLAAD: The Multi-Language Audio Anti-Spoofing Dataset,N. M. M�ller; P. Kawa; W. H. Choong; E. Casanova; E. G�lge; T. M�ller; P. Syga; P. Sperl; K. B�ttinger,2024,"Text-to-Speech (TTS) technology brings significant advantages, such as giving a voice to those with speech impairments, but also enables audio deepfakes and spoofs. The former mislead individuals and may propagate misinformation, while the latter undermine voice biometric security systems. AI-based detection can help to address these challenges by automatically differentiating between genuine and fabricated voice recordings. However, these models are only as good as their training data, which currently is severely limited due to an overwhelming concentration on English and Chinese audio in anti-spoofing databases, thus restricting its worldwide effectiveness.In response, this paper presents the Multi-Language Audio Anti-Spoof Dataset (MLAAD), created using 52 TTS models, comprising 22 different architectures, to generate 160.2 hours of synthetic voice in 23 different languages. We train and evaluate three state-of-the-art deepfake detection models with MLAAD, and observe that MLAAD demonstrates superior performance over comparable datasets like InTheWild or FakeOrReal when used as a training resource. Furthermore, in comparison with the renowned ASVspoof 2019 dataset, MLAAD proves to be a complementary resource. In tests across eight datasets, MLAAD and ASVspoof 2019 alternately outperformed each other, both excelling on four datasets.By publishing 1 MLAAD and making trained models accessible via an interactive webserver 2, we aim to democratize antispoofing technology, making it accessible beyond the realm of specialists, thus contributing to global efforts against audio spoofing and deepfakes.",text-to-speech;anti-spoofing;deepfake;voice;audio;biometrics,IEE
914,Detection of Photoplethysmography Manipulation in Video Forgery,Y. Lin; E. Maiorana; B. Li; P. Campisi,2023,"Recent studies have shown that physiological signals related to blood pressure and heart rate can be estimated in a contactless modality from facial videos using remote photoplethysmography (rPPG). This has paved the way to the development of techniques that can acquire and manipulate the rPPG signals recoverable from facial videos without affecting their visual appearance. The goal of this paper is to analyze the detectability of this new kind of forgery, here referred to as rPPG deepfake videos. Specifically, we propose a two-stream method based on the analysis of rPPG deepfake videos at both spatial and temporal levels. The experimental results obtained from tests performed on samples taken from two distinct databases demonstrate that our method performs better than popular deep learning methods in the rPPG deepfake detection task.",Remote photoplethysmography (rPPG);Face forgery detection;Video forensics,IEE
915,Nowhere to Hide: Detecting Live Video Forgery via Vision-WiFi Silhouette Correspondence,X. Fang; J. Liu; Y. Chen; J. Han; K. Ren; G. Chen,2023,"For safety guard and crime prevention, video surveillance systems have been pervasively deployed in many security-critical scenarios, such as the residence, retail stores, and banks. However, these systems could be infiltrated by the adversary and the video streams would be modified or replaced, i.e., under the video forgery attack. The prevalence of Internet of Things (IoT) devices and the emergence of Deepfake-like techniques severely emphasize the vulnerability of video surveillance systems under such attacks. To secure existing surveillance systems, in this paper we propose a vision-WiFi cross-modal video forgery detection system, namely WiSil. Leveraging a theoretical model based on the principle of signal propagation, WiSil constructs wave front information of the object in the monitoring area from WiFi signals. With a well-designed deep learning network, WiSil further recovers silhouettes from the wave front information. Based on a Siamese network-based semantic feature extractor, WiSil can eventually determine whether a frame is manipulated by comparing the semantic feature vectors extracted from the video�s silhouette with those extracted from the WiFi�s silhouette. Extensive experiments show that WiSil can achieve 95% accuracy in detecting tampered frames. Moreover, WiSil is robust against environment and person changes.",WiFi Sensing;Video Forgery Detection;Deep Learning,IEE
916,Expression Transfer Using Flow-based Generative Models,A. Valenzuela; C. Segura; F. Diego; V. G�mez,2021,"Among the different deepfake generation techniques, flow-based methods appear as natural candidates. Due to the property of invertibility, flow-based methods eliminate the necessity of person-specific training and are able to reconstruct any input image almost perfectly to human perception. We present a method for deepfake generation based on facial expression transfer using flow-based generative models. Our approach relies on simple latent vector operations akin to the ones used for attribute manipulation, but for transferring expressions between identity source-target pairs. We show the feasibility of this approach using a pre-trained Glow model and small sets of source and target images, not necessarily considered during prior training. We also provide an evaluation pipeline of the generated images in terms of similarities between identities and Action Units encoding the expression to be transferred. Our results show that an efficient expression transfer is feasible by using the proposed approach setting up a first precedent in deepfake content creation, and its evaluation, independently of the training identities.",,IEE
917,FaceForensics++: Learning to Detect Manipulated Facial Images,A. R�ssler; D. Cozzolino; L. Verdoliva; C. Riess; J. Thies; M. Niessner,2019,"The rapid progress in synthetic image generation and manipulation has now come to a point where it raises significant concerns for the implications towards society. At best, this leads to a loss of trust in digital content, but could potentially cause further harm by spreading false information or fake news. This paper examines the realism of state-of-the-art image manipulations, and how difficult it is to detect them, either automatically or by humans. To standardize the evaluation of detection methods, we propose an automated benchmark for facial manipulation detection. In particular, the benchmark is based on Deep-Fakes, Face2Face, FaceSwap and NeuralTextures as prominent representatives for facial manipulations at random compression level and size. The benchmark is publicly available and contains a hidden test set as well as a database of over 1.8 million manipulated images. This dataset is over an order of magnitude larger than comparable, publicly available, forgery datasets. Based on this data, we performed a thorough analysis of data-driven forgery detectors. We show that the use of additional domain-specific knowledge improves forgery detection to unprecedented accuracy, even in the presence of strong compression, and clearly outperforms human observers.",,IEE
918,Using Grayscale Frequency Statistic to Detect Manipulated Faces in Wavelet-Domain,G. -J. Wang; W. Li; Q. Jiang; X. Jin; X. -H. Cui,2021,"Manipulating facial images results in negative influences on the social association, with deep generative models. Although many detection methods have been proposed, they have either designed sophisticated neural networks that lack enough interpretability, or found defects specific to one manipulation method. To address this issue, we propose a new approach to explore the defects of fake facial images after wavelet transform and call it GFS (Grayscale Frequency Statistics). First, we utilize Haar wavelet transformation to decompose the image into low-frequency approximation, horizontal detail, vertical detail, and diagonal detail. The GFS of real and fake images exhibit different distribution and forms in these four subbands. We qualitatively analyze these differences and quantify them as weights. Then, these four subband images are used to train four CNNs respectively, and the obtained detection results also verify the differences in GFS. After that, we combine the prediction results of the four CNNs and the corresponding weights to further improve the detection performance. We conduct extensive experiments on 11 datasets generated by various facial manipulation methods, and the superior results show the effectiveness of our proposed approach. Our findings indicate that the fake images generated by the current facial manipulation methods cannot simulate real images in wavelet-domain.",,IEE
919,A GAN-Based Defense Framework Against Model Inversion Attacks,X. Gong; Z. Wang; S. Li; Y. Chen; Q. Wang,2023,"With the development of deep learning, deep neural network (DNN)-based application have become an indispensable aspect of daily life. However, recent studies have shown that these well-trained DNN models are vulnerable to model inversion attacks (MIAs), where attackers can recover their training data with high fidelity. Although several defensive strategies have been proposed to mitigate the impact of such attacks, existing defenses will inevitably compromise the model performance and are ineffective against more sophisticated attacks, such as Mirror (An et al., 2022). In this paper, we introduce a novel GAN-based defense approach against model inversion attacks. Unlike previous works that perturb the prediction vector of the model, we manipulate the training procedure of the victim model by incorporating carefully-designed GAN-based fake samples. We also adjust the loss of the inversed samples to inject misleading features into the protected label of the victim model. Additionally, we adopt the concept of continual learning to improve the utility of the model. Extensive experiments conducted on the CelebA, VGG-Face, and VGG-Face2 datasets demonstrate that our proposed method outperforms existing defenses against state-of-the-art model inversion attacks, including DMI (Chen et al., 2021), Mirror (An et al., 2022), Privacy (Fredrikson et al., 2014), and AMI (Yang et al., 2019). It is shown that our proposed method can also retain a high defense performance in black-box scenarios.",Model inversion attacks;GAN-based fake sample generation;privacy-utility defense framework,IEE
920,Low-Resource Adaptation for Personalized Co-Speech Gesture Generation,C. Ahuja; D. W. Lee; L. -P. Morency,2022,"Personalizing an avatar for co-speech gesture generation from spoken language requires learning the idiosyncrasies of a person's gesture style from a small amount of data. Previous methods in gesture generation require large amounts of data for each speaker, which is often infeasible. We propose an approach, named DiffGAN, that efficiently personalizes co-speech gesture generation models of a high-resource source speaker to target speaker with just 2 minutes of target training data. A unique characteristic of DiffGAN is its ability to account for the crossmodal grounding shift, while also addressing the distribution shift in the output domain. We substantiate the effectiveness of our approach a large scale publicly available dataset through quantitative, qualitative and user studies, which show that our proposed methodology significantly outperforms prior approaches for low-resource adaptation of gesture generation. Code and videos can be found at https://chahuja.com/diffgan.",Face and gestures; Transfer/low-shot/long-tail learning; Vision + X; Vision applications and systems,IEE
921,Comprehensive Analysis of Natural Images and Synthetic Images,G. R. Naidu; C. S. Rao,2024,"N atural photos depict real-world scenes, including still images and videos captured by cameras. They are drawn from elements of nature such as colors, textures and shapes. Realistic computer graphics (CG) are increasingly popular due to technology. CG images are made using software like 3D modeling. They range from animation to concept in media such as movies and games. These images are imperceptible to the naked eye. Differentiating between computer-generated (CG) and natural images (NI) poses a challenge in the field of digital forensics. CG images often lack metadata, impeding the discovery process. Watermarked CG images attempt to mimic natural ones but are limited in their usability. They're often stored in proprietary formats, not indexed by search engines. Interest in NI and CG image recognition has surged. The goal of making computer-generated images as realistic as NI is challenging. Photorealistic CG imagery transforms multimedia, simplifying realistic animations. This aids entertainment, media, and other industries. This article provides a comprehensive overview of the most popular and cutting-edge methods now in use for differentiating between natural images and Computer-Generated Images, as well as the benefits and drawbacks of these methods and their potential future directions.",Natural Images;Computer Generated Images;Realistic;Multimedia,IEE
922,Generative Adversarial Networks,M. Krichen,2023,"Generative Adversarial Networks (GANs) are a type of deep learning techniques that have shown remarkable success in generating realistic images, videos, and other types of data. This paper provides a comprehensive guide to GANs, covering their architecture, loss functions, training methods, applications, evaluation metrics, challenges, and future directions. We begin with an introduction to GANs and their historical development, followed by a review of the background and related work. We then provide a detailed overview of the GAN architecture, including the generator and discriminator networks, and discuss the key design choices and variations. Next, we review the loss functions utilized in GANs, including the original minimax objective, as well as more recent approaches s.a. Wasserstein distance and gradient penalty. We then delve into the training of GANs, discussing common techniques s.a. alternating optimization, minibatch discrimination, and spectral normalization. We also provide a survey of the various applications of GANs across domains. In addition, we review the evaluation metrics utilized to assess the diversity and quality of GAN-produced data. Furthermore, we discuss the challenges and open issues in GANs, including mode collapse, training instability, and ethical considerations. Finally, we provide a glimpse into the future directions of GAN research, including improving scalability, developing new architectures, incorporating domain knowledge, and exploring new applications. Overall, this paper serves as a comprehensive guide to GANs, providing both theoretical and practical insights for researchers and practitioners in the field.",Generative Adversarial Networks;GANs;Applications;Evaluation metrics;Limitations,IEE
923,Cyber Vaccine for Deepfake Immunity,C. -C. Chang; H. H. Nguyen; J. Yamagishi; I. Echizen,2023,"Deepfakes pose an evolving cybersecurity threat that calls for the development of automated countermeasures. While considerable forensic research has been devoted to the detection and localisation of deepfakes, solutions for �fake-to-real� reversal are yet to be developed. In this study, we introduce the concept of cyber vaccination for conferring immunity to deepfakes. In other words, we aim to impart a self-healing ability to the face-containing media so that the original content can be recovered after manipulation by AI-based deepfake technology. Analogous to biological vaccination which uses injected antigens to induce immunity prior to infection by an actual pathogen, cyber vaccination simulates deepfakes and performs adversarial training to build a defensive immune system. Aiming to build up attack-agnostic immunity with limited computational resources, we propose simulating various deepfakes with one single overpowering attack: face masking. The proposed immune system consists of a vaccinator for inducing immunity and a neutraliser for recovering facial content. Experimental evaluations demonstrate effective immunity to face replacement and various types of corruption.",Cybersecurity;deepfakes;forensics;immunity;vaccine,IEE
924,On the Defense of Spoofing Countermeasures Against Adversarial Attacks,L. Nguyen-Vu; T. -P. Doan; M. Bui; K. Hong; S. Jung,2023,"Advances in speech synthesis have exposed the vulnerability of spoofing countermeasure (CM) systems. Adversarial attacks exacerbate this problem, mainly due to the reliance of most CM models on deep neural networks. While research on adversarial attacks in anti-spoofing systems has received considerable attention, there is a relative scarcity of studies focused on developing effective defense techniques. In this study, we propose a defense strategy against such attacks by augmenting training data with frequency band-pass filtering and denoising. Our approach aims to limit the impact of perturbation, thereby reducing the susceptibility to adversarial samples. Furthermore, our findings reveal that the use of Max-Feature-Map (MFM) and frequency band-pass filtering provides additional benefits in suppressing different noise types. To empirically validate this hypothesis, we conduct tests on different CM models using adversarial samples derived from the ASVspoof challenge and other well-known datasets. The evaluation results show that such defense mechanisms can potentially enhance the performance of spoofing countermeasure systems.",Automatic speaker verification;adversarial attack;spoofing countermeasure;psychoacoustics,IEE
925,Detecting Forged Facial Videos Using Convolutional Neural Networks,N. Sambhu; S. Canavan,2023,"In this paper, we propose to detect forged videos, of faces, in online videos. To facilitate this detection, we propose to use smaller (fewer parameters to learn) convolutional neural networks (CNN), for a data-driven approach to forged video detection. To validate our approach, we investigate the Face-Forensics public dataset detailing both frame-based and video-based results. The proposed method is shown to outperform current state of the art. We also perform an ablation study, analyzing the impact of batch size, number of filters, and number of network layers on the accuracy of detecting forged videos.",deepfake;convolutional neural network;videos;deep learning,IEE
926,Deciphering Disinformation: Strategies for Identifying and Addressing Fake News in Today's Information Landscape,O. Osadola; E. Amuta; C. Somefun; T. Somefun; S. Ongbali; J. Mene,2024,"The proliferation of fake news poses a severe threat to information integrity and societal stability, particularly evident in Nigeria's political landscape. Addressing this multifaceted challenge requires a comprehensive approach. Leveraging advanced technological solutions, fostering media literacy through educational initiatives, and promoting collaboration between digital platforms, fact-checkers, and governments are crucial. Transparency in algorithms, accountability for content producers, and international cooperation can enhance countermeasures. Targeted regulations for deepfake content and continuous research efforts are essential. By combining these strategies, societies can mitigate the impact of fake news and cultivate a more informed and resilient public discourse.",Fake news;Detection;Technological solutions;Media literacy;Regulatory frameworks,IEE
927,MetaCloak: Preventing Unauthorized Subject-Driven Text-to-Image Diffusion-Based Synthesis via Meta-Learning,Y. Liu; C. Fan; Y. Dai; X. Chen; P. Zhou; L. Sun,2024,"Text-to-image diffusion models allow seamless generation of personalized images from scant reference photos. Yet, these tools, in the wrong hands, can fabricate misleading or harmful content, endangering individuals. To address this problem, existing poisoning-based approaches perturb user images in an imperceptible way to render them �unlearnable� from malicious uses. We identify two limitations of these defending approaches: i) sub-optimal due to the hand-crafted heuristics for solving the intractable bilevel optimization and ii) lack of robustness against simple data transformations like Gaussian filtering. To solve these challenges, we propose MetaCloak, which solves the bi-level poisoning problem with a meta-learning framework with an additional transformation sampling process to craft transferable and robust perturbation. Specifically, we employ a pool of surrogate diffusion models to craft transferable and model-agnostic perturbation. Furthermore, by incorporating an additional transformation process, we design a simple denoising-error maximization loss that is sufficient for causing transformation-robust semantic distortion and degradation in a personalized generation. Extensive experiments on the VGGFace2 and CelebA-HQ datasets show that MetaCloak outperforms existing approaches. Notably, MetaCloak can successfully fool online training services like Replicate, in a black-box manner, demonstrating the effectiveness of Meta Cloak in real-world scenarios. Our code is available at https://github.com/liuyixin-louis/MetaCloak.",DeepFake Defense;Unlearnable Example;Adversarial ML;Unauthorized Exploitation;Imperceptible Perturbation,IEE
928,InsetGAN for Full-Body Image Generation,A. Fr�hst�ck; K. K. Singh; E. Shechtman; N. J. Mitra; P. Wonka; J. Lu,2022,"While GANs can produce photo-realistic images in ideal conditions for certain domains, the generation of full-body human images remains difficult due to the diversity of identities, hairstyles, clothing, and the variance in pose. In-stead of modeling this complex domain with a single GAN, we propose a novel method to combine multiple pretrained GANs, where one GAN generates a global canvas (e.g., human body) and a set of specialized GANs, or insets, focus on different parts (e.g., faces, shoes) that can be seamlessly inserted onto the global canvas. We model the problem as jointly exploring the respective latent spaces such that the generated images can be combined, by inserting the parts from the specialized generators onto the global canvas, without introducing seams. We demonstrate the setup by combining a full body GAN with a dedicated high-quality face GAN to produce plausible-looking humans. We evalu-ate our results with quantitative metrics and user studies.",Image and video synthesis and generation; Machine learning,IEE
929,Video Manipulations Beyond Faces: A Dataset with Human-Machine Analysis,T. Mittal; R. Sinha; V. Swaminathan; J. Collomosse; D. Manocha,2023,"As tools for content editing mature, and artificial intelligence (AI) based algorithms for synthesizing media grow, the presence of manipulated content across online media is increasing. This phenomenon causes the spread of misinformation, creating a greater need to distinguish between �real� and �manipulated� content. To this end, we present Videosham, a dataset consisting of 826 videos (413 real and 413 manipulated). Many of the existing deepfake datasets focus exclusively on two types of facial manipulations-swapping with a different subject's face or altering the existing face. Videosham, on the other hand, contains more diverse, context-rich, and human-centric, high-resolution videos manipulated using a combination of 6 different spatial and temporal attacks. Our analysis shows that state-of-the-art manipulation detection algorithms only work for a few specific attacks and do not scale well on Videosham. We performed a user study on Amazon Mechanical Turk with 1200 participants to understand if they can differentiate between the real and manipulated videos in Videosham. Finally, we dig deeper into the strengths and weaknesses of performances by humans and SOTA-algorithms to identify gaps that need to be filled with better AI algorithms. We present the dataset here11VideoSham dataset link..",,IEE
930,Tamper-Proof Evidence via Blockchain for Autonomous Vehicle Accident Monitoring,M. Parlak; N. F. Altunel; U. A. Akka?; E. T. Arici,2022,"In case of an accident between two autonomous vehicles equipped with emerging technologies, how do we apportion liability among the various players? A special liability regime has not even yet been established for damages that may arise due to the accidents of autonomous vehicles. Would the immutable, time-stamped sensor records of vehicles on distributed ledger help define the intertwined relations of liability subjects right through the accident? What if the synthetic media created through deepfake gets involved in the insurance claims? While integrating AI-powered anomaly or deepfake detection into automated insurance claims processing helps to prevent insurance fraud, it is only a matter of time before deepfake becomes nearly undetectable even to elaborate forensic tools. This paper proposes a blockchain-based insurtech decentralized application to check the authenticity and provenance of the accident footage and also to decentralize the loss-adjusting process through a hybrid of decentralized and centralized databases using smart contracts.",Blockchain;smart contracts;deepfake;deep learning;autonomous vehicles;insurance;insurtech;liability,IEE
931,Deep Fakes Image Animation Using Generative Adversarial Networks,A. K. Manjula; R. Thirukkumaran; K. H. Raj; A. Athappan; R. P. Reddy,2022,"The idea of picture activity is for the most part moving the pictures at a specific speed so the unaided eye can't detect the distinction. We intend to do the investigation so that for certain adjustments to the current structure that is the deepfake that does the examination without earlier information on the movement target. To do this, We will be training a dataset on a bunch of pictures and recordings for objects of a similar class (e.g., face, body, road view). As of late, a few uses of neural organizations (CNNs) have been applied to the genuine human head. The informational index can be prepared on many pictures and recordings to make practical talking heads. You can energize the first picture of an individual into an objective individual posture (driving video) while safeguarding the individual's appearance and body. In the mean time, in any case, frameworks are being fostered that can recognize recordings and activities produced by Deep-Fakes. Since this is a significant security issue. We energized pictures to create talking heads and tried different things with picture age Using the Deep-Fakes age's contingent generative threatening organization, the outcomes were reasonable. Likewise executed Deep-Fake Detector XceptionNet (a Deep Learning Algorithm that Detects Face Swaps in Videos) with slight adjustments to arrive at 95� exactness when identifying Deep-Fake. At last, you can without much of a stretch idiot Deepfake identifiers by executing an as of late acquainted method with quit making Deep-Fakes. XceptionNet had the option to accomplish a precision of under 30 in recognizing the Deep-Fake age when maddened.",DeepFakes;ImageAnimation;GANS;Generative Adversarial Networks;cGanz;Co-lab;video;MonkeyNET,IEE
932,Combating Deepfakes: Multi-LSTM and Blockchain as Proof of Authenticity for Digital Media,C. C. Ki Chan; V. Kumar; S. Delaney; M. Gochoo,2020,"Malicious use of deep learning algorithms has allowed the proliferation of high realism fake digital content such as text, images, and videos, to exist on the internet as readily available and accessible consumable content. False information provided through algorithmically modified footage, images, audios, and videos (known as deepfakes), coupled with the virality of social networks, may cause major social unrest. The emergence of misinformation from fabricated digital content suggests the necessity for anti-disinformation methods such as deepfake detection algorithms or immutable metadata in order to verify the validity of digital content. Permissioned blockchain, notably Hyperledger Fabric 2.0, coupled with LSTMs for audio/video/descriptive captioning is a step towards providing a feasible tool for combating deepfake media. Original content would require the original artist attestation of untampered data. The smart contract combines a varied multiple LSTM networks into a process that allows for the tracing and tracking of a digital content's historical provenance. The result is a theoretical framework that enables proof of authenticity (PoA) for digital media using a decentralized blockchain using multiple LSTMs as a deep encoder for creating unique discriminative features; which is then compressed and hashed into a transaction. Our work assumes we trust the video at the point of reception. Our contribution is a decentralized blockchain framework of deep discriminative digital media to combat deepfakes.",artificial intelligence;blockchain;computer vision;deepfake;smart contracts,IEE
933,"A Survey on Recent Advancements in Lightweight Generative Adversarial Networks, their Applications and Datasets",M. S. Alexiou; J. S. Mertoguno,2023,"Generative Adversarial Networks (GANs) have garnered significant research attention owing to their revolutionary generator-vs-discriminator architecture, making them versatile for various domains, including medical, military, and computer vision applications. Nevertheless, their computationally demanding nature during training and inference restricts their widespread adoption on mobile and edge devices. In this study, the latest advancements are explored in lightweight GAN implementations, considering their unique characteristics and diverse applications. The objective is to identify modifications that can enhance the efficiency of GAN-based models without compromising their robustness and accuracy, both for specific use-cases and in a more general context. Additionally, a discussion is presented on the availability of datasets suitable for lightweight GAN training and evaluation, as well as potential research directions for the future.",Lightweight Neural Networks;Generative Adversarial Networks;Towards TinyML,IEE
934,"ENF Based Digital Multimedia Forensics: Survey, Application, Challenges and Future Work",E. Ngharamike; L. -M. Ang; K. P. Seng; M. Wang,2023,"The electric network frequency (ENF) represents the transmission frequency of the electrical grid and fluctuates constantly around 50 Hz or 60 Hz, subject to the region. This constant fluctuation, caused by the continuous mismatch in power demand and supply, makes the ENF a unique signature, which can be utilized for several applications. According to studies, the ENF may be intrinsically implanted in audio recordings captured by digital audio recorders (e.g., microphone-based voice recorder) plugged into the mains supply or are situated close to sources of power and power transmission cable due to electromagnetic field interference originated from power source or acoustic hum and mechanical vibrations emitted by electrically operated devices such as regular household appliances. Recent studies further observed that video recordings made under an illumination source powered by main power can pick up the ENF signal. Following this discovery, several research efforts have been invested towards successful and accurate extraction of the ENF signal, and utilizing the ENF signal retrieved for several applications, including time stamp verification, audio/video authentication, location of recording estimation, power grid identification, estimation of camera read-out time, and video record synchronization. To the best of our knowledge, there has been no comprehensive survey on ENF-based multimedia forensics. Thus, in this paper, we present a comprehensive survey of studies conducted in this field, identifying several application specifics, current challenges, and future research directions.",Electric network frequency (ENF);ENF detection;ENF estimation;ENF audio and video forensic;ENF applications,IEE
935,Image Vaccinator and Image Tamper Resilient and Lossless Auto-Recovery Using Invertible Neural Network,P. Kalyanasundaram; K. Shanmuga Priya; S. Kavinkumar; G. Gopinath; S. T. Kiruthigaa Bommi,2024,"Aim: The aim of this endeavor attempts to identify tampering, provide lossless recovery, and improve picture data resilience against illegal adjustments. Materials and Methods: The current undertaking engages four distinct groups. Group 1, which includes the Convolutional Neural Network, specializes in learning pattern hierarchies within data, displaying efficiency in task management and Group 2 includes A Generative Adversarial Network c and Group 3 includes Recurrent Neural Networks (RNNs) store internal states to handle successive inputs and Group 4 includes Invertible Neural Network (INNs) provide bidirectional mappings at low additional cost, facilitating both forward and inverse operations. Results: The computed PSNR values demonstrate its dependability in keeping image authenticity online while maintaining high image quality throughout the procedure. PSNR of Slicing attack is 32.35 db. Conclusion: Using adversarial simulation and Invertible Neural Network technology, the Image Immunizer Middleware fortifies social network photos by introducing subtle perturbations and utilizing self-recovery passes for increased security.",Image Immunizer;Vaccinator;Deep Fakes;Detection;Image;Tamper;Invertible Neural Network;Deep Learning;Online Social Networks;Generative Adversarial Network,IEE
936,DFGC-VRA: DeepFake Game Competition on Visual Realism Assessment,B. Peng; X. Sun; C. Wang; W. Wang; J. Dong; Z. Sun; R. Zhang; H. Cong; L. Fu; H. Wang; Y. Zhang; H. Zhang; X. Zhang; B. Liu; H. Ling; L. Dragar; B. Batagelj; P. Peer; V. �truc; X. Zhou; K. Liu; W. Feng; W. Zhang; H. Wang; W. Diao,2023,"This paper presents the summary report on the DeepFake Game Competition on Visual Realism Assessment (DFGC-VRA). Deep-learning based face-swap videos, also known as deepfakes, are becoming more and more realistic and deceiving. The malicious usage of these face-swap videos has caused wide concerns. There is a ongoing deepfake game between its creators and detectors, with the human in the loop. The research community has been focusing on the automatic detection of these fake videos, but the assessment of their visual realism, as perceived by human eyes, is still an unexplored dimension. Visual realism assessment, or VRA, is essential for assessing the potential impact that may be brought by a specific face-swap video, and it is also useful as a quality metric to compare different face-swap methods. This is the third edition of DFGC competitions, which focuses on the new visual realism assessment topic, different from previous ones that compete creators versus detectors. With this competition, we conduct a comprehensive study of the SOTA performance on the new task. We also release our MindSpore codes to further facilitate research in this field (https://github.com/bomb2peng/DFGC-VRA-benckmark).",,IEE
937,Information-Containing Adversarial Perturbation for Combating Facial Manipulation Systems,Y. Zhu; Y. Chen; X. Li; R. Zhang; X. Tian; B. Zheng; Y. Chen,2023,"With the development of deep learning technology, the facial manipulation system has become powerful and easy to use. Such systems can modify the attributes of the given facial images, such as hair color, gender, and age. Malicious applications of such systems pose a serious threat to individuals� privacy and reputation. Existing studies have proposed various approaches to protect images against facial manipulations. Passive defense methods aim to detect whether the face is real or fake, which works for posterior forensics but can not prevent malicious manipulation. Initiative defense methods protect images upfront by injecting adversarial perturbations into images to disrupt facial manipulation systems but can not identify whether the image is fake. To address the limitation of existing methods, we propose a novel two-tier protection method named Information-containing Adversarial Perturbation (IAP), which provides more comprehensive protection for facial images. We use an encoder to map a facial image and its identity message to a cross-model adversarial example which can disrupt multiple facial manipulation systems to achieve initiative protection. Recovering the message in adversarial examples with a decoder serves passive protection, contributing to provenance tracking and fake image detection. We introduce a feature-level correlation measurement that is more suitable to measure the difference between the facial images than the commonly used mean squared error. Moreover, we propose a spectral diffusion method to spread messages to different frequency channels, thereby improving the robustness of the message against facial manipulation. Extensive experimental results demonstrate that our proposed IAP can recover the messages from the adversarial examples with high average accuracy and effectively disrupt the facial manipulation systems.",Adversarial attack;adversarial perturbation;face protection;facial manipulation,IEE
938,Combating Fake News: Stakeholder Interventions and Potential Solutions,A. Gupta; N. Kumar; P. Prabhat; R. Gupta; S. Tanwar; G. Sharma; P. N. Bokoro; R. Sharma,2022,"The fake news �infodemic�, facilitated by social media and mobile message sharing platforms, has progressed from causing a nuisance to seriously impacting law and order through deliberate and large-scale manipulation of public sentiments. There are social, religious, political, and economic dimensions to the fake news phenomenon, providing enough motivation for interested parties to push biased opinions, claims, conspiracies and fraud to many na�ve information consumers. The ease with which fake news can be created and propagated makes it extremely challenging to detect and mitigate. To combat the fake news, the researchers have utilized mechanisms which are largely based on Artificial Intelligence (AI) algorithms and social network analysis. However, no viable solution has yet been deployed at a scale. This paper present a comprehensive survey on combating fake news and evaluates the challenges involved in its detection with the help of existing detection mechanisms and techniques to control its spread. The challenges associated with combating fake news have been addressed based on the various aspects such as psychological, economic, and technical. Furthermore, we consider the fake news combat spectrum to analyze the stakeholder interventions due to the spread of fake news. Finally, various technology-based solutions have been presented for combating fake news and the associated future challenges and opportunities.",Fake News;misinformation;disinformation;infodemic;fake news detection,IEE
939,Watch Those Words: Video Falsification Detection Using Word-Conditioned Facial Motion,S. Agarwal; L. Hu; E. Ng; T. Darrell; H. Li; A. Rohrbach,2023,"In today�s era of digital misinformation, we are increasingly faced with new threats posed by video falsification techniques. Such falsifications range from cheapfakes (e.g., lookalikes or audio dubbing) to deepfakes (e.g., sophisticated AI media synthesis methods), which are becoming perceptually indistinguishable from real videos. To tackle this challenge, we propose a multi-modal semantic forensic approach to discover clues that go beyond detecting discrepancies in visual quality, thereby handling both simpler cheapfakes and visually persuasive deepfakes. In this work, our goal is to verify that the purported person seen in the video is indeed themselves by detecting anomalous facial movements corresponding to the spoken words. We leverage the idea of attribution to learn person-specific biometric patterns that distinguish a given speaker from others. We use interpretable Action Units (AUs) to capture a person�s face and head movement as opposed to deep CNN features, and we are the first to use word-conditioned facial motion analysis. We further demonstrate our method�s effectiveness on a range of fakes not seen in training including those without video manipulation, that were not addressed in prior work.",Applications: Social good;Biometrics;face;gesture;body pose,IEE
940,SecureReID: Privacy-Preserving Anonymization for Person Re-Identification,M. Ye; W. Shen; J. Zhang; Y. Yang; B. Du,2024,"Anonymization methods have gained widespread use in safeguarding privacy. However, conventional anonymization solutions inevitably lead to the loss of semantic information, resulting in limited data utility. Besides, existing deep learning-based anonymization strategies inadvertently alter the identities of pedestrians, rendering them unsuitable for re-identification (Re-ID) tasks. Beyond these limitations, we propose a joint learning reversible anonymization framework that can reversibly generate full-body anonymized images with little performance drop on Re-ID tasks. Despite these advancements, we reveal that the anonymization methods are vulnerable to model attacks, where attackers can utilize the anonymization model and public data to perform recovery and Re-ID tasks on anonymized images. To defend against the potential attack, we introduce the identity-specific encrypt-decrypt (ISED) architecture for enhanced security, where the anonymized images are encrypted using the specific key for each identity. It renders the images computationally inaccessible to attackers while allowing for seamless reversal without loss using the corresponding keys. Extensive experiments demonstrate that the anonymization framework can guarantee Re-ID performance while protecting pedestrian privacy. In addition, we provide both empirical and theoretical evidence to demonstrate the feasibility of model attacks and the effectiveness of our ISED strategy. Code is available at https://github.com/shentt67/SecureReID.",Privacy protection;anonymization;encryption;person re-identification,IEE
941,"The Not Yet Exploited Goldmine of OSINT: Opportunities, Open Challenges and Future Trends",J. Pastor-Galindo; P. Nespoli; F. G�mez M�rmol; G. Mart�nez P�rez,2020,"The amount of data generated by the current interconnected world is immeasurable, and a large part of such data is publicly available, which means that it is accessible by any user, at any time, from anywhere in the Internet. In this respect, Open Source Intelligence (OSINT) is a type of intelligence that actually benefits from that open nature by collecting, processing and correlating points of the whole cyberspace to generate knowledge. In fact, recent advances in technology are causing OSINT to currently evolve at a dizzying rate, providing innovative data-driven and AI-powered applications for politics, economy or society, but also offering new lines of action against cyberthreats and cybercrime. The paper at hand describes the current state of OSINT and makes a comprehensive review of the paradigm, focusing on the services and techniques enhancing the cybersecurity field. On the one hand, we analyze the strong points of this methodology and propose numerous ways to apply it to cybersecurity. On the other hand, we cover the limitations when adopting it. Considering there is a lot left to explore in this ample field, we also enumerate some open challenges to be addressed in the future. Additionally, we study the role of OSINT in the public sphere of governments, which constitute an ideal landscape to exploit open data.",OSINT;cyberintelligence;cybersecurity;cyberdefence;challenges;national security;computer crime;computational intelligence;knowledge acquisition;social network services;software tools;data privacy;Internet,IEE
942,"Limited Data, Unlimited Potential: A Study on ViTs Augmented by Masked Autoencoders",S. Das; T. Jain; D. Reilly; P. Balaji; S. Karmakar; S. Marjit; X. Li; A. Das; M. S. Ryoo,2024,"Vision Transformers (ViTs) have become ubiquitous in computer vision. Despite their success, ViTs lack inductive biases, which can make it difficult to train them with limited data. To address this challenge, prior studies suggest training ViTs with self-supervised learning (SSL) and fine-tuning sequentially. However, we observe that jointly optimizing ViTs for the primary task and a Self-Supervised Auxiliary Task (SSAT) is surprisingly beneficial when the amount of training data is limited. We explore the appropriate SSL tasks that can be optimized alongside the primary task, the training schemes for these tasks, and the data scale at which they can be most effective. Our findings reveal that SSAT is a powerful technique that enables ViTs to leverage the unique characteristics of both the self-supervised and primary tasks, achieving better performance than typical ViTs pre-training with SSL and fine-tuning sequentially. Our experiments, conducted on 10 datasets, demonstrate that SSAT significantly improves ViT performance while reducing carbon footprint. We also confirm the effectiveness of SSAT in the video domain for deepfake detection, showcasing its generalizability. Our code is available at https://github.com/dominickrei/Limited-data-vits.",Algorithms;Video recognition and understanding;Algorithms;Machine learning architectures;formulations;and algorithms,IEE
943,Defending Low-Bandwidth Talking Head Videoconferencing Systems From Real-Time Puppeteering Attacks,D. S. Vahdati; T. Duc Nguyen; M. C. Stamm,2023,"Talking head videos have gained significant attention in recent years due to advances in AI that allow for the synthesis of realistic videos from only a single image of the speaker. Recently, researchers have proposed low bandwidth talking head video systems for use in applications such as videoconferencing and video calls. However, these systems are vulnerable to puppeteering attacks, where an attacker can control a synthetic version of a different target speaker in real-time. This can be potentially used spread misinformation or committing fraud. Because the receiver always creates a synthetic video of the speaker, deepfake detectors cannot protect against these attacks. As a result, there are currently no defenses against puppeteering in these systems. In this paper, we propose a new defense against puppeteering attacks in low-bandwidth talking head video systems by utilizing the biometric information inherent in the facial expression and pose data transmitted to the receiver. Our proposed system requires no modifications to the video transmission system and operates with low computational cost. We present experimental evidence to demonstrate the effectiveness of our proposed defense and provide a new dataset for benchmarking defenses against puppeteering attacks.",,IEE
944,PulseEdit: Editing Physiological Signals in Facial Videos for Privacy Protection,M. Chen; X. Liao; M. Wu,2022,"Recent studies have shown that physiological signals such as heart beat and breathing can be remotely captured from human faces using a regular color camera under ambient light. This technology, referred to as remote photoplethysmography (rPPG), can be used to collect the physiological status of users who are in front of a camera, which may raise privacy concerns. To avoid the privacy abuse of the rPPG technology, this paper develops PulseEdit, a novel and efficient algorithm that can edit the physiological signals in facial videos without affecting visual appearance and thus protect the user�s physiological signal from disclosure. PulseEdit can either remove the trace of the physiological signal in a video or transform the video to contain a target physiological signal chosen by a user. Experimental results show that PulseEdit can effectively edit physiological signals in facial videos and prevent heart rate measurement based on rPPG. It is possible to utilize PulseEdit in adversarial scenarios against rPPG-based visual security algorithms. We present analyses on the performance of PulseEdit against rPPG-based liveness detection and rPPG-based deepfake detection, and demonstrate its ability to circumvent these visual security algorithms and its important role in supporting the design of attack-resilient systems.",Remote photoplethysmography (rPPG);privacy protection;visual security;video editing;video forgery,IEE
945,Deep fake Detection using deep learning techniques: A Literature Review,A. Mary; A. Edison,2023,"Deep learning is a sophisticated and adaptable technique that has found widespread use in fields such as natural language processing, machine learning, and computer vision. It is one of the most recent deep learning-powered applications to emerge. Deep fakes are altered, high-quality, realistic videos/images that have lately gained popularity. Many incredible uses of this technology are being investigated. Malicious uses of fake videos, such as fake news, celebrity pornographic videos, financial scams, and revenge porn are currently on the rise in the digital world. As a result, celebrities, politicians, and other well-known persons are particularly vulnerable to the Deep fake detection challenge. Numerous research has been undertaken in recent years to understand how deep fakes function and many deep learning-based algorithms to detect deep fake videos or pictures have been presented.This study comprehensively evaluates deep fake production and detection technologies based on several deep learning algorithms. In addition, the limits of current approaches and the availability of databases in society will be discussed. A deep fake detection system that is both precise and automatic. Given the ease with which deep fake videos/images may be generated and shared, the lack of an effective deep fake detection system creates a serious problem for the world. However, there have been various attempts to address this issue, and deep learning-related solutions outperform traditional approaches.",Deep Fakes;Deep Learning;Fake Generation;Fake Detection;Machine Learning,IEE
