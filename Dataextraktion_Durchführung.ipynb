{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                                                        619\n",
      "Title       Attention-Guided Supervised Contrastive Learni...\n",
      "Authors     S. Waseem; S. A. Rahman Bin Syed Abu Bakar; B....\n",
      "Year                                                     2024\n",
      "Abstract    Recent advancements in face deepfake detection...\n",
      "Keywords    Deepfake;Generalization;Contrastive learning;A...\n",
      "Database                                                 IEEE\n",
      "Name: 390, dtype: object\n",
      "Attention-Guided Supervised Contrastive Learning for Deepfake Detection\n",
      "\n",
      "            Extract the information from title and abstract following the instructions below:\n",
      "\n",
      "            1. Review the list of questions provided in <review_questions>. Understand what specific information each question seeks.\n",
      "            1. Carefully read the text provided in <title> and <abstract>. Look for information directly related to the review questions.\n",
      "            2. For each review question try to answer the question based on the information found in the title and abstract. Just answer if you are sure that the information and match the context of the question.\n",
      "                - Locate Information: Find relevant information in the title or abstract that answers the question.\n",
      "                - Match Context: Ensure the answer directly aligns with the review question's context. Be vigilant for misleading or unrelated information.\n",
      "                - Provide Explanation: Include a brief explanation that summarizes why the information supports the answer and quote the original text from the title or abstract in the ***explanation*** field.\n",
      "                - If the title and abstract do not provide sufficient information for a question: Leave the answer field empty. In the explanation field, briefly state why the question could not be answered (e.g., \"No relevant information found in the title or abstract\")\n",
      "            3. Set CountAnswered to the number of questions for which answers were provided.\n",
      "            4. Construct a JSON object using the structure in <desired_output> and return it. Note: Is just an example for the structure of the output!\n",
      "            \n",
      "            <title>\n",
      "            Attention-Guided Supervised Contrastive Learning for Deepfake Detection\n",
      "            </title>\n",
      "\n",
      "            <abstract>\n",
      "            Recent advancements in face deepfake detection have shown impressive results. However, prior studies typically used crossentropy loss to approach face manipulation detection as a classification problem. Approaches based on cross-entropy loss prioritize category distinctions over capturing the underlying differences between real and fake faces, which restricts the model's capacity to generalize to unseen datasets. As original image or video can closely resemble the deepfake in terms of appearance, making it challenging to distinguish them, we propose to utilize the differences in the representation space to develop a generalizable detector. In this paper, we present an attention-guided supervised contrastive learning approach for deepfake detection, aiming to leverage differences in the representation space and prioritize disparities between classes rather than focusing solely on categories. By using supervised contrastive learning, the model learns to create a discriminative representation by contrasting between classes, while an attention module directs the model to relevant features for each class and filters out irrelevant features. This method learns features from a wide variety of deepfake images, thus improving the accuracy of deepfake detection in unseen datasets. Experimental results show the effectiveness of our attention-guided supervised contrastive learning deepfake detector on benchmark datasets such as FF++, Celeb-DF, DFD and DFDC-P.\n",
      "            </abstract>\n",
      "            \n",
      "            <review_questions>\n",
      "            - **RQ1**: Which machine learning methods are used for deepfake detection? (e.g. Logistic Regression, Support Vector Machines (SVMs), Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs) etc)\n",
      "            - **RQ2**: Which machine learning methods are recommended (and thus particularly suitable)? (e.g. Logistic Regression, Support Vector Machines (SVMs), Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs) etc)\n",
      "            - **RQ3**: What challenges exist in detecting deepfakes using machine learning approaches? (e.g. outdated or limited datasets, Generalization issues across datasets, Rapid evolution of deepfake techniques, High computational cost of detection models, Difficulty in detecting low-quality or compressed media etc)\n",
      "            - **RQ4**: What are the use cases for deepfake detection? (e.g., COVID-19 masks, medicine, media, politics etc)     \n",
      "            </review_questions> \n",
      "            \n",
      "        <desired_output>\n",
      "            {\n",
      "                \"RQ1\": {\n",
      "                    \"answer\": \"Some Information/Answer for RQ1\"\n",
      "                    \"explanation\": \"brief explanation and original text here\"\n",
      "                },\n",
      "                \"RQ2\": {\n",
      "                    \"answer\": \"\",\n",
      "                    \"explanation\": \"brief explanation here why it was not possible to answer the question\"\n",
      "                },\n",
      "                \"RQ3\": {\n",
      "                    \"answer\": \"\",\n",
      "                    \"explanation\": \"brief explanation here why it was not possible to answer the question\"\n",
      "                },\n",
      "                \"RQ4\": {\n",
      "                    \"answer\": \"Some Information/Answer for RQ4\"\n",
      "                    \"explanation\": \"brief explanation here and original text here\"\n",
      "                }, \n",
      "                \"CountAnswered\": 2\n",
      "                \n",
      "            }\n",
      "            </desired_output>\n",
      "\n",
      "            Just return the json object according to this structure.\n",
      "            Dont use \" in the answer or explanation field.\n",
      "            \n",
      "content {\n",
      "    \"RQ1\": {\n",
      "        \"answer\": \"Attention-guided supervised contrastive learning\",\n",
      "        \"explanation\": \"The paper presents an attention-guided supervised contrastive learning approach for deepfake detection. This is evidenced in the text: ***attention-guided supervised contrastive learning approach for deepfake detection, aiming to leverage differences in the representation space***\"\n",
      "    },\n",
      "    \"RQ2\": {\n",
      "        \"answer\": \"Attention-guided supervised contrastive learning\",\n",
      "        \"explanation\": \"The method is recommended as it shows effectiveness on multiple benchmark datasets. As stated: ***Experimental results show the effectiveness of our attention-guided supervised contrastive learning deepfake detector on benchmark datasets such as FF++, Celeb-DF, DFD and DFDC-P***\"\n",
      "    },\n",
      "    \"RQ3\": {\n",
      "        \"answer\": \"Generalization issues across datasets and difficulty in distinguishing real from fake faces due to appearance similarities\",\n",
      "        \"explanation\": \"The abstract mentions two main challenges: generalization issues and similarity between real and fake faces. As stated: ***original image or video can closely resemble the deepfake in terms of appearance, making it challenging to distinguish them*** and ***restricts the models capacity to generalize to unseen datasets***\"\n",
      "    },\n",
      "    \"RQ4\": {\n",
      "        \"answer\": \"\",\n",
      "        \"explanation\": \"No specific use cases for deepfake detection are mentioned in the title or abstract\"\n",
      "    },\n",
      "    \"CountAnswered\": 3\n",
      "}\n",
      "data {'RQ1': {'answer': 'Attention-guided supervised contrastive learning', 'explanation': 'The paper presents an attention-guided supervised contrastive learning approach for deepfake detection. This is evidenced in the text: ***attention-guided supervised contrastive learning approach for deepfake detection, aiming to leverage differences in the representation space***'}, 'RQ2': {'answer': 'Attention-guided supervised contrastive learning', 'explanation': 'The method is recommended as it shows effectiveness on multiple benchmark datasets. As stated: ***Experimental results show the effectiveness of our attention-guided supervised contrastive learning deepfake detector on benchmark datasets such as FF++, Celeb-DF, DFD and DFDC-P***'}, 'RQ3': {'answer': 'Generalization issues across datasets and difficulty in distinguishing real from fake faces due to appearance similarities', 'explanation': 'The abstract mentions two main challenges: generalization issues and similarity between real and fake faces. As stated: ***original image or video can closely resemble the deepfake in terms of appearance, making it challenging to distinguish them*** and ***restricts the models capacity to generalize to unseen datasets***'}, 'RQ4': {'answer': '', 'explanation': 'No specific use cases for deepfake detection are mentioned in the title or abstract'}, 'CountAnswered': 3}\n",
      "Existing IDs: ['ID', 2, 3, 4, 5, 7, 8, 9, 10, 11, 13, 15, 17, 18, 20, 22, 24, 26, 27, 28, 29, 30, 31, 34, 36, 38, 39, 41, 44, 45, 47, 48, 50, 51, 57, 58, 59, 60, 62, 63, 67, 68, 70, 72, 75, 76, 77, 79, 80, 81, 82, 83, 84, 86, 88, 89, 90, 91, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 109, 110, 112, 114, 115, 116, 117, 118, 119, 120, 122, 123, 124, 126, 127, 128, 130, 134, 135, 137, 138, 141, 142, 145, 146, 147, 148, 149, 152, 153, 155, 156, 157, 158, 159, 163, 164, 165, 166, 168, 169, 171, 172, 173, 174, 176, 177, 180, 181, 182, 183, 184, 190, 191, 192, 193, 194, 195, 196, 197, 199, 200, 201, 202, 206, 207, 208, 212, 213, 214, 215, 216, 217, 219, 221, 222, 224, 225, 226, 229, 230, 231, 233, 234, 236, 237, 238, 239, 240, 241, 242, 243, 244, 247, 248, 249, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 266, 267, 269, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 284, 285, 286, 287, 289, 291, 292, 294, 296, 297, 298, 299, 302, 304, 305, 307, 308, 310, 311, 313, 314, 315, 316, 317, 318, 319, 320, 322, 323, 324, 325, 326, 327, 329, 330, 332, 333, 334, 336, 337, 338, 342, 344, 345, 346, 348, 351, 352, 353, 354, 357, 359, 360, 361, 365, 366, 368, 369, 371, 373, 375, 378, 379, 380, 381, 382, 383, 384, 385, 388, 389, 392, 395, 396, 397, 398, 399, 401, 402, 404, 405, 407, 412, 413, 414, 418, 419, 420, 423, 424, 427, 430, 431, 433, 434, 436, 437, 438, 439, 440, 442, 450, 453, 454, 455, 457, 458, 459, 460, 464, 465, 466, 467, 470, 471, 472, 476, 478, 480, 482, 484, 488, 490, 492, 494, 496, 497, 498, 502, 503, 504, 508, 509, 511, 513, 514, 515, 516, 517, 519, 520, 521, 523, 525, 527, 529, 531, 533, 534, 535, 536, 537, 541, 542, 545, 546, 549, 550, 553, 554, 556, 557, 558, 559, 561, 564, 565, 568, 570, 572, 574, 575, 577, 578, 582, 583, 584, 588, 591, 592, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 608, 609, 611, 613, 615, 616, 617, 619, 620, 625, 627, 628, 629, 630, 634, 635, 636, 637, 638, 639, 645, 646, 647, 649, 651, 654, 655, 661, 662, 663, 664, 665, 668, 674, 676, 677, 680, 684, 687, 688, 690, 691, 692, 696, 697, 698, 702, 706, 707, 710, 712, 716, 717, 718, 719, 721, 722, 726, 727, 733, 734, 735, 736, 737, 738, 739, 740, 743, 744, 745, 746, 748, 749, 752, 754, 756, 757, 758, 762, 764, 766, 767, 768, 771, 773, 775, 776, 777, 782, 786, 787, 789, 794, 797, 799, 800, 801, 803, 805, 809, 810, 814, 816, 817, 820, 823, 825, 827, 832, 834, 837, 838, 841, 842, 844, 847, 849, 852, 857, 861, 862, 868, 873, 878, 880, 885, 888, 891, 892, 893, 898, 900, 905, 911, 912, 917, 918, 925, 929, 931, 939, 942]\n",
      "Replaced ID: 619\n",
      "Counter: 1\n",
      "Error IDs: [619]\n",
      "Counter: 1\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from openpyxl import load_workbook\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# load the API key from the .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "api_key_openai = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# initialize the client\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "# clientOpenAI = OpenAI(api_key=api_key_openai)\n",
    "\n",
    "\n",
    "# Enter the Error IDs here to rerun the API call for these and replace the existing rows in the output Excel file\n",
    "error_ids = []\n",
    "ids = []  # Enter the IDs here\n",
    "\n",
    "# Global variables\n",
    "counter = 0  # To keep track of processed rows\n",
    "\n",
    "# Load the input CSV file and the output Excel file\n",
    "input_path = 'Dataextraktion_Durchführung_Literatur.csv'\n",
    "output_path = 'Dataextraktion_Durchführung.xlsx'  # Specify the output Excel file\n",
    "df = pd.read_csv(input_path, sep=';', encoding='utf-8-sig')  \n",
    "df_output = pd.read_excel(output_path)  \n",
    "\n",
    "\n",
    "# Filter the input DataFrame to only include the rows with error IDs\n",
    "if len(ids) > 0: \n",
    "    df = df[df['ID'].isin(ids)]\n",
    "\n",
    "if len(error_ids) > 0:\n",
    "    df = df[df['ID'].isin(error_ids)]\n",
    "\n",
    "\n",
    "# Start the counter from the max ID in the output file to continue from where it left off\n",
    "# max_id = df_output['ID'].max()\n",
    "# if pd.isna(max_id):\n",
    "#     print(\"No valid IDs in the file.\")\n",
    "# else:\n",
    "#     print(f\"Max ID: {max_id}\")\n",
    "#     df = df[df['ID'] > max_id]\n",
    "\n",
    "\n",
    "def append_to_excel(row, output_path):\n",
    "    global counter\n",
    "    row_df = pd.DataFrame([row])\n",
    "\n",
    "    # Load existing workbook and sheet\n",
    "    workbook = load_workbook(output_path)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    # Check if ID exists in the sheet\n",
    "    existing_ids = [cell.value for cell in sheet['A']]  # Assuming 'A' is the column where IDs are stored\n",
    "    print(f\"Existing IDs: {existing_ids}\")\n",
    "\n",
    "    # If ID exists, replace the row\n",
    "    if row['ID'] in existing_ids and row['ID'] in error_ids:\n",
    "        # Find the row with the matching ID and replace it\n",
    "        row_index = existing_ids.index(row['ID']) + 1  # Excel is 1-indexed\n",
    "        for col_num, value in enumerate(row_df.iloc[0], start=1):\n",
    "            sheet.cell(row=row_index, column=col_num, value=value)\n",
    "            row[\"Error\"] = \"Error\"\n",
    "        print(f\"Replaced ID: {row['ID']}\")\n",
    "    else:\n",
    "        # Otherwise, append the new row\n",
    "        startrow = sheet.max_row + 1\n",
    "        for col_num, value in enumerate(row_df.iloc[0], start=1):\n",
    "            sheet.cell(row=startrow, column=col_num, value=value)\n",
    "        print(f\"Appended ID: {row['ID']}\")\n",
    "\n",
    "    # Save the workbook\n",
    "    workbook.save(output_path)\n",
    "    counter += 1\n",
    "    print(f\"Counter: {counter}\")\n",
    "\n",
    "\n",
    "def extractInformation(row):\n",
    "    print(row)\n",
    "    try:\n",
    "        title = row['Title']\n",
    "        abstract = row['Abstract']\n",
    "\n",
    "        systemprompt = \"You are a reviewer conducting a systematic literature review. Extract information from the title and abstract provided to answer the review questions in the strict context of the content provided.\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "            Extract the information from title and abstract following the instructions below:\n",
    "\n",
    "            1. Review the list of questions provided in <review_questions>. Understand what specific information each question seeks.\n",
    "            1. Carefully read the text provided in <title> and <abstract>. Look for information directly related to the review questions.\n",
    "            2. For each review question try to answer the question based on the information found in the title and abstract. Just answer if you are sure that the information and match the context of the question.\n",
    "                - Locate Information: Find relevant information in the title or abstract that answers the question.\n",
    "                - Match Context: Ensure the answer directly aligns with the review question's context. Be vigilant for misleading or unrelated information.\n",
    "                - Provide Explanation: Include a brief explanation that summarizes why the information supports the answer and quote the original text from the title or abstract in the ***explanation*** field.\n",
    "                - If the title and abstract do not provide sufficient information for a question: Leave the answer field empty. In the explanation field, briefly state why the question could not be answered (e.g., \"No relevant information found in the title or abstract\")\n",
    "            3. Set CountAnswered to the number of questions for which answers were provided.\n",
    "            4. Construct a JSON object using the structure in <desired_output> and return it. Note: Is just an example for the structure of the output!\n",
    "            \n",
    "            <title>\n",
    "            {title}\n",
    "            </title>\n",
    "\n",
    "            <abstract>\n",
    "            {abstract}\n",
    "            </abstract>\n",
    "            \n",
    "            <review_questions>\n",
    "            - **RQ1**: Which machine learning methods are used for deepfake detection? (e.g. Logistic Regression, Support Vector Machines (SVMs), Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs) etc)\n",
    "            - **RQ2**: Which machine learning methods are recommended (and thus particularly suitable)? (e.g. Logistic Regression, Support Vector Machines (SVMs), Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs) etc)\n",
    "            - **RQ3**: What challenges exist in detecting deepfakes using machine learning approaches? (e.g. outdated or limited datasets, Generalization issues across datasets, Rapid evolution of deepfake techniques, High computational cost of detection models, Difficulty in detecting low-quality or compressed media etc)\n",
    "            - **RQ4**: What are the use cases for deepfake detection? (e.g., COVID-19 masks, medicine, media, politics etc)     \n",
    "            </review_questions> \n",
    "            \n",
    "        <desired_output>\n",
    "            {{\n",
    "                \"RQ1\": {{\n",
    "                    \"answer\": \"Some Information/Answer for RQ1\"\n",
    "                    \"explanation\": \"brief explanation and original text here\"\n",
    "                }},\n",
    "                \"RQ2\": {{\n",
    "                    \"answer\": \"\",\n",
    "                    \"explanation\": \"brief explanation here why it was not possible to answer the question\"\n",
    "                }},\n",
    "                \"RQ3\": {{\n",
    "                    \"answer\": \"\",\n",
    "                    \"explanation\": \"brief explanation here why it was not possible to answer the question\"\n",
    "                }},\n",
    "                \"RQ4\": {{\n",
    "                    \"answer\": \"Some Information/Answer for RQ4\"\n",
    "                    \"explanation\": \"brief explanation here and original text here\"\n",
    "                }}, \n",
    "                \"CountAnswered\": 2\n",
    "                \n",
    "            }}\n",
    "            </desired_output>\n",
    "\n",
    "            Just return the json object according to this structure.\n",
    "            Dont use \" in the answer or explanation field.\n",
    "            \"\"\"\n",
    "        \n",
    "        # API-Aufruf Claude\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-5-sonnet-20241022\",\n",
    "            max_tokens=2048,\n",
    "            system=systemprompt,\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        test_reponse = response\n",
    "\n",
    "\n",
    "        # API-Aufruf ChatGPT\n",
    "        # response = clientOpenAI.chat.completions.create(\n",
    "        # model=\"gpt-4o-mini\",\n",
    "        # temperature=0,\n",
    "        #  messages=[\n",
    "        #         {\"role\": \"system\", \"content\": systemprompt},\n",
    "        #         {\"role\": \"user\", \"content\": prompt}\n",
    "        #     ])\n",
    "\n",
    "        # get the content of the response\n",
    "        \n",
    "        # Claude - Response\n",
    "        content = response.content[0].text\n",
    "\n",
    "        # Open AI - Response\n",
    "        # content = response.choices[0].message.content\n",
    "\n",
    "        data = json.loads(content)\n",
    "        # extract the relevant information\n",
    "    \n",
    "        # add the relevant information to the row\n",
    "        row[\"CountAnswered\"] = data[\"CountAnswered\"]\n",
    "\n",
    "        row[\"RQ1\"] = data[\"RQ1\"].get(\"answer\", None)\n",
    "        row[\"RQ2\"] = data[\"RQ2\"].get(\"answer\", None)\n",
    "        row[\"RQ3\"] = data[\"RQ3\"].get(\"answer\", None)\n",
    "        row[\"RQ4\"] = data[\"RQ4\"].get(\"answer\", None)\n",
    "\n",
    "        row[\"RQ1_Explaination\"] = data[\"RQ1\"].get(\"explanation\", None)\n",
    "        row[\"RQ2_Explaination\"] = data[\"RQ2\"].get(\"explanation\", None)\n",
    "        row[\"RQ3_Explaination\"] = data[\"RQ3\"].get(\"explanation\", None)\n",
    "        row[\"RQ4_Explaination\"] = data[\"RQ4\"].get(\"explanation\", None)\n",
    "\n",
    "\n",
    "        # Claude API - Usage\n",
    "        row[\"input_tokens\"] = response.usage.input_tokens\n",
    "        row[\"output_tokens\"] = response.usage.output_tokens\n",
    "\n",
    "        # OpenAI - Usage\n",
    "        # row[\"input_tokens\"] = response.usage.completion_tokens\n",
    "        # row[\"output_tokens\"] = response.usage.completion_tokens\n",
    "\n",
    "    except Exception as e:\n",
    "        # falls ein Fehler auftritt, füge die ID zur error_ids-Liste hinzu\n",
    "        print(f\"Error bei ID: {row['ID']} : {e}\")\n",
    "        # add the ID to the error_ids list\n",
    "        error_ids.append(row['ID'])\n",
    "        row[\"RQ1\"] = None\n",
    "        row[\"RQ2\"] = None\n",
    "        row[\"RQ3\"] = None\n",
    "        row[\"RQ4\"] = None\n",
    "        row[\"CountAnswered\"] = None\n",
    "        row[\"input_tokens\"] = None\n",
    "        row[\"output_tokens\"] = None\n",
    "\n",
    "    test_row = row\n",
    "\n",
    "    append_to_excel(row, output_path)\n",
    "    return row\n",
    "\n",
    "# apply the function to the DataFrame\n",
    "df = df.apply(extractInformation, axis=1)\n",
    "print(f\"Error IDs: {error_ids}\")\n",
    "print(f\"Counter: {counter}\")\n",
    "print(\"Done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[81, 81]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
