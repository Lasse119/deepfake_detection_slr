ID;Title;Abstract;Database;Manual CountAnswered
9;IoT based application designing of Deep Fake Test for Face animation;"Development of Deep Learning models of Internet of Things (IoT) enclosures with limited resources are difficult because Both Quality of Results are difficult to achieve&nbsp;- QoR as follows two models, DNN Model, and Inference Accuracy and Quality of Services such as power consumption, throughput, and latency. Currently, the development of DNN models is often separated from deploying them to IoT devices, which leads to the most effective solution. If there are many records that represent objects of substantially the same class (face, human body, etc.), you can apply frames to each object of this class. To achieve this, use an independent representation to distinguish between appearance and progress data. Deep fake detection is achieved by using a novel, lightweight Deep Learning method on the IoT platform that is memory-efficient and lightweight.&nbsp;It is carried out in two different stages. The first phase of the deep fake test aims to implement a method of extracting images from a video and using them in conjunction with a Deep Neural Network to implement a test for face animation.&nbsp;It has been reported that the impact of the background elimination has been reported before the background subtraction. Here the Trans GAN model is used for the image classification. In the second phase, the work can be recorded and executed by the IOT device that can record live video streams and then detect activity involved in live video. An activity detection prototype based on IoT devices with small processing power is presented. This prototype provides improvements to the system, extending its application in various ways to improve portability, networking, and other equipment capabilities. The proposed architecture will be evaluated against four highly competitive object detection benchmarking tasks CIFAR10, CIFAR100, SVHN, and ImageNet.";ACM;3
24;EfficientNet-based multi-dimensional network optimization for Deepfake video detection;"The rapid development of deep learning techniques, especially generative adversarial networks, has led to the generation of very realistic forged faces. Deepfake technology has brought convenience to society and also produced a large number of undesirable effects. Many detectors have been developed to defend videos generated by Deepfake manipulation techniques. In this paper, we take low overhead and high performance as the task of Deepfake detection and propose a new EfficientNet-B0 combined with ViT Deepfake detection network, which consists of two key components: (1) ConvFFN block, which brings a larger receptive field to the network; (2) Transformer Encoder with Hilo, which separates the high and low frequencies of the attention layer to focus on the global structure. We conducted extensive experiments on the DFDC dataset and the FF++ dataset to demonstrate the stability and practical applicability of the proposed method.";ACM;2
29;One Detector to Rule Them All: Towards a General Deepfake Attack Detection Framework;Deep learning-based video manipulation methods have become widely accessible to the masses. With little to no effort, people can quickly learn how to generate deepfake (DF) videos. While deep learning-based detection methods have been proposed to identify specific types of DFs, their performance suffers for other types of deepfake methods, including real-world deepfakes, on which they are not sufficiently trained. In other words, most of the proposed deep learning-based detection methods lack transferability and generalizability. Beyond detecting a single type of DF from benchmark deepfake datasets, we focus on developing a generalized approach to detect multiple types of DFs, including deepfakes from unknown generation methods such as DeepFake-in-the-Wild (DFW) videos. To better cope with unknown and unseen deepfakes, we introduce a Convolutional LSTM-based Residual Network (CLRNet), which adopts a unique model training strategy and explores spatial as well as the temporal information in a deepfakes. Through extensive experiments, we show that existing defense methods are not ready for real-world deployment. Whereas our defense method (CLRNet) achieves far better generalization when detecting various benchmark deepfake methods (97.57% on average). Furthermore, we evaluate our approach with a high-quality DeepFake-in-the-Wild dataset, collected from the Internet containing numerous videos and having more than 150,000 frames. Our CLRNet model demonstrated that it generalizes well against high-quality DFW videos by achieving 93.86% detection accuracy, outperforming existing state-of-the-art defense methods by a considerable margin.;ACM;3
67;The Analysis of Neural Network Models to Distinguish AI generated faces from Real faces;The rise of Artificial Intelligence (AI)-generated faces that are identical to actual ones is both a technological innovation and a major concern. While considering the implications, some of the existing security systems are unable to differentiate between a high-quality deep-fake and an actual intruder's face. For instance, the risks are quite high at an airport security checkpoint, where facial recognition is the first line of security against unauthorized entry. The primary concern here is how trustworthy the computer programs and algorithms will be in recognizing counterfeits among a plethora of actual and artificially generated faces. This necessitates the need to introduce machine learning approaches to differentiate between actual and fraudulent faces, particularly when AI-generated faces are involved. Effective artificial intelligence systems must be adaptive and change quickly in the face of more complex threats rather than simply recognizing them. AI-generated faces are becoming more convincing by the day, increasing the risk of their exploitation. This poses the need to ensure that the technology on which people rely should be robust and trustworthy in critical situations, whether it is a security checkpoint or an e-commerce site. In this perspective, this study has attempted to develop and implement Artificial Intelligence-powered solutions to detect the artificial faces while ensuring reliability for critical functions in an age where reality constantly blends with fiction.;ScienceDirect;1
103;Deepfake noise investigation and detection;The fast development of Deepfake has brought huge current and potential future negative impacts to our daily lives. As the circulating popular Deepfake videos have become difficult to be distinguished by human eyes, various Deepfake detection approaches have been attempted using deep learning models. However, even though some existing detection methods have achieved reasonable detection performance with respect to the statistical evaluation metrics, the actual underlying Deepfake forensic traces have been barely discussed. In this study, we investigate the special forensic noise traces within Deepfake image frames and propose a noise-based Deepfake detection model approach using a deep neural network. We train a Siamese noise extractor using a novel face-background strategy to investigate different forensic noise traces of a synthesized face area and an unmodified background area. A similarity matrix module is proposed to analyze the forensic noise trace difference between a cropped face square and a cropped background square from a candidate image frame for the Deepfake detection task. As a result, our proposed model trained on the high-quality Celeb-DF dataset has achieved state-of-the-art performance with 99.15% accuracy and 99.92% AUC score on the in-dataset testing set and 88.95% AUC score on the highly difficult unknown-attack Deepfake video dataset. Furthermore, the visualization of the Deepfake forensic noise traces has shown the explicit distinction between synthesized faces and any unmodified area. We believe that the visualized evidence could provide better proof of Deepfake detection results rather than simply the statistical evaluation numbers.;ScienceDirect;1
146;Facial Action Unit-Based Deepfake Video Detection Using Deep Learning;Deepfake videos are becoming more realistic, making them a menace. As a result of the development of deep learning techniques such as Generative adversarial networks (GAN), Deepfake has become closer to the truth. Widespread use of falsified videos and images on social media requires accurate detection. An identity switch (DeepFake) and an expression swap create facial modifications. This paper can detect deepfakes that are perfectly created. Traditional detection approaches that observe artifacts and pixel irregularities cannot keep up with modern technology. The paper is divided into two stages. In the first stage, the paper extracts facial action units from a person and creates a profile for him. This profile represents the behavior of his facial expressions, which differ from one person to another. This was done by building a deep learning network and training it based on a dataset. The second stage is testing, which involves taking videos, extracting facial action units, and testing them on the network to classify them as fake or real. The network has proven its ability to classify with high accuracy of %95.75 compared to traditional methods.;IEEE;1
149;Security Strengthen and Detection of Deepfake Videos and Images Using Deep Learning Techniques;The identification of fraudulent movies or images created using deep learning algorithms is the subject of this research and attempts an in-depth investigation of Deepfake Detection. Deepfakes are created by manipulating or replacing certain parts of an original video or image using machine learning algorithms, usually concentrating on face features. Deepfake detection's main goal is to precisely recognize and distinguish these altered media from real movies and photos. This study looks at a number of deepfake detection techniques, including forensic methods, machine learning algorithms, and picture analysis. These approaches' efficiency and performance are assessed based on their capacity to accurately identify and categories deep-fakes. The paper also examines the difficulties and restrictions of deepfake detection, such as the development of more complex and convincing deepfakes. Further, prospective uses and future possibilities for deepfake detection research are examined, with an emphasis on improving detection skills and creating effective countermeasures. Overall, this research offers insightful information about cutting-edge methods and developments in Deepfake Detection, giving a greater comprehension of its importance in resolving the issues brought on by manipulated media in the current digital era.;IEEE;1
254;DeepFake Detection Through Key Video Frame Extraction using GAN;The emergence of deepfake videos in recent years has made image falsification a real threat. A deepfake video uses deep learning technology to substitute a person's face, emotion, or speech with the face, emotion, or speech of another person. Finding such deceptive deepfake videos on social media is the first step in preventing them. A robust neural network-based technique to identify false videos is presented in this paper. An important video frame extraction approach is used to speed up the process of finding deep fake videos. A model made up of a convolutional neural network (CNN) and a classifier network consisting of GAN technology is provided. Resnet, Resnext50 and LSTM were passed over in favor of the Confusion Matrix when deciding which structure to pair with the classifier while detecting the fake video. The model is a method for detecting visual artefacts. The subsequent classifier network uses the feature vectors from the CNN module as this is the input to categorize the video whether it is fake or real one. The dataset is considered from DeepFake Detection Challenge to get the best model. The key goal is to get high accuracy without using a lot of data to train the model. In comparison to earlier efforts, the key video frame extraction method dramatically decreases computations by achieving 97.2% accuracy using the Deepfake Detection Challenge dataset.;IEEE;1
259;Beyond Deepfake Images: Detecting AI-Generated Videos;Recent advances in generative AI have led to the development of techniques to generate visually realistic synthetic video. While a number of techniques have been developed to detect AI-generated synthetic images, in this paper we show that synthetic image detectors are unable to detect synthetic videos. We demonstrate that this is because synthetic video generators introduce substantially different traces than those left by image generators. Despite this, we show that synthetic video traces can be learned, and used to perform reliable synthetic video detection or generator source attribution even after H.264 re-compression. Furthermore, we demonstrate that while detecting videos from new generators through zero-shot transferability is challenging, accurate detection of videos from a new generator can be achieved through few-shot learning.;IEEE;0
277;Deep Fake in picture using Convolutional Neural Network;Deepfake is a system that combines fake pictures and videos with deep learning. Deep learning is the source of Deepfake. The unethical practice of creating falsified photographs and movies is now possible because of neoteric advances in the fields of Artificial Intelligence and Machine Learning. Today, it is very easy to create photo simulative images using generative adversarial networks. These fake images and videos are widely available on the internet and social media. It is difficult to tell which of them is real or not. These images are typically taken with the goal of stirring up social disturbance, political turmoil, or distributing false information among the general public. Viewers will easily comprehend these images because they will look to be real. Deepfake is rapidly harming individuals, communities, companies, security, religion, and democracy, according to recent studies. These videos and photographs are of astounding quality, and they have a huge social media reach. It has far-reaching effects that are destructive beyond comprehension. An extensive overview of the different deep-fake methods is provided in this publication. So, the objective of this paper is to identify these fake images using a conventional neural network. In order to address this issue, we train a model for particular datasets, produce deep fakes, and then use that model to try to identify the deep fake. An authentic and false image is required for the training process in order to train the model.;IEEE;2
292;An Efficient Deep Video Model For Deepfake Detection;The use of deep learning technology to manipulate images and videos of people in ways that are difficult to distinguish from the real ones, known as deepfake, has become a matter of national security concern in recent years. As a result, many studies have been carried out to detect deepfake and manipulated media. Among these studies, deep video models based on convolutional neural networks have been the preferred method for detecting deepfake in videos. This study presents a novel deep video model called Sequential-Parallel Networks (SPNet) that provides efficient deepfake detection. The SPNet model consists of a simple yet innovative sequential-parallel block that first extracts spatial and temporal features sequentially, then concatenates them together in parallel. As a result, the presented SPNet possesses comparable spatiotemporal modeling abilities as most state-of-the-art deep video methods but with lower computation complexity and fewer parameters. The efficiency of the presented SPNet is demonstrated on a large-scale deepfake benchmark in terms of high recognition accuracy and low computational cost.;IEEE;2
327;Audio-Visual Deepfake Detection System Using Multimodal Deep Learning;With the rise of deepfake videos in today�s digital landscape, there is a pressing need to develop advanced detection and mitigation technologies. Deepfake videos, which use machine learning algorithms to manipulate and alter audiovisual content, can spread false information, create confusion, and even cause harm. To address this issue, our work leverages Deep Learning technology to process audio-visual data in real-time through a web interface, specifically a browser plugin. Our approach uses a multimodal neural network that is fed extracted audio and visual features from a video for deepfake prediction. The model achieves a maximum validation accuracy of 90 percent and is used to build an API that is responsive, and low-latency. Our end-to-end solution is implemented as a Chrome extension using JavaScript that communicates with the API. With this solution, we aim to contribute to the development of advanced deepfake detection and mitigation technologies that can help prevent the spread of false information and its potential consequences.;IEEE;1
344;Detecting Deepfake Images: A Deep Learning Approach with Streamlit Integration;According to sophisticated machine learning algorithms, deep fake technology can produce incredibly lifelike fake images and videos that may be exploited for fraud, disinformation, and public opinion manipulation. This has raised serious concerns about the technology. In response to this emerging threat, this research project proposes a deep fake detection system utilizing convolutional neural networks (CNNs) to distinguish between authentic and manipulated media. The project begins with the collection and preprocessing of a diverse dataset containing both real and fake images and videos. The dataset is then used to train a CNN model, consisting of multiple convolutional and pooling layers followed by fully connected layers, to learn discriminative features that can differentiate between genuine and manipulated media. Experimental results demonstrate the effectiveness of the proposed deep fake detection system in accurately identifying fake content with high precision, recall, and accuracy. Additionally, the system is capable of processing both individual images and video streams, enabling real-time detection of deep fake content. Overall, this research contributes to the ongoing efforts to combat the proliferation of deep fake technology by providing a robust and reliable solution for detecting manipulated media, thereby safeguarding the integrity of digital content and mitigating the potential negative consequences of deep fake misuse.;IEEE;1
424;Robust Frame-Level Detection for Deepfake Videos With Lightweight Bayesian Inference Weighting;Deepfake threatens the authenticity of the information in artificial intelligence Internet of Things (IoT) systems. Recently, several deepfake detection methods have been proposed in academia and industry for securing the authenticity of visual information in the face of artificial intelligence advances. Frame-level detection methods, a widely employed security method against deepfake, have a small model size and offer real-time responsiveness, despite basing their classification decision only on the information contained within the frame they are evaluating. We propose a new lightweight frame-level detection technique based on Bayesian inference weighting (BIW) to improve the robustness of existing frame-level detection models. Our proposed BIW technique employs the Naive Bayesian algorithm to estimate the reliability of any candidate model�s detection results. Comprehensive experiments were conducted on the attacked data sets by four designed video interference approaches and edge computing platform, showing that BIW enhances the robustness of all the baselines and improves their detection accuracy with a real-time response.;IEEE;2
488;Data Augmentation for Convolutional Neural Network DeepFake Image Detection;We need to develop a technique for better identifying deepfakes because they can distort our perception of reality. This study offers a brand-new forensic technique for spotting falsified facial photos. We made advantage of the Kaggle- provided �real-and - fake- facial-detection� dataset. We are able to distinguish between probable facial alterations based on CNN's design. Thanks to data augmentation approaches, the results exhibit performances that are equivalent to those of previous works. The proposed approach fared better for this binary categorization into fake or real faces than the other cutting-edge studies. Our accuracy is close to 99 percent.;IEEE;1
584;Interactive Two-Stream Network Across Modalities for Deepfake Detection;As face forgery techniques have become more mature, the proliferation of deepfakes may threaten the security of human society. Although existing deepfake detection methods achieve good performance for in-dataset evaluation, it remains to be improved in the generalization ability, where the representation of the imperceptible artifacts plays a significant role. In this paper, we propose an Interactive Two-Stream Network (ITSNet) to explore the discriminant inconsistency representation from the perspective of cross-modality. In particular, the patch-wise Decomposable Discrete Cosine Transform (DDCT) is adopted to extract fine-grained high-frequency clues, and information from different modalities communicates with each other via a designed interaction module. To perceive the temporal inconsistency, we first develop a Short-term Embedding Module (SEM) to refine subtle local inconsistency representation between adjacent frames, and then a Long-term Embedding Module (LEM) is designed to further refine the erratic temporal inconsistency representation from the long-range perspective. Extensive experimental results conducted on three public datasets show that ITSNet outperforms the state-of-the-art methods both in terms of in-dataset and cross-dataset evaluations.;IEEE;1
814;Video Face Manipulation Detection Through Ensemble of CNNs;"In the last few years, several techniques for facial manipulation in videos have been successfully developed and made available to the masses (i.e., FaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in video sequences with incredibly realistic results and a very little effort. Despite the usefulness of these tools in many fields, if used maliciously, they can have a significantly bad impact on society (e.g., fake news spreading, cyber bullying through fake revenge porn). The ability of objectively detecting whether a face has been manipulated in a video sequence is then a task of utmost importance. In this paper, we tackle the problem of face manipulation detection in video sequences targeting modern facial manipulation techniques. In particular, we study the ensembling of different trained Convolutional Neural Network (CNN) models. In the proposed solution, different models are obtained starting from a base network (i.e., EfficientNetB4) making use of two different concepts: (i) attention layers; (ii) siamese training. We show that combining these networks leads to promising face manipulation detection results on two publicly available datasets with more than 119000 videos.";IEEE;1
820;AI-Generated Image Detection With Wasserstein Distance Compression and Dynamic Aggregation;With the rapid advancement of generative models, image detectors for AI-generated content have become an increasingly necessary technology in computer vision, attracting significant attention from researchers. This technology aims to detect whether an image is naturally generated by imaging systems (e.g., digital cameras) or generated by advanced AI techniques. Despite the promising performance achieved by recent fake detection methods, they are typically trained on millions of redundant images with similar characteristics, leading to inefficient training. Furthermore, the performances of existing detectors often deteriorate when the training datasets are imbalanced. To address these challenges, we propose a novel AI-generated image detector based on dynamic aggregation and information compression with the Wasserstein distance. Experimental results show that our proposed method significantly outperforms state-of-the-art models that generalize across different generative models, with an increase of $\mathbf{+ 1. 8 6 \%}$ average accuracy and $\mathbf{+ 0. 1 4 \%}$ average precision, while substantially reducing the training time. On imbalanced datasets, our proposed method leads to a $\mathbf{+ 1 4. 4 6 \%}$ accuracy improvement, clearly demonstrating its robustness on imbalanced datasets.;IEEE;0
898;FakeTransformer: Exposing Face Forgery From Spatial-Temporal Representation Modeled By Facial Pixel Variations;With the rapid development of generation model, AI-based face manipulation technology, which called DeepFakes, has become more and more realistic. This means of face forgery can attack any target, which poses a new threat to personal privacy and property security. Moreover, the misuse of synthetic video shows potential dangers in many areas, such as identity harassment, pornography and news rumors. Inspired by the fact that the spatial coherence and temporal consistency of physiological signal are destroyed in the generated content, we attempt to find inconsistent patterns that can distinguish between real videos and synthetic videos from the variations of facial pixels, which are highly related to physiological information. Our approach first applies Eulerian Video Magnification (EVM) at multiple Gaussian scales to the original video to enlarge the physiological variations caused by the change of facial blood volume, and then transform the original video and magnified videos into a Multi-Scale Eulerian Magnified Spatial-Temporal map (MEMSTmap), which can represent time-varying physiological enhancement sequences on different octaves. Then, these maps are reshaped into frame patches in column units and sent to the vision Transformer to learn the spatio-time descriptors of frame levels. Finally, we sort out the feature embedding and output the probability of judging whether the video is real or fake. We validate our method on the FaceForensics++ and DeepFake Detection datasets. The results show that our model achieves excellent performance in forgery detection, and also show outstanding generalization capability in cross-data domain.;IEEE;2
917;FaceForensics++: Learning to Detect Manipulated Facial Images;The rapid progress in synthetic image generation and manipulation has now come to a point where it raises significant concerns for the implications towards society. At best, this leads to a loss of trust in digital content, but could potentially cause further harm by spreading false information or fake news. This paper examines the realism of state-of-the-art image manipulations, and how difficult it is to detect them, either automatically or by humans. To standardize the evaluation of detection methods, we propose an automated benchmark for facial manipulation detection. In particular, the benchmark is based on Deep-Fakes, Face2Face, FaceSwap and NeuralTextures as prominent representatives for facial manipulations at random compression level and size. The benchmark is publicly available and contains a hidden test set as well as a database of over 1.8 million manipulated images. This dataset is over an order of magnitude larger than comparable, publicly available, forgery datasets. Based on this data, we performed a thorough analysis of data-driven forgery detectors. We show that the use of additional domain-specific knowledge improves forgery detection to unprecedented accuracy, even in the presence of strong compression, and clearly outperforms human observers.;IEEE;1