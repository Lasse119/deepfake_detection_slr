{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anthropic\n",
    "from anthropic import Client\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datei laden\n",
    "file_path = './Dataextraktion_Durchführung.xlsx'\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alle relevanten Felder auslesen\n",
    "data_all_RQ = data.loc[0:524, ['ID', 'Title', 'RQ1', 'RQ2', 'RQ3', 'RQ4']]\n",
    "\n",
    "# ID als Integer ohne Dezimalstellen und RQ1 als String oder NaN einlesen\n",
    "data_all_RQ['ID'] = data_all_RQ['ID'].astype(int)\n",
    "data_all_RQ['Title'] = data_all_RQ['Title'].astype(str)\n",
    "data_all_RQ['RQ1'] = data_all_RQ['RQ1'].astype(str) # NaN wird zu 'nan'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ1, RQ2, RQ3, RQ4 in einzelne DataFrames aufteilen\n",
    "data_RQ1 = data_all_RQ.loc[0:524, ['ID', 'Title', 'RQ1']]\n",
    "data_RQ2 = data_all_RQ.loc[0:524, ['ID', 'Title', 'RQ2']]\n",
    "data_RQ3 = data_all_RQ.loc[0:524, ['ID', 'Title', 'RQ3']]\n",
    "data_RQ4 = data_all_RQ.loc[0:524, ['ID', 'Title', 'RQ4']]\n",
    "\n",
    "# data_ID_RQ1 zu einer Liste umwandeln\n",
    "data_RQ1_list = data_RQ1.values.tolist()\n",
    "data_RQ2_list = data_RQ2.values.tolist()\n",
    "data_RQ3_list = data_RQ3.values.tolist()\n",
    "data_RQ4_list = data_RQ4.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemprompt = \"You are an AI assistant conducting a systematic literature review. Your task is to summarize key insights from all the provided data and associate all sources to them.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt-Vorbereitung für RQ1\n",
    "prompt_RQ1 = f\"\"\"\n",
    "    Extract the information from the 'data_list' containing a list of document IDs with their content to answer to 'review_questions' RQ1. Follow the instructions below!\n",
    "\n",
    "    <review_questions>\n",
    "            - **RQ1**: Which machine learning methods are used for deepfake detection? (e.g. Logistic Regression, Support Vector Machines (SVMs), Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs) etc)  \n",
    "    </review_questions>\n",
    "    \n",
    "    1. Review the data provided in <Data>.\n",
    "    2. Ensure **each item** in the 'data_list' is processed and its content is considered.\n",
    "        - For each document in the list, attempt to extract key findings related to 'review_questions' RQ1.\n",
    "        - If no findings can be extracted from a specific document, include a note explaining the reason.\n",
    "    3. Aggregate all insights related to 'RQ1' into distinct bullet points. For each finding:\n",
    "        - Summarize the insight concisely.\n",
    "        - Include a list of all IDs that contributed to that insight for traceability.\n",
    "    4. Construct a structured JSON object using the format in <desired_output> to represent the findings.\n",
    "\n",
    "    <Data>\n",
    "    {data_RQ1_list}\n",
    "    </Data>\n",
    "\n",
    "    <instructions>\n",
    "    - Ensure **every document ID in the list is processed** and accounted for, either by extracting insights or noting that no relevant data was found.\n",
    "    - Ensure each key insight in the bullet points is distinct and directly related to RQ1.\n",
    "    - Group IDs under the respective bullet point to show which data contributed to the insight.\n",
    "    - If no insights can be drawn from the provided data, return an empty list for the insights and explain why for each unprocessed ID.\n",
    "    </instructions>\n",
    "\n",
    "    <desired_output>\n",
    "    {{\n",
    "        \"Insights\": [\n",
    "            {{\n",
    "                \"insight\": \"Key finding here\",\n",
    "                \"references\": [\"1\", \"25\", \"341\"]\n",
    "            }},\n",
    "            {{\n",
    "                \"insight\": \"Another key finding here\",\n",
    "                \"references\": [\"433\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"Unprocessed\": [\n",
    "            {{\n",
    "                \"ID\": \"7\",\n",
    "                \"reason\": \"No relevant data found in the document.\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    </desired_output>\n",
    "\n",
    "    Return only the JSON object in the format specified above.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt-Vorbereitung für RQ2\n",
    "prompt_RQ2 = f\"\"\"\n",
    "    Extract the information from the 'data_list' containing a list of document IDs with their content to answer to 'review_questions' RQ2. Follow the instructions below!\n",
    "\n",
    "    <review_questions>\n",
    "            - **RQ2**: Which machine learning methods are recommended (and thus particularly suitable)? (e.g. Logistic Regression, Support Vector Machines (SVMs), Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs) etc)\n",
    "    </review_questions>\n",
    "    \n",
    "    1. Review the data provided in <Data>.\n",
    "    2. Ensure **each item** in the 'data_list' is processed and its content is considered.\n",
    "        - For each document in the list, attempt to extract key findings related to 'review_questions' RQ2.\n",
    "        - If no findings can be extracted from a specific document, include a note explaining the reason.\n",
    "    3. Aggregate all insights related to 'RQ2' into distinct bullet points. For each finding:\n",
    "        - Summarize the insight concisely.\n",
    "        - Include a list of all IDs that contributed to that insight for traceability.\n",
    "    4. Construct a structured JSON object using the format in <desired_output> to represent the findings.\n",
    "\n",
    "    <Data>\n",
    "    {data_RQ2_list}\n",
    "    </Data>\n",
    "\n",
    "    <instructions>\n",
    "    - Ensure **every document ID in the list is processed** and accounted for, either by extracting insights or noting that no relevant data was found.\n",
    "    - Ensure each key insight in the bullet points is distinct and directly related to RQ2.\n",
    "    - Group IDs under the respective bullet point to show which data contributed to the insight.\n",
    "    - If no insights can be drawn from the provided data, return an empty list for the insights and explain why for each unprocessed ID.\n",
    "    </instructions>\n",
    "\n",
    "    <desired_output>\n",
    "    {{\n",
    "        \"Insights\": [\n",
    "            {{\n",
    "                \"insight\": \"Key finding here\",\n",
    "                \"references\": [\"1\", \"25\", \"341\"]\n",
    "            }},\n",
    "            {{\n",
    "                \"insight\": \"Another key finding here\",\n",
    "                \"references\": [\"433\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"Unprocessed\": [\n",
    "            {{\n",
    "                \"ID\": \"7\",\n",
    "                \"reason\": \"No relevant data found in the document.\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    </desired_output>\n",
    "\n",
    "    Return only the JSON object in the format specified above.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt-Vorbereitung für RQ3\n",
    "prompt_RQ3 = f\"\"\"\n",
    "    Extract the information from the 'data_list' containing a list of document IDs with their content to answer to 'review_questions' RQ3. Follow the instructions below!\n",
    "\n",
    "    <review_questions>\n",
    "            - **RQ3**: What challenges exist in detecting deepfakes using machine learning approaches? (e.g. outdated or limited datasets, Generalization issues across datasets, Rapid evolution of deepfake techniques, High computational cost of detection models, Difficulty in detecting low-quality or compressed media etc)\n",
    "    </review_questions>\n",
    "    \n",
    "    1. Review the data provided in <Data>.\n",
    "    2. Ensure **each item** in the 'data_list' is processed and its content is considered.\n",
    "        - For each document in the list, attempt to extract key findings related to 'review_questions' RQ3.\n",
    "        - If no findings can be extracted from a specific document, include a note explaining the reason.\n",
    "    3. Aggregate all insights related to 'RQ3' into distinct bullet points. For each finding:\n",
    "        - Summarize the insight concisely.\n",
    "        - Include a list of all IDs that contributed to that insight for traceability.\n",
    "    4. Construct a structured JSON object using the format in <desired_output> to represent the findings.\n",
    "\n",
    "    <Data>\n",
    "    {data_RQ3_list}\n",
    "    </Data>\n",
    "\n",
    "    <instructions>\n",
    "    - Ensure **every document ID in the list is processed** and accounted for, either by extracting insights or noting that no relevant data was found.\n",
    "    - Ensure each key insight in the bullet points is distinct and directly related to RQ3.\n",
    "    - Group IDs under the respective bullet point to show which data contributed to the insight.\n",
    "    - If no insights can be drawn from the provided data, return an empty list for the insights and explain why for each unprocessed ID.\n",
    "    </instructions>\n",
    "\n",
    "    <desired_output>\n",
    "    {{\n",
    "        \"Insights\": [\n",
    "            {{\n",
    "                \"insight\": \"Key finding here\",\n",
    "                \"references\": [\"1\", \"25\", \"341\"]\n",
    "            }},\n",
    "            {{\n",
    "                \"insight\": \"Another key finding here\",\n",
    "                \"references\": [\"433\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"Unprocessed\": [\n",
    "            {{\n",
    "                \"ID\": \"7\",\n",
    "                \"reason\": \"No relevant data found in the document.\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    </desired_output>\n",
    "\n",
    "    Return only the JSON object in the format specified above.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt-Vorbereitung für RQ4\n",
    "prompt_RQ4 = f\"\"\"\n",
    "    Extract the information from the 'data_list' containing a list of document IDs with their content to answer to 'review_questions' RQ4. Follow the instructions below!\n",
    "\n",
    "    <review_questions>\n",
    "            - **RQ4**: What are the use cases for deepfake detection? (e.g., COVID-19 masks, medicine, media, politics etc)  \n",
    "    </review_questions>\n",
    "    \n",
    "    1. Review the data provided in <Data>.\n",
    "    2. Ensure **each item** in the 'data_list' is processed and its content is considered.\n",
    "        - For each document in the list, attempt to extract key findings related to 'review_questions' RQ4.\n",
    "        - If no findings can be extracted from a specific document, include a note explaining the reason.\n",
    "    3. Aggregate all insights related to 'RQ4' into distinct bullet points. For each finding:\n",
    "        - Summarize the insight concisely.\n",
    "        - Include a list of all IDs that contributed to that insight for traceability.\n",
    "    4. Construct a structured JSON object using the format in <desired_output> to represent the findings.\n",
    "\n",
    "    <Data>\n",
    "    {data_RQ4_list}\n",
    "    </Data>\n",
    "\n",
    "    <instructions>\n",
    "    - Ensure **every document ID in the list is processed** and accounted for, either by extracting insights or noting that no relevant data was found.\n",
    "    - Ensure each key insight in the bullet points is distinct and directly related to RQ4.\n",
    "    - Group IDs under the respective bullet point to show which data contributed to the insight.\n",
    "    - If no insights can be drawn from the provided data, return an empty list for the insights and explain why for each unprocessed ID.\n",
    "    </instructions>\n",
    "\n",
    "    <desired_output>\n",
    "    {{\n",
    "        \"Insights\": [\n",
    "            {{\n",
    "                \"insight\": \"Key finding here\",\n",
    "                \"references\": [\"1\", \"25\", \"341\"]\n",
    "            }},\n",
    "            {{\n",
    "                \"insight\": \"Another key finding here\",\n",
    "                \"references\": [\"433\"]\n",
    "            }}\n",
    "        ],\n",
    "        \"Unprocessed\": [\n",
    "            {{\n",
    "                \"ID\": \"7\",\n",
    "                \"reason\": \"No relevant data found in the document.\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "    </desired_output>\n",
    "\n",
    "    Return only the JSON object in the format specified above.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude AI API-Aufruf\n",
    "client = Client(api_key=\"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\")  # Ersetze durch deinen Claude API-Schlüssel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitung abgeschlossen und Excel-Datei heruntergeladen.\n"
     ]
    }
   ],
   "source": [
    "# Abfrage für RQ1\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=2048,\n",
    "    system=systemprompt,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_RQ1}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON-Output parsen\n",
    "response_data = response.content[0].text\n",
    "json_output = json.loads(response_data)\n",
    "\n",
    "# JSON-Daten in DataFrame umwandeln\n",
    "insights = json_output.get(\"Insights\", [])\n",
    "output_data = []\n",
    "\n",
    "for entry in insights:\n",
    "    output_data.append({\n",
    "        \"Insight\": entry.get(\"insight\", \"\"),\n",
    "        \"References\": \", \".join(entry.get(\"references\", []))\n",
    "    })\n",
    "\n",
    "output_df = pd.DataFrame(output_data)\n",
    "\n",
    "# DataFrame als Excel speichern\n",
    "output_excel_path = \"./Output_RQ1.xlsx\"\n",
    "output_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(\"Verarbeitung abgeschlossen und Excel-Datei heruntergeladen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitung abgeschlossen und Excel-Datei heruntergeladen.\n"
     ]
    }
   ],
   "source": [
    "# Abfrage für RQ2\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=2048,\n",
    "    system=systemprompt,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_RQ2}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON-Output parsen\n",
    "response_data = response.content[0].text\n",
    "json_output = json.loads(response_data)\n",
    "\n",
    "# JSON-Daten in DataFrame umwandeln\n",
    "insights = json_output.get(\"Insights\", [])\n",
    "output_data = []\n",
    "\n",
    "for entry in insights:\n",
    "    output_data.append({\n",
    "        \"Insight\": entry.get(\"insight\", \"\"),\n",
    "        \"References\": \", \".join(entry.get(\"references\", []))\n",
    "    })\n",
    "\n",
    "output_df = pd.DataFrame(output_data)\n",
    "\n",
    "# DataFrame als Excel speichern\n",
    "output_excel_path = \"./Output_RQ2.xlsx\"\n",
    "output_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(\"Verarbeitung abgeschlossen und Excel-Datei heruntergeladen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitung abgeschlossen und Excel-Datei heruntergeladen.\n"
     ]
    }
   ],
   "source": [
    "# Abfrage für RQ3\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=2048,\n",
    "    system=systemprompt,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_RQ3}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON-Output parsen\n",
    "response_data = response.content[0].text\n",
    "json_output = json.loads(response_data)\n",
    "\n",
    "# JSON-Daten in DataFrame umwandeln\n",
    "insights = json_output.get(\"Insights\", [])\n",
    "output_data = []\n",
    "\n",
    "for entry in insights:\n",
    "    output_data.append({\n",
    "        \"Insight\": entry.get(\"insight\", \"\"),\n",
    "        \"References\": \", \".join(entry.get(\"references\", []))\n",
    "    })\n",
    "\n",
    "output_df = pd.DataFrame(output_data)\n",
    "\n",
    "# DataFrame als Excel speichern\n",
    "output_excel_path = \"./Output_RQ3.xlsx\"\n",
    "output_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(\"Verarbeitung abgeschlossen und Excel-Datei heruntergeladen.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verarbeitung abgeschlossen und Excel-Datei heruntergeladen.\n"
     ]
    }
   ],
   "source": [
    "# Abfrage für RQ4\n",
    "response = client.messages.create(\n",
    "    model=\"claude-3-5-sonnet-20241022\",\n",
    "    max_tokens=2048,\n",
    "    system=systemprompt,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_RQ4}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON-Output parsen\n",
    "response_data = response.content[0].text\n",
    "json_output = json.loads(response_data)\n",
    "\n",
    "# JSON-Daten in DataFrame umwandeln\n",
    "insights = json_output.get(\"Insights\", [])\n",
    "output_data = []\n",
    "\n",
    "for entry in insights:\n",
    "    output_data.append({\n",
    "        \"Insight\": entry.get(\"insight\", \"\"),\n",
    "        \"References\": \", \".join(entry.get(\"references\", []))\n",
    "    })\n",
    "\n",
    "output_df = pd.DataFrame(output_data)\n",
    "\n",
    "# DataFrame als Excel speichern\n",
    "output_excel_path = \"./Output_RQ4.xlsx\"\n",
    "output_df.to_excel(output_excel_path, index=False)\n",
    "\n",
    "print(\"Verarbeitung abgeschlossen und Excel-Datei heruntergeladen.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
